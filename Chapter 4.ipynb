{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "objective-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "favorite-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  2 * np.random.rand(100,1)\n",
    "y =  4 + 3 * x + np.random.randn(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "magnetic-forward",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfUElEQVR4nO3df3Ac5XkH8O+js0C2JRsjg+KKgPhlGzCYxGompU0rRXEDNAnt9EdCWwipO05D69LW/RGGadN2ppPMdEoT004ST8ikJAGRkKRNMiQTW0gD08RQOcHYCNtgfgXZyMaALdkIrNPTP27PPp927/b3vu/u9zOj8Wn39u7R3vnZd5/3fXdFVUFERPZpyToAIiIKhwmciMhSTOBERJZiAicishQTOBGRpeal+WZLly7Vnp6ewNsdO3YMCxcujD+gGJgaG+MKztTYTI0LMDe2vMW1ffv2V1T1nDkrVDW1nzVr1mgYw8PDobZLg6mxMa7gTI3N1LhUzY0tb3EBGFWXnMoSChGRpZomcBH5sogcFJFdNcv+VUR2i8gTIvIdETkr0SiJiGgOPy3wrwC4tm7ZFgCrVPUqAHsB3B5zXERE1ETTBK6qDwN4tW7Zj1R1xvl1G4DzEoiNiIgaEPVxLRQR6QHwfVVd5bLuewDuV9WveWy7HsB6AOjq6lozODgYOMipqSm0t7cH3i4NpsbGuIIzNTZT4wLMjS1vcfX3929X1d45K9x6Nut/APQA2OWy/A4A34FzIGj2w1Eo6WFcwZkam6lxqZobW9S4ZmbKuvXJl/VzW/bo1idf1pmZcqZxwWMUSuhx4CJyC4APABhw3oCIyHrl8izWf3U7hnYfPLlsYOW52HzTGpRKZg3cCxWNiFwL4G8BfEhVj8cbEhFRdkb2HDoteQPA0O6DGNlzKKOIvPkZRngfgJ8AWCEiL4nIOgD/AaADwBYReVxEvpBwnEREqXhy/xHX5WMH3JdnqWkJRVVvdFl8dwKxEBFl7opfWOy6/PJl7suzZFZBh4goY30rzsHAynNPWzaw8lz0rZh7KZKspXoxKyKiLJXLsxjZcwhP7j+CK35hMfpWnDOnY7JUasHmm9ZgZM8hjB04gsuXuT/PBEzgRFQIQUaXlEotGLi8CwOXd6UdZiDmHVKIiBJg0+gSv5jAiagQbBpd4hcTOBEVgk2jS/xiAieiQrBpdIlf7MQkokKwaXSJX0zgRFQYtowu8cveQw8RUcExgRMRWYoJnIjIUkzgRESWYgInIrIUEzgRkaWYwImILMUETkRkKU7kIaLC8nN9cJMxgRNRIdl093kvdkRJRBSzPFwfnAmciAopD9cHZwInokLKw/XBmcCJqJDycH1wdmISUSHl4frgTOBEVFi2Xx+cCZyIMmf7eOysMIETUabyMB47K9w7RJSpPIzHzgoTOBFlyoTx2OXyLIbGJrBp614MjU2gXJ5N7b2jYAmFiDKV9Xhsm0s4ZkdHRLmX9Xhsm0s4bIETUaayHo/dqIRj+vBCJnAiylyW47GzLuFEwRIKERVa1iWcKNgCJ6JCy7qEEwUTOBEVnq1T6pnAiXKEU9KLpWkCF5EvA/gAgIOquspZdjaA+wH0AHgewO+p6mvJhUlEzdg8npnC8fOpfgXAtXXLPglgSFUvBTDk/E5EGYoyntnWmYhZMmGfNW2Bq+rDItJTt/gGAH3O4/8CMALg7+IMjIiCCTuemS334EzZZ6KqzZ9USeDfrymhvK6qZzmPBcBr1d9dtl0PYD0AdHV1rRkcHAwc5NTUFNrb2wNvlwZTY2NcwZkam9+4Jqdn8PzhY3OW93QuREebd1st7HZBYktb0nH52WeT0zN440QZ81tLJ5eFjau/v3+7qvbWL4/ciamqKiKeRwFV3QxgMwD09vZqX19f4PcYGRlBmO3SYGpsjCs4U2PzG5dXq/DWtY1bhZu27sWdO5+es3zj2vOxoW95LLGlLem4Gu2zW99zSd3nMIOBlYux+aY1eOSRh2ONK2wCnxCRZap6QESWATjYdAsiSlTY8cw2z0TMSqN91qgvohRzHGGLNd8F8FHn8UcB/E884RBRFNXxzBsGlmPg8i5f9VibZyJmpdE+S/PyuH6GEd6HSoflUhF5CcCnAHwGwDdEZB2AFwD8XuyREVEqbJ6JmJVG+6zhGc3B/bHG4WcUyo0eqwZijYSIMmPDTETTJil57bNq67y+L6JvxTl45OBTscbAmZhEZDxThu35keYZDRM4ERmvUcegiWcNaZ3RmHXoIiJyYcJ9M03EBE5ExuNQR3dM4ERkPA51dMcaOBEZj0Md3TGBE5EVbBjqmLZiH76IiCzGFjhRgZk2OYaCYQInKiibJsckzdYDGRM4UUHZNjkmKTYfyMyOjogSY9rkmKxuURblVnRZYwucqKBMmhyTZSs47K3oTMAWOFFBmTQ5xqsVPPTUROLvnfSBrPbMYnJ6JtYzC7bAiQrKpMkxXq3gT/9gNwYu83djirAaXf41qvozi41XzmD9V7fHdmbBBE5UYKZMjvFqBT93+HjinapJHsiS7ihmCYWIMte34hxc1LnAdV0anaphbkXnR9IdxUzgRJS5UqkFn7xupes6m684mHR9nQmcKAVZDZGzycBlXcZ0qsYl6Y5i1sCp0Gpn4F04UxkhEHeHma0TRdKenWhSp2pc6v+mnhMv4ta18X3uTOBUWEmPEKiyccZjVgcdUzpV41T7N42M7I91/9l7aCOKKK0ZeKbNePQjrn3D0lGy2AKnwkprBp5JMx79imPf2Fo6sgn3IhVWWonVpBmPfnntm7dmZn23ouM+w8miNW/6GQRb4FRYSc7Aq1UqteDzv/8O3DX8DLa/8BrWXLAEG/ovMboV6rZvAOCu4X0YOzDpqxUd5xlOFq15G84gzIiCKAPVEQJ339yLjWsvRU/nwkT+c5bLs/jEvT/DXcP78ONnX8Vdw/vwiXt/ZlxrrlZ132zov3jOOr+t6DjPcLK4YqANVylkAqdCq52B19E2L3TybnSqbUMicFMqtaDVY3/46YCNs3SURUewDZ3PLKEQRdTsVNvmy5VGaUXHOa47i45gGzqf2QIniqhZC9uGROAlais6rmuMZNERbEPnM1vgRBE1a2Gn1VmaBFNmR2YRhyl/eyNM4EQRNWthm5AIokyLN2V2ZBZxlEotJw+01QO1SUmcCZwoIj8t7CyToA3D4Uxl+r5jAieKyIQWdiM2XovFFKbvOyZwohiYUmZwk/QomLSvWpgm00cQMYET5VzSo2BMLjFEZfoIIvv3MBE1lORwuMnpGSsnKfll+lBCtsCJcq62Rr9r/HXMzCpKUqnvRi13vHGi7LrclBJDVKb3b0RK4CLylwD+GIAC2AngY6o6HUdgRBSf6nC4ex97MdZyx/zWEoCZOctNKTHEweT+jdCHERHpBvDnAHpVdRWAEoCPxBUYEcUriWuydLTNM7rEkHdRSyjzAMwXkRMAFgDYHz0kIqoql2cxOT2DTVv3Rh7hkdSICpNLDHknqhp+Y5HbAPwLgDcA/EhV/8DlOesBrAeArq6uNYODg4HfZ2pqCu3t7aHjTJKpsTGu4EyM7YXDxzFfTmDijcrv81tLWDS/FfNbS+hoC9b+mpyewfOHj81Z3tO5MPBrVZm4z4D8xdXf379dVXvrl4dO4CKyBMC3AHwYwOsAvgngAVX9mtc2vb29Ojo6Gvi9RkZG0NfXFyrOpJkaG+Ny12jMctax1Rsam8C6e0ax8coZ/NvOuQk2aP06iVmFpu2zqrzFJSKuCTxKCeV9AJ5T1UPOG3wbwDUAPBM4UZayuqtL2EkuXiWPqqAzAk0fUUHBRUngLwJ4t4gsQKWEMgAgePOaKCVpT4uOesDwmkRSK2j9Oq4RFdUD0+HJNzE0NsEDQUZC73FVfRTAAwB+isoQwhYAm2OKiyh2ad9hJeqoD7dJJPWyGK5XPTCtu2cUE0ense6eUaz/6najbxGXV5EOmar6KVVdqaqrVPUmVX0zrsCI4pb2tOioB4xqyaOncyH+cuBirO4+Pc6shuvZeou4POJMTCqMtG+s0OiA4bc2Xiq1oKNtHm7rW4k/e++sEfVr0y/wVCRM4FQYaXfieR0w3nNJZ6jauCkzAk2/wFORMIFToaSZBL0OGKZfY7qZuM9k8nw52qQxgRM1EfftyGwvQdQemA7vexx333x16KRr+h1vTMcETtTAW2/N4He/uA07xk8l3agJJg8liOqBaeTgmeiLcNCx/WwkazzEEXkol2fxO1/8yWnJG4g+4sL0a0z7VXudlqGxiVDDCNMe2pk3bIETeRjZcwhPjB91XRel3JF2Z2oSNeZq6ePq1mO4c+fTAMKdmeThbCRLTOBEHhpNZY+aYNLqTE2qxlwtfVx95allYUofaQ/tzBsmcCIPXq3D1d2LrUkwSdWY4+qI5fVZomECJ/Lg1jq8qnsRvvnxdwe6AmCWQ+SSGvESZ+nDlPHtNmICJ/IQtXVowhC5pGrMpzpiT93DhaWP9DGBEzUQpXVowhC5pGrM1YPbg1uOYOPa81n6yAgTOFFCTJiwk2SNuXqdlg19y2OIlMJgAidKiClD5Fhjzi+e7xAlJC8TdshcbIETJYRD5ChpTOA5Ujtk7cKZGZTLs0wWGWP5gpLE/905UXubqzu3Po3nDx/jba6Ico4JPCd4myui4mEJJSdMGLKWhmYzG+vXv+eSTjzyzGHeLIByqfAJPOupznExZchakprNbHRb37mwFYePnXB9PpHtCp3ATZjqHJciXNWt2cxGt/W1ybv++US2sytLxSxPdePqkLW7b+7FxrWXoqdzoZUHokaaXfy/0eVf3Z5PZLv8/O8OIW93A6kOWdswsBwdbfNylbyB5mUir/Vez89KuTyLobGJSHeySZoNMVLBSyhFqBvnSbMykdt6txp4lmUlG8p2NsRIFYVO4EWoG+dJs5mNbuuro1BMmQlpwhUKm4kzxrwMEjBVoRM4pzrbp9nMRrf1Js2EtGG4Z1wxsiWfvEIncMDuqc5s3WQv6GdgQ9kurhhtONuwXeETuG2qCWPnS69heM8r2DF+qrXE1k26wrQwbSjbxRWjDWcbtmMCt4hbwqjF1k26wrQwbSjbxRWjDWcbtstVAs97ScEtYdQzqXXj9nnkSdgWpg1luzhitOFsw3a5SeBF6DDxM1HFlNaN6+ex4hzcsOwENm3dG+sBNqsDN1uYjdlwtmG73CTwInSYNJuo4tW6SSPB1b9HeXZ27uex5xCuPmMGd+58+mS8UQ+wWR642cJszoazDZvlJoEXocPELWFc1b0IAyvPxarus1wTcxoJzu09Lupc0HS7OA6wWR642cKkrOUmgRfhdDZMwkgjwbm9x7OHj/vatvYAG+ZMIesDdxItzPr9UIrtlSlvcpPAi3I6GzRhpJHgvN7jws4FeK5JIn9rZhabtu7Fyrd14L7HXsTw3ldOrvNzppD2gTvpcpTb2cw//aLw9njkKjcJnKez7tJIcF7vcft1K1FqacHYgSNY0VVJ0MDLJ9d3LmzFXcP7PF/Xz5lCmgfuNMpRbmczR6dP5Kovh+ITKYGLyFkAvgRgFQAF8Eeq+pMY4gqFHSZzpZHgvN5j4LKuk58JAAxc1oUHtzyEjWvPx1szsw2Td5WfIXlpHbjTKEdlXRIiu0RtgX8OwA9V9XdE5AwAzXuuKFVpJDi/71EqtaCjbR429C3Hpq17fb22nzOFtA7caSTXIvTlUHxCJ3ARWQzgVwHcAgCq+haAt+IJi+KURoIL+h5+rt1tUh9GuTyLEx7XxF7R1YGhsYlY6uJuZzOL2lqN2Q9kFlHVcBuKXA1gM4AxAKsBbAdwm6oeq3veegDrAaCrq2vN4OBg4PeamppCe3t7qDiTZmpsNsT1wuHjODp96lrdi9pasWRhK6ZPzGJ+awkdbel20TTaZ/WxVi1qa4VCMTk9c3LZ/NYSLj6nHSLhY5mcnsEbJ8qY31qCzEwb+VkCdnzPTBI2rv7+/u2q2lu/PEoC7wWwDcAvq+qjIvI5AEdV9e+9tunt7dXR0dHA7zUyMoK+vr5QcSbN1NhsiKs6osOUTmevfTY0NoF198z93m7ovxhXdi/G+q/9dM661d2L8e1br4nl7zH1swTMjS1vcYmIawKP0sR5CcBLqvqo8/sDAD4Z4fWoYGzpdPaqfZ8xrwW7X550Xbdj/AhHjlDiQidwVX1ZRH4uIitUdQ+AAVTKKbnGSRbFE7ZjkSNHKGlRi4wbAHzdGYHyLICPRQ/JXHmZZJH3qzbGrdlQzKu6F+GJ8aNztuPIEUpapASuqo8DmFOXyas8TLIowlUb49ZsmOQDH/8l/O4Xt825uQZHjlDScjMTMw15mGRRhKs2JqFRvf6MM+bh27deY1SHLBUDE7ij9lZlZQVKLYIr667wl4dJFnk4CJnIlg5ZyhcmcDS+VVlteSEPkyzycBAiogomcDS+VVltecGtFlo6+JRVp8pFuWojUREwgaP5rcpqywv1p8ojB5+KLY40RoeYetVGjowhCo4JHM2vy5FGecGtjNO/fClufNf52P3yZKxJzbR6LUfGEIXDBA73skJVWuUFtzLO8N5XAt/gwEYcGUMUDhM4Ki3Sz//+O3DX8DMYff5VdLafgYuXLsRVbz87tVN5P3ecz2tS48gYonCYwFE5hf/EvT+bcwr/5+9bkVpr18/lVYF8JrW83RaNKC1M4DDjFL5RGadWHof7+RkZc3Kc/vjrKM8qSgJced6SwMm3Ub2dyDZM4DDjFL46OmToqQk8uPMAZlXx/CvH8MT+U1e7y+twv2YjY/yO0/ej0cGaFyYj2zCBw6zJLfePvnRaglndvRjvXbkUq7qDtzZt0mhkjN9x+n40OlhfyQxOlslnNgioegpfK2hrt1yexdDYBDZt3YuhsQmUPW6/1YhbotoxfgSrupecnEhURH7G6ftl0sGaKCq2wBF9cktc45i9EtX3doznuvXdTJzj9BvV2x+JcVIWURqYwB1RJrd41VWHnprAr69a5vt1vBLVf+84gMk3y7kcA+5HnOP0TZ2JShRG7hN4GkPGvFrOn/nhbgxc5r/00ShR1dd64/y7TB9WV5t0d42/jplZxbwWhO4XMG0mKlFYuU7gaU3R9mo5P/vK8UAdbNVE9VffeBz/s+PAnPXVUTFx/l22TGNn0iWay5z/oQnwKm18duveUJ2MXvpWnIMLOxe4rgvSwQZUEtWHVne7rqvWehsNhQsqztcionTlOoF7lTbuGt6H9V/dHlsSL5VacPt1K13XhRnd0GxUTKOhcEHF+VpElK5cl1AajV6Ie6blwGVdsV1nu1lH28q3dbhuF+ZgwWF1RPYyPoGXy7OYnJ7Bpq17A3ewNZuevmv8NQCIpfMu7OgGrw5Er5pvuTyL+//v53Nep3/50lAHC97ggcheRifwagfb1a3HcOfOpwEE62CrJtXPbt2Lu4b3zVn/0O5X8O9Dp5ZH7bwL2tEWpgNxZM8hDLnUp2981/mh4uawOiJ7Gf2/NI4OtlKpBX/xvuVzaspXdS/CjvHT67zV145jVqUfYf4+r5r1nolJ1+V+VA88GwaWF3rGJ5FtjG6Bx3WRKbdW5s7x1/HE+NE5z901/hrufezFVIbVhfn7WLMmoiqjE3ijZBV08onf8sbMLAJfWnZobCJUHT1MMmbNmoiqjE7gp4bT7T+5bGDluXjPJZ2RJ594JcJSi7g+361VXC7P4oXDx/GpH46GiiNMMmbNmoiqjE7g1WT14JYj2Lj2/JPJKo4bMHglQq/6s1ureGTPIRydPoHa3RgkjrDJmLMSiQgwPIEDlWTV0TYPG/qWn1wWZ228PhEGaRU/uf8I3NrrQeJgMiaisIxP4G6S7Mjz0yqu1t/3HZrCJQnFQUTUjPEJ3G0ij99Wsp+OTq/neLWK68dub7zy9PXsUCSitBidwBtN5PHTSm7W0Rl6Io3LzM7fXL0MH1zdzQ5FIkqN0Zmm4Q1om0w+8TNJJs6JNBef285JMESUKqOzTZQr5fnZNszrcyINEZnC6AQeJVn62TbKRJparHsTURaMTuBRkqWfbcO8fnWUyt0392Lj2kvR07nQuLvXEFExGN2J6TWRJ8iVCN06OmtHnny49zx8uPc87JmYDDWRZmRkP5M3EWXC6AQOuE/kCbJt/XBAW+4BSUTUTOSMJSIlEfmZiHw/joDC8nsJWN4DkojyIo4W+G0AngKwKIbXCiVIqzquafhERFmL1AIXkfMA/AaAL8UTTjhBWtUcBkhEeSGqGn5jkQcAfBpAB4C/VtUPuDxnPYD1ANDV1bVmcHAw8PtMTU2hvb3dc/3ByTcxcXR6zvKuRW04t+PMOctfOHzcuYpgxaK2VlzQuSBwXH5iywrjCs7U2EyNCzA3trzF1d/fv11Ve+uXhy6hiMgHABxU1e0i0uf1PFXdDGAzAPT29mpfn+dTPY2MjKDRdkNjE/jbe0bnLL/75qvR53E9k7iup90stvr3jOMGynHGlTZT4wLMjc3UuABzYytKXFFq4L8M4EMicj2ANgCLRORrqvqH8YTmX9AbI6R9CVeOfCGiJIRO4Kp6O4DbAcBpgf91FskbMP8uNXHcgIKIqJ7x48D9MvnGCBz5QkRJiCWBq+oIgJE4XiuPOPKFiJJgRo0h53gBLCJKQm5KKCYzvUZPRHZiAk+JyTV6IrITm4BERJZiAicishRLKAG4zaYkIsoKE7hPXrMpb+rJLiYiKjaWUHzymk05OT2TUUREVHRsgfvkNZvyjRPlQK+T9kWtiCi/mMB98ppNOb+1dPJxs+TMi1oRUZyYwH3yuuJhR9sxAP6SMy9qRURxYgL3yWs25SOPPAzAX3LmRa2IKE5M4AE0mk3pJznzolZEFCcWXmPiJznzolZEFCe2wGPi565AvKgVEcWJCTwmfpMzL2pFRHFhAo8RkzMRpYnn7kRElmICJyKyFBM4EZGlmMCJiCzFBE5EZClR1fTeTOQQgBdCbLoUwCsxhxMXU2NjXMGZGpupcQHmxpa3uC5Q1Tkz/lJN4GGJyKiq9mYdhxtTY2NcwZkam6lxAebGVpS4WEIhIrIUEzgRkaVsSeCbsw6gAVNjY1zBmRqbqXEB5sZWiLisqIETEdFctrTAiYioDhM4EZGlMk/gInKtiOwRkWdE5JMu688Ukfud9Y+KSE/Nutud5XtE5P0px/VXIjImIk+IyJCIXFCzriwijzs/340zLp+x3SIih2pi+OOadR8Vkaedn4+mHNe/18S0V0Rer1mX2D4TkS+LyEER2eWxXkRkkxP3EyLyzpp1Se6vZnH9gRPPThH5sYisrln3vLP8cREZjTMun7H1iciRms/sH2rWNfweJBzX39TEtMv5Xp3trEtsn4nI20Vk2MkJT4rIbS7Pif97pqqZ/QAoAdgH4CIAZwDYAeDyuufcCuALzuOPALjfeXy58/wzAVzovE4pxbj6ASxwHn+iGpfz+1TG++wWAP/hsu3ZAJ51/l3iPF6SVlx1z98A4Msp7bNfBfBOALs81l8P4AcABMC7ATya9P7yGdc11fcDcF01Luf35wEszXCf9QH4ftTvQdxx1T33gwAeSmOfAVgG4J3O4w4Ae13+X8b+Pcu6Bf4uAM+o6rOq+haAQQA31D3nBgD/5Tx+AMCAiIizfFBV31TV5wA847xeKnGp6rCqHnd+3QbgvJjeO3JsDbwfwBZVfVVVXwOwBcC1GcV1I4D7YnrvhlT1YQCvNnjKDQDu0YptAM4SkWVIdn81jUtVf+y8L5Dud8zPPvMS5fsZd1xpfscOqOpPnceTAJ4C0F33tNi/Z1kn8G4AP6/5/SXM/aNPPkdVZwAcAdDpc9sk46q1DpUja1WbiIyKyDYR+c2YYgoa2287p2kPiMjbA26bZFxwyk0XAnioZnGS+6wZr9iT3F9B1X/HFMCPRGS7iKzPKKZfEpEdIvIDEbnCWWbEPhORBagkwW/VLE5ln0mlzPsOAI/WrYr9e8Y78kQkIn8IoBfAr9UsvkBVx0XkIgAPichOVd2XYljfA3Cfqr4pIh9H5QzmvSm+fzMfAfCAqpZrlmW9z4wlIv2oJPBfqVn8K87+OhfAFhHZ7bRO0/JTVD6zKRG5HsB/A7g0xfdv5oMA/ldVa1vrie8zEWlH5aDxF6p6NM7XdpN1C3wcwNtrfj/PWeb6HBGZB2AxgMM+t00yLojI+wDcAeBDqvpmdbmqjjv/PgtgBJWjcVyaxqaqh2vi+RKANX63TTKuGh9B3altwvusGa/Yk9xfvojIVah8hjeo6uHq8pr9dRDAdxBf+dAXVT2qqlPO4wcBtIrIUhiwzxyNvmOJ7DMRaUUleX9dVb/t8pT4v2dJFPQDFP7noVKwvxCnOjyuqHvOn+L0TsxvOI+vwOmdmM8ivk5MP3G9A5XOmkvrli8BcKbzeCmApxFvJ46f2JbVPP4tANv0VGfJc06MS5zHZ6cVl/O8lah0Jkla+8x53R54d8j9Bk7vXHos6f3lM67zUenbuaZu+UIAHTWPfwzg2jjj8hHb26qfISqJ8EVn//n6HiQVl7N+MSp18oVp7TPnb78HwGcbPCf271msH3jIP/x6VHps9wG4w1n2z6i0agGgDcA3nS/yYwAuqtn2Dme7PQCuSzmurQAmADzu/HzXWX4NgJ3OF3cngHUZ7LNPA3jSiWEYwMqabf/I2ZfPAPhYmnE5v/8jgM/UbZfoPkOlJXYAwAlU6ovrAPwJgD9x1guA/3Ti3gmgN6X91SyuLwF4reY7Nuosv8jZVzucz/mOBL5jzWL7s5rv2DbUHGTcvgdpxeU85xZUBjjUbpfoPkOlvKUAnqj5vK5P+nvGqfRERJbKugZOREQhMYETEVmKCZyIyFJM4ERElmICJyKyFBM4EZGlmMCJiCz1/1GR0uj+JOjzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " %matplotlib inline \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y, linewidths= 0.01)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "attempted-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_b = np.c_[np.ones((100,1)),x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "innocent-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_best = np.linalg.inv(x_b.T.dot(x_b)).dot(x_b.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "romance-python",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.12113682],\n",
       "       [2.88697023]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "native-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new =  np.array([[0],[2]])\n",
    "x_new_b = np.c_[np.ones((2,1)),x_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "excess-final",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 2.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "alleged-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = x_new_b.dot(theta_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "golden-arnold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.12113682],\n",
       "       [9.89507728]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "average-nepal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_new, y_predict,'r-')\n",
    "plt.plot(x,y, 'b.')\n",
    "#plt.axis([0,2,0,15])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "pleasant-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_new, y_predict,'r-')\n",
    "plt.plot(x,y, 'b.')\n",
    "plt.axis([0,2,0,15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "hairy-yeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.12113682]), array([[2.88697023]]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x,y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "governmental-valentine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [2]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "heard-diana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.12113682],\n",
       "       [9.89507728]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "associate-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_best_svd, resiuals, rank , s = np.linalg.lstsq(x_b, y, rcond= 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ranking-alignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.12113682],\n",
       "       [2.88697023]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_best_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "early-remove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([97.01698726])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resiuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aging-keeping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "through-fleece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.19679083,  4.14171034])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "editorial-pickup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.12113682],\n",
       "       [2.88697023]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.1\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "theta = np.random.rand (2,1)\n",
    "for iteration in range(n_iterations):\n",
    "    gradients =  2/m * x_b.T.dot(x_b.dot(theta)- y)\n",
    "    theta = theta - eta * gradients\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "perfect-classification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.12040703],\n",
       "       [2.8876294 ]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.02\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "theta = np.random.rand (2,1)\n",
    "for iteration in range(n_iterations):\n",
    "    gradients =  2/m * x_b.T.dot(x_b.dot(theta)- y)\n",
    "    theta = theta - eta * gradients\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "certified-picnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-14725401.86532769],\n",
       "       [-16303031.13957018]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.5\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "theta = np.random.rand (2,1)\n",
    "for iteration in range(n_iterations):\n",
    "    gradients =  2/m * x_b.T.dot(x_b.dot(theta)- y)\n",
    "    theta = theta - eta * gradients\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "entitled-nursing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: [[0.78229749]\n",
      " [0.39998654]]\n",
      "gradients: [[58452426.69773013]\n",
      " [64714813.44982272]]\n",
      "theta: [[1.59975214]\n",
      " [1.19642242]]\n",
      "gradients: [[-8.1745465 ]\n",
      " [-7.96435881]]\n",
      "theta: [[2.43623171]\n",
      " [1.58817049]]\n",
      "gradients: [[-8.53209165]\n",
      " [-3.99583032]]\n",
      "theta: [[3.3072769 ]\n",
      " [2.60212413]]\n",
      "gradients: [[ -9.0588699 ]\n",
      " [-10.54511784]]\n",
      "theta: [[3.85346401]\n",
      " [3.1447878 ]]\n",
      "gradients: [[-5.78958339]\n",
      " [-5.75223495]]\n",
      "theta: [[3.85301704]\n",
      " [3.14425579]]\n",
      "gradients: [[0.00482732]\n",
      " [0.00574573]]\n",
      "theta: [[3.82173433]\n",
      " [3.08264781]]\n",
      "gradients: [[0.34410978]\n",
      " [0.67768779]]\n",
      "theta: [[3.8114434]\n",
      " [3.0784116]]\n",
      "gradients: [[0.1152584 ]\n",
      " [0.04744561]]\n",
      "theta: [[3.88768684]\n",
      " [3.16638419]]\n",
      "gradients: [[-0.86917528]\n",
      " [-1.00288762]]\n",
      "theta: [[3.89195152]\n",
      " [3.16877325]]\n",
      "gradients: [[-0.04947029]\n",
      " [-0.0277131 ]]\n",
      "theta: [[3.87627418]\n",
      " [3.15400955]]\n",
      "gradients: [[0.18499268]\n",
      " [0.17421166]]\n",
      "theta: [[3.4948457 ]\n",
      " [2.55713103]]\n",
      "gradients: [[4.57714177]\n",
      " [7.16254233]]\n",
      "theta: [[3.87892561]\n",
      " [3.00422519]]\n",
      "gradients: [[-4.68577489]\n",
      " [-5.45454884]]\n",
      "theta: [[3.93000041]\n",
      " [3.04842128]]\n",
      "gradients: [[-0.63332758]\n",
      " [-0.54803153]]\n",
      "theta: [[4.256725  ]\n",
      " [3.48484035]]\n",
      "gradients: [[-4.11672985]\n",
      " [-5.49888021]]\n",
      "theta: [[4.24712209]\n",
      " [3.48335849]]\n",
      "gradients: [[0.1229173 ]\n",
      " [0.01896775]]\n",
      "theta: [[4.0339771 ]\n",
      " [3.15878531]]\n",
      "gradients: [[2.77088487]\n",
      " [4.21945142]]\n",
      "theta: [[3.92684954]\n",
      " [3.10990094]]\n",
      "gradients: [[1.41408375]\n",
      " [0.64527371]]\n",
      "theta: [[4.08774906]\n",
      " [3.18145745]]\n",
      "gradients: [[-2.1560535 ]\n",
      " [-0.95885732]]\n",
      "theta: [[4.40006448]\n",
      " [3.23182166]]\n",
      "gradients: [[-4.2474897]\n",
      " [-0.6849533]]\n",
      "theta: [[4.5705527 ]\n",
      " [3.40121007]]\n",
      "gradients: [[-2.35273749]\n",
      " [-2.33756004]]\n",
      "theta: [[4.41132262]\n",
      " [3.34214722]]\n",
      "gradients: [[2.22922115]\n",
      " [0.82687992]]\n",
      "theta: [[4.39677523]\n",
      " [3.34206019]]\n",
      "gradients: [[0.2065729 ]\n",
      " [0.00123591]]\n",
      "theta: [[4.19804452]\n",
      " [3.00534219]]\n",
      "gradients: [[2.86172224]\n",
      " [4.84873912]]\n",
      "theta: [[4.06675605]\n",
      " [2.82601008]]\n",
      "gradients: [[1.91681165]\n",
      " [2.61824889]]\n",
      "theta: [[4.12855689]\n",
      " [2.83353283]]\n",
      "gradients: [[-0.91465241]\n",
      " [-0.11133682]]\n",
      "theta: [[4.14618589]\n",
      " [2.85603505]]\n",
      "gradients: [[-0.26443505]\n",
      " [-0.33753329]]\n",
      "theta: [[4.02378211]\n",
      " [2.7114049 ]]\n",
      "gradients: [[1.86053752]\n",
      " [2.19837832]]\n",
      "theta: [[4.06118831]\n",
      " [2.7116287 ]]\n",
      "gradients: [[-0.57605548]\n",
      " [-0.00344649]]\n",
      "theta: [[3.87608296]\n",
      " [2.53128286]]\n",
      "gradients: [[2.88764345]\n",
      " [2.81339504]]\n",
      "theta: [[3.85737928]\n",
      " [2.52867399]]\n",
      "gradients: [[0.29551809]\n",
      " [0.04122027]]\n",
      "theta: [[4.0097821 ]\n",
      " [2.75118532]]\n",
      "gradients: [[-2.43844517]\n",
      " [-3.56018142]]\n",
      "theta: [[3.85231849]\n",
      " [2.71443813]]\n",
      "gradients: [[2.55091059]\n",
      " [0.59530448]]\n",
      "theta: [[4.12526491]\n",
      " [2.98562378]]\n",
      "gradients: [[-4.47632127]\n",
      " [-4.44744465]]\n",
      "theta: [[4.08405007]\n",
      " [2.97465515]]\n",
      "gradients: [[0.68416636]\n",
      " [0.18207925]]\n",
      "theta: [[3.94298296]\n",
      " [2.82329173]]\n",
      "gradients: [[2.36992737]\n",
      " [2.54290548]]\n",
      "theta: [[3.8545335 ]\n",
      " [2.75231107]]\n",
      "gradients: [[1.50364085]\n",
      " [1.2066713 ]]\n",
      "theta: [[3.90422875]\n",
      " [2.78695105]]\n",
      "gradients: [[-0.85475841]\n",
      " [-0.59580765]]\n",
      "theta: [[3.74787843]\n",
      " [2.63462088]]\n",
      "gradients: [[2.7204956 ]\n",
      " [2.65054497]]\n",
      "theta: [[4.03785556]\n",
      " [2.6813828 ]]\n",
      "gradients: [[-5.10359748]\n",
      " [-0.82300987]]\n",
      "theta: [[3.95551723]\n",
      " [2.61530632]]\n",
      "gradients: [[1.46562231]\n",
      " [1.17616144]]\n",
      "theta: [[4.13642779]\n",
      " [2.81675116]]\n",
      "gradients: [[-3.25639   ]\n",
      " [-3.62600725]]\n",
      "theta: [[4.08720555]\n",
      " [2.80988541]]\n",
      "gradients: [[0.89584471]\n",
      " [0.12495669]]\n",
      "theta: [[4.2946449 ]\n",
      " [3.01598658]]\n",
      "gradients: [[-3.81688405]\n",
      " [-3.79226144]]\n",
      "theta: [[4.25003125]\n",
      " [2.95428963]]\n",
      "gradients: [[0.82981387]\n",
      " [1.14756328]]\n",
      "theta: [[4.00005294]\n",
      " [2.56311095]]\n",
      "gradients: [[4.69959228]\n",
      " [7.35415906]]\n",
      "theta: [[3.90557799]\n",
      " [2.45880869]]\n",
      "gradients: [[1.79502396]\n",
      " [1.98174292]]\n",
      "theta: [[4.03009476]\n",
      " [2.66325721]]\n",
      "gradients: [[-2.39072197]\n",
      " [-3.92541147]]\n",
      "theta: [[3.99677634]\n",
      " [2.61774626]]\n",
      "gradients: [[0.6463773 ]\n",
      " [0.88291233]]\n",
      "theta: [[4.03096036]\n",
      " [2.63186763]]\n",
      "gradients: [[-0.67000666]\n",
      " [-0.27677877]]\n",
      "theta: [[4.00255854]\n",
      " [2.59307246]]\n",
      "gradients: [[0.56235595]\n",
      " [0.76814425]]\n",
      "theta: [[4.2327026 ]\n",
      " [2.96862187]]\n",
      "gradients: [[-4.6028812 ]\n",
      " [-7.51098815]]\n",
      "theta: [[4.23207835]\n",
      " [2.9680817 ]]\n",
      "gradients: [[0.01260982]\n",
      " [0.01091154]]\n",
      "theta: [[4.03488246]\n",
      " [2.90060248]]\n",
      "gradients: [[4.02279628]\n",
      " [1.37657602]]\n",
      "theta: [[4.23354245]\n",
      " [2.91618587]]\n",
      "gradients: [[-4.09239594]\n",
      " [-0.32101779]]\n",
      "theta: [[4.22569607]\n",
      " [2.91396137]]\n",
      "gradients: [[0.1632048 ]\n",
      " [0.04626954]]\n",
      "theta: [[4.30820274]\n",
      " [2.9506544 ]]\n",
      "gradients: [[-1.73264006]\n",
      " [-0.77055351]]\n",
      "theta: [[4.28055889]\n",
      " [2.93976191]]\n",
      "gradients: [[0.58604956]\n",
      " [0.23092066]]\n",
      "theta: [[4.22531585]\n",
      " [2.85563884]]\n",
      "gradients: [[1.18220115]\n",
      " [1.8002337 ]]\n",
      "theta: [[4.21410905]\n",
      " [2.85344199]]\n",
      "gradients: [[0.24206687]\n",
      " [0.047452  ]]\n",
      "theta: [[4.18404836]\n",
      " [2.83006469]]\n",
      "gradients: [[0.65532307]\n",
      " [0.50962505]]\n",
      "theta: [[4.24532767]\n",
      " [2.93373516]]\n",
      "gradients: [[-1.34814487]\n",
      " [-2.28075019]]\n",
      "theta: [[4.23367725]\n",
      " [2.91547671]]\n",
      "gradients: [[0.25863938]\n",
      " [0.40533744]]\n",
      "theta: [[4.09154706]\n",
      " [2.75720211]]\n",
      "gradients: [[3.1837162 ]\n",
      " [3.54535103]]\n",
      "theta: [[4.1450331 ]\n",
      " [2.75760701]]\n",
      "gradients: [[-1.20878444]\n",
      " [-0.00915057]]\n",
      "theta: [[4.07527203]\n",
      " [2.71692591]]\n",
      "gradients: [[1.59055223]\n",
      " [0.927529  ]]\n",
      "theta: [[4.1899674 ]\n",
      " [2.92815952]]\n",
      "gradients: [[-2.63799351]\n",
      " [-4.85837296]]\n",
      "theta: [[4.02137895]\n",
      " [2.87046959]]\n",
      "gradients: [[3.91125213]\n",
      " [1.3384063 ]]\n",
      "theta: [[3.95368344]\n",
      " [2.74297951]]\n",
      "gradients: [[1.58407487]\n",
      " [2.98326786]]\n",
      "theta: [[3.94076403]\n",
      " [2.73139654]]\n",
      "gradients: [[0.30489815]\n",
      " [0.273358  ]]\n",
      "theta: [[3.95049004]\n",
      " [2.73239786]]\n",
      "gradients: [[-0.23147918]\n",
      " [-0.02383134]]\n",
      "theta: [[3.97992473]\n",
      " [2.74062814]]\n",
      "gradients: [[-0.70643238]\n",
      " [-0.19752663]]\n",
      "theta: [[3.93810204]\n",
      " [2.66186401]]\n",
      "gradients: [[1.01210894]\n",
      " [1.90609178]]\n",
      "theta: [[3.88629676]\n",
      " [2.56420274]]\n",
      "gradients: [[1.26404885]\n",
      " [2.38293508]]\n",
      "theta: [[3.93961351]\n",
      " [2.62766308]]\n",
      "gradients: [[-1.31159186]\n",
      " [-1.56112441]]\n",
      "theta: [[3.97845709]\n",
      " [2.64267249]]\n",
      "gradients: [[-0.96332079]\n",
      " [-0.37223344]]\n",
      "theta: [[4.03368271]\n",
      " [2.75143351]]\n",
      "gradients: [[-1.38064056]\n",
      " [-2.71902545]]\n",
      "theta: [[4.07843491]\n",
      " [2.79865907]]\n",
      "gradients: [[-1.12775561]\n",
      " [-1.19008407]]\n",
      "theta: [[4.12703259]\n",
      " [2.79902696]]\n",
      "gradients: [[-1.23438106]\n",
      " [-0.00934434]]\n",
      "theta: [[4.09205415]\n",
      " [2.78605248]]\n",
      "gradients: [[0.89544812]\n",
      " [0.33214653]]\n",
      "theta: [[4.10841418]\n",
      " [2.78857705]]\n",
      "gradients: [[-0.42208862]\n",
      " [-0.0651338 ]]\n",
      "theta: [[4.15573377]\n",
      " [2.81361477]]\n",
      "gradients: [[-1.23030951]\n",
      " [-0.6509808 ]]\n",
      "theta: [[4.16529585]\n",
      " [2.81628844]]\n",
      "gradients: [[-0.25052656]\n",
      " [-0.07005011]]\n",
      "theta: [[4.21546437]\n",
      " [2.8251325 ]]\n",
      "gradients: [[-1.32444887]\n",
      " [-0.23348318]]\n",
      "theta: [[4.27632735]\n",
      " [2.83642234]]\n",
      "gradients: [[-1.61895523]\n",
      " [-0.30030975]]\n",
      "theta: [[4.13714558]\n",
      " [2.79686968]]\n",
      "gradients: [[3.73007152]\n",
      " [1.06001129]]\n",
      "theta: [[4.32057843]\n",
      " [3.1388529 ]]\n",
      "gradients: [[-4.95268694]\n",
      " [-9.23354693]]\n",
      "theta: [[4.26415778]\n",
      " [3.11792492]]\n",
      "gradients: [[1.53464151]\n",
      " [0.56924108]]\n",
      "theta: [[4.225808  ]\n",
      " [3.06489037]]\n",
      "gradients: [[1.05078407]\n",
      " [1.45314662]]\n",
      "theta: [[4.21756935]\n",
      " [3.05280422]]\n",
      "gradients: [[0.2273868 ]\n",
      " [0.33357788]]\n",
      "theta: [[4.11750569]\n",
      " [3.01969387]]\n",
      "gradients: [[2.78176954]\n",
      " [0.92046768]]\n",
      "theta: [[4.11084236]\n",
      " [3.01358165]]\n",
      "gradients: [[0.18657345]\n",
      " [0.17114227]]\n",
      "theta: [[4.01150101]\n",
      " [2.90827068]]\n",
      "gradients: [[2.80142596]\n",
      " [2.96976932]]\n",
      "theta: [[3.99470854]\n",
      " [2.90706929]]\n",
      "gradients: [[0.47690632]\n",
      " [0.03411935]]\n",
      "theta: [[3.94531212]\n",
      " [2.80887131]]\n",
      "gradients: [[1.41273736]\n",
      " [2.80846224]]\n",
      "theta: [[3.87460581]\n",
      " [2.73391611]]\n",
      "gradients: [[2.0363419 ]\n",
      " [2.15870981]]\n",
      "theta: [[3.93514962]\n",
      " [2.76595102]]\n",
      "gradients: [[-1.75577058]\n",
      " [-0.92901252]]\n",
      "theta: [[4.00579597]\n",
      " [2.88546835]]\n",
      "gradients: [[-2.06287342]\n",
      " [-3.48990608]]\n",
      "theta: [[4.02044822]\n",
      " [2.89152118]]\n",
      "gradients: [[-0.43077619]\n",
      " [-0.17795302]]\n",
      "theta: [[4.03114065]\n",
      " [2.91257879]]\n",
      "gradients: [[-0.31649599]\n",
      " [-0.62330535]]\n",
      "theta: [[4.06368778]\n",
      " [2.96009827]]\n",
      "gradients: [[-0.96990418]\n",
      " [-1.41608058]]\n",
      "theta: [[4.07169606]\n",
      " [2.97016094]]\n",
      "gradients: [[-0.24024852]\n",
      " [-0.30188004]]\n",
      "theta: [[4.07673184]\n",
      " [2.97382899]]\n",
      "gradients: [[-0.15208068]\n",
      " [-0.11077496]]\n",
      "theta: [[4.03295569]\n",
      " [2.95385309]]\n",
      "gradients: [[1.33079496]\n",
      " [0.60726743]]\n",
      "theta: [[3.97909772]\n",
      " [2.89469738]]\n",
      "gradients: [[1.64805395]\n",
      " [1.81016463]]\n",
      "theta: [[3.99930995]\n",
      " [2.91218744]]\n",
      "gradients: [[-0.62253674]\n",
      " [-0.53869399]]\n",
      "theta: [[4.14483296]\n",
      " [2.93565459]]\n",
      "gradients: [[-4.51121327]\n",
      " [-0.72748156]]\n",
      "theta: [[4.09893047]\n",
      " [2.9147084 ]]\n",
      "gradients: [[1.43215776]\n",
      " [0.65352124]]\n",
      "theta: [[4.10461183]\n",
      " [2.91884668]]\n",
      "gradients: [[-0.17839469]\n",
      " [-0.12994198]]\n",
      "theta: [[4.11391317]\n",
      " [2.92144744]]\n",
      "gradients: [[-0.29392234]\n",
      " [-0.08218407]]\n",
      "theta: [[4.14640889]\n",
      " [2.9249298 ]]\n",
      "gradients: [[-1.03336396]\n",
      " [-0.11073918]]\n",
      "theta: [[4.28226161]\n",
      " [3.16952919]]\n",
      "gradients: [[-4.34728713]\n",
      " [-7.82718045]]\n",
      "theta: [[4.26215895]\n",
      " [3.14003846]]\n",
      "gradients: [[0.64730565]\n",
      " [0.94960151]]\n",
      "theta: [[4.30766891]\n",
      " [3.19071404]]\n",
      "gradients: [[-1.47452259]\n",
      " [-1.6418886 ]]\n",
      "theta: [[4.41507102]\n",
      " [3.19913893]]\n",
      "gradients: [[-3.50130888]\n",
      " [-0.27465144]]\n",
      "theta: [[4.30794583]\n",
      " [3.08419479]]\n",
      "gradients: [[3.51370642]\n",
      " [3.77016757]]\n",
      "theta: [[4.34848771]\n",
      " [3.09171515]]\n",
      "gradients: [[-1.33788227]\n",
      " [-0.24817183]]\n",
      "theta: [[4.32772193]\n",
      " [3.05177542]]\n",
      "gradients: [[0.68942395]\n",
      " [1.32599892]]\n",
      "theta: [[4.31292383]\n",
      " [3.02331359]]\n",
      "gradients: [[0.49425677]\n",
      " [0.95062545]]\n",
      "theta: [[4.26489147]\n",
      " [2.94193029]]\n",
      "gradients: [[1.61388726]\n",
      " [2.73447863]]\n",
      "theta: [[4.25438705]\n",
      " [2.93987113]]\n",
      "gradients: [[0.35504927]\n",
      " [0.06959977]]\n",
      "theta: [[4.13532509]\n",
      " [2.89912886]]\n",
      "gradients: [[4.04810671]\n",
      " [1.38523709]]\n",
      "theta: [[4.13791272]\n",
      " [2.90093257]]\n",
      "gradients: [[-0.08849712]\n",
      " [-0.06168674]]\n",
      "theta: [[4.11239996]\n",
      " [2.89469591]]\n",
      "gradients: [[0.87763905]\n",
      " [0.21454104]]\n",
      "theta: [[4.04042032]\n",
      " [2.75900272]]\n",
      "gradients: [[2.49049571]\n",
      " [4.69498437]]\n",
      "theta: [[4.02279779]\n",
      " [2.75469485]]\n",
      "gradients: [[0.61326402]\n",
      " [0.14991391]]\n",
      "theta: [[3.97842143]\n",
      " [2.71908283]]\n",
      "gradients: [[1.55317255]\n",
      " [1.24642047]]\n",
      "theta: [[3.90067613]\n",
      " [2.64333655]]\n",
      "gradients: [[2.73663464]\n",
      " [2.66626903]]\n",
      "theta: [[3.95476276]\n",
      " [2.65287133]]\n",
      "gradients: [[-1.91466668]\n",
      " [-0.33753094]]\n",
      "theta: [[3.94218813]\n",
      " [2.64704104]]\n",
      "gradients: [[0.44765683]\n",
      " [0.20755814]]\n",
      "theta: [[3.9306516 ]\n",
      " [2.64276183]]\n",
      "gradients: [[0.41300761]\n",
      " [0.15319597]]\n",
      "theta: [[3.95942582]\n",
      " [2.67701039]]\n",
      "gradients: [[-1.03587202]\n",
      " [-1.23294841]]\n",
      "theta: [[4.02118317]\n",
      " [2.69181073]]\n",
      "gradients: [[-2.2356158 ]\n",
      " [-0.53577217]]\n",
      "theta: [[4.00629472]\n",
      " [2.68817121]]\n",
      "gradients: [[0.54193923]\n",
      " [0.13247839]]\n",
      "theta: [[3.94556518]\n",
      " [2.62054346]]\n",
      "gradients: [[2.22270139]\n",
      " [2.4751756 ]]\n",
      "theta: [[3.91340772]\n",
      " [2.59473711]]\n",
      "gradients: [[1.18339444]\n",
      " [0.94967366]]\n",
      "theta: [[3.9557732 ]\n",
      " [2.59505782]]\n",
      "gradients: [[-1.56752285]\n",
      " [-0.01186624]]\n",
      "theta: [[3.90431411]\n",
      " [2.53775355]]\n",
      "gradients: [[1.91427828]\n",
      " [2.13171904]]\n",
      "theta: [[3.91063549]\n",
      " [2.55032019]]\n",
      "gradients: [[-0.23641971]\n",
      " [-0.46999241]]\n",
      "theta: [[3.94406122]\n",
      " [2.61175791]]\n",
      "gradients: [[-1.25680716]\n",
      " [-2.31005823]]\n",
      "theta: [[3.97023535]\n",
      " [2.64795456]]\n",
      "gradients: [[-0.98938248]\n",
      " [-1.36823335]]\n",
      "theta: [[4.12396608]\n",
      " [2.93456259]]\n",
      "gradients: [[ -5.84176751]\n",
      " [-10.89110519]]\n",
      "theta: [[4.2295412 ]\n",
      " [3.07558349]]\n",
      "gradients: [[-4.03296971]\n",
      " [-5.38699845]]\n",
      "theta: [[4.14137556]\n",
      " [2.97824683]]\n",
      "gradients: [[3.38556068]\n",
      " [3.73772778]]\n",
      "theta: [[4.13727517]\n",
      " [2.97448557]]\n",
      "gradients: [[0.15827514]\n",
      " [0.14518446]]\n",
      "theta: [[4.11300861]\n",
      " [2.97110076]]\n",
      "gradients: [[0.94154256]\n",
      " [0.13133084]]\n",
      "theta: [[4.15838588]\n",
      " [2.97951806]]\n",
      "gradients: [[-1.7697137 ]\n",
      " [-0.32827484]]\n",
      "theta: [[4.09448355]\n",
      " [2.88319948]]\n",
      "gradients: [[2.50497139]\n",
      " [3.77568839]]\n",
      "theta: [[4.10890856]\n",
      " [2.90436107]]\n",
      "gradients: [[-0.56834549]\n",
      " [-0.83376644]]\n",
      "theta: [[4.1577101 ]\n",
      " [2.91284855]]\n",
      "gradients: [[-1.93254085]\n",
      " [-0.33610453]]\n",
      "theta: [[4.17125353]\n",
      " [2.9271405 ]]\n",
      "gradients: [[-0.53902867]\n",
      " [-0.56881954]]\n",
      "theta: [[4.13001373]\n",
      " [2.87080942]]\n",
      "gradients: [[1.64959211]\n",
      " [2.25324315]]\n",
      "theta: [[4.12105623]\n",
      " [2.8543452 ]]\n",
      "gradients: [[0.36009154]\n",
      " [0.66186163]]\n",
      "theta: [[4.10401908]\n",
      " [2.85312631]]\n",
      "gradients: [[0.68830076]\n",
      " [0.04924316]]\n",
      "theta: [[4.08876375]\n",
      " [2.82727855]]\n",
      "gradients: [[0.61936654]\n",
      " [1.04941938]]\n",
      "theta: [[4.17895717]\n",
      " [2.95571959]]\n",
      "gradients: [[-3.67989182]\n",
      " [-5.24039463]]\n",
      "theta: [[4.20410251]\n",
      " [2.95590994]]\n",
      "gradients: [[-1.03095863]\n",
      " [-0.00780442]]\n",
      "theta: [[4.1848141 ]\n",
      " [2.94090993]]\n",
      "gradients: [[0.79468248]\n",
      " [0.61800068]]\n",
      "theta: [[4.10890506]\n",
      " [2.85637846]]\n",
      "gradients: [[3.14263419]\n",
      " [3.49960255]]\n",
      "theta: [[4.1155878 ]\n",
      " [2.86953942]]\n",
      "gradients: [[-0.27800203]\n",
      " [-0.54749558]]\n",
      "theta: [[4.08364525]\n",
      " [2.82157232]]\n",
      "gradients: [[1.3351985 ]\n",
      " [2.00502476]]\n",
      "theta: [[4.09078759]\n",
      " [2.82655087]]\n",
      "gradients: [[-0.29997807]\n",
      " [-0.20909912]]\n",
      "theta: [[4.16721711]\n",
      " [2.96632586]]\n",
      "gradients: [[-3.22532578]\n",
      " [-5.89850479]]\n",
      "theta: [[4.20687188]\n",
      " [2.97582925]]\n",
      "gradients: [[-1.68136256]\n",
      " [-0.40294368]]\n",
      "theta: [[4.21062157]\n",
      " [2.97727815]]\n",
      "gradients: [[-0.15973667]\n",
      " [-0.06172329]]\n",
      "theta: [[4.10097858]\n",
      " [2.80570327]]\n",
      "gradients: [[4.69272014]\n",
      " [7.34340518]]\n",
      "theta: [[4.05350841]\n",
      " [2.7547683 ]]\n",
      "gradients: [[2.04121743]\n",
      " [2.19020341]]\n",
      "theta: [[4.07950303]\n",
      " [2.79744981]]\n",
      "gradients: [[-1.12296792]\n",
      " [-1.84384098]]\n",
      "theta: [[4.05308625]\n",
      " [2.74493435]]\n",
      "gradients: [[1.14648854]\n",
      " [2.27917082]]\n",
      "theta: [[4.04364363]\n",
      " [2.74242136]]\n",
      "gradients: [[0.41169824]\n",
      " [0.10956649]]\n",
      "theta: [[4.00801017]\n",
      " [2.68871182]]\n",
      "gradients: [[1.56074556]\n",
      " [2.35247753]]\n",
      "theta: [[4.07338382]\n",
      " [2.80910999]]\n",
      "gradients: [[-2.87644058]\n",
      " [-5.29751916]]\n",
      "theta: [[4.10025149]\n",
      " [2.84833736]]\n",
      "gradients: [[-1.18755114]\n",
      " [-1.73384973]]\n",
      "theta: [[4.10049753]\n",
      " [2.84838559]]\n",
      "gradients: [[-0.01092445]\n",
      " [-0.0021415 ]]\n",
      "theta: [[4.09559557]\n",
      " [2.8393756 ]]\n",
      "gradients: [[0.21862747]\n",
      " [0.40184541]]\n",
      "theta: [[4.11067712]\n",
      " [2.8400208 ]]\n",
      "gradients: [[-0.67565326]\n",
      " [-0.02890498]]\n",
      "theta: [[4.0976044 ]\n",
      " [2.81787114]]\n",
      "gradients: [[0.58827216]\n",
      " [0.99673482]]\n",
      "theta: [[4.09537724]\n",
      " [2.81377753]]\n",
      "gradients: [[0.10066783]\n",
      " [0.18503121]]\n",
      "theta: [[4.18315319]\n",
      " [2.82066289]]\n",
      "gradients: [[-3.98502791]\n",
      " [-0.31259557]]\n",
      "theta: [[4.20562273]\n",
      " [2.82083299]]\n",
      "gradients: [[-1.02461138]\n",
      " [-0.00775637]]\n",
      "theta: [[4.21643688]\n",
      " [2.83567954]]\n",
      "gradients: [[-0.49528775]\n",
      " [-0.67997183]]\n",
      "theta: [[4.2218716 ]\n",
      " [2.84038231]]\n",
      "gradients: [[-0.24999717]\n",
      " [-0.21632775]]\n",
      "theta: [[4.22687136]\n",
      " [2.84470871]]\n",
      "gradients: [[-0.2309889]\n",
      " [-0.1998795]]\n",
      "theta: [[4.16932057]\n",
      " [2.75113367]]\n",
      "gradients: [[2.67035644]\n",
      " [4.34188206]]\n",
      "theta: [[4.2108811 ]\n",
      " [2.77059769]]\n",
      "gradients: [[-1.93672047]\n",
      " [-0.90702335]]\n",
      "theta: [[4.20932318]\n",
      " [2.76913056]]\n",
      "gradients: [[0.0729105 ]\n",
      " [0.06866142]]\n",
      "theta: [[4.31382877]\n",
      " [2.96396566]]\n",
      "gradients: [[-4.91176265]\n",
      " [-9.15724969]]\n",
      "theta: [[4.28712774]\n",
      " [2.95743853]]\n",
      "gradients: [[1.26028833]\n",
      " [0.3080806 ]]\n",
      "theta: [[4.31527067]\n",
      " [2.98476781]]\n",
      "gradients: [[-1.33397491]\n",
      " [-1.29540807]]\n",
      "theta: [[4.39711565]\n",
      " [3.13735557]]\n",
      "gradients: [[-3.8958206 ]\n",
      " [-7.26317709]]\n",
      "theta: [[4.33023663]\n",
      " [3.11522578]]\n",
      "gradients: [[3.19681701]\n",
      " [1.05780392]]\n",
      "theta: [[4.34984718]\n",
      " [3.13426936]]\n",
      "gradients: [[-0.94130629]\n",
      " [-0.91409198]]\n",
      "theta: [[4.31854445]\n",
      " [3.10911744]]\n",
      "gradients: [[1.50879159]\n",
      " [1.21232282]]\n",
      "theta: [[4.25392731]\n",
      " [3.03978398]]\n",
      "gradients: [[3.12746917]\n",
      " [3.35573933]]\n",
      "theta: [[4.25543652]\n",
      " [3.04152536]]\n",
      "gradients: [[-0.07334748]\n",
      " [-0.08463113]]\n",
      "theta: [[4.29042335]\n",
      " [3.08048337]]\n",
      "gradients: [[-1.70735716]\n",
      " [-1.9011511 ]]\n",
      "theta: [[4.28184236]\n",
      " [3.06639395]]\n",
      "gradients: [[0.4204683 ]\n",
      " [0.69038187]]\n",
      "theta: [[4.23320315]\n",
      " [3.01297035]]\n",
      "gradients: [[2.39304916]\n",
      " [2.62844123]]\n",
      "theta: [[4.23143317]\n",
      " [3.01054037]]\n",
      "gradients: [[0.08743708]\n",
      " [0.12004083]]\n",
      "theta: [[4.24232781]\n",
      " [3.01186653]]\n",
      "gradients: [[-0.54037396]\n",
      " [-0.06577747]]\n",
      "theta: [[4.23891513]\n",
      " [3.00530277]]\n",
      "gradients: [[0.16995151]\n",
      " [0.32687509]]\n",
      "theta: [[4.25371433]\n",
      " [3.01313332]]\n",
      "gradients: [[-0.73995998]\n",
      " [-0.39152728]]\n",
      "theta: [[4.24145578]\n",
      " [3.00158917]]\n",
      "gradients: [[0.6153792 ]\n",
      " [0.57951608]]\n",
      "theta: [[4.27236567]\n",
      " [3.01606519]]\n",
      "gradients: [[-1.55785865]\n",
      " [-0.72959118]]\n",
      "theta: [[4.26176871]\n",
      " [3.00345214]]\n",
      "gradients: [[0.53620602]\n",
      " [0.63822012]]\n",
      "theta: [[4.23444342]\n",
      " [2.97895351]]\n",
      "gradients: [[1.38812485]\n",
      " [1.24453049]]\n",
      "theta: [[4.21073105]\n",
      " [2.94284476]]\n",
      "gradients: [[1.20933067]\n",
      " [1.84154602]]\n",
      "theta: [[4.2055314 ]\n",
      " [2.93260459]]\n",
      "gradients: [[0.26622241]\n",
      " [0.52429687]]\n",
      "theta: [[4.19072026]\n",
      " [2.92108641]]\n",
      "gradients: [[0.76129252]\n",
      " [0.59203431]]\n",
      "theta: [[4.14976271]\n",
      " [2.84395159]]\n",
      "gradients: [[2.11340952]\n",
      " [3.98015701]]\n",
      "theta: [[4.16392477]\n",
      " [2.86029231]]\n",
      "gradients: [[-0.73359447]\n",
      " [-0.8464493 ]]\n",
      "theta: [[4.16556784]\n",
      " [2.86143761]]\n",
      "gradients: [[-0.08543965]\n",
      " [-0.05955554]]\n",
      "theta: [[4.16564039]\n",
      " [2.86145818]]\n",
      "gradients: [[-0.00378736]\n",
      " [-0.00107374]]\n",
      "theta: [[4.20930377]\n",
      " [2.91007757]]\n",
      "gradients: [[-2.28796091]\n",
      " [-2.54765642]]\n",
      "theta: [[4.20716613]\n",
      " [2.90672749]]\n",
      "gradients: [[0.11243966]\n",
      " [0.17621447]]\n",
      "theta: [[4.23889138]\n",
      " [2.96515564]]\n",
      "gradients: [[-1.67509301]\n",
      " [-3.08500629]]\n",
      "theta: [[4.17151037]\n",
      " [2.88201635]]\n",
      "gradients: [[3.57119336]\n",
      " [4.40638251]]\n",
      "theta: [[4.17590058]\n",
      " [2.88269381]]\n",
      "gradients: [[-0.23355922]\n",
      " [-0.03604124]]\n",
      "theta: [[4.17088395]\n",
      " [2.88071711]]\n",
      "gradients: [[0.26788833]\n",
      " [0.10555583]]\n",
      "theta: [[4.17429255]\n",
      " [2.8816702 ]]\n",
      "gradients: [[-0.18270103]\n",
      " [-0.05108531]]\n",
      "theta: [[4.12139724]\n",
      " [2.83670647]]\n",
      "gradients: [[2.84576754]\n",
      " [2.41904871]]\n",
      "theta: [[4.12945134]\n",
      " [2.8468267 ]]\n",
      "gradients: [[-0.43492119]\n",
      " [-0.54649253]]\n",
      "theta: [[4.08620196]\n",
      " [2.76529468]]\n",
      "gradients: [[2.34411616]\n",
      " [4.41903542]]\n",
      "theta: [[4.07122427]\n",
      " [2.7583502 ]]\n",
      "gradients: [[0.81478644]\n",
      " [0.37777947]]\n",
      "theta: [[4.0737802 ]\n",
      " [2.75978203]]\n",
      "gradients: [[-0.13955412]\n",
      " [-0.07817777]]\n",
      "theta: [[4.09050881]\n",
      " [2.76181833]]\n",
      "gradients: [[-0.91672743]\n",
      " [-0.11158941]]\n",
      "theta: [[4.09386098]\n",
      " [2.76497515]]\n",
      "gradients: [[-0.18436949]\n",
      " [-0.17362479]]\n",
      "theta: [[4.09697184]\n",
      " [2.76790471]]\n",
      "gradients: [[-0.17171946]\n",
      " [-0.16171198]]\n",
      "theta: [[4.11386775]\n",
      " [2.78556628]]\n",
      "gradients: [[-0.9360333 ]\n",
      " [-0.97845103]]\n",
      "theta: [[4.10669714]\n",
      " [2.78442547]]\n",
      "gradients: [[0.39868562]\n",
      " [0.06342937]]\n",
      "theta: [[4.04135052]\n",
      " [2.76206426]]\n",
      "gradients: [[3.6463418 ]\n",
      " [1.24775562]]\n",
      "theta: [[4.01655792]\n",
      " [2.74760648]]\n",
      "gradients: [[1.38838555]\n",
      " [0.8096357 ]]\n",
      "theta: [[4.08898754]\n",
      " [2.86579724]]\n",
      "gradients: [[-4.07054481]\n",
      " [-6.64232086]]\n",
      "theta: [[4.05761856]\n",
      " [2.82873221]]\n",
      "gradients: [[1.76921047]\n",
      " [2.09046788]]\n",
      "theta: [[4.04996251]\n",
      " [2.82258052]]\n",
      "gradients: [[0.4333326 ]\n",
      " [0.34818526]]\n",
      "theta: [[4.03022017]\n",
      " [2.79561368]]\n",
      "gradients: [[1.12136483]\n",
      " [1.5317166 ]]\n",
      "theta: [[4.02502863]\n",
      " [2.79347661]]\n",
      "gradients: [[0.29591741]\n",
      " [0.1218131 ]]\n",
      "theta: [[4.09450143]\n",
      " [2.86250123]]\n",
      "gradients: [[-3.97384378]\n",
      " [-3.94820862]]\n",
      "theta: [[4.13005545]\n",
      " [2.8783131 ]]\n",
      "gradients: [[-2.04080086]\n",
      " [-0.90760125]]\n",
      "theta: [[4.0868043 ]\n",
      " [2.86400161]]\n",
      "gradients: [[2.49126602]\n",
      " [0.82434213]]\n",
      "theta: [[4.09514633]\n",
      " [2.87772192]]\n",
      "gradients: [[-0.482169  ]\n",
      " [-0.79303422]]\n",
      "theta: [[4.08729872]\n",
      " [2.87161908]]\n",
      "gradients: [[0.45516118]\n",
      " [0.35396517]]\n",
      "theta: [[4.09339768]\n",
      " [2.87332441]]\n",
      "gradients: [[-0.35495932]\n",
      " [-0.09925071]]\n",
      "theta: [[4.12720102]\n",
      " [2.88915552]]\n",
      "gradients: [[-1.97411518]\n",
      " [-0.9245364 ]]\n",
      "theta: [[4.13512822]\n",
      " [2.90003862]]\n",
      "gradients: [[-0.46453358]\n",
      " [-0.63774997]]\n",
      "theta: [[4.14552325]\n",
      " [2.91100817]]\n",
      "gradients: [[-0.61122825]\n",
      " [-0.64500943]]\n",
      "theta: [[4.14247104]\n",
      " [2.90929833]]\n",
      "gradients: [[0.18008086]\n",
      " [0.10088072]]\n",
      "theta: [[4.1091516 ]\n",
      " [2.84654827]]\n",
      "gradients: [[1.97251037]\n",
      " [3.71480345]]\n",
      "theta: [[4.14438368]\n",
      " [2.91143492]]\n",
      "gradients: [[-2.0927853 ]\n",
      " [-3.85426708]]\n",
      "theta: [[4.21820804]\n",
      " [3.04435381]]\n",
      "gradients: [[-4.39993194]\n",
      " [-7.9219661 ]]\n",
      "theta: [[4.24382909]\n",
      " [3.04910642]]\n",
      "gradients: [[-1.53213853]\n",
      " [-0.2842056 ]]\n",
      "theta: [[4.25226564]\n",
      " [3.05013336]]\n",
      "gradients: [[-0.50619316]\n",
      " [-0.06161678]]\n",
      "theta: [[4.27654935]\n",
      " [3.05463789]]\n",
      "gradients: [[-1.46187917]\n",
      " [-0.27117276]]\n",
      "theta: [[4.21939068]\n",
      " [2.96170041]]\n",
      "gradients: [[3.45238365]\n",
      " [5.6134239 ]]\n",
      "theta: [[4.16875729]\n",
      " [2.94988413]]\n",
      "gradients: [[3.06838329]\n",
      " [0.71606677]]\n",
      "theta: [[4.23153549]\n",
      " [2.95480861]]\n",
      "gradients: [[-3.81691473]\n",
      " [-0.29940835]]\n",
      "theta: [[4.18854684]\n",
      " [2.90868226]]\n",
      "gradients: [[2.62230798]\n",
      " [2.81370704]]\n",
      "theta: [[4.19167194]\n",
      " [2.90916451]]\n",
      "gradients: [[-0.19125649]\n",
      " [-0.02951338]]\n",
      "theta: [[4.18971199]\n",
      " [2.90683167]]\n",
      "gradients: [[0.12034114]\n",
      " [0.14323625]]\n",
      "theta: [[4.17977841]\n",
      " [2.88857338]]\n",
      "gradients: [[0.61190852]\n",
      " [1.12471058]]\n",
      "theta: [[4.20884463]\n",
      " [2.89362853]]\n",
      "gradients: [[-1.7962927 ]\n",
      " [-0.31240846]]\n",
      "theta: [[4.19482047]\n",
      " [2.8926252 ]]\n",
      "gradients: [[0.86949847]\n",
      " [0.06220661]]\n",
      "theta: [[4.20028697]\n",
      " [2.9006446 ]]\n",
      "gradients: [[-0.34001647]\n",
      " [-0.49880632]]\n",
      "theta: [[4.26392381]\n",
      " [2.98564687]]\n",
      "gradients: [[-3.97093917]\n",
      " [-5.30414178]]\n",
      "theta: [[4.25553615]\n",
      " [2.98234188]]\n",
      "gradients: [[0.52506782]\n",
      " [0.20689207]]\n",
      "theta: [[4.23387577]\n",
      " [2.94564177]]\n",
      "gradients: [[1.36027168]\n",
      " [2.30476683]]\n",
      "theta: [[4.17020857]\n",
      " [2.92385525]]\n",
      "gradients: [[4.01103351]\n",
      " [1.37255087]]\n",
      "theta: [[4.18545484]\n",
      " [2.93192235]]\n",
      "gradients: [[-0.96356403]\n",
      " [-0.50984056]]\n",
      "theta: [[4.19269778]\n",
      " [2.94027953]]\n",
      "gradients: [[-0.45920216]\n",
      " [-0.52984499]]\n",
      "theta: [[4.1801994]\n",
      " [2.9369533]]\n",
      "gradients: [[0.7948969]\n",
      " [0.2115483]]\n",
      "theta: [[4.17420676]\n",
      " [2.92866598]]\n",
      "gradients: [[0.38233001]\n",
      " [0.52873047]]\n",
      "theta: [[4.24275575]\n",
      " [3.05646537]]\n",
      "gradients: [[-4.38713543]\n",
      " [-8.17916039]]\n",
      "theta: [[4.18349952]\n",
      " [2.98335097]]\n",
      "gradients: [[3.80425048]\n",
      " [4.69394431]]\n",
      "theta: [[4.17773392]\n",
      " [2.97199623]]\n",
      "gradients: [[0.3713047 ]\n",
      " [0.73124531]]\n",
      "theta: [[4.17915013]\n",
      " [2.97322171]]\n",
      "gradients: [[-0.09148775]\n",
      " [-0.07916625]]\n",
      "theta: [[4.18115337]\n",
      " [2.97597191]]\n",
      "gradients: [[-0.12980936]\n",
      " [-0.17821298]]\n",
      "theta: [[4.14025966]\n",
      " [2.96244048]]\n",
      "gradients: [[2.65809106]\n",
      " [0.87954335]]\n",
      "theta: [[4.15516587]\n",
      " [2.96403788]]\n",
      "gradients: [[-0.97188504]\n",
      " [-0.10415087]]\n",
      "theta: [[4.18097656]\n",
      " [2.96882566]]\n",
      "gradients: [[-1.68801944]\n",
      " [-0.31312089]]\n",
      "theta: [[4.18235598]\n",
      " [2.9700193 ]]\n",
      "gradients: [[-0.09048957]\n",
      " [-0.0783025 ]]\n",
      "theta: [[4.13368501]\n",
      " [2.91581985]]\n",
      "gradients: [[3.2025497]\n",
      " [3.5663238]]\n",
      "theta: [[4.08460875]\n",
      " [2.85526621]]\n",
      "gradients: [[3.23903288]\n",
      " [3.9965402 ]]\n",
      "theta: [[4.08520533]\n",
      " [2.85538315]]\n",
      "gradients: [[-0.03949341]\n",
      " [-0.00774183]]\n",
      "theta: [[4.08983169]\n",
      " [2.86263355]]\n",
      "gradients: [[-0.30719047]\n",
      " [-0.48142629]]\n",
      "theta: [[4.09704813]\n",
      " [2.87450258]]\n",
      "gradients: [[-0.48061437]\n",
      " [-0.79047729]]\n",
      "theta: [[4.07001364]\n",
      " [2.84255911]]\n",
      "gradients: [[1.80590379]\n",
      " [2.13382407]]\n",
      "theta: [[4.06231891]\n",
      " [2.8295216 ]]\n",
      "gradients: [[0.5155467 ]\n",
      " [0.87351296]]\n",
      "theta: [[4.07579623]\n",
      " [2.84374377]]\n",
      "gradients: [[-0.90567553]\n",
      " [-0.95573014]]\n",
      "theta: [[4.11817904]\n",
      " [2.89308015]]\n",
      "gradients: [[-2.85660182]\n",
      " [-3.3252716 ]]\n",
      "theta: [[4.17964891]\n",
      " [2.9751879 ]]\n",
      "gradients: [[-4.15536329]\n",
      " [-5.55048444]]\n",
      "theta: [[4.1533861 ]\n",
      " [2.93574988]]\n",
      "gradients: [[1.78061862]\n",
      " [2.67389788]]\n",
      "theta: [[4.19310258]\n",
      " [3.00838373]]\n",
      "gradients: [[-2.70072046]\n",
      " [-4.93910186]]\n",
      "theta: [[4.16971442]\n",
      " [2.99771127]]\n",
      "gradients: [[1.59507242]\n",
      " [0.72786234]]\n",
      "theta: [[4.1986088 ]\n",
      " [3.02988531]]\n",
      "gradients: [[-1.97637581]\n",
      " [-2.20070477]]\n",
      "theta: [[4.19008384]\n",
      " [3.01309631]]\n",
      "gradients: [[0.5848122 ]\n",
      " [1.15172574]]\n",
      "theta: [[4.24963501]\n",
      " [3.02269957]]\n",
      "gradients: [[-4.09712021]\n",
      " [-0.66070461]]\n",
      "theta: [[4.26036282]\n",
      " [3.0238492 ]]\n",
      "gradients: [[-0.74021915]\n",
      " [-0.07932468]]\n",
      "theta: [[4.28546209]\n",
      " [3.05179737]]\n",
      "gradients: [[-1.73686954]\n",
      " [-1.93401329]]\n",
      "theta: [[4.28168579]\n",
      " [3.04852966]]\n",
      "gradients: [[0.26207579]\n",
      " [0.22677963]]\n",
      "theta: [[4.29132058]\n",
      " [3.04956216]]\n",
      "gradients: [[-0.6705815 ]\n",
      " [-0.07186205]]\n",
      "theta: [[4.27112165]\n",
      " [3.04206981]]\n",
      "gradients: [[1.40988499]\n",
      " [0.52296542]]\n",
      "theta: [[4.25003485]\n",
      " [3.02316433]]\n",
      "gradients: [[1.47607648]\n",
      " [1.32338398]]\n",
      "theta: [[4.24110446]\n",
      " [3.01475439]]\n",
      "gradients: [[0.62691309]\n",
      " [0.5903778 ]]\n",
      "theta: [[4.29784514]\n",
      " [3.02390443]]\n",
      "gradients: [[-3.99454421]\n",
      " [-0.64416312]]\n",
      "theta: [[4.31927696]\n",
      " [3.02763182]]\n",
      "gradients: [[-1.51308609]\n",
      " [-0.2631536 ]]\n",
      "theta: [[4.30088273]\n",
      " [3.02313531]]\n",
      "gradients: [[1.30231141]\n",
      " [0.31835325]]\n",
      "theta: [[4.26510542]\n",
      " [2.99442402]]\n",
      "gradients: [[2.5401892 ]\n",
      " [2.03850102]]\n",
      "theta: [[4.2408591 ]\n",
      " [2.98335996]]\n",
      "gradients: [[1.72633793]\n",
      " [0.78776133]]\n",
      "theta: [[4.23783492]\n",
      " [2.98250259]]\n",
      "gradients: [[0.2159266 ]\n",
      " [0.06121648]]\n",
      "theta: [[4.23772148]\n",
      " [2.98247087]]\n",
      "gradients: [[0.00812169]\n",
      " [0.00227092]]\n",
      "theta: [[4.23869828]\n",
      " [2.9826216 ]]\n",
      "gradients: [[-0.0701341 ]\n",
      " [-0.01082261]]\n",
      "theta: [[4.28974157]\n",
      " [3.05080216]]\n",
      "gradients: [[-3.67511662]\n",
      " [-4.90899981]]\n",
      "theta: [[4.25408682]\n",
      " [2.97992201]]\n",
      "gradients: [[2.57427316]\n",
      " [5.11754639]]\n",
      "theta: [[4.21242176]\n",
      " [2.93575322]]\n",
      "gradients: [[3.01655026]\n",
      " [3.19782088]]\n",
      "theta: [[4.21015937]\n",
      " [2.93286543]]\n",
      "gradients: [[0.16424937]\n",
      " [0.20965311]]\n",
      "theta: [[4.18342582]\n",
      " [2.87972027]]\n",
      "gradients: [[1.9462023 ]\n",
      " [3.86896804]]\n",
      "theta: [[4.21846123]\n",
      " [2.92050377]]\n",
      "gradients: [[-2.55758463]\n",
      " [-2.97719601]]\n",
      "theta: [[4.27609948]\n",
      " [3.02428   ]]\n",
      "gradients: [[-4.21912037]\n",
      " [-7.59641943]]\n",
      "theta: [[4.28300558]\n",
      " [3.03596352]]\n",
      "gradients: [[-0.50690761]\n",
      " [-0.85757078]]\n",
      "theta: [[4.30210417]\n",
      " [3.03950623]]\n",
      "gradients: [[-1.40565618]\n",
      " [-0.26074362]]\n",
      "theta: [[4.29791357]\n",
      " [3.03262554]]\n",
      "gradients: [[0.3092663 ]\n",
      " [0.50779534]]\n",
      "theta: [[4.27885267]\n",
      " [3.02555532]]\n",
      "gradients: [[1.41050645]\n",
      " [0.52319594]]\n",
      "theta: [[4.26956626]\n",
      " [3.0168101 ]]\n",
      "gradients: [[0.68905204]\n",
      " [0.64889541]]\n",
      "theta: [[4.25560506]\n",
      " [3.00075543]]\n",
      "gradients: [[1.03871289]\n",
      " [1.19446749]]\n",
      "theta: [[4.24863004]\n",
      " [2.99800707]]\n",
      "gradients: [[0.52033675]\n",
      " [0.20502789]]\n",
      "theta: [[4.22991956]\n",
      " [2.9663051 ]]\n",
      "gradients: [[1.39954385]\n",
      " [2.37130736]]\n",
      "theta: [[4.22599074]\n",
      " [2.96553494]]\n",
      "gradients: [[0.29466177]\n",
      " [0.0577621 ]]\n",
      "theta: [[4.2115575]\n",
      " [2.9620067]]\n",
      "gradients: [[1.08537949]\n",
      " [0.2653237 ]]\n",
      "theta: [[4.2610192]\n",
      " [2.9658866]]\n",
      "gradients: [[-3.72941246]\n",
      " [-0.29254446]]\n",
      "theta: [[4.22523814]\n",
      " [2.92749391]]\n",
      "gradients: [[2.70504851]\n",
      " [2.90248671]]\n",
      "theta: [[4.22519126]\n",
      " [2.92741682]]\n",
      "gradients: [[0.00355312]\n",
      " [0.00584389]]\n",
      "theta: [[4.20433131]\n",
      " [2.91789802]]\n",
      "gradients: [[1.58535626]\n",
      " [0.72342867]]\n",
      "theta: [[4.23169203]\n",
      " [2.94836433]]\n",
      "gradients: [[-2.08488696]\n",
      " [-2.3215325 ]]\n",
      "theta: [[4.22736241]\n",
      " [2.9451072 ]]\n",
      "gradients: [[0.33078311]\n",
      " [0.24884463]]\n",
      "theta: [[4.22869901]\n",
      " [2.94531345]]\n",
      "gradients: [[-0.10238366]\n",
      " [-0.01579914]]\n",
      "theta: [[4.22916432]\n",
      " [2.9457161 ]]\n",
      "gradients: [[-0.03573588]\n",
      " [-0.030923  ]]\n",
      "theta: [[4.20289684]\n",
      " [2.91686481]]\n",
      "gradients: [[2.02259644]\n",
      " [2.22154896]]\n",
      "theta: [[4.20303459]\n",
      " [2.91692172]]\n",
      "gradients: [[-0.0106348 ]\n",
      " [-0.00439322]]\n",
      "theta: [[4.20017244]\n",
      " [2.91636065]]\n",
      "gradients: [[0.22153073]\n",
      " [0.04342633]]\n",
      "theta: [[4.24861759]\n",
      " [2.92016081]]\n",
      "gradients: [[-3.75934376]\n",
      " [-0.29489234]]\n",
      "theta: [[4.21161364]\n",
      " [2.88093322]]\n",
      "gradients: [[2.87890706]\n",
      " [3.05190642]]\n",
      "theta: [[4.15529091]\n",
      " [2.79279656]]\n",
      "gradients: [[4.39317347]\n",
      " [6.87465945]]\n",
      "theta: [[4.1848005 ]\n",
      " [2.82708873]]\n",
      "gradients: [[-2.30765009]\n",
      " [-2.68164717]]\n",
      "theta: [[4.17773719]\n",
      " [2.82596498]]\n",
      "gradients: [[0.55376325]\n",
      " [0.08810163]]\n",
      "theta: [[4.18688672]\n",
      " [2.83652205]]\n",
      "gradients: [[-0.71915277]\n",
      " [-0.82978592]]\n",
      "theta: [[4.20364585]\n",
      " [2.86487464]]\n",
      "gradients: [[-1.32061941]\n",
      " [-2.23418347]]\n",
      "theta: [[4.19282323]\n",
      " [2.86410035]]\n",
      "gradients: [[0.85498662]\n",
      " [0.06116839]]\n",
      "theta: [[4.1962851 ]\n",
      " [2.86543804]]\n",
      "gradients: [[-0.27417952]\n",
      " [-0.10594476]]\n",
      "theta: [[4.19596423]\n",
      " [2.86505613]]\n",
      "gradients: [[0.02547644]\n",
      " [0.03032338]]\n",
      "theta: [[4.20122324]\n",
      " [2.87277113]]\n",
      "gradients: [[-0.41861693]\n",
      " [-0.6141137 ]]\n",
      "theta: [[4.1972314 ]\n",
      " [2.87236016]]\n",
      "gradients: [[0.31854895]\n",
      " [0.03279538]]\n",
      "theta: [[4.20046865]\n",
      " [2.87361105]]\n",
      "gradients: [[-0.25897991]\n",
      " [-0.10007152]]\n",
      "theta: [[4.22241524]\n",
      " [2.87742797]]\n",
      "gradients: [[-1.76011667]\n",
      " [-0.30611678]]\n",
      "theta: [[4.20892337]\n",
      " [2.87554606]]\n",
      "gradients: [[1.08474659]\n",
      " [0.15130562]]\n",
      "theta: [[4.17499358]\n",
      " [2.82037772]]\n",
      "gradients: [[2.73474081]\n",
      " [4.44656821]]\n",
      "theta: [[4.17653285]\n",
      " [2.82220984]]\n",
      "gradients: [[-0.12437283]\n",
      " [-0.14803497]]\n",
      "theta: [[4.18289393]\n",
      " [2.82248197]]\n",
      "gradients: [[-0.51524744]\n",
      " [-0.02204269]]\n",
      "theta: [[4.13935598]\n",
      " [2.81010936]]\n",
      "gradients: [[3.53528153]\n",
      " [1.00465589]]\n",
      "theta: [[4.19801514]\n",
      " [2.91572369]]\n",
      "gradients: [[-4.77485557]\n",
      " [-8.5970066 ]]\n",
      "theta: [[4.17938361]\n",
      " [2.90722177]]\n",
      "gradients: [[1.5203324 ]\n",
      " [0.69375703]]\n",
      "theta: [[4.18259277]\n",
      " [2.90724097]]\n",
      "gradients: [[-0.26250936]\n",
      " [-0.00157057]]\n",
      "theta: [[4.14698354]\n",
      " [2.86792765]]\n",
      "gradients: [[2.91995668]\n",
      " [3.22369151]]\n",
      "theta: [[4.10534853]\n",
      " [2.80745399]]\n",
      "gradients: [[3.42239803]\n",
      " [4.97093493]]\n",
      "theta: [[4.08346804]\n",
      " [2.78989491]]\n",
      "gradients: [[1.80295243]\n",
      " [1.44686875]]\n",
      "theta: [[4.09559423]\n",
      " [2.81321773]]\n",
      "gradients: [[-1.00162328]\n",
      " [-1.92646541]]\n",
      "theta: [[4.11851686]\n",
      " [2.81871121]]\n",
      "gradients: [[-1.89799397]\n",
      " [-0.45486006]]\n",
      "theta: [[4.14189795]\n",
      " [2.84141632]]\n",
      "gradients: [[-1.94062976]\n",
      " [-1.88452379]]\n",
      "theta: [[4.1407578 ]\n",
      " [2.84077761]]\n",
      "gradients: [[0.09485998]\n",
      " [0.05314026]]\n",
      "theta: [[4.13750624]\n",
      " [2.83480112]]\n",
      "gradients: [[0.27118052]\n",
      " [0.49843987]]\n",
      "theta: [[4.10347052]\n",
      " [2.82685822]]\n",
      "gradients: [[2.84538558]\n",
      " [0.66402593]]\n",
      "theta: [[4.07478265]\n",
      " [2.81736561]]\n",
      "gradients: [[2.40404406]\n",
      " [0.79548101]]\n",
      "theta: [[4.06668171]\n",
      " [2.81010267]]\n",
      "gradients: [[0.68047903]\n",
      " [0.61008699]]\n",
      "theta: [[4.06835727]\n",
      " [2.81168059]]\n",
      "gradients: [[-0.14108286]\n",
      " [-0.13286082]]\n",
      "theta: [[4.08195919]\n",
      " [2.81313822]]\n",
      "gradients: [[-1.1480018 ]\n",
      " [-0.12302421]]\n",
      "theta: [[4.13962754]\n",
      " [2.91696862]]\n",
      "gradients: [[-4.87874236]\n",
      " [-8.78405214]]\n",
      "theta: [[4.14201304]\n",
      " [2.92089211]]\n",
      "gradients: [[-0.20229044]\n",
      " [-0.33271164]]\n",
      "theta: [[4.18760071]\n",
      " [2.92446812]]\n",
      "gradients: [[-3.87495163]\n",
      " [-0.30396091]]\n",
      "theta: [[4.1417792 ]\n",
      " [2.90878828]]\n",
      "gradients: [[3.90399239]\n",
      " [1.33592206]]\n",
      "theta: [[4.13143368]\n",
      " [2.89125942]]\n",
      "gradients: [[0.88350773]\n",
      " [1.49696515]]\n",
      "theta: [[4.09802723]\n",
      " [2.88346338]]\n",
      "gradients: [[2.85959175]\n",
      " [0.66734122]]\n",
      "theta: [[4.12081697]\n",
      " [2.89413648]]\n",
      "gradients: [[-1.95535933]\n",
      " [-0.91575248]]\n",
      "theta: [[4.11432599]\n",
      " [2.8914645 ]]\n",
      "gradients: [[0.55822396]\n",
      " [0.22979044]]\n",
      "theta: [[4.11420487]\n",
      " [2.89137338]]\n",
      "gradients: [[0.01044076]\n",
      " [0.00785447]]\n",
      "theta: [[4.1163095 ]\n",
      " [2.89290639]]\n",
      "gradients: [[-0.18184016]\n",
      " [-0.13245165]]\n",
      "theta: [[4.11513892]\n",
      " [2.89225063]]\n",
      "gradients: [[0.10137223]\n",
      " [0.0567884 ]]\n",
      "theta: [[4.12250917]\n",
      " [2.89995487]]\n",
      "gradients: [[-0.63973747]\n",
      " [-0.66872811]]\n",
      "theta: [[4.17406112]\n",
      " [2.99277286]]\n",
      "gradients: [[-4.48502004]\n",
      " [-8.07516507]]\n",
      "theta: [[4.17412524]\n",
      " [2.99279935]]\n",
      "gradients: [[-0.00559122]\n",
      " [-0.00230973]]\n",
      "theta: [[4.17089291]\n",
      " [2.9903677 ]]\n",
      "gradients: [[0.28250552]\n",
      " [0.21252591]]\n",
      "theta: [[4.17002819]\n",
      " [2.98973784]]\n",
      "gradients: [[0.07575008]\n",
      " [0.05517605]]\n",
      "theta: [[4.14946924]\n",
      " [2.95886513]]\n",
      "gradients: [[1.80507551]\n",
      " [2.710624  ]]\n",
      "theta: [[4.15243309]\n",
      " [2.96373157]]\n",
      "gradients: [[-0.26081857]\n",
      " [-0.42824729]]\n",
      "theta: [[4.14971542]\n",
      " [2.96345178]]\n",
      "gradients: [[0.23969784]\n",
      " [0.02467747]]\n",
      "theta: [[4.10610794]\n",
      " [2.94852957]]\n",
      "gradients: [[3.85490176]\n",
      " [1.31912355]]\n",
      "theta: [[4.11788187]\n",
      " [2.94979131]]\n",
      "gradients: [[-1.04316997]\n",
      " [-0.11179003]]\n",
      "theta: [[4.12191159]\n",
      " [2.95134842]]\n",
      "gradients: [[-0.35783917]\n",
      " [-0.13827139]]\n",
      "theta: [[4.10617408]\n",
      " [2.94416709]]\n",
      "gradients: [[1.40063781]\n",
      " [0.63913807]]\n",
      "theta: [[4.09978251]\n",
      " [2.94153603]]\n",
      "gradients: [[0.57012795]\n",
      " [0.23469066]]\n",
      "theta: [[4.06360031]\n",
      " [2.89689196]]\n",
      "gradients: [[3.23468866]\n",
      " [3.99118001]]\n",
      "theta: [[4.07881157]\n",
      " [2.92262589]]\n",
      "gradients: [[-1.3629283 ]\n",
      " [-2.30576036]]\n",
      "theta: [[4.06043105]\n",
      " [2.91190731]]\n",
      "gradients: [[1.65057039]\n",
      " [0.96252853]]\n",
      "theta: [[4.0633141 ]\n",
      " [2.91400731]]\n",
      "gradients: [[-0.25947412]\n",
      " [-0.18899992]]\n",
      "theta: [[4.08571293]\n",
      " [2.91790288]]\n",
      "gradients: [[-2.02037446]\n",
      " [-0.35138041]]\n",
      "theta: [[4.09129619]\n",
      " [2.92864141]]\n",
      "gradients: [[-0.50472695]\n",
      " [-0.97076319]]\n",
      "theta: [[4.12867072]\n",
      " [2.98186507]]\n",
      "gradients: [[-3.3861329 ]\n",
      " [-4.82206366]]\n",
      "theta: [[4.12877312]\n",
      " [2.98189411]]\n",
      "gradients: [[-0.00929777]\n",
      " [-0.00263597]]\n",
      "theta: [[4.12540324]\n",
      " [2.97872061]]\n",
      "gradients: [[0.30665949]\n",
      " [0.28878796]]\n",
      "theta: [[4.09132403]\n",
      " [2.94077039]]\n",
      "gradients: [[3.10802359]\n",
      " [3.46106057]]\n",
      "theta: [[4.0438419 ]\n",
      " [2.86646795]]\n",
      "gradients: [[4.33986666]\n",
      " [6.79124227]]\n",
      "theta: [[4.03042467]\n",
      " [2.84814082]]\n",
      "gradients: [[1.22901878]\n",
      " [1.67876539]]\n",
      "theta: [[4.0535581 ]\n",
      " [2.85897489]]\n",
      "gradients: [[-2.12364965]\n",
      " [-0.99456781]]\n",
      "theta: [[4.05873827]\n",
      " [2.85977426]]\n",
      "gradients: [[-0.47657495]\n",
      " [-0.07354175]]\n",
      "theta: [[4.08167485]\n",
      " [2.8699748 ]]\n",
      "gradients: [[-2.11475271]\n",
      " [-0.9404897 ]]\n",
      "theta: [[4.08167453]\n",
      " [2.86997436]]\n",
      "gradients: [[2.95736210e-05]\n",
      " [4.08978481e-05]]\n",
      "theta: [[4.07816241]\n",
      " [2.8659356 ]]\n",
      "gradients: [[0.32522201]\n",
      " [0.37398892]]\n",
      "theta: [[4.08491206]\n",
      " [2.87520207]]\n",
      "gradients: [[-0.62636724]\n",
      " [-0.85992855]]\n",
      "theta: [[4.10065878]\n",
      " [2.87797801]]\n",
      "gradients: [[-1.46444504]\n",
      " [-0.2581627 ]]\n",
      "theta: [[4.06415285]\n",
      " [2.86760376]]\n",
      "gradients: [[3.40235295]\n",
      " [0.96688026]]\n",
      "theta: [[4.07209002]\n",
      " [2.88286967]]\n",
      "gradients: [[-0.74133207]\n",
      " [-1.42583605]]\n",
      "theta: [[4.06900692]\n",
      " [2.87720281]]\n",
      "gradients: [[0.28857849]\n",
      " [0.53041799]]\n",
      "theta: [[4.10866059]\n",
      " [2.91660069]]\n",
      "gradients: [[-3.71951504]\n",
      " [-3.69552055]]\n",
      "theta: [[4.13908838]\n",
      " [2.9722473 ]]\n",
      "gradients: [[-2.86021192]\n",
      " [-5.23078128]]\n",
      "theta: [[4.15833754]\n",
      " [2.99945637]]\n",
      "gradients: [[-1.81327075]\n",
      " [-2.56309495]]\n",
      "theta: [[4.13821858]\n",
      " [2.98772402]]\n",
      "gradients: [[1.89922957]\n",
      " [1.10753389]]\n",
      "theta: [[4.13973337]\n",
      " [2.9890348 ]]\n",
      "gradients: [[-0.14329924]\n",
      " [-0.12399982]]\n",
      "theta: [[4.15776724]\n",
      " [2.99238001]]\n",
      "gradients: [[-1.70961078]\n",
      " [-0.31712599]]\n",
      "theta: [[4.14868828]\n",
      " [2.97569255]]\n",
      "gradients: [[0.86250108]\n",
      " [1.58530902]]\n",
      "theta: [[4.14153376]\n",
      " [2.97274742]]\n",
      "gradients: [[0.68111099]\n",
      " [0.28037634]]\n",
      "theta: [[4.13158014]\n",
      " [2.97135904]]\n",
      "gradients: [[0.94957485]\n",
      " [0.13245122]]\n",
      "theta: [[4.10872988]\n",
      " [2.92832544]]\n",
      "gradients: [[2.18448487]\n",
      " [4.11401231]]\n",
      "theta: [[4.11294245]\n",
      " [2.92835064]]\n",
      "gradients: [[-0.40356429]\n",
      " [-0.00241449]]\n",
      "theta: [[4.09247428]\n",
      " [2.90416582]]\n",
      "gradients: [[1.96494429]\n",
      " [2.32174352]]\n",
      "theta: [[4.08382227]\n",
      " [2.90295899]]\n",
      "gradients: [[0.83232372]\n",
      " [0.11609648]]\n",
      "theta: [[4.08311596]\n",
      " [2.90229385]]\n",
      "gradients: [[0.06808793]\n",
      " [0.0641199 ]]\n",
      "theta: [[4.09205345]\n",
      " [2.90338177]]\n",
      "gradients: [[-0.86336117]\n",
      " [-0.10509336]]\n",
      "theta: [[4.08272591]\n",
      " [2.89992193]]\n",
      "gradients: [[0.90290602]\n",
      " [0.33491287]]\n",
      "theta: [[4.06663978]\n",
      " [2.86794338]]\n",
      "gradients: [[1.56035478]\n",
      " [3.10191945]]\n",
      "theta: [[4.06145172]\n",
      " [2.86656266]]\n",
      "gradients: [[0.50427882]\n",
      " [0.13420524]]\n",
      "theta: [[4.07026114]\n",
      " [2.87672731]]\n",
      "gradients: [[-0.8580374 ]\n",
      " [-0.99003631]]\n",
      "theta: [[4.0913616 ]\n",
      " [2.91558787]]\n",
      "gradients: [[-2.05940521]\n",
      " [-3.79279121]]\n",
      "theta: [[4.06279048]\n",
      " [2.89093335]]\n",
      "gradients: [[2.79425628]\n",
      " [2.41121242]]\n",
      "theta: [[4.03783859]\n",
      " [2.86448205]]\n",
      "gradients: [[2.44528523]\n",
      " [2.59222738]]\n",
      "theta: [[4.02255537]\n",
      " [2.85556966]]\n",
      "gradients: [[1.50081137]\n",
      " [0.8751967 ]]\n",
      "theta: [[4.06446711]\n",
      " [2.85885732]]\n",
      "gradients: [[-4.12411508]\n",
      " [-0.32350592]]\n",
      "theta: [[4.06501159]\n",
      " [2.85937007]]\n",
      "gradients: [[-0.0536854 ]\n",
      " [-0.05055671]]\n",
      "theta: [[4.08809391]\n",
      " [2.89199739]]\n",
      "gradients: [[-2.28053283]\n",
      " [-3.22357938]]\n",
      "theta: [[4.08416753]\n",
      " [2.88748225]]\n",
      "gradients: [[0.38871152]\n",
      " [0.44699867]]\n",
      "theta: [[4.07485278]\n",
      " [2.88316342]]\n",
      "gradients: [[0.92402323]\n",
      " [0.42842761]]\n",
      "theta: [[4.09921091]\n",
      " [2.91028633]]\n",
      "gradients: [[-2.42119833]\n",
      " [-2.69601698]]\n",
      "theta: [[4.07649891]\n",
      " [2.88591661]]\n",
      "gradients: [[2.262115  ]\n",
      " [2.42722402]]\n",
      "theta: [[4.07876815]\n",
      " [2.89038563]]\n",
      "gradients: [[-0.22646982]\n",
      " [-0.44600834]]\n",
      "theta: [[4.05799774]\n",
      " [2.85907885]]\n",
      "gradients: [[2.07704122]\n",
      " [3.13067863]]\n",
      "theta: [[4.02206924]\n",
      " [2.84678434]]\n",
      "gradients: [[3.60003484]\n",
      " [1.23190967]]\n",
      "theta: [[3.99961478]\n",
      " [2.83935432]]\n",
      "gradients: [[2.25442832]\n",
      " [0.74597423]]\n",
      "theta: [[4.00637144]\n",
      " [2.84196514]]\n",
      "gradients: [[-0.67972049]\n",
      " [-0.26264843]]\n",
      "theta: [[4.01291162]\n",
      " [2.84762449]]\n",
      "gradients: [[-0.65924991]\n",
      " [-0.57046266]]\n",
      "theta: [[4.02475352]\n",
      " [2.86491391]]\n",
      "gradients: [[-1.19603156]\n",
      " [-1.74623132]]\n",
      "theta: [[4.05654281]\n",
      " [2.92305045]]\n",
      "gradients: [[-3.21707657]\n",
      " [-5.88341855]]\n",
      "theta: [[4.04938588]\n",
      " [2.92130092]]\n",
      "gradients: [[0.72571277]\n",
      " [0.17740228]]\n",
      "theta: [[4.01609603]\n",
      " [2.87294837]]\n",
      "gradients: [[3.38224899]\n",
      " [4.9126196 ]]\n",
      "theta: [[3.99139518]\n",
      " [2.85195138]]\n",
      "gradients: [[2.5145465]\n",
      " [2.1374938]]\n",
      "theta: [[3.96134801]\n",
      " [2.80830873]]\n",
      "gradients: [[3.06481113]\n",
      " [4.45155022]]\n",
      "theta: [[3.9478639 ]\n",
      " [2.79237614]]\n",
      "gradients: [[1.37807659]\n",
      " [1.62831099]]\n",
      "theta: [[3.9228369 ]\n",
      " [2.76149612]]\n",
      "gradients: [[2.56276407]\n",
      " [3.16211351]]\n",
      "theta: [[3.94066034]\n",
      " [2.76463816]]\n",
      "gradients: [[-1.82868512]\n",
      " [-0.3223735 ]]\n",
      "theta: [[3.95015292]\n",
      " [2.78333279]]\n",
      "gradients: [[-0.97583709]\n",
      " [-1.92180787]]\n",
      "theta: [[3.95269573]\n",
      " [2.78433473]]\n",
      "gradients: [[-0.26190928]\n",
      " [-0.10319991]]\n",
      "theta: [[3.92311042]\n",
      " [2.77592718]]\n",
      "gradients: [[3.05320378]\n",
      " [0.8676591 ]]\n",
      "theta: [[3.95019197]\n",
      " [2.81420749]]\n",
      "gradients: [[-2.80023158]\n",
      " [-3.95818409]]\n",
      "theta: [[3.96041737]\n",
      " [2.82920823]]\n",
      "gradients: [[-1.05935202]\n",
      " [-1.55407615]]\n",
      "theta: [[3.97111236]\n",
      " [2.84049431]]\n",
      "gradients: [[-1.11013999]\n",
      " [-1.17149487]]\n",
      "theta: [[3.97529476]\n",
      " [2.84433079]]\n",
      "gradients: [[-0.43496973]\n",
      " [-0.39899409]]\n",
      "theta: [[3.93876903]\n",
      " [2.78717348]]\n",
      "gradients: [[3.80598104]\n",
      " [5.95579111]]\n",
      "theta: [[3.94532564]\n",
      " [2.79194929]]\n",
      "gradients: [[-0.68450941]\n",
      " [-0.49859394]]\n",
      "theta: [[3.92906946]\n",
      " [2.77450659]]\n",
      "gradients: [[1.70039582]\n",
      " [1.82450564]]\n",
      "theta: [[3.96066535]\n",
      " [2.81128627]]\n",
      "gradients: [[-3.31124856]\n",
      " [-3.85451018]]\n",
      "theta: [[3.97406185]\n",
      " [2.83084546]]\n",
      "gradients: [[-1.40663323]\n",
      " [-2.05371421]]\n",
      "theta: [[4.01112589]\n",
      " [2.88362695]]\n",
      "gradients: [[-3.89913661]\n",
      " [-5.55261283]]\n",
      "theta: [[3.98080057]\n",
      " [2.8395803 ]]\n",
      "gradients: [[3.19628826]\n",
      " [4.64251698]]\n",
      "theta: [[3.99327345]\n",
      " [2.84091694]]\n",
      "gradients: [[-1.31713553]\n",
      " [-0.14114922]]\n",
      "theta: [[4.03054269]\n",
      " [2.87794575]]\n",
      "gradients: [[-3.94308557]\n",
      " [-3.91764883]]\n",
      "theta: [[4.05033949]\n",
      " [2.88138878]]\n",
      "gradients: [[-2.09846082]\n",
      " [-0.36496107]]\n",
      "theta: [[4.06875595]\n",
      " [2.88580234]]\n",
      "gradients: [[-1.95582866]\n",
      " [-0.46872032]]\n",
      "theta: [[4.06361197]\n",
      " [2.88166912]]\n",
      "gradients: [[0.54731976]\n",
      " [0.43977461]]\n",
      "theta: [[4.08288496]\n",
      " [2.91716405]]\n",
      "gradients: [[-2.05450093]\n",
      " [-3.78375904]]\n",
      "theta: [[4.08230724]\n",
      " [2.91684041]]\n",
      "gradients: [[0.06170129]\n",
      " [0.03456487]]\n",
      "theta: [[4.1072923 ]\n",
      " [2.94592465]]\n",
      "gradients: [[-2.67340125]\n",
      " [-3.11201414]]\n",
      "theta: [[4.12418586]\n",
      " [2.94997325]]\n",
      "gradients: [[-1.81099061]\n",
      " [-0.43400944]]\n",
      "theta: [[4.10722133]\n",
      " [2.93133999]]\n",
      "gradients: [[1.82199134]\n",
      " [2.00121136]]\n",
      "theta: [[4.10814883]\n",
      " [2.93198651]]\n",
      "gradients: [[-0.09979923]\n",
      " [-0.06956486]]\n",
      "theta: [[4.10041883]\n",
      " [2.93009689]]\n",
      "gradients: [[0.83329368]\n",
      " [0.2037007 ]]\n",
      "theta: [[4.11807528]\n",
      " [2.93836593]]\n",
      "gradients: [[-1.90689642]\n",
      " [-0.89305587]]\n",
      "theta: [[4.08625243]\n",
      " [2.90736133]]\n",
      "gradients: [[3.44323191]\n",
      " [3.35469796]]\n",
      "theta: [[4.06109061]\n",
      " [2.87958216]]\n",
      "gradients: [[2.72754176]\n",
      " [3.01126153]]\n",
      "theta: [[4.08163605]\n",
      " [2.90862355]]\n",
      "gradients: [[-2.23123438]\n",
      " [-3.15389503]]\n",
      "theta: [[4.05785175]\n",
      " [2.86995133]]\n",
      "gradients: [[2.58773125]\n",
      " [4.20753715]]\n",
      "theta: [[4.06211414]\n",
      " [2.87060908]]\n",
      "gradients: [[-0.46460004]\n",
      " [-0.07169386]]\n",
      "theta: [[4.06500363]\n",
      " [2.87629962]]\n",
      "gradients: [[-0.31553251]\n",
      " [-0.62140788]]\n",
      "theta: [[4.04108719]\n",
      " [2.84989539]]\n",
      "gradients: [[2.61645865]\n",
      " [2.88862352]]\n",
      "theta: [[4.04870968]\n",
      " [2.86241103]]\n",
      "gradients: [[-0.83542526]\n",
      " [-1.37171446]]\n",
      "theta: [[4.04650661]\n",
      " [2.85987761]]\n",
      "gradients: [[0.24189743]\n",
      " [0.27816986]]\n",
      "theta: [[4.02329619]\n",
      " [2.84014756]]\n",
      "gradients: [[2.55314602]\n",
      " [2.17030538]]\n",
      "theta: [[4.03551009]\n",
      " [2.84661017]]\n",
      "gradients: [[-1.34597155]\n",
      " [-0.71217985]]\n",
      "theta: [[4.03172525]\n",
      " [2.84356903]]\n",
      "gradients: [[0.41784575]\n",
      " [0.33574149]]\n",
      "theta: [[4.07575446]\n",
      " [2.92284251]]\n",
      "gradients: [[-4.86963042]\n",
      " [-8.76764632]]\n",
      "theta: [[4.11330593]\n",
      " [2.9730015 ]]\n",
      "gradients: [[-4.16070291]\n",
      " [-5.55761677]]\n",
      "theta: [[4.15171681]\n",
      " [2.97919567]]\n",
      "gradients: [[-4.26360747]\n",
      " [-0.68755246]]\n",
      "theta: [[4.15988423]\n",
      " [2.99301307]]\n",
      "gradients: [[-0.90821752]\n",
      " [-1.53649458]]\n",
      "theta: [[4.164171  ]\n",
      " [2.99927183]]\n",
      "gradients: [[-0.47754554]\n",
      " [-0.69722657]]\n",
      "theta: [[4.15610072]\n",
      " [2.98443836]]\n",
      "gradients: [[0.90064344]\n",
      " [1.6554161 ]]\n",
      "theta: [[4.15885699]\n",
      " [2.98445485]]\n",
      "gradients: [[-0.30815119]\n",
      " [-0.00184364]]\n",
      "theta: [[4.14056491]\n",
      " [2.94809097]]\n",
      "gradients: [[2.0487127 ]\n",
      " [4.07275438]]\n",
      "theta: [[4.14501178]\n",
      " [2.95278361]]\n",
      "gradients: [[-0.49893868]\n",
      " [-0.52651387]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: [[4.1321279 ]\n",
      " [2.94690444]]\n",
      "gradients: [[1.448148  ]\n",
      " [0.66081789]]\n",
      "theta: [[4.12780692]\n",
      " [2.94621699]]\n",
      "gradients: [[0.4865425 ]\n",
      " [0.07740707]]\n",
      "theta: [[4.13225353]\n",
      " [2.95086511]]\n",
      "gradients: [[-0.50157762]\n",
      " [-0.52430735]]\n",
      "theta: [[4.13277632]\n",
      " [2.95124591]]\n",
      "gradients: [[-0.05907576]\n",
      " [-0.04303055]]\n",
      "theta: [[4.12361971]\n",
      " [2.9430365 ]]\n",
      "gradients: [[1.03652853]\n",
      " [0.929305  ]]\n",
      "theta: [[4.15254817]\n",
      " [2.98423242]]\n",
      "gradients: [[-3.28048686]\n",
      " [-4.67161714]]\n",
      "theta: [[4.14607259]\n",
      " [2.97919656]]\n",
      "gradients: [[0.73562487]\n",
      " [0.57207335]]\n",
      "theta: [[4.1456805 ]\n",
      " [2.97892325]]\n",
      "gradients: [[0.04461995]\n",
      " [0.03110225]]\n",
      "theta: [[4.13935216]\n",
      " [2.97723907]]\n",
      "gradients: [[0.7214311 ]\n",
      " [0.19199662]]\n",
      "theta: [[4.14297415]\n",
      " [2.9810252 ]]\n",
      "gradients: [[-0.41363135]\n",
      " [-0.43237566]]\n",
      "theta: [[4.14545244]\n",
      " [2.98198283]]\n",
      "gradients: [[-0.28351664]\n",
      " [-0.10955268]]\n",
      "theta: [[4.14914951]\n",
      " [2.98624864]]\n",
      "gradients: [[-0.42368357]\n",
      " [-0.48886228]]\n",
      "theta: [[4.14885207]\n",
      " [2.98616432]]\n",
      "gradients: [[0.03414534]\n",
      " [0.00968041]]\n",
      "theta: [[4.15165753]\n",
      " [2.9861811 ]]\n",
      "gradients: [[-0.32262782]\n",
      " [-0.00193026]]\n",
      "theta: [[4.15108872]\n",
      " [2.98578462]]\n",
      "gradients: [[0.06552695]\n",
      " [0.04567543]]\n",
      "theta: [[4.15255475]\n",
      " [2.98819174]]\n",
      "gradients: [[-0.16917947]\n",
      " [-0.27778179]]\n",
      "theta: [[4.14588996]\n",
      " [2.98771492]]\n",
      "gradients: [[0.7704494 ]\n",
      " [0.05512033]]\n",
      "theta: [[4.16770036]\n",
      " [3.02760198]]\n",
      "gradients: [[-2.52564449]\n",
      " [-4.61892136]]\n",
      "theta: [[4.182977  ]\n",
      " [3.03025886]]\n",
      "gradients: [[-1.77208951]\n",
      " [-0.30819908]]\n",
      "theta: [[4.18714703]\n",
      " [3.03043726]]\n",
      "gradients: [[-0.48455813]\n",
      " [-0.02072978]]\n",
      "theta: [[4.17608802]\n",
      " [3.02052225]]\n",
      "gradients: [[1.28726879]\n",
      " [1.15410747]]\n",
      "theta: [[4.19533721]\n",
      " [3.04292956]]\n",
      "gradients: [[-2.24445477]\n",
      " [-2.61269235]]\n",
      "theta: [[4.22808138]\n",
      " [3.10188461]]\n",
      "gradients: [[-3.82451935]\n",
      " [-6.88595029]]\n",
      "theta: [[4.2200148 ]\n",
      " [3.09856404]]\n",
      "gradients: [[0.94378999]\n",
      " [0.388507  ]]\n",
      "theta: [[4.2512607 ]\n",
      " [3.15681738]]\n",
      "gradients: [[-3.66202013]\n",
      " [-6.82729095]]\n",
      "theta: [[4.25693129]\n",
      " [3.16726085]]\n",
      "gradients: [[-0.6657265 ]\n",
      " [-1.22606354]]\n",
      "theta: [[4.22394392]\n",
      " [3.1578865 ]]\n",
      "gradients: [[3.87931469]\n",
      " [1.1024232 ]]\n",
      "theta: [[4.18928584]\n",
      " [3.12411957]]\n",
      "gradients: [[4.08272151]\n",
      " [3.9777447 ]]\n",
      "theta: [[4.21160285]\n",
      " [3.15590038]]\n",
      "gradients: [[-2.63340752]\n",
      " [-3.75013594]]\n",
      "theta: [[4.23597277]\n",
      " [3.18011308]]\n",
      "gradients: [[-2.88052377]\n",
      " [-2.86194159]]\n",
      "theta: [[4.21511026]\n",
      " [3.15161616]]\n",
      "gradients: [[2.4701211 ]\n",
      " [3.37403617]]\n",
      "theta: [[4.2217008 ]\n",
      " [3.15232242]]\n",
      "gradients: [[-0.78163828]\n",
      " [-0.08376331]]\n",
      "theta: [[4.20152642]\n",
      " [3.1220272 ]]\n",
      "gradients: [[2.39671685]\n",
      " [3.59907283]]\n",
      "theta: [[4.19971224]\n",
      " [3.12151287]]\n",
      "gradients: [[0.21588722]\n",
      " [0.06120532]]\n",
      "theta: [[4.21036696]\n",
      " [3.13657354]]\n",
      "gradients: [[-1.27004321]\n",
      " [-1.79523182]]\n",
      "theta: [[4.20565599]\n",
      " [3.13393447]]\n",
      "gradients: [[0.56249028]\n",
      " [0.31510526]]\n",
      "theta: [[4.18634661]\n",
      " [3.10493819]]\n",
      "gradients: [[2.30940201]\n",
      " [3.46795493]]\n",
      "theta: [[4.17524452]\n",
      " [3.09979065]]\n",
      "gradients: [[1.33003027]\n",
      " [0.61667463]]\n",
      "theta: [[4.19242447]\n",
      " [3.11978924]]\n",
      "gradients: [[-2.06159456]\n",
      " [-2.39983108]]\n",
      "theta: [[4.16283836]\n",
      " [3.08684248]]\n",
      "gradients: [[3.55625099]\n",
      " [3.96020163]]\n",
      "theta: [[4.17771902]\n",
      " [3.10341217]]\n",
      "gradients: [[-1.7916318 ]\n",
      " [-1.99499135]]\n",
      "theta: [[4.17367932]\n",
      " [3.09676798]]\n",
      "gradients: [[0.48718833]\n",
      " [0.80128962]]\n",
      "theta: [[4.14061583]\n",
      " [3.08545386]]\n",
      "gradients: [[3.9940695 ]\n",
      " [1.36674589]]\n",
      "theta: [[4.17510111]\n",
      " [3.09101498]]\n",
      "gradients: [[-4.17271938]\n",
      " [-0.67289578]]\n",
      "theta: [[4.16513248]\n",
      " [3.08731734]]\n",
      "gradients: [[1.20819806]\n",
      " [0.44815415]]\n",
      "theta: [[4.13360374]\n",
      " [3.05659928]]\n",
      "gradients: [[3.82758932]\n",
      " [3.72917259]]\n",
      "theta: [[4.13247355]\n",
      " [3.05637773]]\n",
      "gradients: [[0.13743058]\n",
      " [0.02694031]]\n",
      "theta: [[4.14319148]\n",
      " [3.05826716]]\n",
      "gradients: [[-1.30544421]\n",
      " [-0.23013291]]\n",
      "theta: [[4.17742375]\n",
      " [3.06378748]]\n",
      "gradients: [[-4.17633636]\n",
      " [-0.67347906]]\n",
      "theta: [[4.17425433]\n",
      " [3.0608802 ]]\n",
      "gradients: [[0.38730297]\n",
      " [0.35526977]]\n",
      "theta: [[4.20786028]\n",
      " [3.06629952]]\n",
      "gradients: [[-4.11336791]\n",
      " [-0.66332472]]\n",
      "theta: [[4.20397366]\n",
      " [3.06476808]]\n",
      "gradients: [[0.47649975]\n",
      " [0.18775483]]\n",
      "theta: [[4.21005602]\n",
      " [3.06798638]]\n",
      "gradients: [[-0.74691441]\n",
      " [-0.39520701]]\n",
      "theta: [[4.20742498]\n",
      " [3.06468039]]\n",
      "gradients: [[0.32361775]\n",
      " [0.40663616]]\n",
      "theta: [[4.20239344]\n",
      " [3.05994207]]\n",
      "gradients: [[0.61988653]\n",
      " [0.58376073]]\n",
      "theta: [[4.16240173]\n",
      " [2.99736103]]\n",
      "gradients: [[4.93497721]\n",
      " [7.72250127]]\n",
      "theta: [[4.14108504]\n",
      " [2.99030748]]\n",
      "gradients: [[2.63474279]\n",
      " [0.87181757]]\n",
      "theta: [[4.16197485]\n",
      " [3.00065123]]\n",
      "gradients: [[-2.58615885]\n",
      " [-1.28055545]]\n",
      "theta: [[4.14115579]\n",
      " [2.97831261]]\n",
      "gradients: [[2.58156393]\n",
      " [2.76998913]]\n",
      "theta: [[4.12633931]\n",
      " [2.96967239]]\n",
      "gradients: [[1.84020613]\n",
      " [1.07311443]]\n",
      "theta: [[4.11858323]\n",
      " [2.95786158]]\n",
      "gradients: [[0.96485623]\n",
      " [1.46926494]]\n",
      "theta: [[4.12685633]\n",
      " [2.96223904]]\n",
      "gradients: [[-1.03082789]\n",
      " [-0.54543118]]\n",
      "theta: [[4.12183733]\n",
      " [2.96017299]]\n",
      "gradients: [[0.62637092]\n",
      " [0.25784283]]\n",
      "theta: [[4.09884277]\n",
      " [2.94062643]]\n",
      "gradients: [[2.87431993]\n",
      " [2.44331971]]\n",
      "theta: [[4.09441464]\n",
      " [2.93248736]]\n",
      "gradients: [[0.55440214]\n",
      " [1.01901173]]\n",
      "theta: [[4.06742536]\n",
      " [2.90619204]]\n",
      "gradients: [[3.38445581]\n",
      " [3.29743313]]\n",
      "theta: [[4.06727815]\n",
      " [2.90610958]]\n",
      "gradients: [[0.01848911]\n",
      " [0.01035754]]\n",
      "theta: [[4.09641593]\n",
      " [2.93505938]]\n",
      "gradients: [[-3.66553199]\n",
      " [-3.64188574]]\n",
      "theta: [[4.07687989]\n",
      " [2.92859505]]\n",
      "gradients: [[2.46154085]\n",
      " [0.81450629]]\n",
      "theta: [[4.11135518]\n",
      " [2.93415456]]\n",
      "gradients: [[-4.35078159]\n",
      " [-0.70161023]]\n",
      "theta: [[4.14604012]\n",
      " [2.99660392]]\n",
      "gradients: [[-4.38417668]\n",
      " [-7.89359914]]\n",
      "theta: [[4.13049403]\n",
      " [2.97952864]]\n",
      "gradients: [[1.96813484]\n",
      " [2.16173025]]\n",
      "theta: [[4.10763196]\n",
      " [2.97419333]]\n",
      "gradients: [[2.89891113]\n",
      " [0.67651716]]\n",
      "theta: [[4.10228864]\n",
      " [2.97381106]]\n",
      "gradients: [[0.67860083]\n",
      " [0.0485492 ]]\n",
      "theta: [[4.07267278]\n",
      " [2.96367669]]\n",
      "gradients: [[3.76713796]\n",
      " [1.28909132]]\n",
      "theta: [[4.07825255]\n",
      " [2.9639154 ]]\n",
      "gradients: [[-0.71086345]\n",
      " [-0.0304113 ]]\n",
      "theta: [[4.0641002 ]\n",
      " [2.93578111]]\n",
      "gradients: [[1.80584071]\n",
      " [3.58993512]]\n",
      "theta: [[4.09237037]\n",
      " [2.96386891]]\n",
      "gradients: [[-3.61292766]\n",
      " [-3.58962076]]\n",
      "theta: [[4.11354045]\n",
      " [2.97435143]]\n",
      "gradients: [[-2.7097707 ]\n",
      " [-1.34176276]]\n",
      "theta: [[4.100702  ]\n",
      " [2.95507234]]\n",
      "gradients: [[1.64588948]\n",
      " [2.47157945]]\n",
      "theta: [[4.10620588]\n",
      " [2.96310812]]\n",
      "gradients: [[-0.70669854]\n",
      " [-1.03179479]]\n",
      "theta: [[4.10938003]\n",
      " [2.96312711]]\n",
      "gradients: [[-0.40819609]\n",
      " [-0.0024422 ]]\n",
      "theta: [[4.10426986]\n",
      " [2.95373442]]\n",
      "gradients: [[0.65819084]\n",
      " [1.20977922]]\n",
      "theta: [[4.1123763 ]\n",
      " [2.95460314]]\n",
      "gradients: [[-1.04573059]\n",
      " [-0.11206444]]\n",
      "theta: [[4.13311109]\n",
      " [2.96487012]]\n",
      "gradients: [[-2.67893487]\n",
      " [-1.32649417]]\n",
      "theta: [[4.11032715]\n",
      " [2.93971619]]\n",
      "gradients: [[2.94824082]\n",
      " [3.25491777]]\n",
      "theta: [[4.12749001]\n",
      " [2.95882712]]\n",
      "gradients: [[-2.22430597]\n",
      " [-2.4767763 ]]\n",
      "theta: [[4.14403408]\n",
      " [2.97724903]]\n",
      "gradients: [[-2.14742002]\n",
      " [-2.3911634 ]]\n",
      "theta: [[4.1443145 ]\n",
      " [2.97760139]]\n",
      "gradients: [[-0.03645496]\n",
      " [-0.04580684]]\n",
      "theta: [[4.15841783]\n",
      " [2.98005422]]\n",
      "gradients: [[-1.83625329]\n",
      " [-0.31935834]]\n",
      "theta: [[4.1595841 ]\n",
      " [2.98038032]]\n",
      "gradients: [[-0.15208167]\n",
      " [-0.04252379]]\n",
      "theta: [[4.15388957]\n",
      " [2.97595186]]\n",
      "gradients: [[0.74370542]\n",
      " [0.57835735]]\n",
      "theta: [[4.154347  ]\n",
      " [2.97614082]]\n",
      "gradients: [[-0.05983179]\n",
      " [-0.02471643]]\n",
      "theta: [[4.1613187 ]\n",
      " [2.98793534]]\n",
      "gradients: [[-0.91329335]\n",
      " [-1.54508171]]\n",
      "theta: [[4.13844918]\n",
      " [2.96849507]]\n",
      "gradients: [[3.00048152]\n",
      " [2.55056355]]\n",
      "theta: [[4.1302391 ]\n",
      " [2.96113428]]\n",
      "gradients: [[1.07880389]\n",
      " [0.96720719]]\n",
      "theta: [[4.12247223]\n",
      " [2.95825333]]\n",
      "gradients: [[1.02212134]\n",
      " [0.37913314]]\n",
      "theta: [[4.12079865]\n",
      " [2.95759389]]\n",
      "gradients: [[0.22057693]\n",
      " [0.08691376]]\n",
      "theta: [[4.08707541]\n",
      " [2.90482206]]\n",
      "gradients: [[4.45146845]\n",
      " [6.96588238]]\n",
      "theta: [[4.08664988]\n",
      " [2.90458368]]\n",
      "gradients: [[0.05625429]\n",
      " [0.03151347]]\n",
      "theta: [[4.0879102 ]\n",
      " [2.90619239]]\n",
      "gradients: [[-0.16686595]\n",
      " [-0.212993  ]]\n",
      "theta: [[4.06006628]\n",
      " [2.89666437]]\n",
      "gradients: [[3.69210369]\n",
      " [1.26341506]]\n",
      "theta: [[4.06219286]\n",
      " [2.89821336]]\n",
      "gradients: [[-0.28240946]\n",
      " [-0.20570593]]\n",
      "theta: [[4.06534214]\n",
      " [2.90339305]]\n",
      "gradients: [[-0.41885421]\n",
      " [-0.68889896]]\n",
      "theta: [[4.06993099]\n",
      " [2.91092766]]\n",
      "gradients: [[-0.61123592]\n",
      " [-1.00361   ]]\n",
      "theta: [[4.05615477]\n",
      " [2.89464992]]\n",
      "gradients: [[1.83774801]\n",
      " [2.17145063]]\n",
      "theta: [[4.05768009]\n",
      " [2.89508236]]\n",
      "gradients: [[-0.20378171]\n",
      " [-0.05777333]]\n",
      "theta: [[4.05180842]\n",
      " [2.88981809]]\n",
      "gradients: [[0.78562862]\n",
      " [0.70435939]]\n",
      "theta: [[4.05491113]\n",
      " [2.89068564]]\n",
      "gradients: [[-0.41576261]\n",
      " [-0.11625201]]\n",
      "theta: [[4.05488292]\n",
      " [2.89064664]]\n",
      "gradients: [[0.00378486]\n",
      " [0.00523415]]\n",
      "theta: [[4.05682642]\n",
      " [2.89200135]]\n",
      "gradients: [[-0.26120649]\n",
      " [-0.18207346]]\n",
      "theta: [[4.06630774]\n",
      " [2.89207312]]\n",
      "gradients: [[-1.27618483]\n",
      " [-0.00966079]]\n",
      "theta: [[4.04151796]\n",
      " [2.88502837]]\n",
      "gradients: [[3.34166196]\n",
      " [0.94963311]]\n",
      "theta: [[4.0365026 ]\n",
      " [2.88380235]]\n",
      "gradients: [[0.67707388]\n",
      " [0.16551239]]\n",
      "theta: [[4.05192053]\n",
      " [2.88648381]]\n",
      "gradients: [[-2.08450386]\n",
      " [-0.3625337 ]]\n",
      "theta: [[4.02528363]\n",
      " [2.87736883]]\n",
      "gradients: [[3.60663604]\n",
      " [1.23416856]]\n",
      "theta: [[4.04231243]\n",
      " [2.90143939]]\n",
      "gradients: [[-2.30910552]\n",
      " [-3.26396745]]\n",
      "theta: [[4.05365554]\n",
      " [2.90343903]]\n",
      "gradients: [[-1.5403937 ]\n",
      " [-0.27155146]]\n",
      "theta: [[4.05705743]\n",
      " [2.90396399]]\n",
      "gradients: [[-0.46265729]\n",
      " [-0.07139407]]\n",
      "theta: [[4.06119957]\n",
      " [2.90965066]]\n",
      "gradients: [[-0.56416019]\n",
      " [-0.7745256 ]]\n",
      "theta: [[4.03720011]\n",
      " [2.88626829]]\n",
      "gradients: [[3.27352665]\n",
      " [3.18935624]]\n",
      "theta: [[4.03438523]\n",
      " [2.88510956]]\n",
      "gradients: [[0.38451243]\n",
      " [0.15828285]]\n",
      "theta: [[4.03673253]\n",
      " [2.88810572]]\n",
      "gradients: [[-0.32111004]\n",
      " [-0.40987504]]\n",
      "theta: [[4.03890319]\n",
      " [2.8923806 ]]\n",
      "gradients: [[-0.29738016]\n",
      " [-0.58565875]]\n",
      "theta: [[4.01277609]\n",
      " [2.88344007]]\n",
      "gradients: [[3.58463705]\n",
      " [1.22664064]]\n",
      "theta: [[3.99398713]\n",
      " [2.86722675]]\n",
      "gradients: [[2.58160346]\n",
      " [2.22771059]]\n",
      "theta: [[3.99469254]\n",
      " [2.86729937]]\n",
      "gradients: [[-0.09706488]\n",
      " [-0.00999306]]\n",
      "theta: [[4.0063099 ]\n",
      " [2.88695326]]\n",
      "gradients: [[-1.60087152]\n",
      " [-2.7083054 ]]\n",
      "theta: [[4.01042338]\n",
      " [2.89371878]]\n",
      "gradients: [[-0.56765963]\n",
      " [-0.93364258]]\n",
      "theta: [[4.00512325]\n",
      " [2.89175282]]\n",
      "gradients: [[0.73247733]\n",
      " [0.27169615]]\n",
      "theta: [[4.00774373]\n",
      " [2.89509768]]\n",
      "gradients: [[-0.36267466]\n",
      " [-0.46292944]]\n",
      "theta: [[4.02307583]\n",
      " [2.90227816]]\n",
      "gradients: [[-2.12502895]\n",
      " [-0.99521377]]\n",
      "theta: [[4.01909113]\n",
      " [2.89621034]]\n",
      "gradients: [[0.55307592]\n",
      " [0.84221362]]\n",
      "theta: [[4.0193435 ]\n",
      " [2.89630978]]\n",
      "gradients: [[-0.03507875]\n",
      " [-0.01382205]]\n",
      "theta: [[4.01028067]\n",
      " [2.8839305 ]]\n",
      "gradients: [[1.26154623]\n",
      " [1.72319592]]\n",
      "theta: [[4.0019033 ]\n",
      " [2.87135047]]\n",
      "gradients: [[1.16780548]\n",
      " [1.75365604]]\n",
      "theta: [[3.9853771]\n",
      " [2.8444796]]\n",
      "gradients: [[2.30705696]\n",
      " [3.75117311]]\n",
      "theta: [[3.99305173]\n",
      " [2.8454138 ]]\n",
      "gradients: [[-1.07291387]\n",
      " [-0.13060133]]\n",
      "theta: [[3.98313032]\n",
      " [2.83962814]]\n",
      "gradients: [[1.3889984 ]\n",
      " [0.80999308]]\n",
      "theta: [[3.99511713]\n",
      " [2.84174126]]\n",
      "gradients: [[-1.68055097]\n",
      " [-0.29625937]]\n",
      "theta: [[3.99961731]\n",
      " [2.84176818]]\n",
      "gradients: [[-0.63182585]\n",
      " [-0.00378016]]\n",
      "theta: [[3.98147055]\n",
      " [2.82156015]]\n",
      "gradients: [[2.55143432]\n",
      " [2.84124894]]\n",
      "theta: [[3.98665351]\n",
      " [2.82356288]]\n",
      "gradients: [[-0.72976051]\n",
      " [-0.28198422]]\n",
      "theta: [[4.00490472]\n",
      " [2.84477203]]\n",
      "gradients: [[-2.57341975]\n",
      " [-2.99048969]]\n",
      "theta: [[4.02616991]\n",
      " [2.85530164]]\n",
      "gradients: [[-3.00264539]\n",
      " [-1.4867818 ]]\n",
      "theta: [[4.02856654]\n",
      " [2.85815424]]\n",
      "gradients: [[-0.33888366]\n",
      " [-0.40335684]]\n",
      "theta: [[4.01220022]\n",
      " [2.83154332]]\n",
      "gradients: [[2.31747047]\n",
      " [3.76810501]]\n",
      "theta: [[4.01290419]\n",
      " [2.83182071]]\n",
      "gradients: [[-0.09982196]\n",
      " [-0.03933277]]\n",
      "theta: [[4.0130271 ]\n",
      " [2.83204662]]\n",
      "gradients: [[-0.01745296]\n",
      " [-0.03207919]]\n",
      "theta: [[4.01424636]\n",
      " [2.83272964]]\n",
      "gradients: [[-0.17337948]\n",
      " [-0.09712663]]\n",
      "theta: [[4.01841543]\n",
      " [2.83275459]]\n",
      "gradients: [[-0.59367522]\n",
      " [-0.00355191]]\n",
      "theta: [[4.01080384]\n",
      " [2.82928127]]\n",
      "gradients: [[1.08541218]\n",
      " [0.49529453]]\n",
      "theta: [[4.01766696]\n",
      " [2.83645541]]\n",
      "gradients: [[-0.98005343]\n",
      " [-1.024466  ]]\n",
      "theta: [[4.01001187]\n",
      " [2.82599901]]\n",
      "gradients: [[1.09467824]\n",
      " [1.49526434]]\n",
      "theta: [[4.01374821]\n",
      " [2.82704374]]\n",
      "gradients: [[-0.53504481]\n",
      " [-0.14960469]]\n",
      "theta: [[4.03017384]\n",
      " [2.85729469]]\n",
      "gradients: [[-2.35543478]\n",
      " [-4.33798666]]\n",
      "theta: [[4.03303778]\n",
      " [2.86178304]]\n",
      "gradients: [[-0.41126197]\n",
      " [-0.64452626]]\n",
      "theta: [[4.01551015]\n",
      " [2.84243217]]\n",
      "gradients: [[2.52047374]\n",
      " [2.78265422]]\n",
      "theta: [[4.00092914]\n",
      " [2.81494463]]\n",
      "gradients: [[2.09966501]\n",
      " [3.95820574]]\n",
      "theta: [[4.00422075]\n",
      " [2.81723904]]\n",
      "gradients: [[-0.47464992]\n",
      " [-0.33085378]]\n",
      "theta: [[4.0086635 ]\n",
      " [2.82598856]]\n",
      "gradients: [[-0.64153256]\n",
      " [-1.26343047]]\n",
      "theta: [[4.00633504]\n",
      " [2.82204336]]\n",
      "gradients: [[0.33669404]\n",
      " [0.5704752 ]]\n",
      "theta: [[4.03291003]\n",
      " [2.86540847]]\n",
      "gradients: [[-3.84805811]\n",
      " [-6.27926675]]\n",
      "theta: [[4.0307615 ]\n",
      " [2.86373762]]\n",
      "gradients: [[0.31153697]\n",
      " [0.24227294]]\n",
      "theta: [[4.01503814]\n",
      " [2.85853487]]\n",
      "gradients: [[2.28303227]\n",
      " [0.75543907]]\n",
      "theta: [[4.0292764 ]\n",
      " [2.87236148]]\n",
      "gradients: [[-2.07024259]\n",
      " [-2.01038936]]\n",
      "theta: [[4.04371964]\n",
      " [2.87487343]]\n",
      "gradients: [[-2.10293582]\n",
      " [-0.36573936]]\n",
      "theta: [[4.04971636]\n",
      " [2.88179268]]\n",
      "gradients: [[-0.87432302]\n",
      " [-1.00882728]]\n",
      "theta: [[4.02709557]\n",
      " [2.87536431]]\n",
      "gradients: [[3.30263622]\n",
      " [0.93854278]]\n",
      "theta: [[4.00971764]\n",
      " [2.86059218]]\n",
      "gradients: [[2.54065292]\n",
      " [2.1596856 ]]\n",
      "theta: [[3.99879981]\n",
      " [2.84769186]]\n",
      "gradients: [[1.59837025]\n",
      " [1.88860609]]\n",
      "theta: [[4.03236485]\n",
      " [2.90812487]]\n",
      "gradients: [[-4.92063521]\n",
      " [-8.85947915]]\n",
      "theta: [[4.03428499]\n",
      " [2.9094633 ]]\n",
      "gradients: [[-0.28187629]\n",
      " [-0.19648131]]\n",
      "theta: [[4.02407133]\n",
      " [2.88915896]]\n",
      "gradients: [[1.50140864]\n",
      " [2.98473701]]\n",
      "theta: [[4.02466442]\n",
      " [2.88949121]]\n",
      "gradients: [[-0.0873027 ]\n",
      " [-0.04890669]]\n",
      "theta: [[4.01615994]\n",
      " [2.8778746 ]]\n",
      "gradients: [[1.25356057]\n",
      " [1.71228799]]\n",
      "theta: [[4.03081699]\n",
      " [2.9048684 ]]\n",
      "gradients: [[-2.16338169]\n",
      " [-3.98428391]]\n",
      "theta: [[4.00303289]\n",
      " [2.86139043]]\n",
      "gradients: [[4.1064901 ]\n",
      " [6.42604285]]\n",
      "theta: [[3.99367416]\n",
      " [2.85111113]]\n",
      "gradients: [[1.38509289]\n",
      " [1.52133743]]\n",
      "theta: [[4.00924051]\n",
      " [2.87977956]]\n",
      "gradients: [[-2.30693343]\n",
      " [-4.24866209]]\n",
      "theta: [[4.00730958]\n",
      " [2.87827794]]\n",
      "gradients: [[0.28654987]\n",
      " [0.22284122]]\n",
      "theta: [[3.99044929]\n",
      " [2.85966384]]\n",
      "gradients: [[2.50543875]\n",
      " [2.76605529]]\n",
      "theta: [[3.99979749]\n",
      " [2.86461015]]\n",
      "gradients: [[-1.39101246]\n",
      " [-0.73601187]]\n",
      "theta: [[3.98448926]\n",
      " [2.83971964]]\n",
      "gradients: [[2.28092645]\n",
      " [3.70868605]]\n",
      "theta: [[3.99170004]\n",
      " [2.84059738]]\n",
      "gradients: [[-1.07584837]\n",
      " [-0.13095854]]\n",
      "theta: [[4.00549353]\n",
      " [2.84315602]]\n",
      "gradients: [[-2.06074654]\n",
      " [-0.38226028]]\n",
      "theta: [[4.0196593 ]\n",
      " [2.85691224]]\n",
      "gradients: [[-2.11920028]\n",
      " [-2.05793162]]\n",
      "theta: [[4.0089146 ]\n",
      " [2.84421649]]\n",
      "gradients: [[1.60955729]\n",
      " [1.90182451]]\n",
      "theta: [[4.00429635]\n",
      " [2.84250345]]\n",
      "gradients: [[0.69273623]\n",
      " [0.25695507]]\n",
      "theta: [[4.0344143 ]\n",
      " [2.84736029]]\n",
      "gradients: [[-4.52371505]\n",
      " [-0.7294976 ]]\n",
      "theta: [[4.03210773]\n",
      " [2.84641081]]\n",
      "gradients: [[0.3469082 ]\n",
      " [0.14280323]]\n",
      "theta: [[4.01981586]\n",
      " [2.82788354]]\n",
      "gradients: [[1.85115579]\n",
      " [2.79020649]]\n",
      "theta: [[4.02417084]\n",
      " [2.83165199]]\n",
      "gradients: [[-0.65673129]\n",
      " [-0.56828324]]\n",
      "theta: [[4.03032426]\n",
      " [2.84175552]]\n",
      "gradients: [[-0.92916691]\n",
      " [-1.52563221]]\n",
      "theta: [[4.03358326]\n",
      " [2.84817377]]\n",
      "gradients: [[-0.49276031]\n",
      " [-0.97043928]]\n",
      "theta: [[4.04157354]\n",
      " [2.84903004]]\n",
      "gradients: [[-1.20972834]\n",
      " [-0.12963906]]\n",
      "theta: [[4.05533645]\n",
      " [2.85142366]]\n",
      "gradients: [[-2.08645708]\n",
      " [-0.3628734 ]]\n",
      "theta: [[4.04434869]\n",
      " [2.83844072]]\n",
      "gradients: [[1.66794115]\n",
      " [1.97080984]]\n",
      "theta: [[4.06001334]\n",
      " [2.86058302]]\n",
      "gradients: [[-2.38102673]\n",
      " [-3.36562954]]\n",
      "theta: [[4.06331037]\n",
      " [2.86060275]]\n",
      "gradients: [[-0.50180797]\n",
      " [-0.00300228]]\n",
      "theta: [[4.05961428]\n",
      " [2.8543403 ]]\n",
      "gradients: [[0.56328442]\n",
      " [0.95439703]]\n",
      "theta: [[4.03794436]\n",
      " [2.84818215]]\n",
      "gradients: [[3.30682923]\n",
      " [0.93973434]]\n",
      "theta: [[4.0388318 ]\n",
      " [2.84835611]]\n",
      "gradients: [[-0.13559955]\n",
      " [-0.02658137]]\n",
      "theta: [[4.0529803 ]\n",
      " [2.85464835]]\n",
      "gradients: [[-2.1647216 ]\n",
      " [-0.96271226]]\n",
      "theta: [[4.08500105]\n",
      " [2.91434625]]\n",
      "gradients: [[-4.90557807]\n",
      " [-9.14571945]]\n",
      "theta: [[4.06620153]\n",
      " [2.89341132]]\n",
      "gradients: [[2.88384607]\n",
      " [3.21141897]]\n",
      "theta: [[4.06660096]\n",
      " [2.89348962]]\n",
      "gradients: [[-0.06135281]\n",
      " [-0.0120269 ]]\n",
      "theta: [[4.06779438]\n",
      " [2.89382796]]\n",
      "gradients: [[-0.18354724]\n",
      " [-0.05203674]]\n",
      "theta: [[4.0630286 ]\n",
      " [2.89266295]]\n",
      "gradients: [[0.73392887]\n",
      " [0.17941073]]\n",
      "theta: [[4.06681102]\n",
      " [2.89785576]]\n",
      "gradients: [[-0.58324781]\n",
      " [-0.80073066]]\n",
      "theta: [[4.06316594]\n",
      " [2.89492692]]\n",
      "gradients: [[0.56279987]\n",
      " [0.45221296]]\n",
      "theta: [[4.05345459]\n",
      " [2.87562116]]\n",
      "gradients: [[1.50137512]\n",
      " [2.98467037]]\n",
      "theta: [[4.04895621]\n",
      " [2.87452152]]\n",
      "gradients: [[0.6963479 ]\n",
      " [0.17022397]]\n",
      "theta: [[4.03924147]\n",
      " [2.86385119]]\n",
      "gradients: [[1.50578499]\n",
      " [1.65390139]]\n",
      "theta: [[4.03400785]\n",
      " [2.8614246 ]]\n",
      "gradients: [[0.81225782]\n",
      " [0.37660706]]\n",
      "theta: [[4.01772228]\n",
      " [2.84758102]]\n",
      "gradients: [[2.53077856]\n",
      " [2.15129188]]\n",
      "theta: [[4.02419701]\n",
      " [2.84836916]]\n",
      "gradients: [[-1.00746847]\n",
      " [-0.12263494]]\n",
      "theta: [[4.02570316]\n",
      " [2.84950222]]\n",
      "gradients: [[-0.23465753]\n",
      " [-0.17653037]]\n",
      "theta: [[4.00737357]\n",
      " [2.82688593]]\n",
      "gradients: [[2.85941473]\n",
      " [3.52814138]]\n",
      "theta: [[4.01126276]\n",
      " [2.8269092 ]]\n",
      "gradients: [[-0.60749072]\n",
      " [-0.00363457]]\n",
      "theta: [[4.02504008]\n",
      " [2.82930533]]\n",
      "gradients: [[-2.15477308]\n",
      " [-0.37475481]]\n",
      "theta: [[4.0229024 ]\n",
      " [2.82605011]]\n",
      "gradients: [[0.33476112]\n",
      " [0.50976794]]\n",
      "theta: [[4.01815414]\n",
      " [2.82384856]]\n",
      "gradients: [[0.74452638]\n",
      " [0.34520307]]\n",
      "theta: [[4.01950604]\n",
      " [2.82512167]]\n",
      "gradients: [[-0.21224838]\n",
      " [-0.19987895]]\n",
      "theta: [[4.02082377]\n",
      " [2.8263626 ]]\n",
      "gradients: [[-0.20714674]\n",
      " [-0.19507462]]\n",
      "theta: [[4.02281337]\n",
      " [2.82692667]]\n",
      "gradients: [[-0.31316344]\n",
      " [-0.08878371]]\n",
      "theta: [[4.02212496]\n",
      " [2.82613502]]\n",
      "gradients: [[0.10849436]\n",
      " [0.12476304]]\n",
      "theta: [[4.0067895 ]\n",
      " [2.80920436]]\n",
      "gradients: [[2.41993584]\n",
      " [2.67165833]]\n",
      "theta: [[3.98299813]\n",
      " [2.77197444]]\n",
      "gradients: [[3.7590353 ]\n",
      " [5.88232805]]\n",
      "theta: [[3.98540181]\n",
      " [2.77423804]]\n",
      "gradients: [[-0.38026238]\n",
      " [-0.35810142]]\n",
      "theta: [[3.97814388]\n",
      " [2.76056926]]\n",
      "gradients: [[1.14965731]\n",
      " [2.16513485]]\n",
      "theta: [[3.99229322]\n",
      " [2.76303009]]\n",
      "gradients: [[-2.24408632]\n",
      " [-0.39028803]]\n",
      "theta: [[3.9774228 ]\n",
      " [2.74647056]]\n",
      "gradients: [[2.36142242]\n",
      " [2.6296538 ]]\n",
      "theta: [[3.97516723]\n",
      " [2.74444831]]\n",
      "gradients: [[0.3586367 ]\n",
      " [0.32153759]]\n",
      "theta: [[3.98119255]\n",
      " [2.75201933]]\n",
      "gradients: [[-0.95923193]\n",
      " [-1.20530593]]\n",
      "theta: [[3.98967354]\n",
      " [2.76833118]]\n",
      "gradients: [[-1.35186974]\n",
      " [-2.60010959]]\n",
      "theta: [[3.99223224]\n",
      " [2.76905659]]\n",
      "gradients: [[-0.4083684 ]\n",
      " [-0.11577489]]\n",
      "theta: [[3.97943019]\n",
      " [2.75548524]]\n",
      "gradients: [[2.0457676 ]\n",
      " [2.16870192]]\n",
      "theta: [[3.97842207]\n",
      " [2.75507025]]\n",
      "gradients: [[0.16130006]\n",
      " [0.06639846]]\n",
      "theta: [[3.99098851]\n",
      " [2.77632977]]\n",
      "gradients: [[-2.01314407]\n",
      " [-3.40577547]]\n",
      "theta: [[4.01717106]\n",
      " [2.77838359]]\n",
      "gradients: [[-4.19968036]\n",
      " [-0.32943345]]\n",
      "theta: [[4.01408664]\n",
      " [2.77561825]]\n",
      "gradients: [[0.4953568 ]\n",
      " [0.44411469]]\n",
      "theta: [[4.00152376]\n",
      " [2.75519156]]\n",
      "gradients: [[2.0201109 ]\n",
      " [3.28461143]]\n",
      "theta: [[4.00661146]\n",
      " [2.75959405]]\n",
      "gradients: [[-0.81911924]\n",
      " [-0.70880091]]\n",
      "theta: [[4.00805685]\n",
      " [2.75987739]]\n",
      "gradients: [[-0.23299694]\n",
      " [-0.04567403]]\n",
      "theta: [[4.01833452]\n",
      " [2.76168921]]\n",
      "gradients: [[-1.65881595]\n",
      " [-0.29242777]]\n",
      "theta: [[4.01480478]\n",
      " [2.76082635]]\n",
      "gradients: [[0.57040587]\n",
      " [0.13943713]]\n",
      "theta: [[4.01361388]\n",
      " [2.76063688]]\n",
      "gradients: [[0.19268763]\n",
      " [0.03065587]]\n",
      "theta: [[3.9974661 ]\n",
      " [2.74071265]]\n",
      "gradients: [[2.61593992]\n",
      " [3.22772552]]\n",
      "theta: [[4.02708285]\n",
      " [2.78027292]]\n",
      "gradients: [[-4.80383584]\n",
      " [-6.41667508]]\n",
      "theta: [[4.0593162 ]\n",
      " [2.84036721]]\n",
      "gradients: [[-5.23469678]\n",
      " [-9.75931227]]\n",
      "theta: [[4.06090781]\n",
      " [2.84182717]]\n",
      "gradients: [[-0.25879522]\n",
      " [-0.23739069]]\n",
      "theta: [[4.07446225]\n",
      " [2.86679028]]\n",
      "gradients: [[-2.20666251]\n",
      " [-4.06399387]]\n",
      "theta: [[4.05838366]\n",
      " [2.85312266]]\n",
      "gradients: [[2.62080956]\n",
      " [2.22782286]]\n",
      "theta: [[4.06770631]\n",
      " [2.86889443]]\n",
      "gradients: [[-1.52145675]\n",
      " [-2.57395393]]\n",
      "theta: [[4.05283069]\n",
      " [2.84470733]]\n",
      "gradients: [[2.43067619]\n",
      " [3.95217253]]\n",
      "theta: [[4.05288074]\n",
      " [2.84472705]]\n",
      "gradients: [[-0.00818701]\n",
      " [-0.00322592]]\n",
      "theta: [[4.05021034]\n",
      " [2.84066062]]\n",
      "gradients: [[0.43741023]\n",
      " [0.66608008]]\n",
      "theta: [[4.03446253]\n",
      " [2.82707156]]\n",
      "gradients: [[2.5826417 ]\n",
      " [2.22860652]]\n",
      "theta: [[4.05946114]\n",
      " [2.82903251]]\n",
      "gradients: [[-4.1047717 ]\n",
      " [-0.32198857]]\n",
      "theta: [[4.05196737]\n",
      " [2.81413523]]\n",
      "gradients: [[1.23197493]\n",
      " [2.44911416]]\n",
      "theta: [[4.0496397 ]\n",
      " [2.81019135]]\n",
      "gradients: [[0.38313457]\n",
      " [0.64916139]]\n",
      "theta: [[4.03600017]\n",
      " [2.79573219]]\n",
      "gradients: [[2.2477958]\n",
      " [2.3828704]]\n",
      "theta: [[4.03869415]\n",
      " [2.79684507]]\n",
      "gradients: [[-0.44450756]\n",
      " [-0.18362543]]\n",
      "theta: [[4.03661037]\n",
      " [2.79517074]]\n",
      "gradients: [[0.34424078]\n",
      " [0.27659947]]\n",
      "theta: [[4.02473809]\n",
      " [2.77278959]]\n",
      "gradients: [[1.96367467]\n",
      " [3.70184211]]\n",
      "theta: [[4.0190926 ]\n",
      " [2.76507819]]\n",
      "gradients: [[0.93489319]\n",
      " [1.27700761]]\n",
      "theta: [[4.01182095]\n",
      " [2.75709126]]\n",
      "gradients: [[1.20564033]\n",
      " [1.32423303]]\n",
      "theta: [[4.01116108]\n",
      " [2.75597322]]\n",
      "gradients: [[0.10953763]\n",
      " [0.18559432]]\n",
      "theta: [[4.03846489]\n",
      " [2.76037626]]\n",
      "gradients: [[-4.53789345]\n",
      " [-0.73178402]]\n",
      "theta: [[4.03864585]\n",
      " [2.76039488]]\n",
      "gradients: [[-0.03011039]\n",
      " [-0.00309994]]\n",
      "theta: [[4.0513898 ]\n",
      " [2.76261129]]\n",
      "gradients: [[-2.12314304]\n",
      " [-0.36925377]]\n",
      "theta: [[4.04563206]\n",
      " [2.75474657]]\n",
      "gradients: [[0.96039073]\n",
      " [1.31183571]]\n",
      "theta: [[4.04745334]\n",
      " [2.75526292]]\n",
      "gradients: [[-0.304154  ]\n",
      " [-0.08622948]]\n",
      "theta: [[4.03893103]\n",
      " [2.7451931 ]]\n",
      "gradients: [[1.42493127]\n",
      " [1.68367365]]\n",
      "theta: [[4.04176359]\n",
      " [2.74779138]]\n",
      "gradients: [[-0.4741704 ]\n",
      " [-0.43495254]]\n",
      "theta: [[4.03638977]\n",
      " [2.74045107]]\n",
      "gradients: [[0.90065209]\n",
      " [1.23023634]]\n",
      "theta: [[4.02476667]\n",
      " [2.72155241]]\n",
      "gradients: [[1.95035658]\n",
      " [3.17119398]]\n",
      "theta: [[4.02971221]\n",
      " [2.72583189]]\n",
      "gradients: [[-0.83085073]\n",
      " [-0.71895242]]\n",
      "theta: [[4.02586852]\n",
      " [2.72440617]]\n",
      "gradients: [[0.64650719]\n",
      " [0.23980744]]\n",
      "theta: [[4.02159373]\n",
      " [2.71798684]]\n",
      "gradients: [[0.71987606]\n",
      " [1.08101479]]\n",
      "theta: [[4.05327883]\n",
      " [2.77503507]]\n",
      "gradients: [[-5.3421086 ]\n",
      " [-9.61833133]]\n",
      "theta: [[4.04564605]\n",
      " [2.76066035]]\n",
      "gradients: [[1.2884134 ]\n",
      " [2.42645242]]\n",
      "theta: [[4.04147911]\n",
      " [2.75911472]]\n",
      "gradients: [[0.70421256]\n",
      " [0.26121196]]\n",
      "theta: [[4.02746148]\n",
      " [2.74719901]]\n",
      "gradients: [[2.37178375]\n",
      " [2.01613812]]\n",
      "theta: [[4.05136979]\n",
      " [2.78621262]]\n",
      "gradients: [[-4.05006751]\n",
      " [-6.60890598]]\n",
      "theta: [[4.05690713]\n",
      " [2.79433594]]\n",
      "gradients: [[-0.9391337 ]\n",
      " [-1.37771512]]\n",
      "theta: [[4.04182837]\n",
      " [2.7775444 ]]\n",
      "gradients: [[2.56037393]\n",
      " [2.85120398]]\n",
      "theta: [[4.03354957]\n",
      " [2.77271662]]\n",
      "gradients: [[1.40739572]\n",
      " [0.82072145]]\n",
      "theta: [[4.0488128 ]\n",
      " [2.79045354]]\n",
      "gradients: [[-2.59780129]\n",
      " [-3.0188227 ]]\n",
      "theta: [[4.04961383]\n",
      " [2.79061056]]\n",
      "gradients: [[-0.13649559]\n",
      " [-0.02675702]]\n",
      "theta: [[4.04620136]\n",
      " [2.7875511 ]]\n",
      "gradients: [[0.58216664]\n",
      " [0.52194451]]\n",
      "theta: [[4.04785332]\n",
      " [2.78879385]]\n",
      "gradients: [[-0.2821544 ]\n",
      " [-0.21226176]]\n",
      "theta: [[4.06355717]\n",
      " [2.80628017]]\n",
      "gradients: [[-2.68535928]\n",
      " [-2.99016157]]\n",
      "theta: [[4.05352513]\n",
      " [2.79822946]]\n",
      "gradients: [[1.71748574]\n",
      " [1.37828175]]\n",
      "theta: [[4.06041282]\n",
      " [2.79896757]]\n",
      "gradients: [[-1.18054904]\n",
      " [-0.12651209]]\n",
      "theta: [[4.05838119]\n",
      " [2.7955253 ]]\n",
      "gradients: [[0.34862704]\n",
      " [0.59069379]]\n",
      "theta: [[4.06224873]\n",
      " [2.800385  ]]\n",
      "gradients: [[-0.66444422]\n",
      " [-0.83489565]]\n",
      "theta: [[4.06808426]\n",
      " [2.81160871]]\n",
      "gradients: [[-1.00370981]\n",
      " [-1.93047853]]\n",
      "theta: [[4.06531316]\n",
      " [2.81087123]]\n",
      "gradients: [[0.47718276]\n",
      " [0.12699408]]\n",
      "theta: [[4.06997244]\n",
      " [2.81726787]]\n",
      "gradients: [[-0.80325955]\n",
      " [-1.10278089]]\n",
      "theta: [[4.06122381]\n",
      " [2.81216611]]\n",
      "gradients: [[1.51001327]\n",
      " [0.88056278]]\n",
      "theta: [[4.05512335]\n",
      " [2.80300525]]\n",
      "gradients: [[1.05415923]\n",
      " [1.58299711]]\n",
      "theta: [[4.05362679]\n",
      " [2.80184142]]\n",
      "gradients: [[0.25890541]\n",
      " [0.20134295]]\n",
      "theta: [[4.06346791]\n",
      " [2.81849033]]\n",
      "gradients: [[-1.70448255]\n",
      " [-2.88359137]]\n",
      "theta: [[4.05044433]\n",
      " [2.79731455]]\n",
      "gradients: [[2.25828968]\n",
      " [3.67187965]]\n",
      "theta: [[4.05073412]\n",
      " [2.79742874]]\n",
      "gradients: [[-0.05030803]\n",
      " [-0.01982283]]\n",
      "theta: [[4.05373252]\n",
      " [2.79744668]]\n",
      "gradients: [[-0.52112211]\n",
      " [-0.00311783]]\n",
      "theta: [[4.06361264]\n",
      " [2.81416156]]\n",
      "gradients: [[-1.71914085]\n",
      " [-2.90838984]]\n",
      "theta: [[4.0569603 ]\n",
      " [2.81112597]]\n",
      "gradients: [[1.15883789]\n",
      " [0.5288001 ]]\n",
      "theta: [[4.05098261]\n",
      " [2.80214947]]\n",
      "gradients: [[1.04250831]\n",
      " [1.56550129]]\n",
      "theta: [[4.0681823 ]\n",
      " [2.82217104]]\n",
      "gradients: [[-3.00306602]\n",
      " [-3.49576552]]\n",
      "theta: [[4.0671051 ]\n",
      " [2.82093231]]\n",
      "gradients: [[0.18829475]\n",
      " [0.21652948]]\n",
      "theta: [[4.05282848]\n",
      " [2.80517064]]\n",
      "gradients: [[2.49840833]\n",
      " [2.75829356]]\n",
      "theta: [[4.06016579]\n",
      " [2.80522618]]\n",
      "gradients: [[-1.28549534]\n",
      " [-0.00973128]]\n",
      "theta: [[4.08180365]\n",
      " [2.84053488]]\n",
      "gradients: [[-3.79528124]\n",
      " [-6.19314537]]\n",
      "theta: [[4.10902688]\n",
      " [2.88954962]]\n",
      "gradients: [[-4.78039947]\n",
      " [-8.60698826]]\n",
      "theta: [[4.13147194]\n",
      " [2.89131026]]\n",
      "gradients: [[-3.94584112]\n",
      " [-0.30952166]]\n",
      "theta: [[4.1222469 ]\n",
      " [2.87297127]]\n",
      "gradients: [[1.6236076 ]\n",
      " [3.22766337]]\n",
      "theta: [[4.11916143]\n",
      " [2.87170115]]\n",
      "gradients: [[0.54365868]\n",
      " [0.2237947 ]]\n",
      "theta: [[4.10474696]\n",
      " [2.84826384]]\n",
      "gradients: [[2.54271362]\n",
      " [4.13434046]]\n",
      "theta: [[4.11765649]\n",
      " [2.86326561]]\n",
      "gradients: [[-2.27982444]\n",
      " [-2.64931187]]\n",
      "theta: [[4.14192289]\n",
      " [2.86717883]]\n",
      "gradients: [[-4.29029853]\n",
      " [-0.69185668]]\n",
      "theta: [[4.14751032]\n",
      " [2.8677776 ]]\n",
      "gradients: [[-0.98897577]\n",
      " [-0.10598238]]\n",
      "theta: [[4.1580695 ]\n",
      " [2.87272277]]\n",
      "gradients: [[-1.87108537]\n",
      " [-0.8762845 ]]\n",
      "theta: [[4.16412356]\n",
      " [2.8727686 ]]\n",
      "gradients: [[-1.07399057]\n",
      " [-0.00813017]]\n",
      "theta: [[4.18404525]\n",
      " [2.89256178]]\n",
      "gradients: [[-3.53809297]\n",
      " [-3.51526883]]\n",
      "theta: [[4.18375945]\n",
      " [2.89248075]]\n",
      "gradients: [[0.05081525]\n",
      " [0.01440643]]\n",
      "theta: [[4.19372789]\n",
      " [2.91083956]]\n",
      "gradients: [[-1.77438258]\n",
      " [-3.26786716]]\n",
      "theta: [[4.17693037]\n",
      " [2.90691953]]\n",
      "gradients: [[2.99331899]\n",
      " [0.69854906]]\n",
      "theta: [[4.16668099]\n",
      " [2.90094261]]\n",
      "gradients: [[1.82848968]\n",
      " [1.06628199]]\n",
      "theta: [[4.16160414]\n",
      " [2.89234069]]\n",
      "gradients: [[0.90672477]\n",
      " [1.5363028 ]]\n",
      "theta: [[4.14541499]\n",
      " [2.87837079]]\n",
      "gradients: [[2.89462055]\n",
      " [2.4978185 ]]\n",
      "theta: [[4.14168661]\n",
      " [2.87737855]]\n",
      "gradients: [[0.6673794 ]\n",
      " [0.17761168]]\n",
      "theta: [[4.1276581 ]\n",
      " [2.87273661]]\n",
      "gradients: [[2.51390986]\n",
      " [0.83183482]]\n",
      "theta: [[4.12456842]\n",
      " [2.87146476]]\n",
      "gradients: [[0.55428789]\n",
      " [0.22817017]]\n",
      "theta: [[4.1199106 ]\n",
      " [2.87032614]]\n",
      "gradients: [[0.83654348]\n",
      " [0.20449512]]\n",
      "theta: [[4.11255414]\n",
      " [2.86696925]]\n",
      "gradients: [[1.32269179]\n",
      " [0.6035698 ]]\n",
      "theta: [[4.1388902]\n",
      " [2.9160689]]\n",
      "gradients: [[-4.74048941]\n",
      " [-8.83793624]]\n",
      "theta: [[4.13373772]\n",
      " [2.9153502 ]]\n",
      "gradients: [[0.92847615]\n",
      " [0.12950828]]\n",
      "theta: [[4.1096516 ]\n",
      " [2.87765902]]\n",
      "gradients: [[4.34513647]\n",
      " [6.79948873]]\n",
      "theta: [[4.11547259]\n",
      " [2.87828282]]\n",
      "gradients: [[-1.05127216]\n",
      " [-0.1126583 ]]\n",
      "theta: [[4.10041853]\n",
      " [2.86166283]]\n",
      "gradients: [[2.72177557]\n",
      " [3.00489553]]\n",
      "theta: [[4.09719165]\n",
      " [2.856749  ]]\n",
      "gradients: [[0.58406478]\n",
      " [0.88940288]]\n",
      "theta: [[4.10866589]\n",
      " [2.87788102]]\n",
      "gradients: [[-2.079132  ]\n",
      " [-3.82912188]]\n",
      "theta: [[4.11089464]\n",
      " [2.87789435]]\n",
      "gradients: [[-0.40429589]\n",
      " [-0.00241887]]\n",
      "theta: [[4.09687306]\n",
      " [2.85509587]]\n",
      "gradients: [[2.54631979]\n",
      " [4.14020394]]\n",
      "theta: [[4.09928095]\n",
      " [2.85812147]]\n",
      "gradients: [[-0.43775579]\n",
      " [-0.5500543 ]]\n",
      "theta: [[4.1189019 ]\n",
      " [2.88606293]]\n",
      "gradients: [[-3.57101292]\n",
      " [-5.0853443 ]]\n",
      "theta: [[4.11534521]\n",
      " [2.8832051 ]]\n",
      "gradients: [[0.64803042]\n",
      " [0.52069621]]\n",
      "theta: [[4.10037546]\n",
      " [2.87048004]]\n",
      "gradients: [[2.73048235]\n",
      " [2.32105037]]\n",
      "theta: [[4.10038638]\n",
      " [2.87048218]]\n",
      "gradients: [[-0.00199532]\n",
      " [-0.00039114]]\n",
      "theta: [[4.10218846]\n",
      " [2.87098607]]\n",
      "gradients: [[-0.32941977]\n",
      " [-0.09210956]]\n",
      "theta: [[4.10446929]\n",
      " [2.87295971]]\n",
      "gradients: [[-0.41739105]\n",
      " [-0.36117716]]\n",
      "theta: [[4.09250133]\n",
      " [2.86011823]]\n",
      "gradients: [[2.19252967]\n",
      " [2.35255974]]\n",
      "theta: [[4.07735372]\n",
      " [2.84325002]]\n",
      "gradients: [[2.77807118]\n",
      " [3.09362923]]\n",
      "theta: [[4.09099797]\n",
      " [2.85844296]]\n",
      "gradients: [[-2.50508401]\n",
      " [-2.78942411]]\n",
      "theta: [[4.11719707]\n",
      " [2.90728727]]\n",
      "gradients: [[-4.81539374]\n",
      " [-8.97758421]]\n",
      "theta: [[4.102038  ]\n",
      " [2.89055136]]\n",
      "gradients: [[2.78926751]\n",
      " [3.07940801]]\n",
      "theta: [[4.11257383]\n",
      " [2.8954856 ]]\n",
      "gradients: [[-1.94069876]\n",
      " [-0.90888651]]\n",
      "theta: [[4.12235369]\n",
      " [2.90498271]]\n",
      "gradients: [[-1.80340634]\n",
      " [-1.75126767]]\n",
      "theta: [[4.12501887]\n",
      " [2.90935877]]\n",
      "gradients: [[-0.49199259]\n",
      " [-0.80782014]]\n",
      "theta: [[4.12640707]\n",
      " [2.91164198]]\n",
      "gradients: [[-0.25653999]\n",
      " [-0.4219371 ]]\n",
      "theta: [[4.12810774]\n",
      " [2.91190441]]\n",
      "gradients: [[-0.31462257]\n",
      " [-0.04855038]]\n",
      "theta: [[4.13936688]\n",
      " [2.92498831]]\n",
      "gradients: [[-2.08519351]\n",
      " [-2.42313741]]\n",
      "theta: [[4.14116859]\n",
      " [2.9256845 ]]\n",
      "gradients: [[-0.33403722]\n",
      " [-0.12907416]]\n",
      "theta: [[4.15544655]\n",
      " [2.93275433]]\n",
      "gradients: [[-2.64998883]\n",
      " [-1.31216133]]\n",
      "theta: [[4.17394089]\n",
      " [2.95112937]]\n",
      "gradients: [[-3.43624945]\n",
      " [-3.4140823 ]]\n",
      "theta: [[4.16243137]\n",
      " [2.93752992]]\n",
      "gradients: [[2.14077107]\n",
      " [2.52949733]]\n",
      "theta: [[4.16583881]\n",
      " [2.94250485]]\n",
      "gradients: [[-0.63446439]\n",
      " [-0.92633139]]\n",
      "theta: [[4.16713051]\n",
      " [2.94427821]]\n",
      "gradients: [[-0.24077328]\n",
      " [-0.3305534 ]]\n",
      "theta: [[4.15821974]\n",
      " [2.93089719]]\n",
      "gradients: [[1.66274961]\n",
      " [2.49689776]]\n",
      "theta: [[4.16075068]\n",
      " [2.93354283]]\n",
      "gradients: [[-0.47278006]\n",
      " [-0.49420478]]\n",
      "theta: [[4.16229134]\n",
      " [2.93580298]]\n",
      "gradients: [[-0.28810321]\n",
      " [-0.42264924]]\n",
      "theta: [[4.14762646]\n",
      " [2.90815733]]\n",
      "gradients: [[2.74526534]\n",
      " [5.17526604]]\n",
      "theta: [[4.15674434]\n",
      " [2.9170116 ]]\n",
      "gradients: [[-1.70869031]\n",
      " [-1.65929   ]]\n",
      "theta: [[4.16050635]\n",
      " [2.92250421]]\n",
      "gradients: [[-0.70575283]\n",
      " [-1.03041402]]\n",
      "theta: [[4.14001402]\n",
      " [2.91549186]]\n",
      "gradients: [[3.8484596 ]\n",
      " [1.31691908]]\n",
      "theta: [[4.14107623]\n",
      " [2.91682656]]\n",
      "gradients: [[-0.19969483]\n",
      " [-0.25092301]]\n",
      "theta: [[4.13814434]\n",
      " [2.91345504]]\n",
      "gradients: [[0.55178075]\n",
      " [0.63452006]]\n",
      "theta: [[4.12568796]\n",
      " [2.90008948]]\n",
      "gradients: [[2.34678184]\n",
      " [2.51807059]]\n",
      "theta: [[4.12092861]\n",
      " [2.89942563]]\n",
      "gradients: [[0.89761391]\n",
      " [0.12520347]]\n",
      "theta: [[4.12700842]\n",
      " [2.89947165]]\n",
      "gradients: [[-1.14786806]\n",
      " [-0.00868943]]\n",
      "theta: [[4.1197942 ]\n",
      " [2.89617967]]\n",
      "gradients: [[1.36348673]\n",
      " [0.62218532]]\n",
      "theta: [[4.13196296]\n",
      " [2.90972964]]\n",
      "gradients: [[-2.30232817]\n",
      " [-2.56365443]]\n",
      "theta: [[4.12883015]\n",
      " [2.90844003]]\n",
      "gradients: [[0.59335365]\n",
      " [0.24425142]]\n",
      "theta: [[4.14748942]\n",
      " [2.92697893]]\n",
      "gradients: [[-3.53779716]\n",
      " [-3.51497493]]\n",
      "theta: [[4.13335669]\n",
      " [2.90033646]]\n",
      "gradients: [[2.68239197]\n",
      " [5.05673965]]\n",
      "theta: [[4.11073887]\n",
      " [2.86494296]]\n",
      "gradients: [[4.29738589]\n",
      " [6.72476622]]\n",
      "theta: [[4.10803628]\n",
      " [2.86383045]]\n",
      "gradients: [[0.51403299]\n",
      " [0.21159942]]\n",
      "theta: [[4.10865336]\n",
      " [2.8640054 ]]\n",
      "gradients: [[-0.11749371]\n",
      " [-0.03331017]]\n",
      "theta: [[4.10546517]\n",
      " [2.85915048]]\n",
      "gradients: [[0.6076689 ]\n",
      " [0.92534678]]\n",
      "theta: [[4.11606189]\n",
      " [2.86386314]]\n",
      "gradients: [[-2.02185372]\n",
      " [-0.89917492]]\n",
      "theta: [[4.11407267]\n",
      " [2.86157563]]\n",
      "gradients: [[0.37994155]\n",
      " [0.43691364]]\n",
      "theta: [[4.09970833]\n",
      " [2.84918039]]\n",
      "gradients: [[2.7464622 ]\n",
      " [2.36997008]]\n",
      "theta: [[4.09658725]\n",
      " [2.84389222]]\n",
      "gradients: [[0.59737354]\n",
      " [1.01215569]]\n",
      "theta: [[4.09604795]\n",
      " [2.8438367 ]]\n",
      "gradients: [[0.10333067]\n",
      " [0.01063814]]\n",
      "theta: [[4.09698104]\n",
      " [2.84469261]]\n",
      "gradients: [[-0.17896666]\n",
      " [-0.16416462]]\n",
      "theta: [[4.08669082]\n",
      " [2.82918239]]\n",
      "gradients: [[1.97572283]\n",
      " [2.97796365]]\n",
      "theta: [[4.09091681]\n",
      " [2.8361212 ]]\n",
      "gradients: [[-0.81223683]\n",
      " [-1.33364055]]\n",
      "theta: [[4.09178711]\n",
      " [2.83636794]]\n",
      "gradients: [[-0.16744411]\n",
      " [-0.04747141]]\n",
      "theta: [[4.08232586]\n",
      " [2.82877529]]\n",
      "gradients: [[1.82223644]\n",
      " [1.46234416]]\n",
      "theta: [[4.09039615]\n",
      " [2.84242836]]\n",
      "gradients: [[-1.55595262]\n",
      " [-2.63231299]]\n",
      "theta: [[4.09450694]\n",
      " [2.84672544]]\n",
      "gradients: [[-0.79338308]\n",
      " [-0.8293364 ]]\n",
      "theta: [[4.07785308]\n",
      " [2.83049979]]\n",
      "gradients: [[3.21752688]\n",
      " [3.13479635]]\n",
      "theta: [[4.08228255]\n",
      " [2.83901917]]\n",
      "gradients: [[-0.85665895]\n",
      " [-1.64764924]]\n",
      "theta: [[4.09305798]\n",
      " [2.84381131]]\n",
      "gradients: [[-2.08612489]\n",
      " [-0.92775811]]\n",
      "theta: [[4.08139668]\n",
      " [2.82182788]]\n",
      "gradients: [[2.25996049]\n",
      " [4.26038846]]\n",
      "theta: [[4.08170095]\n",
      " [2.82188753]]\n",
      "gradients: [[-0.05902729]\n",
      " [-0.01157103]]\n",
      "theta: [[4.0856855]\n",
      " [2.8277329]]\n",
      "gradients: [[-0.77380074]\n",
      " [-1.13517061]]\n",
      "theta: [[4.08840616]\n",
      " [2.83115149]]\n",
      "gradients: [[-0.52889582]\n",
      " [-0.6645747 ]]\n",
      "theta: [[4.09262476]\n",
      " [2.83556126]]\n",
      "gradients: [[-0.82093886]\n",
      " [-0.85814091]]\n",
      "theta: [[4.11495174]\n",
      " [2.83916173]]\n",
      "gradients: [[-4.34929725]\n",
      " [-0.70137086]]\n",
      "theta: [[4.11215891]\n",
      " [2.83490885]]\n",
      "gradients: [[0.54460271]\n",
      " [0.82931078]]\n",
      "theta: [[4.11299458]\n",
      " [2.83567541]]\n",
      "gradients: [[-0.16312362]\n",
      " [-0.14963193]]\n",
      "theta: [[4.11362683]\n",
      " [2.83585465]]\n",
      "gradients: [[-0.12354134]\n",
      " [-0.03502471]]\n",
      "theta: [[4.13782727]\n",
      " [2.87942694]]\n",
      "gradients: [[-4.73360635]\n",
      " [-8.52273843]]\n",
      "theta: [[4.13449343]\n",
      " [2.87853969]]\n",
      "gradients: [[0.65276613]\n",
      " [0.17372261]]\n",
      "theta: [[4.13840358]\n",
      " [2.87901566]]\n",
      "gradients: [[-0.76638922]\n",
      " [-0.09328936]]\n",
      "theta: [[4.13398001]\n",
      " [2.8779343 ]]\n",
      "gradients: [[0.86790547]\n",
      " [0.21216164]]\n",
      "theta: [[4.12140129]\n",
      " [2.85422141]]\n",
      "gradients: [[2.47045917]\n",
      " [4.65721227]]\n",
      "theta: [[4.13544145]\n",
      " [2.8611735 ]]\n",
      "gradients: [[-2.76029437]\n",
      " [-1.36677992]]\n",
      "theta: [[4.13576762]\n",
      " [2.86126597]]\n",
      "gradients: [[-0.06418989]\n",
      " [-0.01819822]]\n",
      "theta: [[4.12293341]\n",
      " [2.84766052]]\n",
      "gradients: [[2.5283392 ]\n",
      " [2.68027222]]\n",
      "theta: [[4.11109657]\n",
      " [2.82534619]]\n",
      "gradients: [[2.33422409]\n",
      " [4.40038728]]\n",
      "theta: [[4.1103107 ]\n",
      " [2.82390173]]\n",
      "gradients: [[0.15513099]\n",
      " [0.28513652]]\n",
      "theta: [[4.11632859]\n",
      " [2.82708591]]\n",
      "gradients: [[-1.18913451]\n",
      " [-0.6291943 ]]\n",
      "theta: [[4.12017007]\n",
      " [2.83339338]]\n",
      "gradients: [[-0.75984586]\n",
      " [-1.24761795]]\n",
      "theta: [[4.12728457]\n",
      " [2.83464757]]\n",
      "gradients: [[-1.40866967]\n",
      " [-0.24833022]]\n",
      "theta: [[4.131321  ]\n",
      " [2.83930496]]\n",
      "gradients: [[-0.80002142]\n",
      " [-0.92309525]]\n",
      "theta: [[4.13265847]\n",
      " [2.84140104]]\n",
      "gradients: [[-0.26535434]\n",
      " [-0.41586106]]\n",
      "theta: [[4.12970361]\n",
      " [2.83690143]]\n",
      "gradients: [[0.58683613]\n",
      " [0.89362304]]\n",
      "theta: [[4.14534564]\n",
      " [2.86550771]]\n",
      "gradients: [[-3.10963534]\n",
      " [-5.68692908]]\n",
      "theta: [[4.13461599]\n",
      " [2.84933514]]\n",
      "gradients: [[2.1352003 ]\n",
      " [3.21834054]]\n",
      "theta: [[4.14422516]\n",
      " [2.85383541]]\n",
      "gradients: [[-1.91414833]\n",
      " [-0.89645216]]\n",
      "theta: [[4.13914524]\n",
      " [2.85148007]]\n",
      "gradients: [[1.01293748]\n",
      " [0.4696531 ]]\n",
      "theta: [[4.14096036]\n",
      " [2.85376083]]\n",
      "gradients: [[-0.36229816]\n",
      " [-0.45523935]]\n",
      "theta: [[4.12664189]\n",
      " [2.83781594]]\n",
      "gradients: [[2.86083019]\n",
      " [3.18578874]]\n",
      "theta: [[4.12360065]\n",
      " [2.83700657]]\n",
      "gradients: [[0.60824724]\n",
      " [0.16187466]]\n",
      "theta: [[4.12503921]\n",
      " [2.83926106]]\n",
      "gradients: [[-0.28799908]\n",
      " [-0.45134971]]\n",
      "theta: [[4.10990541]\n",
      " [2.82058794]]\n",
      "gradients: [[3.03281436]\n",
      " [3.74209369]]\n",
      "theta: [[4.11239001]\n",
      " [2.82370993]]\n",
      "gradients: [[-0.49841175]\n",
      " [-0.62627048]]\n",
      "theta: [[4.11380456]\n",
      " [2.82474028]]\n",
      "gradients: [[-0.28404145]\n",
      " [-0.20689467]]\n",
      "theta: [[4.13755219]\n",
      " [2.86749728]]\n",
      "gradients: [[-4.77327319]\n",
      " [-8.59415757]]\n",
      "theta: [[4.12361759]\n",
      " [2.85547288]]\n",
      "gradients: [[2.80364103]\n",
      " [2.41931068]]\n",
      "theta: [[4.13349256]\n",
      " [2.85986455]]\n",
      "gradients: [[-1.98881996]\n",
      " [-0.88448388]]\n",
      "theta: [[4.12683606]\n",
      " [2.8498687 ]]\n",
      "gradients: [[1.34195117]\n",
      " [2.01516504]]\n",
      "theta: [[4.15050151]\n",
      " [2.89398941]]\n",
      "gradients: [[-4.77568844]\n",
      " [-8.9035596 ]]\n",
      "theta: [[4.15589164]\n",
      " [2.89403021]]\n",
      "gradients: [[-1.08880455]\n",
      " [-0.00824232]]\n",
      "theta: [[4.13991896]\n",
      " [2.87432203]]\n",
      "gradients: [[3.22967504]\n",
      " [3.98499386]]\n",
      "theta: [[4.13953063]\n",
      " [2.87424591]]\n",
      "gradients: [[0.07859797]\n",
      " [0.01540744]]\n",
      "theta: [[4.1271539 ]\n",
      " [2.87015054]]\n",
      "gradients: [[2.50752477]\n",
      " [0.82972204]]\n",
      "theta: [[4.12044697]\n",
      " [2.86007895]]\n",
      "gradients: [[1.36016611]\n",
      " [2.04251783]]\n",
      "theta: [[4.10686752]\n",
      " [2.84836101]]\n",
      "gradients: [[2.75662778]\n",
      " [2.37874213]]\n",
      "theta: [[4.09889475]\n",
      " [2.84371169]]\n",
      "gradients: [[1.62006731]\n",
      " [0.94474069]]\n",
      "theta: [[4.10933599]\n",
      " [2.86294124]]\n",
      "gradients: [[-2.1237472 ]\n",
      " [-3.91128938]]\n",
      "theta: [[4.11009417]\n",
      " [2.86384366]]\n",
      "gradients: [[-0.15436542]\n",
      " [-0.18373369]]\n",
      "theta: [[4.11101737]\n",
      " [2.86448718]]\n",
      "gradients: [[-0.18814992]\n",
      " [-0.13114953]]\n",
      "theta: [[4.09755965]\n",
      " [2.85287428]]\n",
      "gradients: [[2.74537647]\n",
      " [2.36903318]]\n",
      "theta: [[4.09980251]\n",
      " [2.85481508]]\n",
      "gradients: [[-0.45799369]\n",
      " [-0.39631147]]\n",
      "theta: [[4.09157376]\n",
      " [2.83931796]]\n",
      "gradients: [[1.68195811]\n",
      " [3.16761012]]\n",
      "theta: [[4.08320715]\n",
      " [2.82943213]]\n",
      "gradients: [[1.71180801]\n",
      " [2.02264215]]\n",
      "theta: [[4.08864903]\n",
      " [2.8300153 ]]\n",
      "gradients: [[-1.11449741]\n",
      " [-0.11943375]]\n",
      "theta: [[4.10705877]\n",
      " [2.84830628]]\n",
      "gradients: [[-3.77399702]\n",
      " [-3.74965107]]\n",
      "theta: [[4.09523901]\n",
      " [2.84439521]]\n",
      "gradients: [[2.42541458]\n",
      " [0.80255236]]\n",
      "theta: [[4.10108166]\n",
      " [2.84443944]]\n",
      "gradients: [[-1.20008041]\n",
      " [-0.00908468]]\n",
      "theta: [[4.11635067]\n",
      " [2.87236354]]\n",
      "gradients: [[-3.13930807]\n",
      " [-5.74119483]]\n",
      "theta: [[4.11839508]\n",
      " [2.87315351]]\n",
      "gradients: [[-0.42073875]\n",
      " [-0.1625762 ]]\n",
      "theta: [[4.13601054]\n",
      " [2.89065533]]\n",
      "gradients: [[-3.62878508]\n",
      " [-3.60537589]]\n",
      "theta: [[4.13534006]\n",
      " [2.89027973]]\n",
      "gradients: [[0.13825224]\n",
      " [0.07744847]]\n",
      "theta: [[4.139345  ]\n",
      " [2.89612703]]\n",
      "gradients: [[-0.82661956]\n",
      " [-1.206882  ]]\n",
      "theta: [[4.15325462]\n",
      " [2.92156507]]\n",
      "gradients: [[-2.87372792]\n",
      " [-5.25549946]]\n",
      "theta: [[4.15497395]\n",
      " [2.92487192]]\n",
      "gradients: [[-0.35555626]\n",
      " [-0.68385674]]\n",
      "theta: [[4.16544772]\n",
      " [2.93653452]]\n",
      "gradients: [[-2.16807073]\n",
      " [-2.41415807]]\n",
      "theta: [[4.16992195]\n",
      " [2.937014  ]]\n",
      "gradients: [[-0.92706127]\n",
      " [-0.09934739]]\n",
      "theta: [[4.1597996]\n",
      " [2.9250536]]\n",
      "gradients: [[2.09937623]\n",
      " [2.48058592]]\n",
      "theta: [[4.14968109]\n",
      " [2.9169335 ]]\n",
      "gradients: [[2.10060187]\n",
      " [1.68573233]]\n",
      "theta: [[4.15780206]\n",
      " [2.92481968]]\n",
      "gradients: [[-1.68753616]\n",
      " [-1.63874744]]\n",
      "theta: [[4.14789035]\n",
      " [2.90615309]]\n",
      "gradients: [[2.06163474]\n",
      " [3.88265024]]\n",
      "theta: [[4.14737633]\n",
      " [2.90605233]]\n",
      "gradients: [[0.10702034]\n",
      " [0.02097903]]\n",
      "theta: [[4.15647572]\n",
      " [2.91009909]]\n",
      "gradients: [[-1.89631429]\n",
      " [-0.84334403]]\n",
      "theta: [[4.15734017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [2.91118529]]\n",
      "gradients: [[-0.18032382]\n",
      " [-0.22658271]]\n",
      "theta: [[4.15236283]\n",
      " [2.90933906]]\n",
      "gradients: [[1.03926855]\n",
      " [0.38549351]]\n",
      "theta: [[4.15721746]\n",
      " [2.91190774]]\n",
      "gradients: [[-1.01461712]\n",
      " [-0.53685374]]\n",
      "theta: [[4.15694039]\n",
      " [2.91157796]]\n",
      "gradients: [[0.05796244]\n",
      " [0.06898989]]\n",
      "theta: [[4.17530982]\n",
      " [2.9130189 ]]\n",
      "gradients: [[-3.84655819]\n",
      " [-0.30173366]]\n",
      "theta: [[4.18326144]\n",
      " [2.9144939 ]]\n",
      "gradients: [[-1.66665918]\n",
      " [-0.30915864]]\n",
      "theta: [[4.18350865]\n",
      " [2.91459602]]\n",
      "gradients: [[-0.05186445]\n",
      " [-0.02142513]]\n",
      "theta: [[4.18405606]\n",
      " [2.91528386]]\n",
      "gradients: [[-0.1149569 ]\n",
      " [-0.14444706]]\n",
      "theta: [[4.17970475]\n",
      " [2.90865776]]\n",
      "gradients: [[0.91464605]\n",
      " [1.39280582]]\n",
      "theta: [[4.18144059]\n",
      " [2.91150791]]\n",
      "gradients: [[-0.36522208]\n",
      " [-0.59967112]]\n",
      "theta: [[4.19046376]\n",
      " [2.92426234]]\n",
      "gradients: [[-1.90027903]\n",
      " [-2.68608293]]\n",
      "theta: [[4.18911266]\n",
      " [2.92350546]]\n",
      "gradients: [[0.28481176]\n",
      " [0.15955064]]\n",
      "theta: [[4.18461124]\n",
      " [2.91665079]]\n",
      "gradients: [[0.94979864]\n",
      " [1.44633553]]\n",
      "theta: [[4.18402393]\n",
      " [2.91595173]]\n",
      "gradients: [[0.12404086]\n",
      " [0.14763984]]\n",
      "theta: [[4.18255589]\n",
      " [2.91537328]]\n",
      "gradients: [[0.31034421]\n",
      " [0.12228469]]\n",
      "theta: [[4.16799425]\n",
      " [2.8991576 ]]\n",
      "gradients: [[3.08124313]\n",
      " [3.43123815]]\n",
      "theta: [[4.16372936]\n",
      " [2.89193143]]\n",
      "gradients: [[0.90330246]\n",
      " [1.53050422]]\n",
      "theta: [[4.14844554]\n",
      " [2.8730732 ]]\n",
      "gradients: [[3.24017125]\n",
      " [3.9979448 ]]\n",
      "theta: [[4.15193194]\n",
      " [2.87349758]]\n",
      "gradients: [[-0.73981584]\n",
      " [-0.0900547 ]]\n",
      "theta: [[4.15456877]\n",
      " [2.87361039]]\n",
      "gradients: [[-0.56006098]\n",
      " [-0.02395985]]\n",
      "theta: [[4.15765221]\n",
      " [2.87716818]]\n",
      "gradients: [[-0.65553945]\n",
      " [-0.75638644]]\n",
      "theta: [[4.17700806]\n",
      " [2.90302256]]\n",
      "gradients: [[-4.11892547]\n",
      " [-5.50181298]]\n",
      "theta: [[4.17012202]\n",
      " [2.89988033]]\n",
      "gradients: [[1.46672671]\n",
      " [0.66929571]]\n",
      "theta: [[4.19124133]\n",
      " [2.93925415]]\n",
      "gradients: [[-4.50263805]\n",
      " [-8.39449782]]\n",
      "theta: [[4.17809871]\n",
      " [2.92532176]]\n",
      "gradients: [[2.80463593]\n",
      " [2.97317219]]\n",
      "theta: [[4.16661858]\n",
      " [2.9130037 ]]\n",
      "gradients: [[2.45215629]\n",
      " [2.63113619]]\n",
      "theta: [[4.17264152]\n",
      " [2.91406547]]\n",
      "gradients: [[-1.28770412]\n",
      " [-0.22700556]]\n",
      "theta: [[4.16404328]\n",
      " [2.90462146]]\n",
      "gradients: [[1.84002295]\n",
      " [2.02101665]]\n",
      "theta: [[4.16415254]\n",
      " [2.90469762]]\n",
      "gradients: [[-0.02340353]\n",
      " [-0.01631338]]\n",
      "theta: [[4.16910282]\n",
      " [2.9047351 ]]\n",
      "gradients: [[-1.06134038]\n",
      " [-0.00803441]]\n",
      "theta: [[4.18206986]\n",
      " [2.92844934]]\n",
      "gradients: [[-2.78272726]\n",
      " [-5.08907663]]\n",
      "theta: [[4.18952048]\n",
      " [2.93568455]]\n",
      "gradients: [[-1.60039283]\n",
      " [-1.55412352]]\n",
      "theta: [[4.17229117]\n",
      " [2.91065947]]\n",
      "gradients: [[3.7043018 ]\n",
      " [5.38039207]]\n",
      "theta: [[4.1555758 ]\n",
      " [2.88638088]]\n",
      "gradients: [[3.59714676]\n",
      " [5.22475245]]\n",
      "theta: [[4.149036  ]\n",
      " [2.88339664]]\n",
      "gradients: [[1.40867436]\n",
      " [0.64280531]]\n",
      "theta: [[4.15139923]\n",
      " [2.88727693]]\n",
      "gradients: [[-0.50951383]\n",
      " [-0.83658889]]\n",
      "theta: [[4.15037102]\n",
      " [2.88717107]]\n",
      "gradients: [[0.22188775]\n",
      " [0.02284388]]\n",
      "theta: [[4.1410148 ]\n",
      " [2.87966271]]\n",
      "gradients: [[2.02094327]\n",
      " [1.62180633]]\n",
      "theta: [[4.14687232]\n",
      " [2.88957228]]\n",
      "gradients: [[-1.26639517]\n",
      " [-2.14244856]]\n",
      "theta: [[4.13618385]\n",
      " [2.87810366]]\n",
      "gradients: [[2.31298593]\n",
      " [2.48180796]]\n",
      "theta: [[4.1355766 ]\n",
      " [2.87726388]]\n",
      "gradients: [[0.13153065]\n",
      " [0.18189591]]\n",
      "theta: [[4.11977076]\n",
      " [2.85430636]]\n",
      "gradients: [[3.42670534]\n",
      " [4.97719118]]\n",
      "theta: [[4.11808698]\n",
      " [2.8523701 ]]\n",
      "gradients: [[0.36537966]\n",
      " [0.4201682 ]]\n",
      "theta: [[4.1161147 ]\n",
      " [2.85205632]]\n",
      "gradients: [[0.42838055]\n",
      " [0.06815372]]\n",
      "theta: [[4.11602569]\n",
      " [2.85193323]]\n",
      "gradients: [[0.01934975]\n",
      " [0.02675908]]\n",
      "theta: [[4.11934487]\n",
      " [2.85540282]]\n",
      "gradients: [[-0.72225281]\n",
      " [-0.75498276]]\n",
      "theta: [[4.11804956]\n",
      " [2.853022  ]]\n",
      "gradients: [[0.282118  ]\n",
      " [0.51854337]]\n",
      "theta: [[4.12112861]\n",
      " [2.8580776 ]]\n",
      "gradients: [[-0.67123313]\n",
      " [-1.10212157]]\n",
      "theta: [[4.1241718 ]\n",
      " [2.86393071]]\n",
      "gradients: [[-0.66402469]\n",
      " [-1.27714743]]\n",
      "theta: [[4.12036197]\n",
      " [2.86299938]]\n",
      "gradients: [[0.83206681]\n",
      " [0.20340079]]\n",
      "theta: [[4.12365078]\n",
      " [2.86646996]]\n",
      "gradients: [[-0.71893336]\n",
      " [-0.75866715]]\n",
      "theta: [[4.1123591 ]\n",
      " [2.86273362]]\n",
      "gradients: [[2.47061906]\n",
      " [0.8175102 ]]\n",
      "theta: [[4.11303862]\n",
      " [2.86354241]]\n",
      "gradients: [[-0.14881342]\n",
      " [-0.17712542]]\n",
      "theta: [[4.10934514]\n",
      " [2.86263953]]\n",
      "gradients: [[0.8096106 ]\n",
      " [0.19791132]]\n",
      "theta: [[4.10928648]\n",
      " [2.86262803]]\n",
      "gradients: [[0.01287012]\n",
      " [0.00252291]]\n",
      "theta: [[4.11922624]\n",
      " [2.87667809]]\n",
      "gradients: [[-2.18277265]\n",
      " [-3.08539339]]\n",
      "theta: [[4.1356963 ]\n",
      " [2.89304191]]\n",
      "gradients: [[-3.62011905]\n",
      " [-3.59676576]]\n",
      "theta: [[4.12276896]\n",
      " [2.88188668]]\n",
      "gradients: [[2.84401506]\n",
      " [2.45415014]]\n",
      "theta: [[4.12271031]\n",
      " [2.88184255]]\n",
      "gradients: [[0.01291611]\n",
      " [0.00971665]]\n",
      "theta: [[4.12588752]\n",
      " [2.88550855]]\n",
      "gradients: [[-0.7002592]\n",
      " [-0.8079858]]\n",
      "theta: [[4.12646033]\n",
      " [2.88590782]]\n",
      "gradients: [[-0.12636027]\n",
      " [-0.08807918]]\n",
      "theta: [[4.12439602]\n",
      " [2.8855794 ]]\n",
      "gradients: [[0.45579869]\n",
      " [0.07251585]]\n",
      "theta: [[4.11549811]\n",
      " [2.87843882]]\n",
      "gradients: [[1.96643863]\n",
      " [1.57806638]]\n",
      "theta: [[4.12539048]\n",
      " [2.88993443]]\n",
      "gradients: [[-2.18819136]\n",
      " [-2.54282796]]\n",
      "theta: [[4.12820925]\n",
      " [2.89288094]]\n",
      "gradients: [[-0.62407668]\n",
      " [-0.65235764]]\n",
      "theta: [[4.12871213]\n",
      " [2.89323148]]\n",
      "gradients: [[-0.111439  ]\n",
      " [-0.07767833]]\n",
      "theta: [[4.13169669]\n",
      " [2.89667517]]\n",
      "gradients: [[-0.66197359]\n",
      " [-0.7638104 ]]\n",
      "theta: [[4.14350556]\n",
      " [2.91042147]]\n",
      "gradients: [[-2.62156968]\n",
      " [-3.0516788 ]]\n",
      "theta: [[4.13948457]\n",
      " [2.90943853]]\n",
      "gradients: [[0.89346388]\n",
      " [0.21840946]]\n",
      "theta: [[4.14128923]\n",
      " [2.91208598]]\n",
      "gradients: [[-0.40135776]\n",
      " [-0.58879439]]\n",
      "theta: [[4.13888861]\n",
      " [2.90767355]]\n",
      "gradients: [[0.53437825]\n",
      " [0.98220707]]\n",
      "theta: [[4.14233894]\n",
      " [2.91271109]]\n",
      "gradients: [[-0.76873177]\n",
      " [-1.12236462]]\n",
      "theta: [[4.13013073]\n",
      " [2.89286109]]\n",
      "gradients: [[2.72242936]\n",
      " [4.42655035]]\n",
      "theta: [[4.12121678]\n",
      " [2.88570765]]\n",
      "gradients: [[1.98959517]\n",
      " [1.59664949]]\n",
      "theta: [[4.11874549]\n",
      " [2.88469035]]\n",
      "gradients: [[0.55208419]\n",
      " [0.22726303]]\n",
      "theta: [[4.11856519]\n",
      " [2.88465501]]\n",
      "gradients: [[0.04031601]\n",
      " [0.00790309]]\n",
      "theta: [[4.11894333]\n",
      " [2.88476221]]\n",
      "gradients: [[-0.08462811]\n",
      " [-0.02399258]]\n",
      "theta: [[4.11587   ]\n",
      " [2.88454234]]\n",
      "gradients: [[0.68842722]\n",
      " [0.04925221]]\n",
      "theta: [[4.11615833]\n",
      " [2.88480683]]\n",
      "gradients: [[-0.06464468]\n",
      " [-0.05929802]]\n",
      "theta: [[4.1352597 ]\n",
      " [2.88788713]]\n",
      "gradients: [[-4.28634735]\n",
      " [-0.69121951]]\n",
      "theta: [[4.13119312]\n",
      " [2.8873199 ]]\n",
      "gradients: [[0.9133533 ]\n",
      " [0.12739887]]\n",
      "theta: [[4.13089845]\n",
      " [2.88726214]]\n",
      "gradients: [[0.0662422 ]\n",
      " [0.01298536]]\n",
      "theta: [[4.12739267]\n",
      " [2.88132214]]\n",
      "gradients: [[0.78880087]\n",
      " [1.33649925]]\n",
      "theta: [[4.11453708]\n",
      " [2.8670063 ]]\n",
      "gradients: [[2.89507874]\n",
      " [3.22392755]]\n",
      "theta: [[4.12339565]\n",
      " [2.87094595]]\n",
      "gradients: [[-1.9967225 ]\n",
      " [-0.88799837]]\n",
      "theta: [[4.12301375]\n",
      " [2.87041781]]\n",
      "gradients: [[0.08615724]\n",
      " [0.11914827]]\n",
      "theta: [[4.12455037]\n",
      " [2.87234863]]\n",
      "gradients: [[-0.34696937]\n",
      " [-0.43597823]]\n",
      "theta: [[4.11379577]\n",
      " [2.85207448]]\n",
      "gradients: [[2.43054012]\n",
      " [4.58195845]]\n",
      "theta: [[4.10300275]\n",
      " [2.84850314]]\n",
      "gradients: [[2.44138232]\n",
      " [0.80783597]]\n",
      "theta: [[4.09950119]\n",
      " [2.8453638 ]]\n",
      "gradients: [[0.79275227]\n",
      " [0.71074613]]\n",
      "theta: [[4.10475954]\n",
      " [2.84540361]]\n",
      "gradients: [[-1.1915414 ]\n",
      " [-0.00902004]]\n",
      "theta: [[4.09535047]\n",
      " [2.83530779]]\n",
      "gradients: [[2.1339754 ]\n",
      " [2.28973166]]\n",
      "theta: [[4.09706018]\n",
      " [2.83867488]]\n",
      "gradients: [[-0.38810412]\n",
      " [-0.76432998]]\n",
      "theta: [[4.09530729]\n",
      " [2.83731171]]\n",
      "gradients: [[0.39825747]\n",
      " [0.30971287]]\n",
      "theta: [[4.10774893]\n",
      " [2.84347228]]\n",
      "gradients: [[-2.8292283 ]\n",
      " [-1.40091306]]\n",
      "theta: [[4.09769592]\n",
      " [2.82452075]]\n",
      "gradients: [[2.28806411]\n",
      " [4.31336829]]\n",
      "theta: [[4.0922681 ]\n",
      " [2.82204393]]\n",
      "gradients: [[1.23645865]\n",
      " [0.56421995]]\n",
      "theta: [[4.08493312]\n",
      " [2.81337704]]\n",
      "gradients: [[1.6723753 ]\n",
      " [1.97604915]]\n",
      "theta: [[4.08577583]\n",
      " [2.81361596]]\n",
      "gradients: [[-0.19230771]\n",
      " [-0.05452039]]\n",
      "theta: [[4.09227509]\n",
      " [2.8147617 ]]\n",
      "gradients: [[-1.48443116]\n",
      " [-0.26168599]]\n",
      "theta: [[4.08709299]\n",
      " [2.80768325]]\n",
      "gradients: [[1.18462991]\n",
      " [1.61813288]]\n",
      "theta: [[4.09000753]\n",
      " [2.81247687]]\n",
      "gradients: [[-0.66684779]\n",
      " [-1.09677958]]\n",
      "theta: [[4.11179255]\n",
      " [2.85309178]]\n",
      "gradients: [[-4.9887685 ]\n",
      " [-9.30081561]]\n",
      "theta: [[4.11796507]\n",
      " [2.86353428]]\n",
      "gradients: [[-1.41474345]\n",
      " [-2.39341963]]\n",
      "theta: [[4.1299875 ]\n",
      " [2.86948727]]\n",
      "gradients: [[-2.75794414]\n",
      " [-1.36561619]]\n",
      "theta: [[4.11940115]\n",
      " [2.8495303 ]]\n",
      "gradients: [[2.43062611]\n",
      " [4.58212056]]\n",
      "theta: [[4.14025328]\n",
      " [2.88840599]]\n",
      "gradients: [[-4.79182006]\n",
      " [-8.9336346 ]]\n",
      "theta: [[4.14382834]\n",
      " [2.89362566]]\n",
      "gradients: [[-0.82226453]\n",
      " [-1.20052358]]\n",
      "theta: [[4.14132069]\n",
      " [2.89167553]]\n",
      "gradients: [[0.57726092]\n",
      " [0.44891846]]\n",
      "theta: [[4.13917475]\n",
      " [2.88920781]]\n",
      "gradients: [[0.49442486]\n",
      " [0.56856368]]\n",
      "theta: [[4.14378142]\n",
      " [2.89164529]]\n",
      "gradients: [[-1.06229695]\n",
      " [-0.56208207]]\n",
      "theta: [[4.14530211]\n",
      " [2.89223289]]\n",
      "gradients: [[-0.35097607]\n",
      " [-0.13561944]]\n",
      "theta: [[4.15281028]\n",
      " [2.89362563]]\n",
      "gradients: [[-1.73438604]\n",
      " [-0.3217217 ]]\n",
      "theta: [[4.1495342 ]\n",
      " [2.89339125]]\n",
      "gradients: [[0.75742934]\n",
      " [0.05418884]]\n",
      "theta: [[4.13819459]\n",
      " [2.88137022]]\n",
      "gradients: [[2.62398387]\n",
      " [2.78166437]]\n",
      "theta: [[4.13076273]\n",
      " [2.87703634]]\n",
      "gradients: [[1.72122003]\n",
      " [1.0037278 ]]\n",
      "theta: [[4.13227858]\n",
      " [2.8795295 ]]\n",
      "gradients: [[-0.35137512]\n",
      " [-0.57791458]]\n",
      "theta: [[4.13485984]\n",
      " [2.87963993]]\n",
      "gradients: [[-0.5988516 ]\n",
      " [-0.02561934]]\n",
      "theta: [[4.1351336 ]\n",
      " [2.87996577]]\n",
      "gradients: [[-0.06356642]\n",
      " [-0.07566004]]\n",
      "theta: [[4.13095247]\n",
      " [2.87841487]]\n",
      "gradients: [[0.97169503]\n",
      " [0.36042862]]\n",
      "theta: [[4.12124824]\n",
      " [2.86800235]]\n",
      "gradients: [[2.25720268]\n",
      " [2.42195315]]\n",
      "theta: [[4.10701942]\n",
      " [2.85413938]]\n",
      "gradients: [[3.31246911]\n",
      " [3.22729739]]\n",
      "theta: [[4.10512145]\n",
      " [2.85266339]]\n",
      "gradients: [[0.4422285 ]\n",
      " [0.34390781]]\n",
      "theta: [[4.09708088]\n",
      " [2.84621084]]\n",
      "gradients: [[1.87505931]\n",
      " [1.50473449]]\n",
      "theta: [[4.0987667 ]\n",
      " [2.84647098]]\n",
      "gradients: [[-0.39346872]\n",
      " [-0.06071737]]\n",
      "theta: [[4.09542493]\n",
      " [2.8434749 ]]\n",
      "gradients: [[0.78063627]\n",
      " [0.69988348]]\n",
      "theta: [[4.11622199]\n",
      " [2.88224791]]\n",
      "gradients: [[-4.86235125]\n",
      " [-9.0651295 ]]\n",
      "theta: [[4.11607536]\n",
      " [2.88221917]]\n",
      "gradients: [[0.03431141]\n",
      " [0.00672601]]\n",
      "theta: [[4.12165872]\n",
      " [2.89166493]]\n",
      "gradients: [[-1.30762419]\n",
      " [-2.21219855]]\n",
      "theta: [[4.12655004]\n",
      " [2.89170196]]\n",
      "gradients: [[-1.14652533]\n",
      " [-0.00867926]]\n",
      "theta: [[4.12706134]\n",
      " [2.8923546 ]]\n",
      "gradients: [[-0.1199509 ]\n",
      " [-0.15310914]]\n",
      "theta: [[4.12680601]\n",
      " [2.89230455]]\n",
      "gradients: [[0.05995252]\n",
      " [0.0117524 ]]\n",
      "theta: [[4.12664999]\n",
      " [2.89218718]]\n",
      "gradients: [[0.03666471]\n",
      " [0.02758247]]\n",
      "theta: [[4.12481346]\n",
      " [2.88881158]]\n",
      "gradients: [[0.43195026]\n",
      " [0.79394062]]\n",
      "theta: [[4.10886607]\n",
      " [2.88335448]]\n",
      "gradients: [[3.75401501]\n",
      " [1.28460073]]\n",
      "theta: [[4.09850671]\n",
      " [2.86382541]]\n",
      "gradients: [[2.44066711]\n",
      " [4.60104947]]\n",
      "theta: [[4.11828247]\n",
      " [2.89943117]]\n",
      "gradients: [[-4.66312533]\n",
      " [-8.39583913]]\n",
      "theta: [[4.11815391]\n",
      " [2.89933446]]\n",
      "gradients: [[0.03034021]\n",
      " [0.02282462]]\n",
      "theta: [[4.118366 ]\n",
      " [2.8995869]]\n",
      "gradients: [[-0.05009539]\n",
      " [-0.05962612]]\n",
      "theta: [[4.11544978]\n",
      " [2.89937826]]\n",
      "gradients: [[0.68939377]\n",
      " [0.04932136]]\n",
      "theta: [[4.09745074]\n",
      " [2.87121245]]\n",
      "gradients: [[4.2585732 ]\n",
      " [6.66403016]]\n",
      "theta: [[4.09730292]\n",
      " [2.87100803]]\n",
      "gradients: [[0.03500451]\n",
      " [0.04840831]]\n",
      "theta: [[4.09458909]\n",
      " [2.87081387]]\n",
      "gradients: [[0.64317836]\n",
      " [0.04601497]]\n",
      "theta: [[4.09086305]\n",
      " [2.86943178]]\n",
      "gradients: [[0.88381662]\n",
      " [0.32783208]]\n",
      "theta: [[4.09866306]\n",
      " [2.87087865]]\n",
      "gradients: [[-1.8517232 ]\n",
      " [-0.34348728]]\n",
      "theta: [[4.11656586]\n",
      " [2.89479214]]\n",
      "gradients: [[-4.2537061 ]\n",
      " [-5.68184485]]\n",
      "theta: [[4.11598364]\n",
      " [2.89398698]]\n",
      "gradients: [[0.13845222]\n",
      " [0.19146786]]\n",
      "theta: [[4.11582214]\n",
      " [2.89395532]]\n",
      "gradients: [[0.03843711]\n",
      " [0.00753477]]\n",
      "theta: [[4.13479778]\n",
      " [2.92812048]]\n",
      "gradients: [[-4.51999819]\n",
      " [-8.13814233]]\n",
      "theta: [[4.13537469]\n",
      " [2.9283588 ]]\n",
      "gradients: [[-0.1375335 ]\n",
      " [-0.05681489]]\n",
      "theta: [[4.14101081]\n",
      " [2.92935237]]\n",
      "gradients: [[-1.3447781 ]\n",
      " [-0.23706696]]\n",
      "theta: [[4.13673908]\n",
      " [2.92776787]]\n",
      "gradients: [[1.02008717]\n",
      " [0.37837861]]\n",
      "theta: [[4.15053714]\n",
      " [2.94741716]]\n",
      "gradients: [[-3.29773505]\n",
      " [-4.69617964]]\n",
      "theta: [[4.13813104]\n",
      " [2.93671172]]\n",
      "gradients: [[2.96753944]\n",
      " [2.56074148]]\n",
      "theta: [[4.13864803]\n",
      " [2.93692529]]\n",
      "gradients: [[-0.12376894]\n",
      " [-0.05112877]]\n",
      "theta: [[4.13870991]\n",
      " [2.93694283]]\n",
      "gradients: [[-0.01482454]\n",
      " [-0.00420285]]\n",
      "theta: [[4.13496996]\n",
      " [2.93602859]]\n",
      "gradients: [[0.89683901]\n",
      " [0.21923452]]\n",
      "theta: [[4.14406676]\n",
      " [2.94615793]]\n",
      "gradients: [[-2.18323268]\n",
      " [-2.43104098]]\n",
      "theta: [[4.13949461]\n",
      " [2.94403803]]\n",
      "gradients: [[1.0982322 ]\n",
      " [0.50920039]]\n",
      "theta: [[4.14150275]\n",
      " [2.94613717]]\n",
      "gradients: [[-0.48275765]\n",
      " [-0.50463453]]\n",
      "theta: [[4.14834886]\n",
      " [2.95278536]]\n",
      "gradients: [[-1.64717414]\n",
      " [-1.59955233]]\n",
      "theta: [[4.15934755]\n",
      " [2.97289987]]\n",
      "gradients: [[-2.64848569]\n",
      " [-4.84357445]]\n",
      "theta: [[4.1600755 ]\n",
      " [2.97396777]]\n",
      "gradients: [[-0.1754354 ]\n",
      " [-0.25736485]]\n",
      "theta: [[4.15109121]\n",
      " [2.96335209]]\n",
      "gradients: [[2.16701118]\n",
      " [2.56050218]]\n",
      "theta: [[4.15046826]\n",
      " [2.96278066]]\n",
      "gradients: [[0.1503808 ]\n",
      " [0.13794305]]\n",
      "theta: [[4.13878227]\n",
      " [2.9407507 ]]\n",
      "gradients: [[2.82333369]\n",
      " [5.32243741]]\n",
      "theta: [[4.12906806]\n",
      " [2.92610868]]\n",
      "gradients: [[2.3488978]\n",
      " [3.5404421]]\n",
      "theta: [[4.13754021]\n",
      " [2.9359539 ]]\n",
      "gradients: [[-2.05026021]\n",
      " [-2.38254253]]\n",
      "theta: [[4.15406417]\n",
      " [2.95802562]]\n",
      "gradients: [[-4.00210462]\n",
      " [-5.34577071]]\n",
      "theta: [[4.14385679]\n",
      " [2.94707321]]\n",
      "gradients: [[2.47426896]\n",
      " [2.65486284]]\n",
      "theta: [[4.14467974]\n",
      " [2.94730332]]\n",
      "gradients: [[-0.19964749]\n",
      " [-0.05582374]]\n",
      "theta: [[4.15547693]\n",
      " [2.95264962]]\n",
      "gradients: [[-2.6215571 ]\n",
      " [-1.29808315]]\n",
      "theta: [[4.16615457]\n",
      " [2.95793674]]\n",
      "gradients: [[-2.5946682 ]\n",
      " [-1.28476891]]\n",
      "theta: [[4.18337883]\n",
      " [2.98894858]]\n",
      "gradients: [[-4.18893946]\n",
      " [-7.54207947]]\n",
      "theta: [[4.17842674]\n",
      " [2.98450876]]\n",
      "gradients: [[1.2053386 ]\n",
      " [1.08065254]]\n",
      "theta: [[4.17385278]\n",
      " [2.97754362]]\n",
      "gradients: [[1.11421616]\n",
      " [1.69670744]]\n",
      "theta: [[4.17147485]\n",
      " [2.9771653 ]]\n",
      "gradients: [[0.57974143]\n",
      " [0.09223466]]\n",
      "theta: [[4.18506478]\n",
      " [2.99066756]]\n",
      "gradients: [[-3.31594392]\n",
      " [-3.29455285]]\n",
      "theta: [[4.19109903]\n",
      " [2.99652736]]\n",
      "gradients: [[-1.47356415]\n",
      " [-1.43096162]]\n",
      "theta: [[4.207466  ]\n",
      " [3.02599567]]\n",
      "gradients: [[-4.00008768]\n",
      " [-7.20205662]]\n",
      "theta: [[4.19933499]\n",
      " [3.01378559]]\n",
      "gradients: [[1.9888456 ]\n",
      " [2.98658565]]\n",
      "theta: [[4.2159951 ]\n",
      " [3.01647222]]\n",
      "gradients: [[-4.07839561]\n",
      " [-0.65768506]]\n",
      "theta: [[4.21515413]\n",
      " [3.01541551]]\n",
      "gradients: [[0.2060375 ]\n",
      " [0.25889278]]\n",
      "theta: [[4.21492471]\n",
      " [3.01503881]]\n",
      "gradients: [[0.0562554 ]\n",
      " [0.09236774]]\n",
      "theta: [[4.21500418]\n",
      " [3.01506103]]\n",
      "gradients: [[-0.01950373]\n",
      " [-0.00545347]]\n",
      "theta: [[4.20129017]\n",
      " [2.99978926]]\n",
      "gradients: [[3.36816206]\n",
      " [3.75074788]]\n",
      "theta: [[4.19280509]\n",
      " [2.99046954]]\n",
      "gradients: [[2.08563226]\n",
      " [2.29078529]]\n",
      "theta: [[4.1784088 ]\n",
      " [2.97270641]]\n",
      "gradients: [[3.54148884]\n",
      " [4.36973104]]\n",
      "theta: [[4.17734933]\n",
      " [2.97190938]]\n",
      "gradients: [[0.26084122]\n",
      " [0.19622808]]\n",
      "theta: [[4.1844017 ]\n",
      " [2.98187805]]\n",
      "gradients: [[-1.73770415]\n",
      " [-2.45628004]]\n",
      "theta: [[4.18115577]\n",
      " [2.9810142 ]]\n",
      "gradients: [[0.80044622]\n",
      " [0.21302515]]\n",
      "theta: [[4.17303535]\n",
      " [2.97209502]]\n",
      "gradients: [[2.00411973]\n",
      " [2.20125479]]\n",
      "theta: [[4.17208681]\n",
      " [2.97060847]]\n",
      "gradients: [[0.23428923]\n",
      " [0.36717609]]\n",
      "theta: [[4.17179898]\n",
      " [2.97052687]]\n",
      "gradients: [[0.07115177]\n",
      " [0.02017195]]\n",
      "theta: [[4.15947098]\n",
      " [2.95988883]]\n",
      "gradients: [[3.04994666]\n",
      " [2.6318521 ]]\n",
      "theta: [[4.1444689 ]\n",
      " [2.93809874]]\n",
      "gradients: [[3.71451483]\n",
      " [5.3952262 ]]\n",
      "theta: [[4.15193333]\n",
      " [2.93939694]]\n",
      "gradients: [[-1.84968497]\n",
      " [-0.32169436]]\n",
      "theta: [[4.15932972]\n",
      " [2.94068331]]\n",
      "gradients: [[-1.83430455]\n",
      " [-0.31901942]]\n",
      "theta: [[4.15904506]\n",
      " [2.94031997]]\n",
      "gradients: [[0.07065114]\n",
      " [0.09018136]]\n",
      "theta: [[4.15861546]\n",
      " [2.9396467 ]]\n",
      "gradients: [[0.10671349]\n",
      " [0.16724047]]\n",
      "theta: [[4.17450479]\n",
      " [2.96087072]]\n",
      "gradients: [[-3.95008886]\n",
      " [-5.2762912 ]]\n",
      "theta: [[4.18074497]\n",
      " [2.96693048]]\n",
      "gradients: [[-1.5525549 ]\n",
      " [-1.50766864]]\n",
      "theta: [[4.16618982]\n",
      " [2.95274958]]\n",
      "gradients: [[3.62423146]\n",
      " [3.53104356]]\n",
      "theta: [[4.16852732]\n",
      " [2.95616238]]\n",
      "gradients: [[-0.58250545]\n",
      " [-0.85047026]]\n",
      "theta: [[4.15868431]\n",
      " [2.94132623]]\n",
      "gradients: [[2.45484726]\n",
      " [3.70013739]]\n",
      "theta: [[4.14444389]\n",
      " [2.93727938]]\n",
      "gradients: [[3.55440859]\n",
      " [1.01009142]]\n",
      "theta: [[4.14656103]\n",
      " [2.93972222]]\n",
      "gradients: [[-0.52886176]\n",
      " [-0.61022089]]\n",
      "theta: [[4.14770891]\n",
      " [2.94129812]]\n",
      "gradients: [[-0.28696928]\n",
      " [-0.39397507]]\n",
      "theta: [[4.14970326]\n",
      " [2.9434027 ]]\n",
      "gradients: [[-0.49898722]\n",
      " [-0.5265651 ]]\n",
      "theta: [[4.15687525]\n",
      " [2.94676155]]\n",
      "gradients: [[-1.79586456]\n",
      " [-0.84105637]]\n",
      "theta: [[4.15800132]\n",
      " [2.94719667]]\n",
      "gradients: [[-0.28219385]\n",
      " [-0.10904154]]\n",
      "theta: [[4.15214395]\n",
      " [2.94452384]]\n",
      "gradients: [[1.46902823]\n",
      " [0.67034594]]\n",
      "theta: [[4.1491026 ]\n",
      " [2.94430625]]\n",
      "gradients: [[0.76337952]\n",
      " [0.05461453]]\n",
      "theta: [[4.14819082]\n",
      " [2.94421239]]\n",
      "gradients: [[0.22903709]\n",
      " [0.02357992]]\n",
      "theta: [[4.14939024]\n",
      " [2.94467585]]\n",
      "gradients: [[-0.30153272]\n",
      " [-0.11651421]]\n",
      "theta: [[4.15372354]\n",
      " [2.94470865]]\n",
      "gradients: [[-1.0902597 ]\n",
      " [-0.00825333]]\n",
      "theta: [[4.15759354]\n",
      " [2.94675634]]\n",
      "gradients: [[-0.97446621]\n",
      " [-0.51560911]]\n",
      "theta: [[4.16598281]\n",
      " [2.95609783]]\n",
      "gradients: [[-2.1140947 ]\n",
      " [-2.35405548]]\n",
      "theta: [[4.15058866]\n",
      " [2.95083005]]\n",
      "gradients: [[3.88240358]\n",
      " [1.3285345 ]]\n",
      "theta: [[4.15489837]\n",
      " [2.95086268]]\n",
      "gradients: [[-1.08776968]\n",
      " [-0.00823448]]\n",
      "theta: [[4.16160242]\n",
      " [2.95210625]]\n",
      "gradients: [[-1.69344234]\n",
      " [-0.31412681]]\n",
      "theta: [[4.16100601]\n",
      " [2.95155917]]\n",
      "gradients: [[0.15077178]\n",
      " [0.13830169]]\n",
      "theta: [[4.17332233]\n",
      " [2.97165695]]\n",
      "gradients: [[-3.11602803]\n",
      " [-5.084739  ]]\n",
      "theta: [[4.16531774]\n",
      " [2.95574418]]\n",
      "gradients: [[2.02676003]\n",
      " [4.02911339]]\n",
      "theta: [[4.15364664]\n",
      " [2.95302051]]\n",
      "gradients: [[2.95745742]\n",
      " [0.69018007]]\n",
      "theta: [[4.14196231]\n",
      " [2.94012076]]\n",
      "gradients: [[2.9631475 ]\n",
      " [3.27137505]]\n",
      "theta: [[4.13944543]\n",
      " [2.93549466]]\n",
      "gradients: [[0.63878232]\n",
      " [1.17410563]]\n",
      "theta: [[4.13591157]\n",
      " [2.93463079]]\n",
      "gradients: [[0.89760204]\n",
      " [0.21942104]]\n",
      "theta: [[4.13717926]\n",
      " [2.93637119]]\n",
      "gradients: [[-0.32224808]\n",
      " [-0.44240871]]\n",
      "theta: [[4.13637912]\n",
      " [2.93628881]]\n",
      "gradients: [[0.20355655]\n",
      " [0.02095664]]\n",
      "theta: [[4.13238866]\n",
      " [2.93480864]]\n",
      "gradients: [[1.01596962]\n",
      " [0.3768513 ]]\n",
      "theta: [[4.13923489]\n",
      " [2.93607859]]\n",
      "gradients: [[-1.74441767]\n",
      " [-0.32358253]]\n",
      "theta: [[4.13522891]\n",
      " [2.93459266]]\n",
      "gradients: [[1.02152521]\n",
      " [0.37891202]]\n",
      "theta: [[4.15263875]\n",
      " [2.96705072]]\n",
      "gradients: [[-4.44299233]\n",
      " [-8.28329727]]\n",
      "theta: [[4.14844412]\n",
      " [2.96549482]]\n",
      "gradients: [[1.07130978]\n",
      " [0.39737849]]\n",
      "theta: [[4.14836209]\n",
      " [2.96547156]]\n",
      "gradients: [[0.02096688]\n",
      " [0.00594424]]\n",
      "theta: [[4.14727512]\n",
      " [2.96504326]]\n",
      "gradients: [[0.27804504]\n",
      " [0.10955787]]\n",
      "theta: [[4.14463812]\n",
      " [2.96201085]]\n",
      "gradients: [[0.67507211]\n",
      " [0.77629891]]\n",
      "theta: [[4.14028966]\n",
      " [2.95999466]]\n",
      "gradients: [[1.11407547]\n",
      " [0.5165462 ]]\n",
      "theta: [[4.14755373]\n",
      " [2.9632252 ]]\n",
      "gradients: [[-1.86250829]\n",
      " [-0.82830955]]\n",
      "theta: [[4.1463493 ]\n",
      " [2.96209095]]\n",
      "gradients: [[0.30905888]\n",
      " [0.29104752]]\n",
      "theta: [[4.1451635 ]\n",
      " [2.96097426]]\n",
      "gradients: [[0.30451372]\n",
      " [0.28676724]]\n",
      "theta: [[4.15181393]\n",
      " [2.96220789]]\n",
      "gradients: [[-1.70916077]\n",
      " [-0.31704252]]\n",
      "theta: [[4.14464931]\n",
      " [2.95802985]]\n",
      "gradients: [[1.84273951]\n",
      " [1.07459176]]\n",
      "theta: [[4.14567426]\n",
      " [2.95818801]]\n",
      "gradients: [[-0.26382159]\n",
      " [-0.04071112]]\n",
      "theta: [[4.15807031]\n",
      " [2.97584077]]\n",
      "gradients: [[-3.19322438]\n",
      " [-4.54734994]]\n",
      "theta: [[4.14793906]\n",
      " [2.97248841]]\n",
      "gradients: [[2.61183816]\n",
      " [0.8642386 ]]\n",
      "theta: [[4.14365633]\n",
      " [2.9686487 ]]\n",
      "gradients: [[1.10494414]\n",
      " [0.99064337]]\n",
      "theta: [[4.13229937]\n",
      " [2.9589947 ]]\n",
      "gradients: [[2.93236751]\n",
      " [2.49266313]]\n",
      "theta: [[4.12677153]\n",
      " [2.95647225]]\n",
      "gradients: [[1.42839166]\n",
      " [0.65180269]]\n",
      "theta: [[4.1421189 ]\n",
      " [2.97697233]]\n",
      "gradients: [[-3.9688276 ]\n",
      " [-5.30132127]]\n",
      "theta: [[4.15705685]\n",
      " [2.9781441 ]]\n",
      "gradients: [[-3.86594178]\n",
      " [-0.30325416]]\n",
      "theta: [[4.15326485]\n",
      " [2.97761517]]\n",
      "gradients: [[0.98212654]\n",
      " [0.13699169]]\n",
      "theta: [[4.1534952 ]\n",
      " [2.97771033]]\n",
      "gradients: [[-0.059707  ]\n",
      " [-0.02466487]]\n",
      "theta: [[4.16946689]\n",
      " [3.00646694]]\n",
      "gradients: [[-4.1430545 ]\n",
      " [-7.45946476]]\n",
      "theta: [[4.15941923]\n",
      " [2.99132232]]\n",
      "gradients: [[2.60837231]\n",
      " [3.93154232]]\n",
      "theta: [[4.14782482]\n",
      " [2.97247033]]\n",
      "gradients: [[3.01222675]\n",
      " [4.89774815]]\n",
      "theta: [[4.14510219]\n",
      " [2.97035302]]\n",
      "gradients: [[0.70788414]\n",
      " [0.55050022]]\n",
      "theta: [[4.13858027]\n",
      " [2.96055926]]\n",
      "gradients: [[1.6970044 ]\n",
      " [2.54833708]]\n",
      "theta: [[4.13600396]\n",
      " [2.95855575]]\n",
      "gradients: [[0.67086927]\n",
      " [0.52171486]]\n",
      "theta: [[4.1225027 ]\n",
      " [2.94540163]]\n",
      "gradients: [[3.51843066]\n",
      " [3.42796316]]\n",
      "theta: [[4.12896973]\n",
      " [2.95168169]]\n",
      "gradients: [[-1.68660281]\n",
      " [-1.63784107]]\n",
      "theta: [[4.11924694]\n",
      " [2.94846449]]\n",
      "gradients: [[2.53764887]\n",
      " [0.83968989]]\n",
      "theta: [[4.10898593]\n",
      " [2.93758688]]\n",
      "gradients: [[2.68017477]\n",
      " [2.8412319 ]]\n",
      "theta: [[4.10580142]\n",
      " [2.93273757]]\n",
      "gradients: [[0.83243104]\n",
      " [1.26761034]]\n",
      "theta: [[4.11267589]\n",
      " [2.93401275]]\n",
      "gradients: [[-1.79836051]\n",
      " [-0.33358871]]\n",
      "theta: [[4.11293723]\n",
      " [2.93408685]]\n",
      "gradients: [[-0.06842028]\n",
      " [-0.01939756]]\n",
      "theta: [[4.11982798]\n",
      " [2.93573823]]\n",
      "gradients: [[-1.80537466]\n",
      " [-0.43266356]]\n",
      "theta: [[4.10311888]\n",
      " [2.90959099]]\n",
      "gradients: [[4.38112542]\n",
      " [6.85580606]]\n",
      "theta: [[4.11190627]\n",
      " [2.9193758 ]]\n",
      "gradients: [[-2.30581165]\n",
      " [-2.5675333 ]]\n",
      "theta: [[4.11285758]\n",
      " [2.92094045]]\n",
      "gradients: [[-0.2498147 ]\n",
      " [-0.41087587]]\n",
      "theta: [[4.11224866]\n",
      " [2.92036701]]\n",
      "gradients: [[0.16002562]\n",
      " [0.15069964]]\n",
      "theta: [[4.10572847]\n",
      " [2.91656477]]\n",
      "gradients: [[1.71481003]\n",
      " [0.99998982]]\n",
      "theta: [[4.10821363]\n",
      " [2.91943224]]\n",
      "gradients: [[-0.65409524]\n",
      " [-0.75472006]]\n",
      "theta: [[4.10917564]\n",
      " [2.92064104]]\n",
      "gradients: [[-0.25339317]\n",
      " [-0.31839672]]\n",
      "theta: [[4.10706349]\n",
      " [2.91977158]]\n",
      "gradients: [[0.55676228]\n",
      " [0.22918874]]\n",
      "theta: [[4.10815713]\n",
      " [2.92007738]]\n",
      "gradients: [[-0.28850178]\n",
      " [-0.08066842]]\n",
      "theta: [[4.10848046]\n",
      " [2.92016904]]\n",
      "gradients: [[-0.08535932]\n",
      " [-0.02419988]]\n",
      "theta: [[4.10786509]\n",
      " [2.91992657]]\n",
      "gradients: [[0.16258076]\n",
      " [0.06406157]]\n",
      "theta: [[4.10730484]\n",
      " [2.91939897]]\n",
      "gradients: [[0.14813106]\n",
      " [0.13949826]]\n",
      "theta: [[4.11261125]\n",
      " [2.92033442]]\n",
      "gradients: [[-1.4040768 ]\n",
      " [-0.24752056]]\n",
      "theta: [[4.1106953 ]\n",
      " [2.91681283]]\n",
      "gradients: [[0.50734414]\n",
      " [0.93251737]]\n",
      "theta: [[4.11809192]\n",
      " [2.92010231]]\n",
      "gradients: [[-1.96010535]\n",
      " [-0.8717137 ]]\n",
      "theta: [[4.11729438]\n",
      " [2.91899938]]\n",
      "gradients: [[0.21150805]\n",
      " [0.29249798]]\n",
      "theta: [[4.12996054]\n",
      " [2.93703677]]\n",
      "gradients: [[-3.36159823]\n",
      " [-4.78712477]]\n",
      "theta: [[4.1320629 ]\n",
      " [2.93946256]]\n",
      "gradients: [[-0.55838833]\n",
      " [-0.64428977]]\n",
      "theta: [[4.13264739]\n",
      " [2.94019699]]\n",
      "gradients: [[-0.15535714]\n",
      " [-0.19521127]]\n",
      "theta: [[4.1308224 ]\n",
      " [2.93990664]]\n",
      "gradients: [[0.48544723]\n",
      " [0.07723281]]\n",
      "theta: [[4.13273352]\n",
      " [2.94190437]]\n",
      "gradients: [[-0.50873927]\n",
      " [-0.53179354]]\n",
      "theta: [[4.12508879]\n",
      " [2.93287149]]\n",
      "gradients: [[2.03655611]\n",
      " [2.40635877]]\n",
      "theta: [[4.11381617]\n",
      " [2.92031842]]\n",
      "gradients: [[3.00528054]\n",
      " [3.34664706]]\n",
      "theta: [[4.1017832 ]\n",
      " [2.90547132]]\n",
      "gradients: [[3.2103965 ]\n",
      " [3.96120667]]\n",
      "theta: [[4.09908576]\n",
      " [2.90136371]]\n",
      "gradients: [[0.72021563]\n",
      " [1.09673083]]\n",
      "theta: [[4.09371586]\n",
      " [2.89402875]]\n",
      "gradients: [[1.4348375 ]\n",
      " [1.95990133]]\n",
      "theta: [[4.09707757]\n",
      " [2.89893692]]\n",
      "gradients: [[-0.89892066]\n",
      " [-1.31244314]]\n",
      "theta: [[4.10020259]\n",
      " [2.89931731]]\n",
      "gradients: [[-0.83625521]\n",
      " [-0.10179386]]\n",
      "theta: [[4.10016911]\n",
      " [2.89931075]]\n",
      "gradients: [[0.0089648 ]\n",
      " [0.00175736]]\n",
      "theta: [[4.10495123]\n",
      " [2.90740099]]\n",
      "gradients: [[-1.28160663]\n",
      " [-2.16818284]]\n",
      "theta: [[4.11832789]\n",
      " [2.92069135]]\n",
      "gradients: [[-3.58761968]\n",
      " [-3.56447605]]\n",
      "theta: [[4.11809533]\n",
      " [2.9205164 ]]\n",
      "gradients: [[0.06241865]\n",
      " [0.04695689]]\n",
      "theta: [[4.10197463]\n",
      " [2.89528991]]\n",
      "gradients: [[4.33002034]\n",
      " [6.77583425]]\n",
      "theta: [[4.10156299]\n",
      " [2.89472066]]\n",
      "gradients: [[0.11064652]\n",
      " [0.15301489]]\n",
      "theta: [[4.0892018 ]\n",
      " [2.88267731]]\n",
      "gradients: [[3.32516127]\n",
      " [3.2396632 ]]\n",
      "theta: [[4.08800531]\n",
      " [2.88047811]]\n",
      "gradients: [[0.3220949 ]\n",
      " [0.59202239]]\n",
      "theta: [[4.0876575 ]\n",
      " [2.88044231]]\n",
      "gradients: [[0.0937    ]\n",
      " [0.00964664]]\n",
      "theta: [[4.09003871]\n",
      " [2.88435209]]\n",
      "gradients: [[-0.64197249]\n",
      " [-1.05407747]]\n",
      "theta: [[4.09080058]\n",
      " [2.88585251]]\n",
      "gradients: [[-0.20555255]\n",
      " [-0.404814  ]]\n",
      "theta: [[4.09308917]\n",
      " [2.88961023]]\n",
      "gradients: [[-0.61791992]\n",
      " [-1.01458471]]\n",
      "theta: [[4.0870173 ]\n",
      " [2.88606943]]\n",
      "gradients: [[1.64061948]\n",
      " [0.95672567]]\n",
      "theta: [[4.08857658]\n",
      " [2.8874187 ]]\n",
      "gradients: [[-0.42162948]\n",
      " [-0.36484476]]\n",
      "theta: [[4.09021871]\n",
      " [2.88742853]]\n",
      "gradients: [[-0.44436039]\n",
      " [-0.00265857]]\n",
      "theta: [[4.08549597]\n",
      " [2.88527346]]\n",
      "gradients: [[1.27891629]\n",
      " [0.58359419]]\n",
      "theta: [[4.09282441]\n",
      " [2.886548  ]]\n",
      "gradients: [[-1.9860054]\n",
      " [-0.345403 ]]\n",
      "theta: [[4.09507953]\n",
      " [2.89025077]]\n",
      "gradients: [[-0.61158835]\n",
      " [-1.00418867]]\n",
      "theta: [[4.09931454]\n",
      " [2.8924916 ]]\n",
      "gradients: [[-1.14938371]\n",
      " [-0.60816138]]\n",
      "theta: [[4.09613247]\n",
      " [2.88963869]]\n",
      "gradients: [[0.86425201]\n",
      " [0.7748496 ]]\n",
      "theta: [[4.10896376]\n",
      " [2.90791124]]\n",
      "gradients: [[-3.48754495]\n",
      " [-4.96648072]]\n",
      "theta: [[4.11280995]\n",
      " [2.90832342]]\n",
      "gradients: [[-1.04616396]\n",
      " [-0.11211088]]\n",
      "theta: [[4.11110683]\n",
      " [2.90519303]]\n",
      "gradients: [[0.46358821]\n",
      " [0.85209235]]\n",
      "theta: [[4.11833744]\n",
      " [2.90840868]]\n",
      "gradients: [[-1.96961759]\n",
      " [-0.87594405]]\n",
      "theta: [[4.12496577]\n",
      " [2.90999718]]\n",
      "gradients: [[-1.80688195]\n",
      " [-0.43302479]]\n",
      "theta: [[4.12633829]\n",
      " [2.91052753]]\n",
      "gradients: [[-0.37442479]\n",
      " [-0.14468018]]\n",
      "theta: [[4.12425562]\n",
      " [2.9089079 ]]\n",
      "gradients: [[0.56856898]\n",
      " [0.442159  ]]\n",
      "theta: [[4.14054145]\n",
      " [2.93823012]]\n",
      "gradients: [[-4.44928772]\n",
      " [-8.01082994]]\n",
      "theta: [[4.14022224]\n",
      " [2.93785018]]\n",
      "gradients: [[0.08727094]\n",
      " [0.10387438]]\n",
      "theta: [[4.13664448]\n",
      " [2.93178823]]\n",
      "gradients: [[0.97887546]\n",
      " [1.65855081]]\n",
      "theta: [[4.13679177]\n",
      " [2.9318909 ]]\n",
      "gradients: [[-0.04032804]\n",
      " [-0.02811058]]\n",
      "theta: [[4.14602313]\n",
      " [2.94263681]]\n",
      "gradients: [[-2.52939267]\n",
      " [-2.94437872]]\n",
      "theta: [[4.15283014]\n",
      " [2.94566407]]\n",
      "gradients: [[-1.8664804 ]\n",
      " [-0.83007606]]\n",
      "theta: [[4.15902368]\n",
      " [2.94681295]]\n",
      "gradients: [[-1.69950745]\n",
      " [-0.31525186]]\n",
      "theta: [[4.15768628]\n",
      " [2.94496344]]\n",
      "gradients: [[0.36724872]\n",
      " [0.5078743 ]]\n",
      "theta: [[4.15381066]\n",
      " [2.94352587]]\n",
      "gradients: [[1.06501927]\n",
      " [0.39504517]]\n",
      "theta: [[4.15139294]\n",
      " [2.94253062]]\n",
      "gradients: [[0.6648732 ]\n",
      " [0.27369213]]\n",
      "theta: [[4.13516651]\n",
      " [2.91713869]]\n",
      "gradients: [[4.46551351]\n",
      " [6.98786079]]\n",
      "theta: [[4.12528096]\n",
      " [2.90106521]]\n",
      "gradients: [[2.72248266]\n",
      " [4.42663702]]\n",
      "theta: [[4.12550553]\n",
      " [2.90112887]]\n",
      "gradients: [[-0.0618918]\n",
      " [-0.0175467]]\n",
      "theta: [[4.13317573]\n",
      " [2.91004217]]\n",
      "gradients: [[-2.11544175]\n",
      " [-2.45828794]]\n",
      "theta: [[4.14515828]\n",
      " [2.92959531]]\n",
      "gradients: [[-3.30718358]\n",
      " [-5.39666691]]\n",
      "theta: [[4.144881  ]\n",
      " [2.92934096]]\n",
      "gradients: [[0.07658532]\n",
      " [0.07025107]]\n",
      "theta: [[4.15653364]\n",
      " [2.94835576]]\n",
      "gradients: [[-3.22078945]\n",
      " [-5.25568885]]\n",
      "theta: [[4.17074544]\n",
      " [2.96733904]]\n",
      "gradients: [[-3.93098643]\n",
      " [-5.25077532]]\n",
      "theta: [[4.18174635]\n",
      " [2.98529033]]\n",
      "gradients: [[-3.04504994]\n",
      " [-4.96891685]]\n",
      "theta: [[4.17761979]\n",
      " [2.98375967]]\n",
      "gradients: [[1.14305612]\n",
      " [0.4239912 ]]\n",
      "theta: [[4.17802241]\n",
      " [2.98387225]]\n",
      "gradients: [[-0.11160557]\n",
      " [-0.0312062 ]]\n",
      "theta: [[4.17079771]\n",
      " [2.97593689]]\n",
      "gradients: [[2.00413138]\n",
      " [2.20126758]]\n",
      "theta: [[4.1598177 ]\n",
      " [2.96381474]]\n",
      "gradients: [[3.04804996]\n",
      " [3.36510909]]\n",
      "theta: [[4.16139034]\n",
      " [2.96562931]]\n",
      "gradients: [[-0.43687911]\n",
      " [-0.5040878 ]]\n",
      "theta: [[4.16200107]\n",
      " [2.96680396]]\n",
      "gradients: [[-0.16978349]\n",
      " [-0.32655194]]\n",
      "theta: [[4.15144155]\n",
      " [2.94963464]]\n",
      "gradients: [[2.93765888]\n",
      " [4.77650408]]\n",
      "theta: [[4.15808458]\n",
      " [2.95258898]]\n",
      "gradients: [[-1.84941929]\n",
      " [-0.8224885 ]]\n",
      "theta: [[4.16383289]\n",
      " [2.95817111]]\n",
      "gradients: [[-1.60147991]\n",
      " [-1.55517918]]\n",
      "theta: [[4.17778615]\n",
      " [2.97680902]]\n",
      "gradients: [[-3.89016641]\n",
      " [-5.19625038]]\n",
      "theta: [[4.16698148]\n",
      " [2.9676245 ]]\n",
      "gradients: [[3.01450052]\n",
      " [2.56248042]]\n",
      "theta: [[4.17026705]\n",
      " [2.9679766 ]]\n",
      "gradients: [[-0.91733031]\n",
      " [-0.09830458]]\n",
      "theta: [[4.17067284]\n",
      " [2.96832774]]\n",
      "gradients: [[-0.11337802]\n",
      " [-0.09810836]]\n",
      "theta: [[4.17057004]\n",
      " [2.96815866]]\n",
      "gradients: [[0.02874314]\n",
      " [0.0472745 ]]\n",
      "theta: [[4.15990041]\n",
      " [2.95908893]]\n",
      "gradients: [[2.98536181]\n",
      " [2.53771101]]\n",
      "theta: [[4.1661889 ]\n",
      " [2.96203401]]\n",
      "gradients: [[-1.76077761]\n",
      " [-0.82462412]]\n",
      "theta: [[4.16696326]\n",
      " [2.96330545]]\n",
      "gradients: [[-0.21697303]\n",
      " [-0.35625574]]\n",
      "theta: [[4.17027391]\n",
      " [2.96505718]]\n",
      "gradients: [[-0.92830693]\n",
      " [-0.49118533]]\n",
      "theta: [[4.16410341]\n",
      " [2.95579113]]\n",
      "gradients: [[1.73144263]\n",
      " [2.60005187]]\n",
      "theta: [[4.15375422]\n",
      " [2.93896381]]\n",
      "gradients: [[2.9060508 ]\n",
      " [4.72511072]]\n",
      "theta: [[4.15473168]\n",
      " [2.94030575]]\n",
      "gradients: [[-0.27466531]\n",
      " [-0.37708316]]\n",
      "theta: [[4.14496239]\n",
      " [2.92188908]]\n",
      "gradients: [[2.74712289]\n",
      " [5.17876782]]\n",
      "theta: [[4.16085043]\n",
      " [2.95150995]]\n",
      "gradients: [[-4.47089323]\n",
      " [-8.33531434]]\n",
      "theta: [[4.1541079]\n",
      " [2.9441042]]\n",
      "gradients: [[1.8986962 ]\n",
      " [2.08546128]]\n",
      "theta: [[4.15183473]\n",
      " [2.94149016]]\n",
      "gradients: [[0.64057992]\n",
      " [0.73663463]]\n",
      "theta: [[4.14946693]\n",
      " [2.9396488 ]]\n",
      "gradients: [[0.66771926]\n",
      " [0.5192652 ]]\n",
      "theta: [[4.15128602]\n",
      " [2.94174773]]\n",
      "gradients: [[-0.51334785]\n",
      " [-0.59232034]]\n",
      "theta: [[4.15513345]\n",
      " [2.94177686]]\n",
      "gradients: [[-1.08651247]\n",
      " [-0.00822496]]\n",
      "theta: [[4.14472547]\n",
      " [2.93028624]]\n",
      "gradients: [[2.94129468]\n",
      " [3.2472491 ]]\n",
      "theta: [[4.15183026]\n",
      " [2.9385425 ]]\n",
      "gradients: [[-2.00923616]\n",
      " [-2.33486978]]\n",
      "theta: [[4.14828101]\n",
      " [2.93252885]]\n",
      "gradients: [[1.00443754]\n",
      " [1.70186174]]\n",
      "theta: [[4.13873138]\n",
      " [2.92240536]]\n",
      "gradients: [[2.70445643]\n",
      " [2.8669727 ]]\n",
      "theta: [[4.13545006]\n",
      " [2.92194767]]\n",
      "gradients: [[0.9299262 ]\n",
      " [0.12971054]]\n",
      "theta: [[4.12329918]\n",
      " [2.91010922]]\n",
      "gradients: [[3.44598926]\n",
      " [3.3573844 ]]\n",
      "theta: [[4.11290099]\n",
      " [2.89852991]]\n",
      "gradients: [[2.9510057 ]\n",
      " [3.28620719]]\n",
      "theta: [[4.11036117]\n",
      " [2.89466231]]\n",
      "gradients: [[0.72131072]\n",
      " [1.09839841]]\n",
      "theta: [[4.11679826]\n",
      " [2.89620498]]\n",
      "gradients: [[-1.82942322]\n",
      " [-0.43842687]]\n",
      "theta: [[4.10987739]\n",
      " [2.89065098]]\n",
      "gradients: [[1.96829717]\n",
      " [1.57955785]]\n",
      "theta: [[4.11295701]\n",
      " [2.89514729]]\n",
      "gradients: [[-0.87646085]\n",
      " [-1.27965135]]\n",
      "theta: [[4.12109712]\n",
      " [2.90421134]]\n",
      "gradients: [[-2.31830166]\n",
      " [-2.58144099]]\n",
      "theta: [[4.11946537]\n",
      " [2.90121214]]\n",
      "gradients: [[0.46504625]\n",
      " [0.85477228]]\n",
      "theta: [[4.12001582]\n",
      " [2.90161308]]\n",
      "gradients: [[-0.15698611]\n",
      " [-0.11434806]]\n",
      "theta: [[4.12026848]\n",
      " [2.90168471]]\n",
      "gradients: [[-0.07211142]\n",
      " [-0.02044402]]\n",
      "theta: [[4.11522261]\n",
      " [2.89410748]]\n",
      "gradients: [[1.441103  ]\n",
      " [2.16405816]]\n",
      "theta: [[4.11469447]\n",
      " [2.89405311]]\n",
      "gradients: [[0.15094094]\n",
      " [0.01553973]]\n",
      "theta: [[4.10456148]\n",
      " [2.88276912]]\n",
      "gradients: [[2.89803647]\n",
      " [3.22722125]]\n",
      "theta: [[4.10600259]\n",
      " [2.88277774]]\n",
      "gradients: [[-0.41244622]\n",
      " [-0.00246763]]\n",
      "theta: [[4.11805046]\n",
      " [2.90243747]]\n",
      "gradients: [[-3.45051014]\n",
      " [-5.6305474 ]]\n",
      "theta: [[4.11939461]\n",
      " [2.90244551]]\n",
      "gradients: [[-0.38523291]\n",
      " [-0.00230482]]\n",
      "theta: [[4.11630645]\n",
      " [2.90201476]]\n",
      "gradients: [[0.88568446]\n",
      " [0.12353949]]\n",
      "theta: [[4.10667445]\n",
      " [2.89382707]]\n",
      "gradients: [[2.7643832 ]\n",
      " [2.34986783]]\n",
      "theta: [[4.11870276]\n",
      " [2.91095614]]\n",
      "gradients: [[-3.45453195]\n",
      " [-4.91946817]]\n",
      "theta: [[4.1252729 ]\n",
      " [2.91403313]]\n",
      "gradients: [[-1.88825692]\n",
      " [-0.88432644]]\n",
      "theta: [[4.11546652]\n",
      " [2.90320668]]\n",
      "gradients: [[2.8203143 ]\n",
      " [3.11368429]]\n",
      "theta: [[4.11585828]\n",
      " [2.90370674]]\n",
      "gradients: [[-0.11274796]\n",
      " [-0.14391507]]\n",
      "theta: [[4.12753361]\n",
      " [2.92275856]]\n",
      "gradients: [[-3.36249482]\n",
      " [-5.48692388]]\n",
      "theta: [[4.132261  ]\n",
      " [2.92359193]]\n",
      "gradients: [[-1.36243475]\n",
      " [-0.2401796 ]]\n",
      "theta: [[4.13432451]\n",
      " [2.92368021]]\n",
      "gradients: [[-0.59511672]\n",
      " [-0.02545956]]\n",
      "theta: [[4.147803 ]\n",
      " [2.9247375]]\n",
      "gradients: [[-3.88989128]\n",
      " [-0.30513282]]\n",
      "theta: [[4.14574651]\n",
      " [2.9209576 ]]\n",
      "gradients: [[0.5939137 ]\n",
      " [1.09163543]]\n",
      "theta: [[4.14647479]\n",
      " [2.92116123]]\n",
      "gradients: [[-0.2104725 ]\n",
      " [-0.05885053]]\n",
      "theta: [[4.15230376]\n",
      " [2.92682168]]\n",
      "gradients: [[-1.68573777]\n",
      " [-1.63700104]]\n",
      "theta: [[4.14343069]\n",
      " [2.92388565]]\n",
      "gradients: [[2.56786492]\n",
      " [0.84968816]]\n",
      "theta: [[4.14402438]\n",
      " [2.92486209]]\n",
      "gradients: [[-0.17193097]\n",
      " [-0.28277874]]\n",
      "theta: [[4.13787493]\n",
      " [2.91263724]]\n",
      "gradients: [[1.78211172]\n",
      " [3.54276288]]\n",
      "theta: [[4.13809756]\n",
      " [2.91279243]]\n",
      "gradients: [[-0.06456548]\n",
      " [-0.04500524]]\n",
      "theta: [[4.1321628 ]\n",
      " [2.90099436]]\n",
      "gradients: [[1.72227012]\n",
      " [3.42380031]]\n",
      "theta: [[4.12890799]\n",
      " [2.89807625]]\n",
      "gradients: [[0.9451949 ]\n",
      " [0.84741936]]\n",
      "theta: [[4.12831536]\n",
      " [2.89725668]]\n",
      "gradients: [[0.17221977]\n",
      " [0.23816556]]\n",
      "theta: [[4.11960841]\n",
      " [2.88084268]]\n",
      "gradients: [[2.53198143]\n",
      " [4.77319163]]\n",
      "theta: [[4.13309997]\n",
      " [2.88190099]]\n",
      "gradients: [[-3.92604406]\n",
      " [-0.30796873]]\n",
      "theta: [[4.14540077]\n",
      " [2.89412244]]\n",
      "gradients: [[-3.5819932 ]\n",
      " [-3.55888586]]\n",
      "theta: [[4.14623338]\n",
      " [2.89516865]]\n",
      "gradients: [[-0.24262408]\n",
      " [-0.304865  ]]\n",
      "theta: [[4.1405116 ]\n",
      " [2.88379399]]\n",
      "gradients: [[1.6684711 ]\n",
      " [3.31685012]]\n",
      "theta: [[4.13192485]\n",
      " [2.86760658]]\n",
      "gradients: [[2.50561526]\n",
      " [4.72348715]]\n",
      "theta: [[4.12426747]\n",
      " [2.8593903 ]]\n",
      "gradients: [[2.23595309]\n",
      " [2.39915258]]\n",
      "theta: [[4.13038876]\n",
      " [2.86052578]]\n",
      "gradients: [[-1.78863966]\n",
      " [-0.33178553]]\n",
      "theta: [[4.13040238]\n",
      " [2.86053602]]\n",
      "gradients: [[-0.00398345]\n",
      " [-0.00299671]]\n",
      "theta: [[4.12109938]\n",
      " [2.852628  ]]\n",
      "gradients: [[2.72205695]\n",
      " [2.31388834]]\n",
      "theta: [[4.10838824]\n",
      " [2.84827832]]\n",
      "gradients: [[3.72182326]\n",
      " [1.27358491]]\n",
      "theta: [[4.10990459]\n",
      " [2.84959045]]\n",
      "gradients: [[-0.44429046]\n",
      " [-0.38445377]]\n",
      "theta: [[4.11679913]\n",
      " [2.85265664]]\n",
      "gradients: [[-2.02147812]\n",
      " [-0.89900788]]\n",
      "theta: [[4.11759345]\n",
      " [2.85323523]]\n",
      "gradients: [[-0.23305387]\n",
      " [-0.16975552]]\n",
      "theta: [[4.11839748]\n",
      " [2.85426152]]\n",
      "gradients: [[-0.23606442]\n",
      " [-0.30132011]]\n",
      "theta: [[4.11918494]\n",
      " [2.85458682]]\n",
      "gradients: [[-0.23135617]\n",
      " [-0.0955729 ]]\n",
      "theta: [[4.11907444]\n",
      " [2.854434  ]]\n",
      "gradients: [[0.03248918]\n",
      " [0.04492983]]\n",
      "theta: [[4.12299101]\n",
      " [2.85446365]]\n",
      "gradients: [[-1.15225758]\n",
      " [-0.00872266]]\n",
      "theta: [[4.1136431 ]\n",
      " [2.84639717]]\n",
      "gradients: [[2.75202478]\n",
      " [2.37477012]]\n",
      "theta: [[4.10633192]\n",
      " [2.83855235]]\n",
      "gradients: [[2.15387469]\n",
      " [2.31108338]]\n",
      "theta: [[4.10690211]\n",
      " [2.83907539]]\n",
      "gradients: [[-0.16809329]\n",
      " [-0.15419057]]\n",
      "theta: [[4.09870214]\n",
      " [2.83636207]]\n",
      "gradients: [[2.41899239]\n",
      " [0.80042731]]\n",
      "theta: [[4.10129237]\n",
      " [2.84061507]]\n",
      "gradients: [[-0.76463701]\n",
      " [-1.25548472]]\n",
      "theta: [[4.10963047]\n",
      " [2.84989959]]\n",
      "gradients: [[-2.46307476]\n",
      " [-2.7426466 ]]\n",
      "theta: [[4.11106924]\n",
      " [2.85170745]]\n",
      "gradients: [[-0.42529955]\n",
      " [-0.53440263]]\n",
      "theta: [[4.1027477 ]\n",
      " [2.83817699]]\n",
      "gradients: [[2.46151148]\n",
      " [4.00230936]]\n",
      "theta: [[4.09756686]\n",
      " [2.83248654]]\n",
      "gradients: [[1.53352884]\n",
      " [1.68437427]]\n",
      "theta: [[4.09986059]\n",
      " [2.83563555]]\n",
      "gradients: [[-0.67940159]\n",
      " [-0.93273849]]\n",
      "theta: [[4.10679034]\n",
      " [2.83871741]]\n",
      "gradients: [[-2.05397839]\n",
      " [-0.91346166]]\n",
      "theta: [[4.09535304]\n",
      " [2.83546716]]\n",
      "gradients: [[3.39230192]\n",
      " [0.96402396]]\n",
      "theta: [[4.10306   ]\n",
      " [2.84636109]]\n",
      "gradients: [[-2.28742442]\n",
      " [-3.23332078]]\n",
      "theta: [[4.10401178]\n",
      " [2.84757598]]\n",
      "gradients: [[-0.28268003]\n",
      " [-0.36082177]]\n",
      "theta: [[4.09728743]\n",
      " [2.83744052]]\n",
      "gradients: [[1.99847639]\n",
      " [3.0122596 ]]\n",
      "theta: [[4.10383321]\n",
      " [2.84379705]]\n",
      "gradients: [[-1.94671297]\n",
      " [-1.89043113]]\n",
      "theta: [[4.10660811]\n",
      " [2.84699883]]\n",
      "gradients: [[-0.82581011]\n",
      " [-0.95285123]]\n",
      "theta: [[4.09988571]\n",
      " [2.83686631]]\n",
      "gradients: [[2.00192919]\n",
      " [3.01746392]]\n",
      "theta: [[4.08855202]\n",
      " [2.83364551]]\n",
      "gradients: [[3.37744058]\n",
      " [0.95980067]]\n",
      "theta: [[4.09121419]\n",
      " [2.83801661]]\n",
      "gradients: [[-0.79385811]\n",
      " [-1.30346389]]\n",
      "theta: [[4.09223815]\n",
      " [2.83876246]]\n",
      "gradients: [[-0.30555124]\n",
      " [-0.22256231]]\n",
      "theta: [[4.08097485]\n",
      " [2.83556166]]\n",
      "gradients: [[3.36322315]\n",
      " [0.95576036]]\n",
      "theta: [[4.07941633]\n",
      " [2.83318838]]\n",
      "gradients: [[0.46568469]\n",
      " [0.70913589]]\n",
      "theta: [[4.08238484]\n",
      " [2.83354972]]\n",
      "gradients: [[-0.88758428]\n",
      " [-0.10804193]]\n",
      "theta: [[4.08334006]\n",
      " [2.83421556]]\n",
      "gradients: [[-0.28580124]\n",
      " [-0.19921719]]\n",
      "theta: [[4.08216066]\n",
      " [2.83402792]]\n",
      "gradients: [[0.35311007]\n",
      " [0.05617847]]\n",
      "theta: [[4.07527026]\n",
      " [2.82663459]]\n",
      "gradients: [[2.06436568]\n",
      " [2.21504121]]\n",
      "theta: [[4.08376343]\n",
      " [2.83609179]]\n",
      "gradients: [[-2.54625367]\n",
      " [-2.83526675]]\n",
      "theta: [[4.08885784]\n",
      " [2.84471035]]\n",
      "gradients: [[-1.52832182]\n",
      " [-2.58556804]]\n",
      "theta: [[4.07997401]\n",
      " [2.83704433]]\n",
      "gradients: [[2.66692584]\n",
      " [2.30133676]]\n",
      "theta: [[4.07119928]\n",
      " [2.82947247]]\n",
      "gradients: [[2.63592791]\n",
      " [2.27458811]]\n",
      "theta: [[4.07410653]\n",
      " [2.8350641 ]]\n",
      "gradients: [[-0.87391832]\n",
      " [-1.68084494]]\n",
      "theta: [[4.06362115]\n",
      " [2.82484832]]\n",
      "gradients: [[3.15400305]\n",
      " [3.07290588]]\n",
      "theta: [[4.05781578]\n",
      " [2.82018952]]\n",
      "gradients: [[1.74741555]\n",
      " [1.40230042]]\n",
      "theta: [[4.06751421]\n",
      " [2.82499177]]\n",
      "gradients: [[-2.92116768]\n",
      " [-1.44643751]]\n",
      "theta: [[4.07397908]\n",
      " [2.82654109]]\n",
      "gradients: [[-1.94851065]\n",
      " [-0.46696654]]\n",
      "theta: [[4.06724189]\n",
      " [2.81931217]]\n",
      "gradients: [[2.03193594]\n",
      " [2.18024447]]\n",
      "theta: [[4.0686447 ]\n",
      " [2.82110276]]\n",
      "gradients: [[-0.42336847]\n",
      " [-0.54040096]]\n",
      "theta: [[4.06370211]\n",
      " [2.81179444]]\n",
      "gradients: [[1.49266253]\n",
      " [2.81111218]]\n",
      "theta: [[4.06101215]\n",
      " [2.81054723]]\n",
      "gradients: [[0.81290639]\n",
      " [0.37690778]]\n",
      "theta: [[4.06794894]\n",
      " [2.81379593]]\n",
      "gradients: [[-2.09768707]\n",
      " [-0.98240876]]\n",
      "theta: [[4.06922907]\n",
      " [2.81472837]]\n",
      "gradients: [[-0.38736622]\n",
      " [-0.28215602]]\n",
      "theta: [[4.06779562]\n",
      " [2.81357659]]\n",
      "gradients: [[0.43404929]\n",
      " [0.34876113]]\n",
      "theta: [[4.06977664]\n",
      " [2.81606581]]\n",
      "gradients: [[-0.60025132]\n",
      " [-0.75423519]]\n",
      "theta: [[4.06490872]\n",
      " [2.80689811]]\n",
      "gradients: [[1.47595438]\n",
      " [2.77964594]]\n",
      "theta: [[4.05898372]\n",
      " [2.79796749]]\n",
      "gradients: [[1.79764455]\n",
      " [2.70955017]]\n",
      "theta: [[4.05813132]\n",
      " [2.7973046 ]]\n",
      "gradients: [[0.25879072]\n",
      " [0.20125376]]\n",
      "theta: [[4.05991992]\n",
      " [2.80010769]]\n",
      "gradients: [[-0.54337893]\n",
      " [-0.85157884]]\n",
      "theta: [[4.04988289]\n",
      " [2.78552919]]\n",
      "gradients: [[3.05125769]\n",
      " [4.43186424]]\n",
      "theta: [[4.05314839]\n",
      " [2.78894267]]\n",
      "gradients: [[-0.99336488]\n",
      " [-1.03838067]]\n",
      "theta: [[4.04766599]\n",
      " [2.78454305]]\n",
      "gradients: [[1.66884149]\n",
      " [1.33924476]]\n",
      "theta: [[4.04972107]\n",
      " [2.78533715]]\n",
      "gradients: [[-0.62597692]\n",
      " [-0.24188157]]\n",
      "theta: [[4.04502202]\n",
      " [2.7825969 ]]\n",
      "gradients: [[1.43226979]\n",
      " [0.83522675]]\n",
      "theta: [[4.05209665]\n",
      " [2.78946699]]\n",
      "gradients: [[-2.15775984]\n",
      " [-2.09537638]]\n",
      "theta: [[4.05425476]\n",
      " [2.79133444]]\n",
      "gradients: [[-0.65865499]\n",
      " [-0.56994786]]\n",
      "theta: [[4.05491384]\n",
      " [2.79195512]]\n",
      "gradients: [[-0.20128566]\n",
      " [-0.18955511]]\n",
      "theta: [[4.05637083]\n",
      " [2.79301638]]\n",
      "gradients: [[-0.44525393]\n",
      " [-0.3243212 ]]\n",
      "theta: [[4.04391977]\n",
      " [2.77353233]]\n",
      "gradients: [[3.80753442]\n",
      " [5.95822193]]\n",
      "theta: [[4.03243829]\n",
      " [2.76960344]]\n",
      "gradients: [[3.51333193]\n",
      " [1.20224047]]\n",
      "theta: [[4.02294227]\n",
      " [2.75581075]]\n",
      "gradients: [[2.90768133]\n",
      " [4.2233237 ]]\n",
      "theta: [[4.02072467]\n",
      " [2.75478255]]\n",
      "gradients: [[0.67947252]\n",
      " [0.31504055]]\n",
      "theta: [[4.02197193]\n",
      " [2.75572085]]\n",
      "gradients: [[-0.38241065]\n",
      " [-0.28768347]]\n",
      "theta: [[4.013571  ]\n",
      " [2.75376033]]\n",
      "gradients: [[2.57740715]\n",
      " [0.60148797]]\n",
      "theta: [[4.01150278]\n",
      " [2.75299317]]\n",
      "gradients: [[0.63494363]\n",
      " [0.23551819]]\n",
      "theta: [[4.01818781]\n",
      " [2.75423321]]\n",
      "gradients: [[-2.05364154]\n",
      " [-0.38094233]]\n",
      "theta: [[4.01447968]\n",
      " [2.74724974]]\n",
      "gradients: [[1.13987964]\n",
      " [2.14672069]]\n",
      "theta: [[4.01931061]\n",
      " [2.754303  ]]\n",
      "gradients: [[-1.48599396]\n",
      " [-2.16958254]]\n",
      "theta: [[4.03278199]\n",
      " [2.75535973]]\n",
      "gradients: [[-4.14649184]\n",
      " [-0.32526121]]\n",
      "theta: [[4.03624573]\n",
      " [2.76044106]]\n",
      "gradients: [[-1.06683207]\n",
      " [-1.56504944]]\n",
      "theta: [[4.03720449]\n",
      " [2.76134394]]\n",
      "gradients: [[-0.29548967]\n",
      " [-0.2782691 ]]\n",
      "theta: [[4.03643389]\n",
      " [2.76122134]]\n",
      "gradients: [[0.23765173]\n",
      " [0.03780949]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: [[4.0348036 ]\n",
      " [2.75975969]]\n",
      "gradients: [[0.50310866]\n",
      " [0.45106467]]\n",
      "theta: [[4.02620206]\n",
      " [2.74914653]]\n",
      "gradients: [[2.65615468]\n",
      " [3.27734523]]\n",
      "theta: [[4.02407736]\n",
      " [2.74885017]]\n",
      "gradients: [[0.65653363]\n",
      " [0.09157644]]\n",
      "theta: [[4.020778 ]\n",
      " [2.7473446]]\n",
      "gradients: [[1.02016162]\n",
      " [0.46551944]]\n",
      "theta: [[4.02125964]\n",
      " [2.74753439]]\n",
      "gradients: [[-0.14901992]\n",
      " [-0.05871821]]\n",
      "theta: [[4.01419528]\n",
      " [2.74519684]]\n",
      "gradients: [[2.18712691]\n",
      " [0.72370468]]\n",
      "theta: [[4.03159767]\n",
      " [2.777641  ]]\n",
      "gradients: [[ -5.39126018]\n",
      " [-10.05120139]]\n",
      "theta: [[4.03335766]\n",
      " [2.77791259]]\n",
      "gradients: [[-0.54559759]\n",
      " [-0.08419285]]\n",
      "theta: [[4.04041822]\n",
      " [2.78476902]]\n",
      "gradients: [[-2.19018633]\n",
      " [-2.12686538]]\n",
      "theta: [[4.04352799]\n",
      " [2.78933107]]\n",
      "gradients: [[-0.96527236]\n",
      " [-1.4160607 ]]\n",
      "theta: [[4.04110775]\n",
      " [2.78820892]]\n",
      "gradients: [[0.75172767]\n",
      " [0.34854198]]\n",
      "theta: [[4.04185893]\n",
      " [2.78891632]]\n",
      "gradients: [[-0.23346643]\n",
      " [-0.21986046]]\n",
      "theta: [[4.04335583]\n",
      " [2.79069801]]\n",
      "gradients: [[-0.46553611]\n",
      " [-0.55410513]]\n",
      "theta: [[4.044717  ]\n",
      " [2.79164681]]\n",
      "gradients: [[-0.42359867]\n",
      " [-0.29526861]]\n",
      "theta: [[4.03257847]\n",
      " [2.77265182]]\n",
      "gradients: [[3.77994043]\n",
      " [5.91504146]]\n",
      "theta: [[4.03501889]\n",
      " [2.77745798]]\n",
      "gradients: [[-0.76043675]\n",
      " [-1.4975997 ]]\n",
      "theta: [[4.02310056]\n",
      " [2.75880756]]\n",
      "gradients: [[3.7161374 ]\n",
      " [5.81519926]]\n",
      "theta: [[4.01866273]\n",
      " [2.75356391]]\n",
      "gradients: [[1.38460228]\n",
      " [1.63602163]]\n",
      "theta: [[4.02249557]\n",
      " [2.75985719]]\n",
      "gradients: [[-1.19661435]\n",
      " [-1.96476369]]\n",
      "theta: [[4.02978146]\n",
      " [2.76309743]]\n",
      "gradients: [[-2.27610993]\n",
      " [-1.01224977]]\n",
      "theta: [[4.03981468]\n",
      " [2.77477676]]\n",
      "gradients: [[-3.13638661]\n",
      " [-3.65095942]]\n",
      "theta: [[4.05292936]\n",
      " [2.77580551]]\n",
      "gradients: [[-4.10227166]\n",
      " [-0.32179247]]\n",
      "theta: [[4.0586609 ]\n",
      " [2.78550195]]\n",
      "gradients: [[-1.79397091]\n",
      " [-3.03498504]]\n",
      "theta: [[4.06487822]\n",
      " [2.78665523]]\n",
      "gradients: [[-1.94726479]\n",
      " [-0.36120987]]\n",
      "theta: [[4.07161136]\n",
      " [2.79319371]]\n",
      "gradients: [[-2.11016544]\n",
      " [-2.04915799]]\n",
      "theta: [[4.07393143]\n",
      " [2.79329296]]\n",
      "gradients: [[-0.72757308]\n",
      " [-0.03112615]]\n",
      "theta: [[4.06954233]\n",
      " [2.78847213]]\n",
      "gradients: [[1.37729821]\n",
      " [1.51277602]]\n",
      "theta: [[4.07029778]\n",
      " [2.78868631]]\n",
      "gradients: [[-0.23721067]\n",
      " [-0.06725065]]\n",
      "theta: [[4.07314316]\n",
      " [2.79286051]]\n",
      "gradients: [[-0.89401988]\n",
      " [-1.31153285]]\n",
      "theta: [[4.07316995]\n",
      " [2.79287106]]\n",
      "gradients: [[-0.00842041]\n",
      " [-0.00331789]]\n",
      "theta: [[4.08151593]\n",
      " [2.80216435]]\n",
      "gradients: [[-2.62564603]\n",
      " [-2.92367056]]\n",
      "theta: [[4.089246  ]\n",
      " [2.81114723]]\n",
      "gradients: [[-2.43342802]\n",
      " [-2.82780973]]\n",
      "theta: [[4.08465188]\n",
      " [2.80610121]]\n",
      "gradients: [[1.44714837]\n",
      " [1.58949699]]\n",
      "theta: [[4.08650888]\n",
      " [2.80843458]]\n",
      "gradients: [[-0.58532489]\n",
      " [-0.73547965]]\n",
      "theta: [[4.08505518]\n",
      " [2.80726653]]\n",
      "gradients: [[0.45849472]\n",
      " [0.36840317]]\n",
      "theta: [[4.08612257]\n",
      " [2.80770747]]\n",
      "gradients: [[-0.33686789]\n",
      " [-0.13915963]]\n",
      "theta: [[4.08833064]\n",
      " [2.80780193]]\n",
      "gradients: [[-0.69730883]\n",
      " [-0.02983142]]\n",
      "theta: [[4.08720822]\n",
      " [2.80762336]]\n",
      "gradients: [[0.35468663]\n",
      " [0.0564293 ]]\n",
      "theta: [[4.08804023]\n",
      " [2.80838656]]\n",
      "gradients: [[-0.26308251]\n",
      " [-0.24132338]]\n",
      "theta: [[4.0984614 ]\n",
      " [2.82744489]]\n",
      "gradients: [[-3.29725859]\n",
      " [-6.03005616]]\n",
      "theta: [[4.10188659]\n",
      " [2.82781195]]\n",
      "gradients: [[-1.08441482]\n",
      " [-0.11620999]]\n",
      "theta: [[4.10302373]\n",
      " [2.82959406]]\n",
      "gradients: [[-0.36024668]\n",
      " [-0.56457554]]\n",
      "theta: [[4.09546632]\n",
      " [2.82158251]]\n",
      "gradients: [[2.39570118]\n",
      " [2.53966371]]\n",
      "theta: [[4.10451063]\n",
      " [2.83211068]]\n",
      "gradients: [[-2.86885596]\n",
      " [-3.33953623]]\n",
      "theta: [[4.10658512]\n",
      " [2.83219943]]\n",
      "gradients: [[-0.65844474]\n",
      " [-0.02816879]]\n",
      "theta: [[4.09900217]\n",
      " [2.82416079]]\n",
      "gradients: [[2.40834781]\n",
      " [2.55307031]]\n",
      "theta: [[4.10167872]\n",
      " [2.8244866 ]]\n",
      "gradients: [[-0.85061039]\n",
      " [-0.10354126]]\n",
      "theta: [[4.1079784 ]\n",
      " [2.82743692]]\n",
      "gradients: [[-2.00329747]\n",
      " [-0.93820333]]\n",
      "theta: [[4.11002714]\n",
      " [2.82752457]]\n",
      "gradients: [[-0.65190909]\n",
      " [-0.02788919]]\n",
      "theta: [[4.11718961]\n",
      " [2.83764887]]\n",
      "gradients: [[-2.28053023]\n",
      " [-3.22357571]]\n",
      "theta: [[4.11506099]\n",
      " [2.83749658]]\n",
      "gradients: [[0.67817851]\n",
      " [0.04851899]]\n",
      "theta: [[4.12490021]\n",
      " [2.85549064]]\n",
      "gradients: [[-3.13674373]\n",
      " [-5.73650515]]\n",
      "theta: [[4.1180165 ]\n",
      " [2.84810449]]\n",
      "gradients: [[2.19590328]\n",
      " [2.35617958]]\n",
      "theta: [[4.11618298]\n",
      " [2.84663125]]\n",
      "gradients: [[0.58525997]\n",
      " [0.47025979]]\n",
      "theta: [[4.11749922]\n",
      " [2.84828515]]\n",
      "gradients: [[-0.42040809]\n",
      " [-0.52825635]]\n",
      "theta: [[4.10680098]\n",
      " [2.84524493]]\n",
      "gradients: [[3.41915761]\n",
      " [0.97165581]]\n",
      "theta: [[4.11048123]\n",
      " [2.84527278]]\n",
      "gradients: [[-1.17694361]\n",
      " [-0.00890953]]\n",
      "theta: [[4.11036765]\n",
      " [2.84520915]]\n",
      "gradients: [[0.03634731]\n",
      " [0.02036165]]\n",
      "theta: [[4.10366941]\n",
      " [2.83802203]]\n",
      "gradients: [[2.14477432]\n",
      " [2.30131879]]\n",
      "theta: [[4.10124965]\n",
      " [2.83585258]]\n",
      "gradients: [[0.7752918 ]\n",
      " [0.69509187]]\n",
      "theta: [[4.08980036]\n",
      " [2.8319347 ]]\n",
      "gradients: [[3.6706429 ]\n",
      " [1.25607131]]\n",
      "theta: [[4.10117457]\n",
      " [2.85049515]]\n",
      "gradients: [[-3.64884609]\n",
      " [-5.95419229]]\n",
      "theta: [[4.09681091]\n",
      " [2.84182037]]\n",
      "gradients: [[1.40073541]\n",
      " [2.78460287]]\n",
      "theta: [[4.09943985]\n",
      " [2.84485375]]\n",
      "gradients: [[-0.84441623]\n",
      " [-0.97431968]]\n",
      "theta: [[4.09989239]\n",
      " [2.84498204]]\n",
      "gradients: [[-0.14544658]\n",
      " [-0.04123498]]\n",
      "theta: [[4.09868082]\n",
      " [2.84478929]]\n",
      "gradients: [[0.38964055]\n",
      " [0.06199033]]\n",
      "theta: [[4.09954662]\n",
      " [2.84514695]]\n",
      "gradients: [[-0.27861542]\n",
      " [-0.11509562]]\n",
      "theta: [[4.08953255]\n",
      " [2.83539037]]\n",
      "gradients: [[3.22453043]\n",
      " [3.14161982]]\n",
      "theta: [[4.08214271]\n",
      " [2.82755645]]\n",
      "gradients: [[2.38100805]\n",
      " [2.52408764]]\n",
      "theta: [[4.08082118]\n",
      " [2.82701245]]\n",
      "gradients: [[0.42606069]\n",
      " [0.17538601]]\n",
      "theta: [[4.06853714]\n",
      " [2.80778976]]\n",
      "gradients: [[3.96283265]\n",
      " [6.20124043]]\n",
      "theta: [[4.07005418]\n",
      " [2.81016726]]\n",
      "gradients: [[-0.48970279]\n",
      " [-0.76745805]]\n",
      "theta: [[4.07641378]\n",
      " [2.81634299]]\n",
      "gradients: [[-2.05414898]\n",
      " [-1.99476104]]\n",
      "theta: [[4.07137914]\n",
      " [2.81039416]]\n",
      "gradients: [[1.62719442]\n",
      " [1.92266422]]\n",
      "theta: [[4.07415709]\n",
      " [2.81329799]]\n",
      "gradients: [[-0.89838887]\n",
      " [-0.93910068]]\n",
      "theta: [[4.07452827]\n",
      " [2.81364754]]\n",
      "gradients: [[-0.12011388]\n",
      " [-0.11311387]]\n",
      "theta: [[4.06429501]\n",
      " [2.81073945]]\n",
      "gradients: [[3.31352908]\n",
      " [0.94163831]]\n",
      "theta: [[4.07987116]\n",
      " [2.83977886]]\n",
      "gradients: [[-5.04667182]\n",
      " [-9.40876774]]\n",
      "theta: [[4.07527124]\n",
      " [2.83472647]]\n",
      "gradients: [[1.49129464]\n",
      " [1.6379857 ]]\n",
      "theta: [[4.0904848 ]\n",
      " [2.86308988]]\n",
      "gradients: [[-4.93527894]\n",
      " [-9.20109231]]\n",
      "theta: [[4.08308477]\n",
      " [2.86064127]]\n",
      "gradients: [[2.40205021]\n",
      " [0.79482126]]\n",
      "theta: [[4.08360572]\n",
      " [2.86078896]]\n",
      "gradients: [[-0.16920503]\n",
      " [-0.04797064]]\n",
      "theta: [[4.09844089]\n",
      " [2.88844693]]\n",
      "gradients: [[-4.82143072]\n",
      " [-8.98883925]]\n",
      "theta: [[4.0964062 ]\n",
      " [2.88534853]]\n",
      "gradients: [[0.66168216]\n",
      " [1.00759716]]\n",
      "theta: [[4.09758241]\n",
      " [2.88553004]]\n",
      "gradients: [[-0.38273917]\n",
      " [-0.05906166]]\n",
      "theta: [[4.09361462]\n",
      " [2.88371946]]\n",
      "gradients: [[1.29191106]\n",
      " [0.58952396]]\n",
      "theta: [[4.10808949]\n",
      " [2.9107057 ]]\n",
      "gradients: [[-4.7159119 ]\n",
      " [-8.79211514]]\n",
      "theta: [[4.11512442]\n",
      " [2.91853913]]\n",
      "gradients: [[-2.29338798]\n",
      " [-2.55369948]]\n",
      "theta: [[4.11300099]\n",
      " [2.91683294]]\n",
      "gradients: [[0.6926651 ]\n",
      " [0.55656043]]\n",
      "theta: [[4.11165687]\n",
      " [2.91661909]]\n",
      "gradients: [[0.43872015]\n",
      " [0.06979871]]\n",
      "theta: [[4.10705903]\n",
      " [2.91033872]]\n",
      "gradients: [[1.50165556]\n",
      " [2.05117076]]\n",
      "theta: [[4.10809802]\n",
      " [2.91123778]]\n",
      "gradients: [[-0.33954458]\n",
      " [-0.29381499]]\n",
      "theta: [[4.09500632]\n",
      " [2.89075123]]\n",
      "gradients: [[4.28098644]\n",
      " [6.69910352]]\n",
      "theta: [[4.09758087]\n",
      " [2.89106462]]\n",
      "gradients: [[-0.84239052]\n",
      " [-0.10254069]]\n",
      "theta: [[4.0872241 ]\n",
      " [2.87602171]]\n",
      "gradients: [[3.39080422]\n",
      " [4.92504582]]\n",
      "theta: [[4.08796889]\n",
      " [2.8774885 ]]\n",
      "gradients: [[-0.24399334]\n",
      " [-0.48051905]]\n",
      "theta: [[4.08344892]\n",
      " [2.86850298]]\n",
      "gradients: [[1.48164735]\n",
      " [2.94545239]]\n",
      "theta: [[4.07539497]\n",
      " [2.86165671]]\n",
      "gradients: [[2.64169467]\n",
      " [2.24557628]]\n",
      "theta: [[4.07983909]\n",
      " [2.86917513]]\n",
      "gradients: [[-1.45855881]\n",
      " [-2.46754512]]\n",
      "theta: [[4.07961059]\n",
      " [2.86915161]]\n",
      "gradients: [[0.07504022]\n",
      " [0.00772557]]\n",
      "theta: [[4.07884007]\n",
      " [2.86773538]]\n",
      "gradients: [[0.25319101]\n",
      " [0.46537447]]\n",
      "theta: [[4.07887606]\n",
      " [2.86778515]]\n",
      "gradients: [[-0.01183385]\n",
      " [-0.01636523]]\n",
      "theta: [[4.07888105]\n",
      " [2.86778794]]\n",
      "gradients: [[-0.00164032]\n",
      " [-0.0009189 ]]\n",
      "theta: [[4.07792538]\n",
      " [2.86668897]]\n",
      "gradients: [[0.31460651]\n",
      " [0.36178164]]\n",
      "theta: [[4.08403125]\n",
      " [2.86954853]]\n",
      "gradients: [[-2.01127493]\n",
      " [-0.94193941]]\n",
      "theta: [[4.08486251]\n",
      " [2.87015401]]\n",
      "gradients: [[-0.27398166]\n",
      " [-0.19956715]]\n",
      "theta: [[4.08085666]\n",
      " [2.86468226]]\n",
      "gradients: [[1.32112986]\n",
      " [1.80458356]]\n",
      "theta: [[4.08228382]\n",
      " [2.86591722]]\n",
      "gradients: [[-0.47096429]\n",
      " [-0.40753519]]\n",
      "theta: [[4.07395716]\n",
      " [2.86397403]]\n",
      "gradients: [[2.74946384]\n",
      " [0.64164073]]\n",
      "theta: [[4.07164965]\n",
      " [2.86190522]]\n",
      "gradients: [[0.76240209]\n",
      " [0.68353553]]\n",
      "theta: [[4.07436025]\n",
      " [2.86223517]]\n",
      "gradients: [[-0.89612649]\n",
      " [-0.10908174]]\n",
      "theta: [[4.06912586]\n",
      " [2.8560503 ]]\n",
      "gradients: [[1.73153813]\n",
      " [2.04595491]]\n",
      "theta: [[4.0707684 ]\n",
      " [2.85875182]]\n",
      "gradients: [[-0.5436813 ]\n",
      " [-0.89420488]]\n",
      "theta: [[4.06851399]\n",
      " [2.85673062]]\n",
      "gradients: [[0.74666058]\n",
      " [0.6694224 ]]\n",
      "theta: [[4.06936259]\n",
      " [2.85732214]]\n",
      "gradients: [[-0.28122654]\n",
      " [-0.1960284 ]]\n",
      "theta: [[4.06674967]\n",
      " [2.85611064]]\n",
      "gradients: [[0.8664456 ]\n",
      " [0.40173148]]\n",
      "theta: [[4.07891254]\n",
      " [2.85706473]]\n",
      "gradients: [[-4.03564163]\n",
      " [-0.31656584]]\n",
      "theta: [[4.0773419 ]\n",
      " [2.85580271]]\n",
      "gradients: [[0.52145125]\n",
      " [0.41898911]]\n",
      "theta: [[4.07674111]\n",
      " [2.85469844]]\n",
      "gradients: [[0.19958211]\n",
      " [0.36683932]]\n",
      "theta: [[4.09135564]\n",
      " [2.88194505]]\n",
      "gradients: [[-4.85786966]\n",
      " [-9.05677423]]\n",
      "theta: [[4.09486022]\n",
      " [2.88379939]]\n",
      "gradients: [[-1.1656209 ]\n",
      " [-0.61675279]]\n",
      "theta: [[4.08649795]\n",
      " [2.88184789]]\n",
      "gradients: [[2.78296294]\n",
      " [0.6494584 ]]\n",
      "theta: [[4.07895926]\n",
      " [2.86959032]]\n",
      "gradients: [[2.51038298]\n",
      " [4.08177225]]\n",
      "theta: [[4.07517146]\n",
      " [2.8639023 ]]\n",
      "gradients: [[1.2620943 ]\n",
      " [1.89524654]]\n",
      "theta: [[4.06553641]\n",
      " [2.85451499]]\n",
      "gradients: [[3.21232632]\n",
      " [3.12972951]]\n",
      "theta: [[4.06566587]\n",
      " [2.85458752]]\n",
      "gradients: [[-0.04318742]\n",
      " [-0.02419346]]\n",
      "theta: [[4.07696346]\n",
      " [2.86581223]]\n",
      "gradients: [[-3.77113594]\n",
      " [-3.74680845]]\n",
      "theta: [[4.06605755]\n",
      " [2.86208029]]\n",
      "gradients: [[3.64257453]\n",
      " [1.24646649]]\n",
      "theta: [[4.05395983]\n",
      " [2.84314917]]\n",
      "gradients: [[4.04305724]\n",
      " [6.32677991]]\n",
      "theta: [[4.05041452]\n",
      " [2.8383065 ]]\n",
      "gradients: [[1.18555054]\n",
      " [1.61939041]]\n",
      "theta: [[4.05155172]\n",
      " [2.83877627]]\n",
      "gradients: [[-0.38050408]\n",
      " [-0.15718568]]\n",
      "theta: [[4.06478471]\n",
      " [2.84091023]]\n",
      "gradients: [[-4.43040642]\n",
      " [-0.71445058]]\n",
      "theta: [[4.06377819]\n",
      " [2.84012749]]\n",
      "gradients: [[0.33718325]\n",
      " [0.26221728]]\n",
      "theta: [[4.06374806]\n",
      " [2.84011562]]\n",
      "gradients: [[0.0100988 ]\n",
      " [0.00397922]]\n",
      "theta: [[4.05911335]\n",
      " [2.83138713]]\n",
      "gradients: [[1.55448262]\n",
      " [2.92753716]]\n",
      "theta: [[4.05228522]\n",
      " [2.82028489]]\n",
      "gradients: [[2.29151981]\n",
      " [3.72591038]]\n",
      "theta: [[4.04888507]\n",
      " [2.81873334]]\n",
      "gradients: [[1.14177145]\n",
      " [0.52101235]]\n",
      "theta: [[4.04576244]\n",
      " [2.81404418]]\n",
      "gradients: [[1.04920532]\n",
      " [1.57555798]]\n",
      "theta: [[4.0546435 ]\n",
      " [2.82438232]]\n",
      "gradients: [[-2.98581395]\n",
      " [-3.47568298]]\n",
      "theta: [[4.05025286]\n",
      " [2.81611347]]\n",
      "gradients: [[1.47701283]\n",
      " [2.78163929]]\n",
      "theta: [[4.05120775]\n",
      " [2.81698939]]\n",
      "gradients: [[-0.32141741]\n",
      " [-0.2948335 ]]\n",
      "theta: [[4.04208368]\n",
      " [2.80809992]]\n",
      "gradients: [[3.07298555]\n",
      " [2.99397154]]\n",
      "theta: [[4.04282638]\n",
      " [2.80912701]]\n",
      "gradients: [[-0.25028832]\n",
      " [-0.34612785]]\n",
      "theta: [[4.04414433]\n",
      " [2.810087  ]]\n",
      "gradients: [[-0.444413  ]\n",
      " [-0.32370866]]\n",
      "theta: [[4.04572747]\n",
      " [2.81009647]]\n",
      "gradients: [[-0.53415022]\n",
      " [-0.00319578]]\n",
      "theta: [[4.05192324]\n",
      " [2.81117403]]\n",
      "gradients: [[-2.09169175]\n",
      " [-0.36378381]]\n",
      "theta: [[4.05489811]\n",
      " [2.81460656]]\n",
      "gradients: [[-1.00491341]\n",
      " [-1.15950746]]\n",
      "theta: [[4.06102764]\n",
      " [2.8156726 ]]\n",
      "gradients: [[-2.07178168]\n",
      " [-0.36032108]]\n",
      "theta: [[4.06132977]\n",
      " [2.81573182]]\n",
      "gradients: [[-0.10217859]\n",
      " [-0.02002991]]\n",
      "theta: [[4.06244479]\n",
      " [2.81619244]]\n",
      "gradients: [[-0.37732472]\n",
      " [-0.15587229]]\n",
      "theta: [[4.06332161]\n",
      " [2.81699673]]\n",
      "gradients: [[-0.29688867]\n",
      " [-0.27233349]]\n",
      "theta: [[4.06551203]\n",
      " [2.81709044]]\n",
      "gradients: [[-0.74211596]\n",
      " [-0.03174831]]\n",
      "theta: [[4.06540684]\n",
      " [2.81707961]]\n",
      "gradients: [[0.03566161]\n",
      " [0.00367145]]\n",
      "theta: [[4.06530848]\n",
      " [2.81689882]]\n",
      "gradients: [[0.03336296]\n",
      " [0.06132235]]\n",
      "theta: [[4.0577309]\n",
      " [2.81036  ]]\n",
      "gradients: [[2.57182902]\n",
      " [2.21927606]]\n",
      "theta: [[4.05574918]\n",
      " [2.80987556]]\n",
      "gradients: [[0.67299403]\n",
      " [0.16451506]]\n",
      "theta: [[4.06691894]\n",
      " [2.825782  ]]\n",
      "gradients: [[-3.79548683]\n",
      " [-5.4050091 ]]\n",
      "theta: [[4.06907827]\n",
      " [2.82587438]]\n",
      "gradients: [[-0.7341696 ]\n",
      " [-0.03140836]]\n",
      "theta: [[4.06672831]\n",
      " [2.82500272]]\n",
      "gradients: [[0.79945637]\n",
      " [0.29654053]]\n",
      "theta: [[4.05993225]\n",
      " [2.81779828]]\n",
      "gradients: [[2.31337582]\n",
      " [2.45239126]]\n",
      "theta: [[4.0746976 ]\n",
      " [2.84532607]]\n",
      "gradients: [[-5.02907709]\n",
      " [-9.37596498]]\n",
      "theta: [[4.07486987]\n",
      " [2.8454883 ]]\n",
      "gradients: [[-0.05870978]\n",
      " [-0.05528829]]\n",
      "theta: [[4.07469326]\n",
      " [2.84547011]]\n",
      "gradients: [[0.06022455]\n",
      " [0.00620026]]\n",
      "theta: [[4.07486456]\n",
      " [2.84563143]]\n",
      "gradients: [[-0.05844715]\n",
      " [-0.05504097]]\n",
      "theta: [[4.07124962]\n",
      " [2.84069364]]\n",
      "gradients: [[1.23414123]\n",
      " [1.68576235]]\n",
      "theta: [[4.07169488]\n",
      " [2.8410286 ]]\n",
      "gradients: [[-0.15210075]\n",
      " [-0.11442378]]\n",
      "theta: [[4.07267701]\n",
      " [2.84143432]]\n",
      "gradients: [[-0.33569438]\n",
      " [-0.13867486]]\n",
      "theta: [[4.07501628]\n",
      " [2.84527525]]\n",
      "gradients: [[-0.80003066]\n",
      " [-1.31359881]]\n",
      "theta: [[4.0736038 ]\n",
      " [2.84312435]]\n",
      "gradients: [[0.48335092]\n",
      " [0.7360377 ]]\n",
      "theta: [[4.06424754]\n",
      " [2.82953464]]\n",
      "gradients: [[3.20358638]\n",
      " [4.65311729]]\n",
      "theta: [[4.05684228]\n",
      " [2.82323979]]\n",
      "gradients: [[2.53704172]\n",
      " [2.15661589]]\n",
      "theta: [[4.05856548]\n",
      " [2.82473092]]\n",
      "gradients: [[-0.59071511]\n",
      " [-0.51115807]]\n",
      "theta: [[4.05386776]\n",
      " [2.81918017]]\n",
      "gradients: [[1.61131987]\n",
      " [1.90390714]]\n",
      "theta: [[4.05417695]\n",
      " [2.81935337]]\n",
      "gradients: [[-0.10611364]\n",
      " [-0.05944452]]\n",
      "theta: [[4.06848075]\n",
      " [2.84510701]]\n",
      "gradients: [[-4.91192639]\n",
      " [-8.84379915]]\n",
      "theta: [[4.06892021]\n",
      " [2.84543761]]\n",
      "gradients: [[-0.15099821]\n",
      " [-0.11359435]]\n",
      "theta: [[4.07564535]\n",
      " [2.85494373]]\n",
      "gradients: [[-2.3121032 ]\n",
      " [-3.26820474]]\n",
      "theta: [[4.06770106]\n",
      " [2.84609706]]\n",
      "gradients: [[2.7328347 ]\n",
      " [3.04325439]]\n",
      "theta: [[4.0660148 ]\n",
      " [2.84597642]]\n",
      "gradients: [[0.58041024]\n",
      " [0.04152434]]\n",
      "theta: [[4.07180075]\n",
      " [2.85159509]]\n",
      "gradients: [[-1.99267999]\n",
      " [-1.93506919]]\n",
      "theta: [[4.07073333]\n",
      " [2.85076499]]\n",
      "gradients: [[0.36783392]\n",
      " [0.28605338]]\n",
      "theta: [[4.0692978 ]\n",
      " [2.84961154]]\n",
      "gradients: [[0.49496907]\n",
      " [0.39771053]]\n",
      "theta: [[4.06165646]\n",
      " [2.84301769]]\n",
      "gradients: [[2.63626442]\n",
      " [2.27487849]]\n",
      "theta: [[4.05963788]\n",
      " [2.84252424]]\n",
      "gradients: [[0.69681164]\n",
      " [0.17033733]]\n",
      "theta: [[4.05541999]\n",
      " [2.83789146]]\n",
      "gradients: [[1.45685894]\n",
      " [1.60016274]]\n",
      "theta: [[4.05202269]\n",
      " [2.83325095]]\n",
      "gradients: [[1.17410743]\n",
      " [1.60375981]]\n",
      "theta: [[4.04979361]\n",
      " [2.83242412]]\n",
      "gradients: [[0.77081758]\n",
      " [0.28591761]]\n",
      "theta: [[4.06091188]\n",
      " [2.84347067]]\n",
      "gradients: [[-3.84692131]\n",
      " [-3.82210492]]\n",
      "theta: [[4.05873895]\n",
      " [2.84316758]]\n",
      "gradients: [[0.75226682]\n",
      " [0.10492976]]\n",
      "theta: [[4.0596126 ]\n",
      " [2.84420744]]\n",
      "gradients: [[-0.30263075]\n",
      " [-0.36020676]]\n",
      "theta: [[4.05621312]\n",
      " [2.84265619]]\n",
      "gradients: [[1.17825883]\n",
      " [0.53766225]]\n",
      "theta: [[4.05394618]\n",
      " [2.84181532]]\n",
      "gradients: [[0.78617576]\n",
      " [0.29161438]]\n",
      "theta: [[4.0538954 ]\n",
      " [2.84181009]]\n",
      "gradients: [[0.01762088]\n",
      " [0.00181411]]\n",
      "theta: [[4.04722838]\n",
      " [2.83960402]]\n",
      "gradients: [[2.31478874]\n",
      " [0.76594706]]\n",
      "theta: [[4.05564264]\n",
      " [2.8437704 ]]\n",
      "gradients: [[-2.92311601]\n",
      " [-1.44740225]]\n",
      "theta: [[4.06628466]\n",
      " [2.85892529]]\n",
      "gradients: [[-3.69916317]\n",
      " [-5.26783822]]\n",
      "theta: [[4.06028683]\n",
      " [2.85248969]]\n",
      "gradients: [[2.08604286]\n",
      " [2.23830058]]\n",
      "theta: [[4.06580166]\n",
      " [2.85351267]]\n",
      "gradients: [[-1.91916101]\n",
      " [-0.35599672]]\n",
      "theta: [[4.06438029]\n",
      " [2.8531344 ]]\n",
      "gradients: [[0.49492162]\n",
      " [0.13171498]]\n",
      "theta: [[4.06682494]\n",
      " [2.85571416]]\n",
      "gradients: [[-0.85171712]\n",
      " [-0.89878957]]\n",
      "theta: [[4.06085755]\n",
      " [2.84931122]]\n",
      "gradients: [[2.08023243]\n",
      " [2.23206606]]\n",
      "theta: [[4.05663104]\n",
      " [2.84466897]]\n",
      "gradients: [[1.47420744]\n",
      " [1.61921772]]\n",
      "theta: [[4.05464498]\n",
      " [2.84288836]]\n",
      "gradients: [[0.69313376]\n",
      " [0.62143264]]\n",
      "theta: [[4.06018338]\n",
      " [2.84391571]]\n",
      "gradients: [[-1.93400672]\n",
      " [-0.35875055]]\n",
      "theta: [[4.06139884]\n",
      " [2.84425556]]\n",
      "gradients: [[-0.42468237]\n",
      " [-0.11874608]]\n",
      "theta: [[4.05595479]\n",
      " [2.83604986]]\n",
      "gradients: [[1.90324092]\n",
      " [2.86871326]]\n",
      "theta: [[4.05717345]\n",
      " [2.83795975]]\n",
      "gradients: [[-0.42628951]\n",
      " [-0.66807729]]\n",
      "theta: [[4.05380831]\n",
      " [2.83336316]]\n",
      "gradients: [[1.1778009 ]\n",
      " [1.60880486]]\n",
      "theta: [[4.04721486]\n",
      " [2.83118144]]\n",
      "gradients: [[2.3090245 ]\n",
      " [0.76403972]]\n",
      "theta: [[4.04296896]\n",
      " [2.82318518]]\n",
      "gradients: [[1.48776494]\n",
      " [2.80188862]]\n",
      "theta: [[4.04256907]\n",
      " [2.82272533]]\n",
      "gradients: [[0.14020048]\n",
      " [0.16122348]]\n",
      "theta: [[4.04316447]\n",
      " [2.82354872]]\n",
      "gradients: [[-0.20886612]\n",
      " [-0.2888444 ]]\n",
      "theta: [[4.04456348]\n",
      " [2.82574124]]\n",
      "gradients: [[-0.49105352]\n",
      " [-0.76957489]]\n",
      "theta: [[4.04797074]\n",
      " [2.8307159 ]]\n",
      "gradients: [[-1.19662785]\n",
      " [-1.74710192]]\n",
      "theta: [[4.04375419]\n",
      " [2.82825703]]\n",
      "gradients: [[1.48169428]\n",
      " [0.86404859]]\n",
      "theta: [[4.04602564]\n",
      " [2.83137545]]\n",
      "gradients: [[-0.79864017]\n",
      " [-1.09643903]]\n",
      "theta: [[4.04484771]\n",
      " [2.83042898]]\n",
      "gradients: [[0.41439448]\n",
      " [0.33296837]]\n",
      "theta: [[4.04857826]\n",
      " [2.83240289]]\n",
      "gradients: [[-1.31315309]\n",
      " [-0.69481495]]\n",
      "theta: [[4.04997829]\n",
      " [2.8351601 ]]\n",
      "gradients: [[-0.49309035]\n",
      " [-0.97108925]]\n",
      "theta: [[4.05672926]\n",
      " [2.84470273]]\n",
      "gradients: [[-2.379042  ]\n",
      " [-3.36282408]]\n",
      "theta: [[4.05666181]\n",
      " [2.84469579]]\n",
      "gradients: [[0.02378157]\n",
      " [0.00244837]]\n",
      "theta: [[4.04944059]\n",
      " [2.83855738]]\n",
      "gradients: [[2.54764578]\n",
      " [2.16562989]]\n",
      "theta: [[4.04375038]\n",
      " [2.83245185]]\n",
      "gradients: [[2.00864566]\n",
      " [2.15525426]]\n",
      "theta: [[4.04449743]\n",
      " [2.83266364]]\n",
      "gradients: [[-0.26385755]\n",
      " [-0.07480519]]\n",
      "theta: [[4.04591289]\n",
      " [2.83545125]]\n",
      "gradients: [[-0.50022497]\n",
      " [-0.98514014]]\n",
      "theta: [[4.06002854]\n",
      " [2.86176777]]\n",
      "gradients: [[-4.99129316]\n",
      " [-9.30552247]]\n",
      "theta: [[4.05450765]\n",
      " [2.85344625]]\n",
      "gradients: [[1.95329184]\n",
      " [2.94415392]]\n",
      "theta: [[4.05469534]\n",
      " [2.85355139]]\n",
      "gradients: [[-0.06644236]\n",
      " [-0.0372208 ]]\n",
      "theta: [[4.06123858]\n",
      " [2.86280039]]\n",
      "gradients: [[-2.31761497]\n",
      " [-3.27599573]]\n",
      "theta: [[4.05770079]\n",
      " [2.85796798]]\n",
      "gradients: [[1.25379279]\n",
      " [1.71260519]]\n",
      "theta: [[4.05875592]\n",
      " [2.86004595]]\n",
      "gradients: [[-0.3741498 ]\n",
      " [-0.73684843]]\n",
      "theta: [[4.07118303]\n",
      " [2.86204996]]\n",
      "gradients: [[-4.40913809]\n",
      " [-0.71102084]]\n",
      "theta: [[4.08252343]\n",
      " [2.86293953]]\n",
      "gradients: [[-4.02584312]\n",
      " [-0.31579722]]\n",
      "theta: [[4.08833527]\n",
      " [2.86552422]]\n",
      "gradients: [[-2.06436702]\n",
      " [-0.91808178]]\n",
      "theta: [[4.08841411]\n",
      " [2.86553967]]\n",
      "gradients: [[-0.02801865]\n",
      " [-0.00549245]]\n",
      "theta: [[4.08915374]\n",
      " [2.86648376]]\n",
      "gradients: [[-0.26301152]\n",
      " [-0.33571625]]\n",
      "theta: [[4.09473335]\n",
      " [2.86745415]]\n",
      "gradients: [[-1.98522563]\n",
      " [-0.34526738]]\n",
      "theta: [[4.08558062]\n",
      " [2.85853677]]\n",
      "gradients: [[3.25837114]\n",
      " [3.17459041]]\n",
      "theta: [[4.08494584]\n",
      " [2.85737001]]\n",
      "gradients: [[0.22611012]\n",
      " [0.4155988 ]]\n",
      "theta: [[4.08381479]\n",
      " [2.85649043]]\n",
      "gradients: [[0.40310605]\n",
      " [0.31348346]]\n",
      "theta: [[4.0764947 ]\n",
      " [2.84840891]]\n",
      "gradients: [[2.61034145]\n",
      " [2.88187   ]]\n",
      "theta: [[4.06745681]\n",
      " [2.83528163]]\n",
      "gradients: [[3.2247195 ]\n",
      " [4.68381254]]\n",
      "theta: [[4.05865814]\n",
      " [2.82670919]]\n",
      "gradients: [[3.14112748]\n",
      " [3.06036137]]\n",
      "theta: [[4.04863797]\n",
      " [2.82328035]]\n",
      "gradients: [[3.57920225]\n",
      " [1.22478088]]\n",
      "theta: [[4.04118898]\n",
      " [2.82154198]]\n",
      "gradients: [[2.66227187]\n",
      " [0.6212928 ]]\n",
      "theta: [[4.03711339]\n",
      " [2.8191653 ]]\n",
      "gradients: [[1.45743123]\n",
      " [0.84989962]]\n",
      "theta: [[4.03892325]\n",
      " [2.82143946]]\n",
      "gradients: [[-0.64757097]\n",
      " [-0.81369386]]\n",
      "theta: [[4.0349163 ]\n",
      " [2.81389323]]\n",
      "gradients: [[1.43448786]\n",
      " [2.70155257]]\n",
      "theta: [[4.03394419]\n",
      " [2.81224613]]\n",
      "gradients: [[0.34821237]\n",
      " [0.58999121]]\n",
      "theta: [[4.03536161]\n",
      " [2.81405536]]\n",
      "gradients: [[-0.50800251]\n",
      " [-0.64843053]]\n",
      "theta: [[4.03228788]\n",
      " [2.81265276]]\n",
      "gradients: [[1.1022389 ]\n",
      " [0.50297289]]\n",
      "theta: [[4.03518858]\n",
      " [2.8159997 ]]\n",
      "gradients: [[-1.0407717 ]\n",
      " [-1.20088212]]\n",
      "theta: [[4.03027036]\n",
      " [2.80858657]]\n",
      "gradients: [[1.76564152]\n",
      " [2.6613127 ]]\n",
      "theta: [[4.03213344]\n",
      " [2.81019874]]\n",
      "gradients: [[-0.66921841]\n",
      " [-0.57908861]]\n",
      "theta: [[4.0365656 ]\n",
      " [2.81098007]]\n",
      "gradients: [[-1.59292077]\n",
      " [-0.2808113 ]]\n",
      "theta: [[4.03877957]\n",
      " [2.81107479]]\n",
      "gradients: [[-0.79614276]\n",
      " [-0.03405962]]\n",
      "theta: [[4.03450087]\n",
      " [2.80601915]]\n",
      "gradients: [[1.53947636]\n",
      " [1.81901811]]\n",
      "theta: [[4.03371542]\n",
      " [2.80482308]]\n",
      "gradients: [[0.28276318]\n",
      " [0.43058646]]\n",
      "theta: [[4.02316801]\n",
      " [2.78831797]]\n",
      "gradients: [[3.79917502]\n",
      " [5.94514071]]\n",
      "theta: [[4.02614658]\n",
      " [2.79320858]]\n",
      "gradients: [[-1.07347593]\n",
      " [-1.76257833]]\n",
      "theta: [[4.0266753 ]\n",
      " [2.79350477]]\n",
      "gradients: [[-0.19065439]\n",
      " [-0.10680398]]\n",
      "theta: [[4.02517452]\n",
      " [2.79215924]]\n",
      "gradients: [[0.54147921]\n",
      " [0.48546598]]\n",
      "theta: [[4.02810754]\n",
      " [2.79525436]]\n",
      "gradients: [[-1.05881889]\n",
      " [-1.11733737]]\n",
      "theta: [[4.02745086]\n",
      " [2.79425438]]\n",
      "gradients: [[0.23719167]\n",
      " [0.36119102]]\n",
      "theta: [[4.02080042]\n",
      " [2.78860117]]\n",
      "gradients: [[2.4034683 ]\n",
      " [2.04307162]]\n",
      "theta: [[4.0111837 ]\n",
      " [2.78531039]]\n",
      "gradients: [[3.47740616]\n",
      " [1.18994689]]\n",
      "theta: [[4.00313837]\n",
      " [2.77362478]]\n",
      "gradients: [[2.91079992]\n",
      " [4.22785336]]\n",
      "theta: [[4.00934837]\n",
      " [2.7765331 ]]\n",
      "gradients: [[-2.24801836]\n",
      " [-1.05281334]]\n",
      "theta: [[4.00749442]\n",
      " [2.77567351]]\n",
      "gradients: [[0.67150075]\n",
      " [0.3113444 ]]\n",
      "theta: [[4.00565392]\n",
      " [2.77482015]]\n",
      "gradients: [[0.66699574]\n",
      " [0.30925563]]\n",
      "theta: [[4.00787606]\n",
      " [2.77919641]]\n",
      "gradients: [[-0.80574522]\n",
      " [-1.58682994]]\n",
      "theta: [[4.00157011]\n",
      " [2.77223452]]\n",
      "gradients: [[2.28779566]\n",
      " [2.5257729 ]]\n",
      "theta: [[4.00616359]\n",
      " [2.77304429]]\n",
      "gradients: [[-1.66743262]\n",
      " [-0.29394678]]\n",
      "theta: [[4.01910431]\n",
      " [2.79032972]]\n",
      "gradients: [[-4.70006755]\n",
      " [-6.27806763]]\n",
      "theta: [[4.02003175]\n",
      " [2.79059266]]\n",
      "gradients: [[-0.33703344]\n",
      " [-0.095551  ]]\n",
      "theta: [[4.02165746]\n",
      " [2.79266775]]\n",
      "gradients: [[-0.59110574]\n",
      " [-0.75450612]]\n",
      "theta: [[4.01591063]\n",
      " [2.78332367]]\n",
      "gradients: [[2.09069603]\n",
      " [3.39937975]]\n",
      "theta: [[4.02160208]\n",
      " [2.78468764]]\n",
      "gradients: [[-2.07168959]\n",
      " [-0.49648675]]\n",
      "theta: [[4.02605837]\n",
      " [2.78547322]]\n",
      "gradients: [[-1.62297803]\n",
      " [-0.28611001]]\n",
      "theta: [[4.02735602]\n",
      " [2.78600929]]\n",
      "gradients: [[-0.47286709]\n",
      " [-0.19534071]]\n",
      "theta: [[4.02385108]\n",
      " [2.77940847]]\n",
      "gradients: [[1.27790301]\n",
      " [2.40665833]]\n",
      "theta: [[4.02949166]\n",
      " [2.78076025]]\n",
      "gradients: [[-2.05768526]\n",
      " [-0.49313057]]\n",
      "theta: [[4.03099535]\n",
      " [2.78099229]]\n",
      "gradients: [[-0.54884692]\n",
      " [-0.08469426]]\n",
      "theta: [[4.0318676 ]\n",
      " [2.78123958]]\n",
      "gradients: [[-0.31854578]\n",
      " [-0.09030964]]\n",
      "theta: [[4.02745076]\n",
      " [2.77769506]]\n",
      "gradients: [[1.61391646]\n",
      " [1.29516744]]\n",
      "theta: [[4.02836565]\n",
      " [2.77838332]]\n",
      "gradients: [[-0.3344848 ]\n",
      " [-0.25162936]]\n",
      "theta: [[4.02927221]\n",
      " [2.77906532]]\n",
      "gradients: [[-0.33161946]\n",
      " [-0.2494738 ]]\n",
      "theta: [[4.02478459]\n",
      " [2.77230123]]\n",
      "gradients: [[1.642468  ]\n",
      " [2.47565597]]\n",
      "theta: [[4.01529737]\n",
      " [2.76905476]]\n",
      "gradients: [[3.47421902]\n",
      " [1.18885627]]\n",
      "theta: [[4.02940984]\n",
      " [2.79446391]]\n",
      "gradients: [[-5.17080829]\n",
      " [-9.30990946]]\n",
      "theta: [[4.02834408]\n",
      " [2.79418027]]\n",
      "gradients: [[0.39070833]\n",
      " [0.10398038]]\n",
      "theta: [[4.0230458 ]\n",
      " [2.78419217]]\n",
      "gradients: [[1.94340771]\n",
      " [3.66363563]]\n",
      "theta: [[4.02542241]\n",
      " [2.78810103]]\n",
      "gradients: [[-0.87221477]\n",
      " [-1.43455128]]\n",
      "theta: [[4.02459549]\n",
      " [2.78743659]]\n",
      "gradients: [[0.30364552]\n",
      " [0.24398094]]\n",
      "theta: [[4.02840375]\n",
      " [2.78945162]]\n",
      "gradients: [[-1.39915376]\n",
      " [-0.74031959]]\n",
      "theta: [[4.03921738]\n",
      " [2.80019549]]\n",
      "gradients: [[-3.97509161]\n",
      " [-3.9494484 ]]\n",
      "theta: [[4.03244517]\n",
      " [2.79435163]]\n",
      "gradients: [[2.49081964]\n",
      " [2.14937165]]\n",
      "theta: [[4.02588641]\n",
      " [2.78877635]]\n",
      "gradients: [[2.41362224]\n",
      " [2.05170299]]\n",
      "theta: [[4.02426025]\n",
      " [2.78837883]]\n",
      "gradients: [[0.59875269]\n",
      " [0.14636658]]\n",
      "theta: [[4.02620436]\n",
      " [2.79006111]]\n",
      "gradients: [[-0.71621099]\n",
      " [-0.61975227]]\n",
      "theta: [[4.02332312]\n",
      " [2.78874635]]\n",
      "gradients: [[1.06202634]\n",
      " [0.48462312]]\n",
      "theta: [[4.01628536]\n",
      " [2.78710395]]\n",
      "gradients: [[2.5955238 ]\n",
      " [0.60571584]]\n",
      "theta: [[4.01998728]\n",
      " [2.79250882]]\n",
      "gradients: [[-1.3660066 ]\n",
      " [-1.99439847]]\n",
      "theta: [[4.01478578]\n",
      " [2.78270317]]\n",
      "gradients: [[1.92039221]\n",
      " [3.62024772]]\n",
      "theta: [[4.01423825]\n",
      " [2.78177546]]\n",
      "gradients: [[0.20225802]\n",
      " [0.34269446]]\n",
      "theta: [[4.01169918]\n",
      " [2.77830724]]\n",
      "gradients: [[0.93844183]\n",
      " [1.28185483]]\n",
      "theta: [[4.02294296]\n",
      " [2.77918923]]\n",
      "gradients: [[-4.15794879]\n",
      " [-0.32615992]]\n",
      "theta: [[4.02889754]\n",
      " [2.78197794]]\n",
      "gradients: [[-2.2031972 ]\n",
      " [-1.03182227]]\n",
      "theta: [[4.03069521]\n",
      " [2.78267257]]\n",
      "gradients: [[-0.66549618]\n",
      " [-0.25715206]]\n",
      "theta: [[4.03370045]\n",
      " [2.78614013]]\n",
      "gradients: [[-1.11314161]\n",
      " [-1.28438529]]\n",
      "theta: [[4.03103102]\n",
      " [2.78249386]]\n",
      "gradients: [[0.98928998]\n",
      " [1.35131033]]\n",
      "theta: [[4.0247166 ]\n",
      " [2.77552261]]\n",
      "gradients: [[2.34138649]\n",
      " [2.58493826]]\n",
      "theta: [[4.0280671 ]\n",
      " [2.77588166]]\n",
      "gradients: [[-1.2430328 ]\n",
      " [-0.13320809]]\n",
      "theta: [[4.03759322]\n",
      " [2.79330311]]\n",
      "gradients: [[-3.53609536]\n",
      " [-6.46684299]]\n",
      "theta: [[4.0311894 ]\n",
      " [2.78623317]]\n",
      "gradients: [[2.37837815]\n",
      " [2.62577781]]\n",
      "theta: [[4.02831399]\n",
      " [2.78492106]]\n",
      "gradients: [[1.06850287]\n",
      " [0.48757849]]\n",
      "theta: [[4.03318854]\n",
      " [2.79316768]]\n",
      "gradients: [[-1.81235884]\n",
      " [-3.06609318]]\n",
      "theta: [[4.02863797]\n",
      " [2.7863087 ]]\n",
      "gradients: [[1.69281303]\n",
      " [2.55153992]]\n",
      "theta: [[4.02284765]\n",
      " [2.78017043]]\n",
      "gradients: [[2.15515671]\n",
      " [2.28466444]]\n",
      "theta: [[4.03345906]\n",
      " [2.79748615]]\n",
      "gradients: [[-3.95168953]\n",
      " [-6.44837265]]\n",
      "theta: [[4.03162188]\n",
      " [2.79722989]]\n",
      "gradients: [[0.6845329 ]\n",
      " [0.09548191]]\n",
      "theta: [[4.03428263]\n",
      " [2.79755377]]\n",
      "gradients: [[-0.99192733]\n",
      " [-0.12074318]]\n",
      "theta: [[4.03338033]\n",
      " [2.79682877]]\n",
      "gradients: [[0.33655663]\n",
      " [0.27042521]]\n",
      "theta: [[4.04140062]\n",
      " [2.80080008]]\n",
      "gradients: [[-2.99317306]\n",
      " [-1.4820915 ]]\n",
      "theta: [[4.04064897]\n",
      " [2.79965547]]\n",
      "gradients: [[0.28066767]\n",
      " [0.42739546]]\n",
      "theta: [[4.0543944 ]\n",
      " [2.82528178]]\n",
      "gradients: [[-5.13529278]\n",
      " [-9.5739883 ]]\n",
      "theta: [[4.05989497]\n",
      " [2.83062332]]\n",
      "gradients: [[-2.05611348]\n",
      " [-1.99666873]]\n",
      "theta: [[4.0707328 ]\n",
      " [2.83147347]]\n",
      "gradients: [[-4.05334959]\n",
      " [-0.3179549 ]]\n",
      "theta: [[4.06941519]\n",
      " [2.83112281]]\n",
      "gradients: [[0.49305319]\n",
      " [0.13121772]]\n",
      "theta: [[4.06245848]\n",
      " [2.82511974]]\n",
      "gradients: [[2.60459069]\n",
      " [2.24754667]]\n",
      "theta: [[4.06320723]\n",
      " [2.82580657]]\n",
      "gradients: [[-0.28048341]\n",
      " [-0.25728508]]\n",
      "theta: [[4.05653334]\n",
      " [2.81843846]]\n",
      "gradients: [[2.50137515]\n",
      " [2.76156899]]\n",
      "theta: [[4.05971737]\n",
      " [2.82308721]]\n",
      "gradients: [[-1.19401256]\n",
      " [-1.74328355]]\n",
      "theta: [[4.06217325]\n",
      " [2.8278107 ]]\n",
      "gradients: [[-0.92144422]\n",
      " [-1.77225355]]\n",
      "theta: [[4.05784237]\n",
      " [2.82269341]]\n",
      "gradients: [[1.62581344]\n",
      " [1.92103249]]\n",
      "theta: [[4.05848456]\n",
      " [2.82287547]]\n",
      "gradients: [[-0.24120673]\n",
      " [-0.06838355]]\n",
      "theta: [[4.05883959]\n",
      " [2.82320981]]\n",
      "gradients: [[-0.1334203 ]\n",
      " [-0.12564482]]\n",
      "theta: [[4.05562793]\n",
      " [2.81682518]]\n",
      "gradients: [[1.20758125]\n",
      " [2.40062055]]\n",
      "theta: [[4.05692299]\n",
      " [2.81885479]]\n",
      "gradients: [[-0.48720072]\n",
      " [-0.76353682]]\n",
      "theta: [[4.05487746]\n",
      " [2.81809604]]\n",
      "gradients: [[0.7699383 ]\n",
      " [0.28559146]]\n",
      "theta: [[4.04666337]\n",
      " [2.80616531]]\n",
      "gradients: [[3.09342789]\n",
      " [4.49311524]]\n",
      "theta: [[4.04702068]\n",
      " [2.80623535]]\n",
      "gradients: [[-0.13463454]\n",
      " [-0.0263922 ]]\n",
      "theta: [[4.04955596]\n",
      " [2.80888552]]\n",
      "gradients: [[-0.95580034]\n",
      " [-0.99911384]]\n",
      "theta: [[4.06270246]\n",
      " [2.83255547]]\n",
      "gradients: [[-4.9588626]\n",
      " [-8.9283066]]\n",
      "theta: [[4.06495243]\n",
      " [2.83624977]]\n",
      "gradients: [[-0.84913676]\n",
      " [-1.39422786]]\n",
      "theta: [[4.06640624]\n",
      " [2.83807653]]\n",
      "gradients: [[-0.54895852]\n",
      " [-0.68978413]]\n",
      "theta: [[4.0665647]\n",
      " [2.8381653]]\n",
      "gradients: [[-0.05986532]\n",
      " [-0.03353636]]\n",
      "theta: [[4.06951799]\n",
      " [2.84247717]]\n",
      "gradients: [[-1.11634665]\n",
      " [-1.62988967]]\n",
      "theta: [[4.07489305]\n",
      " [2.84341199]]\n",
      "gradients: [[-2.03284749]\n",
      " [-0.3535497 ]]\n",
      "theta: [[4.07377092]\n",
      " [2.84295007]]\n",
      "gradients: [[0.42461511]\n",
      " [0.17479094]]\n",
      "theta: [[4.0705363 ]\n",
      " [2.83853177]]\n",
      "gradients: [[1.22462881]\n",
      " [1.67276896]]\n",
      "theta: [[4.06337371]\n",
      " [2.83686024]]\n",
      "gradients: [[2.71318694]\n",
      " [0.63317482]]\n",
      "theta: [[4.07100839]\n",
      " [2.84064061]]\n",
      "gradients: [[-2.89354255]\n",
      " [-1.43275873]]\n",
      "theta: [[4.06886105]\n",
      " [2.8398441 ]]\n",
      "gradients: [[0.81427103]\n",
      " [0.30203569]]\n",
      "theta: [[4.06011808]\n",
      " [2.83735953]]\n",
      "gradients: [[3.31708371]\n",
      " [0.94264846]]\n",
      "theta: [[4.05342133]\n",
      " [2.83166694]]\n",
      "gradients: [[2.54208591]\n",
      " [2.16090371]]\n",
      "theta: [[4.05880747]\n",
      " [2.83689737]]\n",
      "gradients: [[-2.04565849]\n",
      " [-1.98651602]]\n",
      "theta: [[4.05269863]\n",
      " [2.834876  ]]\n",
      "gradients: [[2.32136173]\n",
      " [0.76812202]]\n",
      "theta: [[4.04566074]\n",
      " [2.83323357]]\n",
      "gradients: [[2.67580532]\n",
      " [0.62445109]]\n",
      "theta: [[4.05880497]\n",
      " [2.85773904]]\n",
      "gradients: [[-5.00006651]\n",
      " [-9.32187908]]\n",
      "theta: [[4.05814459]\n",
      " [2.85697962]]\n",
      "gradients: [[0.25134289]\n",
      " [0.28903167]]\n",
      "theta: [[4.05193659]\n",
      " [2.85039858]]\n",
      "gradients: [[2.36400531]\n",
      " [2.50606318]]\n",
      "theta: [[4.04615561]\n",
      " [2.8395005 ]]\n",
      "gradients: [[2.2025538 ]\n",
      " [4.15216763]]\n",
      "theta: [[4.05181655]\n",
      " [2.84201808]]\n",
      "gradients: [[-2.15795065]\n",
      " [-0.95970103]]\n",
      "theta: [[4.05586043]\n",
      " [2.84273096]]\n",
      "gradients: [[-1.54233587]\n",
      " [-0.27189384]]\n",
      "theta: [[4.06585599]\n",
      " [2.85266204]]\n",
      "gradients: [[-3.81430696]\n",
      " [-3.78970097]]\n",
      "theta: [[4.06816429]\n",
      " [2.85532544]]\n",
      "gradients: [[-0.88130699]\n",
      " [-1.01688565]]\n",
      "theta: [[4.06720522]\n",
      " [2.85457961]]\n",
      "gradients: [[0.36636296]\n",
      " [0.28490946]]\n",
      "theta: [[4.07776245]\n",
      " [2.85540774]]\n",
      "gradients: [[-4.03497071]\n",
      " [-0.31651321]]\n",
      "theta: [[4.07097414]\n",
      " [2.84791332]]\n",
      "gradients: [[2.59584616]\n",
      " [2.8658669 ]]\n",
      "theta: [[4.06655459]\n",
      " [2.84269125]]\n",
      "gradients: [[1.69092103]\n",
      " [1.99796246]]\n",
      "theta: [[4.06847061]\n",
      " [2.84277322]]\n",
      "gradients: [[-0.73345153]\n",
      " [-0.03137764]]\n",
      "theta: [[4.06965011]\n",
      " [2.84295523]]\n",
      "gradients: [[-0.4517502 ]\n",
      " [-0.06971097]]\n",
      "theta: [[4.07090989]\n",
      " [2.84296277]]\n",
      "gradients: [[-0.48274536]\n",
      " [-0.00288823]]\n",
      "theta: [[4.0655342 ]\n",
      " [2.83719472]]\n",
      "gradients: [[2.06103811]\n",
      " [2.21147078]]\n",
      "theta: [[4.07060881]\n",
      " [2.83841087]]\n",
      "gradients: [[-1.94662172]\n",
      " [-0.46651385]]\n",
      "theta: [[4.06449634]\n",
      " [2.83638829]]\n",
      "gradients: [[2.34596602]\n",
      " [0.7762634 ]]\n",
      "theta: [[4.06267538]\n",
      " [2.83594316]]\n",
      "gradients: [[0.69925027]\n",
      " [0.17093346]]\n",
      "theta: [[4.06155553]\n",
      " [2.83423786]]\n",
      "gradients: [[0.43024763]\n",
      " [0.655173  ]]\n",
      "theta: [[4.060082  ]\n",
      " [2.83413244]]\n",
      "gradients: [[0.56642228]\n",
      " [0.0405236 ]]\n",
      "theta: [[4.06855576]\n",
      " [2.84962932]]\n",
      "gradients: [[-3.25900643]\n",
      " [-5.96010026]]\n",
      "theta: [[4.07387279]\n",
      " [2.85211945]]\n",
      "gradients: [[-2.04599324]\n",
      " [-0.95819902]]\n",
      "theta: [[4.07680345]\n",
      " [2.85243351]]\n",
      "gradients: [[-1.12830361]\n",
      " [-0.12091328]]\n",
      "theta: [[4.08416159]\n",
      " [2.86099887]]\n",
      "gradients: [[-2.83435653]\n",
      " [-3.29937663]]\n",
      "theta: [[4.0801489 ]\n",
      " [2.85659147]]\n",
      "gradients: [[1.54649012]\n",
      " [1.69861048]]\n",
      "theta: [[4.0732246 ]\n",
      " [2.85061637]]\n",
      "gradients: [[2.67001283]\n",
      " [2.30400058]]\n",
      "theta: [[4.075483  ]\n",
      " [2.85322219]]\n",
      "gradients: [[-0.87129055]\n",
      " [-1.0053283 ]]\n",
      "theta: [[4.08520894]\n",
      " [2.8628854 ]]\n",
      "gradients: [[-3.75421472]\n",
      " [-3.72999639]]\n",
      "theta: [[4.07807818]\n",
      " [2.8612213 ]]\n",
      "gradients: [[2.75389902]\n",
      " [0.64267577]]\n",
      "theta: [[4.07192911]\n",
      " [2.85918661]]\n",
      "gradients: [[2.37600037]\n",
      " [0.78620155]]\n",
      "theta: [[4.0738902 ]\n",
      " [2.86295846]]\n",
      "gradients: [[-0.75815767]\n",
      " [-1.45819746]]\n",
      "theta: [[4.06715604]\n",
      " [2.85552381]]\n",
      "gradients: [[2.60477397]\n",
      " [2.87572339]]\n",
      "theta: [[4.06108269]\n",
      " [2.85351418]]\n",
      "gradients: [[2.35038557]\n",
      " [0.7777258 ]]\n",
      "theta: [[4.06147821]\n",
      " [2.85381173]]\n",
      "gradients: [[-0.15314508]\n",
      " [-0.11520942]]\n",
      "theta: [[4.0689138 ]\n",
      " [2.85749351]]\n",
      "gradients: [[-2.88054624]\n",
      " [-1.42632351]]\n",
      "theta: [[4.06386174]\n",
      " [2.84987866]]\n",
      "gradients: [[1.95817738]\n",
      " [2.95151778]]\n",
      "theta: [[4.05777317]\n",
      " [2.8399789 ]]\n",
      "gradients: [[2.36114942]\n",
      " [3.83912507]]\n",
      "theta: [[4.0682271 ]\n",
      " [2.84079894]]\n",
      "gradients: [[-4.05612545]\n",
      " [-0.31817264]]\n",
      "theta: [[4.06162187]\n",
      " [2.83518415]]\n",
      "gradients: [[2.5641513 ]\n",
      " [2.17966043]]\n",
      "theta: [[4.0613841 ]\n",
      " [2.83474713]]\n",
      "gradients: [[0.09234666]\n",
      " [0.16973659]]\n",
      "theta: [[4.05540534]\n",
      " [2.82840909]]\n",
      "gradients: [[2.32334737]\n",
      " [2.46296202]]\n",
      "theta: [[4.05463636]\n",
      " [2.82781108]]\n",
      "gradients: [[0.29898099]\n",
      " [0.23250853]]\n",
      "theta: [[4.05368197]\n",
      " [2.82741821]]\n",
      "gradients: [[0.37125762]\n",
      " [0.15282657]]\n",
      "theta: [[4.05373363]\n",
      " [2.82743857]]\n",
      "gradients: [[-0.02010931]\n",
      " [-0.00792365]]\n",
      "theta: [[4.05488103]\n",
      " [2.82775939]]\n",
      "gradients: [[-0.44679625]\n",
      " [-0.12492938]]\n",
      "theta: [[4.05015702]\n",
      " [2.82063899]]\n",
      "gradients: [[1.84047667]\n",
      " [2.77411008]]\n",
      "theta: [[4.05153277]\n",
      " [2.82334839]]\n",
      "gradients: [[-0.53626835]\n",
      " [-1.05612377]]\n",
      "theta: [[4.05904714]\n",
      " [2.82706918]]\n",
      "gradients: [[-2.93060543]\n",
      " [-1.45111068]]\n",
      "theta: [[4.05898362]\n",
      " [2.82706264]]\n",
      "gradients: [[0.0247865 ]\n",
      " [0.00255183]]\n",
      "theta: [[4.06044489]\n",
      " [2.82762729]]\n",
      "gradients: [[-0.57048198]\n",
      " [-0.22043796]]\n",
      "theta: [[4.0636961]\n",
      " [2.8276519]]\n",
      "gradients: [[-1.26992252]\n",
      " [-0.00961339]]\n",
      "theta: [[4.06256061]\n",
      " [2.82673952]]\n",
      "gradients: [[0.44375162]\n",
      " [0.35655701]]\n",
      "theta: [[4.06208092]\n",
      " [2.82618791]]\n",
      "gradients: [[0.18755841]\n",
      " [0.21568273]]\n",
      "theta: [[4.06031857]\n",
      " [2.82575709]]\n",
      "gradients: [[0.6894324 ]\n",
      " [0.16853346]]\n",
      "theta: [[4.05116713]\n",
      " [2.82262553]]\n",
      "gradients: [[3.5818715 ]\n",
      " [1.22569429]]\n",
      "theta: [[4.05356836]\n",
      " [2.82724391]]\n",
      "gradients: [[-0.94032065]\n",
      " [-1.80855941]]\n",
      "theta: [[4.05262743]\n",
      " [2.82685659]]\n",
      "gradients: [[0.36865468]\n",
      " [0.15175508]]\n",
      "theta: [[4.05394627]\n",
      " [2.82686448]]\n",
      "gradients: [[-0.51698335]\n",
      " [-0.00309307]]\n",
      "theta: [[4.05518469]\n",
      " [2.82705558]]\n",
      "gradients: [[-0.48570874]\n",
      " [-0.07495121]]\n",
      "theta: [[4.05711519]\n",
      " [2.82713817]]\n",
      "gradients: [[-0.75752914]\n",
      " [-0.03240769]]\n",
      "theta: [[4.05040646]\n",
      " [2.81966741]]\n",
      "gradients: [[2.63384645]\n",
      " [2.93302217]]\n",
      "theta: [[4.06292769]\n",
      " [2.84221155]]\n",
      "gradients: [[-4.91833655]\n",
      " [-8.85534047]]\n",
      "theta: [[4.06114916]\n",
      " [2.84177679]]\n",
      "gradients: [[0.69895998]\n",
      " [0.1708625 ]]\n",
      "theta: [[4.06323961]\n",
      " [2.84520916]]\n",
      "gradients: [[-0.82196175]\n",
      " [-1.34960824]]\n",
      "theta: [[4.06537962]\n",
      " [2.84744615]]\n",
      "gradients: [[-0.84188255]\n",
      " [-0.8800337 ]]\n",
      "theta: [[4.06434073]\n",
      " [2.84701849]]\n",
      "gradients: [[0.40890953]\n",
      " [0.16832581]]\n",
      "theta: [[4.06398194]\n",
      " [2.84635904]]\n",
      "gradients: [[0.14128832]\n",
      " [0.25969317]]\n",
      "theta: [[4.05715355]\n",
      " [2.83875501]]\n",
      "gradients: [[2.69038825]\n",
      " [2.99598649]]\n",
      "theta: [[4.04879979]\n",
      " [2.83638105]]\n",
      "gradients: [[3.29304971]\n",
      " [0.93581848]]\n",
      "theta: [[4.04977678]\n",
      " [2.83678464]]\n",
      "gradients: [[-0.38532434]\n",
      " [-0.15917692]]\n",
      "theta: [[4.05950382]\n",
      " [2.84644893]]\n",
      "gradients: [[-3.83829018]\n",
      " [-3.81352948]]\n",
      "theta: [[4.06085698]\n",
      " [2.84814921]]\n",
      "gradients: [[-0.53422458]\n",
      " [-0.67127046]]\n",
      "theta: [[4.06146821]\n",
      " [2.84870989]]\n",
      "gradients: [[-0.24143695]\n",
      " [-0.22146809]]\n",
      "theta: [[4.07262046]\n",
      " [2.85050831]]\n",
      "gradients: [[-4.40736963]\n",
      " [-0.71073565]]\n",
      "theta: [[4.0821433 ]\n",
      " [2.85996972]]\n",
      "gradients: [[-3.76533255]\n",
      " [-3.74104249]]\n",
      "theta: [[4.0815758 ]\n",
      " [2.85892663]]\n",
      "gradients: [[0.22450314]\n",
      " [0.4126451 ]]\n",
      "theta: [[4.08438388]\n",
      " [2.85922756]]\n",
      "gradients: [[-1.11143862]\n",
      " [-0.11910596]]\n",
      "theta: [[4.09527628]\n",
      " [2.87377697]]\n",
      "gradients: [[-4.31339011]\n",
      " [-5.76156716]]\n",
      "theta: [[4.09541326]\n",
      " [2.87388002]]\n",
      "gradients: [[-0.05427094]\n",
      " [-0.04082745]]\n",
      "theta: [[4.09598774]\n",
      " [2.87461329]]\n",
      "gradients: [[-0.22772145]\n",
      " [-0.29067089]]\n",
      "theta: [[4.0940187 ]\n",
      " [2.87413196]]\n",
      "gradients: [[0.78092145]\n",
      " [0.19089818]]\n",
      "theta: [[4.10007459]\n",
      " [2.88087523]]\n",
      "gradients: [[-2.40297966]\n",
      " [-2.67573039]]\n",
      "theta: [[4.09328189]\n",
      " [2.87337595]]\n",
      "gradients: [[2.6967037 ]\n",
      " [2.97721568]]\n",
      "theta: [[4.09105857]\n",
      " [2.87255125]]\n",
      "gradients: [[0.88310291]\n",
      " [0.32756735]]\n",
      "theta: [[4.08873356]\n",
      " [2.87147325]]\n",
      "gradients: [[0.92395966]\n",
      " [0.42839813]]\n",
      "theta: [[4.08402412]\n",
      " [2.86769393]]\n",
      "gradients: [[1.87247335]\n",
      " [1.50265927]]\n",
      "theta: [[4.07710161]\n",
      " [2.86607843]]\n",
      "gradients: [[2.75377369]\n",
      " [0.64264652]]\n",
      "theta: [[4.07829773]\n",
      " [2.86711346]]\n",
      "gradients: [[-0.47605812]\n",
      " [-0.41194299]]\n",
      "theta: [[4.07697389]\n",
      " [2.86676114]]\n",
      "gradients: [[0.527153  ]\n",
      " [0.14029281]]\n",
      "theta: [[4.07235193]\n",
      " [2.86305202]]\n",
      "gradients: [[1.84139109]\n",
      " [1.47771576]]\n",
      "theta: [[4.07314517]\n",
      " [2.8633797 ]]\n",
      "gradients: [[-0.31618459]\n",
      " [-0.13061539]]\n",
      "theta: [[4.07688676]\n",
      " [2.8640393 ]]\n",
      "gradients: [[-1.49214709]\n",
      " [-0.26304621]]\n",
      "theta: [[4.07477301]\n",
      " [2.86325525]]\n",
      "gradients: [[0.84338621]\n",
      " [0.31283532]]\n",
      "theta: [[4.07042738]\n",
      " [2.85812053]]\n",
      "gradients: [[1.73477426]\n",
      " [2.04977867]]\n",
      "theta: [[4.07234341]\n",
      " [2.86180571]]\n",
      "gradients: [[-0.76526201]\n",
      " [-1.47186154]]\n",
      "theta: [[4.07332028]\n",
      " [2.86207886]]\n",
      "gradients: [[-0.3903578 ]\n",
      " [-0.10914854]]\n",
      "theta: [[4.06836577]\n",
      " [2.85461103]]\n",
      "gradients: [[1.98081312]\n",
      " [2.98563614]]\n",
      "theta: [[4.08055314]\n",
      " [2.87733256]]\n",
      "gradients: [[-4.87494626]\n",
      " [-9.08861101]]\n",
      "theta: [[4.07742877]\n",
      " [2.87590685]]\n",
      "gradients: [[1.25037118]\n",
      " [0.57056851]]\n",
      "theta: [[4.07807442]\n",
      " [2.87673097]]\n",
      "gradients: [[-0.2585162 ]\n",
      " [-0.32997828]]\n",
      "theta: [[4.07828468]\n",
      " [2.87688915]]\n",
      "gradients: [[-0.08423014]\n",
      " [-0.06336544]]\n",
      "theta: [[4.07944503]\n",
      " [2.87689609]]\n",
      "gradients: [[-0.46507018]\n",
      " [-0.00278248]]\n",
      "theta: [[4.0809256 ]\n",
      " [2.87892874]]\n",
      "gradients: [[-0.59370706]\n",
      " [-0.81508997]]\n",
      "theta: [[4.08639273]\n",
      " [2.88665663]]\n",
      "gradients: [[-2.19341167]\n",
      " [-3.10043185]]\n",
      "theta: [[4.09390212]\n",
      " [2.90038988]]\n",
      "gradients: [[-3.01427157]\n",
      " [-5.51252695]]\n",
      "theta: [[4.09423742]\n",
      " [2.90105022]]\n",
      "gradients: [[-0.13465624]\n",
      " [-0.26519122]]\n",
      "theta: [[4.09296625]\n",
      " [2.90052695]]\n",
      "gradients: [[0.51075689]\n",
      " [0.21025082]]\n",
      "theta: [[4.09596072]\n",
      " [2.90054962]]\n",
      "gradients: [[-1.2037761 ]\n",
      " [-0.00911266]]\n",
      "theta: [[4.09496292]\n",
      " [2.89871563]]\n",
      "gradients: [[0.40131267]\n",
      " [0.7376276 ]]\n",
      "theta: [[4.08448696]\n",
      " [2.88232233]]\n",
      "gradients: [[4.21552565]\n",
      " [6.59666718]]\n",
      "theta: [[4.0859547 ]\n",
      " [2.88447551]]\n",
      "gradients: [[-0.59091224]\n",
      " [-0.86687202]]\n",
      "theta: [[4.08752405]\n",
      " [2.88705228]]\n",
      "gradients: [[-0.63213356]\n",
      " [-1.03792258]]\n",
      "theta: [[4.08868296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [2.88750009]]\n",
      "gradients: [[-0.46704033]\n",
      " [-0.18046743]]\n",
      "theta: [[4.09228556]\n",
      " [2.88813518]]\n",
      "gradients: [[-1.45256727]\n",
      " [-0.2560688 ]]\n",
      "theta: [[4.09216662]\n",
      " [2.88806855]]\n",
      "gradients: [[0.04797872]\n",
      " [0.02687753]]\n",
      "theta: [[4.09959368]\n",
      " [2.90165122]]\n",
      "gradients: [[-2.99755951]\n",
      " [-5.48196378]]\n",
      "theta: [[4.10410658]\n",
      " [2.90248834]]\n",
      "gradients: [[-1.82230878]\n",
      " [-0.33803102]]\n",
      "theta: [[4.1147619 ]\n",
      " [2.90420663]]\n",
      "gradients: [[-4.30474819]\n",
      " [-0.69418684]]\n",
      "theta: [[4.11443454]\n",
      " [2.90389835]]\n",
      "gradients: [[0.13231704]\n",
      " [0.12460586]]\n",
      "theta: [[4.1155911 ]\n",
      " [2.90559503]]\n",
      "gradients: [[-0.46771276]\n",
      " [-0.6861376 ]]\n",
      "theta: [[4.12530488]\n",
      " [2.906357  ]]\n",
      "gradients: [[-3.9301954 ]\n",
      " [-0.30829437]]\n",
      "theta: [[4.12869588]\n",
      " [2.90695479]]\n",
      "gradients: [[-1.37267497]\n",
      " [-0.24198482]]\n",
      "theta: [[4.12975815]\n",
      " [2.90851316]]\n",
      "gradients: [[-0.43022245]\n",
      " [-0.63113907]]\n",
      "theta: [[4.12733436]\n",
      " [2.90761411]]\n",
      "gradients: [[0.98212218]\n",
      " [0.36429634]]\n",
      "theta: [[4.12558675]\n",
      " [2.90748908]]\n",
      "gradients: [[0.70847906]\n",
      " [0.05068678]]\n",
      "theta: [[4.12367855]\n",
      " [2.9045833 ]]\n",
      "gradients: [[0.77396794]\n",
      " [1.17858384]]\n",
      "theta: [[4.12432854]\n",
      " [2.90476504]]\n",
      "gradients: [[-0.26376531]\n",
      " [-0.07375182]]\n",
      "theta: [[4.13140284]\n",
      " [2.91770259]]\n",
      "gradients: [[-2.8721663 ]\n",
      " [-5.25264356]]\n",
      "theta: [[4.13288024]\n",
      " [2.91940727]]\n",
      "gradients: [[-0.60012078]\n",
      " [-0.69244226]]\n",
      "theta: [[4.14151189]\n",
      " [2.92798324]]\n",
      "gradients: [[-3.50790399]\n",
      " [-3.4852746 ]]\n",
      "theta: [[4.13996866]\n",
      " [2.92734798]]\n",
      "gradients: [[0.62747955]\n",
      " [0.2582992 ]]\n",
      "theta: [[4.1333884]\n",
      " [2.9203723]]\n",
      "gradients: [[2.67684731]\n",
      " [2.83770449]]\n",
      "theta: [[4.14143028]\n",
      " [2.93349505]]\n",
      "gradients: [[-3.27304479]\n",
      " [-5.34095919]]\n",
      "theta: [[4.13516669]\n",
      " [2.93142247]]\n",
      "gradients: [[2.55053431]\n",
      " [0.84395359]]\n",
      "theta: [[4.13701296]\n",
      " [2.93164721]]\n",
      "gradients: [[-0.7521683 ]\n",
      " [-0.09155831]]\n",
      "theta: [[4.13942949]\n",
      " [2.93190618]]\n",
      "gradients: [[-0.98497829]\n",
      " [-0.10555399]]\n",
      "theta: [[4.1349842 ]\n",
      " [2.92702362]]\n",
      "gradients: [[1.81279011]\n",
      " [1.99110505]]\n",
      "theta: [[4.13914433]\n",
      " [2.93106348]]\n",
      "gradients: [[-1.69733316]\n",
      " [-1.64826119]]\n",
      "theta: [[4.14949576]\n",
      " [2.93273276]]\n",
      "gradients: [[-4.2254566 ]\n",
      " [-0.68140022]]\n",
      "theta: [[4.1492413 ]\n",
      " [2.93223162]]\n",
      "gradients: [[0.10392279]\n",
      " [0.20466493]]\n",
      "theta: [[4.14113889]\n",
      " [2.92223431]]\n",
      "gradients: [[3.3106454 ]\n",
      " [4.08490062]]\n",
      "theta: [[4.14909257]\n",
      " [2.93521315]]\n",
      "gradients: [[-3.25146696]\n",
      " [-5.30574845]]\n",
      "theta: [[4.14053726]\n",
      " [2.92687781]]\n",
      "gradients: [[3.49912308]\n",
      " [3.40915202]]\n",
      "theta: [[4.13707793]\n",
      " [2.92529926]]\n",
      "gradients: [[1.41555634]\n",
      " [0.64594569]]\n",
      "theta: [[4.14357171]\n",
      " [2.9285147 ]]\n",
      "gradients: [[-2.65855165]\n",
      " [-1.31640127]]\n",
      "theta: [[4.14386385]\n",
      " [2.92863538]]\n",
      "gradients: [[-0.11965995]\n",
      " [-0.04943135]]\n",
      "theta: [[4.14367712]\n",
      " [2.92826764]]\n",
      "gradients: [[0.07652024]\n",
      " [0.15069852]]\n",
      "theta: [[4.1534585 ]\n",
      " [2.94133302]]\n",
      "gradients: [[-4.01036445]\n",
      " [-5.3568037 ]]\n",
      "theta: [[4.15802195]\n",
      " [2.94778354]]\n",
      "gradients: [[-1.87192643]\n",
      " [-2.64600595]]\n",
      "theta: [[4.15728873]\n",
      " [2.94709306]]\n",
      "gradients: [[0.30091182]\n",
      " [0.28337525]]\n",
      "theta: [[4.16202582]\n",
      " [2.95259788]]\n",
      "gradients: [[-1.94504829]\n",
      " [-2.26027908]]\n",
      "theta: [[4.17218343]\n",
      " [2.9542359 ]]\n",
      "gradients: [[-4.1727483 ]\n",
      " [-0.67290045]]\n",
      "theta: [[4.17657235]\n",
      " [2.95618777]]\n",
      "gradients: [[-1.8038429 ]\n",
      " [-0.80221941]]\n",
      "theta: [[4.18157024]\n",
      " [2.96175295]]\n",
      "gradients: [[-2.0551332 ]\n",
      " [-2.28840154]]\n",
      "theta: [[4.18284747]\n",
      " [2.96361774]]\n",
      "gradients: [[-0.52545439]\n",
      " [-0.76717449]]\n",
      "theta: [[4.17795475]\n",
      " [2.95389121]]\n",
      "gradients: [[2.01384711]\n",
      " [4.00344305]]\n",
      "theta: [[4.18800932]\n",
      " [2.95551261]]\n",
      "gradients: [[-4.14047333]\n",
      " [-0.66769576]]\n",
      "theta: [[4.18888733]\n",
      " [2.95643041]]\n",
      "gradients: [[-0.36173909]\n",
      " [-0.37813182]]\n",
      "theta: [[4.18460572]\n",
      " [2.950582  ]]\n",
      "gradients: [[1.76487618]\n",
      " [2.41071422]]\n",
      "theta: [[4.18561892]\n",
      " [2.95175106]]\n",
      "gradients: [[-0.41783996]\n",
      " [-0.4821197 ]]\n",
      "theta: [[4.1949833 ]\n",
      " [2.96425944]]\n",
      "gradients: [[-3.86374539]\n",
      " [-5.16095878]]\n",
      "theta: [[4.19887938]\n",
      " [2.96498215]]\n",
      "gradients: [[-1.60830238]\n",
      " [-0.29833369]]\n",
      "theta: [[4.20630665]\n",
      " [2.97555905]]\n",
      "gradients: [[-3.06746358]\n",
      " [-4.36825875]]\n",
      "theta: [[4.21617302]\n",
      " [2.9771501 ]]\n",
      "gradients: [[-4.07678116]\n",
      " [-0.65742472]]\n",
      "theta: [[4.20724765]\n",
      " [2.97461369]]\n",
      "gradients: [[3.68974685]\n",
      " [1.04855183]]\n",
      "theta: [[4.20921249]\n",
      " [2.97793775]]\n",
      "gradients: [[-0.81265914]\n",
      " [-1.37483184]]\n",
      "theta: [[4.20371547]\n",
      " [2.97144257]]\n",
      "gradients: [[2.27466689]\n",
      " [2.68770627]]\n",
      "theta: [[4.20099808]\n",
      " [2.96730458]]\n",
      "gradients: [[1.12499975]\n",
      " [1.71312848]]\n",
      "theta: [[4.20037653]\n",
      " [2.96673444]]\n",
      "gradients: [[0.25744572]\n",
      " [0.2361528 ]]\n",
      "theta: [[4.19971975]\n",
      " [2.96570514]]\n",
      "gradients: [[0.2721695 ]\n",
      " [0.42654173]]\n",
      "theta: [[4.1935789 ]\n",
      " [2.95644916]]\n",
      "gradients: [[2.54599931]\n",
      " [3.83752887]]\n",
      "theta: [[4.18714201]\n",
      " [2.95431924]]\n",
      "gradients: [[2.67002224]\n",
      " [0.88349129]]\n",
      "theta: [[4.19323763]\n",
      " [2.95733753]]\n",
      "gradients: [[-2.5296846 ]\n",
      " [-1.25259181]]\n",
      "theta: [[4.19689017]\n",
      " [2.96406439]]\n",
      "gradients: [[-1.51653372]\n",
      " [-2.79298884]]\n",
      "theta: [[4.20677318]\n",
      " [2.9818585 ]]\n",
      "gradients: [[-4.10540292]\n",
      " [-7.39167406]]\n",
      "theta: [[4.20484258]\n",
      " [2.98106377]]\n",
      "gradients: [[0.80235715]\n",
      " [0.33028679]]\n",
      "theta: [[4.20393539]\n",
      " [2.98055557]]\n",
      "gradients: [[0.37720937]\n",
      " [0.21131149]]\n",
      "theta: [[4.2074341 ]\n",
      " [2.98395313]]\n",
      "gradients: [[-1.45546222]\n",
      " [-1.41338303]]\n",
      "theta: [[4.21707537]\n",
      " [3.00131199]]\n",
      "gradients: [[-4.01269672]\n",
      " [-7.22475888]]\n",
      "theta: [[4.21222698]\n",
      " [2.99848465]]\n",
      "gradients: [[2.01886943]\n",
      " [1.17730176]]\n",
      "theta: [[4.20984133]\n",
      " [2.99409974]]\n",
      "gradients: [[0.99386168]\n",
      " [1.82675467]]\n",
      "theta: [[4.20025369]\n",
      " [2.99081891]]\n",
      "gradients: [[3.99612866]\n",
      " [1.36745052]]\n",
      "theta: [[4.19295465]\n",
      " [2.98911554]]\n",
      "gradients: [[3.04370005]\n",
      " [0.71030646]]\n",
      "theta: [[4.19485344]\n",
      " [2.99232786]]\n",
      "gradients: [[-0.79217759]\n",
      " [-1.34018178]]\n",
      "theta: [[4.20203512]\n",
      " [3.00255501]]\n",
      "gradients: [[-2.99763146]\n",
      " [-4.26881348]]\n",
      "theta: [[4.19466819]\n",
      " [2.98866717]]\n",
      "gradients: [[3.0764295 ]\n",
      " [5.79956367]]\n",
      "theta: [[4.19470316]\n",
      " [2.98873442]]\n",
      "gradients: [[-0.01460838]\n",
      " [-0.02809694]]\n",
      "theta: [[4.19543254]\n",
      " [2.98950412]]\n",
      "gradients: [[-0.30488274]\n",
      " [-0.32173291]]\n",
      "theta: [[4.19449728]\n",
      " [2.9891356 ]]\n",
      "gradients: [[0.39112501]\n",
      " [0.15411469]]\n",
      "theta: [[4.19371082]\n",
      " [2.98905463]]\n",
      "gradients: [[0.32905704]\n",
      " [0.03387721]]\n",
      "theta: [[4.19278553]\n",
      " [2.98869004]]\n",
      "gradients: [[0.38732734]\n",
      " [0.15261829]]\n",
      "theta: [[4.19082031]\n",
      " [2.98716175]]\n",
      "gradients: [[0.8230327 ]\n",
      " [0.64004779]]\n",
      "theta: [[4.19076472]\n",
      " [2.98713878]]\n",
      "gradients: [[0.02329127]\n",
      " [0.00962159]]\n",
      "theta: [[4.18299398]\n",
      " [2.97848537]]\n",
      "gradients: [[3.25749532]\n",
      " [3.62751063]]\n",
      "theta: [[4.18179515]\n",
      " [2.97682749]]\n",
      "gradients: [[0.50278995]\n",
      " [0.69531652]]\n",
      "theta: [[4.17687555]\n",
      " [2.96704753]]\n",
      "gradients: [[2.06426328]\n",
      " [4.10366826]]\n",
      "theta: [[4.17412886]\n",
      " [2.96458497]]\n",
      "gradients: [[1.15306104]\n",
      " [1.03378283]]\n",
      "theta: [[4.1745183 ]\n",
      " [2.96511963]]\n",
      "gradients: [[-0.16356636]\n",
      " [-0.22455738]]\n",
      "theta: [[4.17171792]\n",
      " [2.96382123]]\n",
      "gradients: [[1.17671864]\n",
      " [0.54559099]]\n",
      "theta: [[4.17537085]\n",
      " [2.9705488 ]]\n",
      "gradients: [[-1.5356912 ]\n",
      " [-2.82827103]]\n",
      "theta: [[4.17518615]\n",
      " [2.97049643]]\n",
      "gradients: [[0.07768602]\n",
      " [0.02202445]]\n",
      "theta: [[4.18121651]\n",
      " [2.97348241]]\n",
      "gradients: [[-2.5375758 ]\n",
      " [-1.25649919]]\n",
      "theta: [[4.17409583]\n",
      " [2.96190449]]\n",
      "gradients: [[2.99780748]\n",
      " [4.87430306]]\n",
      "theta: [[4.17447261]\n",
      " [2.96262918]]\n",
      "gradients: [[-0.15870074]\n",
      " [-0.30523601]]\n",
      "theta: [[4.1669493]\n",
      " [2.9542513]]\n",
      "gradients: [[3.17032384]\n",
      " [3.53043744]]\n",
      "theta: [[4.16599182]\n",
      " [2.95292718]]\n",
      "gradients: [[0.40367319]\n",
      " [0.55824632]]\n",
      "theta: [[4.16587841]\n",
      " [2.95284813]]\n",
      "gradients: [[0.04783637]\n",
      " [0.03334424]]\n",
      "theta: [[4.16083408]\n",
      " [2.94688784]]\n",
      "gradients: [[2.1287078 ]\n",
      " [2.51524359]]\n",
      "theta: [[4.15584939]\n",
      " [2.94099802]]\n",
      "gradients: [[2.10453399]\n",
      " [2.48668024]]\n",
      "theta: [[4.15702711]\n",
      " [2.94235692]]\n",
      "gradients: [[-0.49746934]\n",
      " [-0.57399912]]\n",
      "theta: [[4.15673432]\n",
      " [2.94208834]]\n",
      "gradients: [[0.12373522]\n",
      " [0.11350128]]\n",
      "theta: [[4.15490789]\n",
      " [2.94195768]]\n",
      "gradients: [[0.77221177]\n",
      " [0.05524642]]\n",
      "theta: [[4.15641282]\n",
      " [2.94415489]]\n",
      "gradients: [[-0.63658212]\n",
      " [-0.92942333]]\n",
      "theta: [[4.15699074]\n",
      " [2.94424408]]\n",
      "gradients: [[-0.24457675]\n",
      " [-0.03774139]]\n",
      "theta: [[4.15505945]\n",
      " [2.94269228]]\n",
      "gradients: [[0.81770587]\n",
      " [0.65703142]]\n",
      "theta: [[4.15622834]\n",
      " [2.94404098]]\n",
      "gradients: [[-0.49513943]\n",
      " [-0.57131077]]\n",
      "theta: [[4.1555434 ]\n",
      " [2.94339596]]\n",
      "gradients: [[0.29027569]\n",
      " [0.27335898]]\n",
      "theta: [[4.15808579]\n",
      " [2.94341521]]\n",
      "gradients: [[-1.07797275]\n",
      " [-0.00816032]]\n",
      "theta: [[4.15079028]\n",
      " [2.935291  ]]\n",
      "gradients: [[3.09475729]\n",
      " [3.44628737]]\n",
      "theta: [[4.15987401]\n",
      " [2.93600355]]\n",
      "gradients: [[-3.85513819]\n",
      " [-0.3024067 ]]\n",
      "theta: [[4.16105382]\n",
      " [2.93736486]]\n",
      "gradients: [[-0.50094571]\n",
      " [-0.57801029]]\n",
      "theta: [[4.15460313]\n",
      " [2.93052653]]\n",
      "gradients: [[2.74025527]\n",
      " [2.90492276]]\n",
      "theta: [[4.15408522]\n",
      " [2.9302364 ]]\n",
      "gradients: [[0.22010885]\n",
      " [0.12330428]]\n",
      "theta: [[4.1484063 ]\n",
      " [2.92414299]]\n",
      "gradients: [[2.41467604]\n",
      " [2.5909203 ]]\n",
      "theta: [[4.15888021]\n",
      " [2.94367003]]\n",
      "gradients: [[-4.45560126]\n",
      " [-8.30680473]]\n",
      "theta: [[4.16126295]\n",
      " [2.94770107]]\n",
      "gradients: [[-1.01409309]\n",
      " [-1.71561163]]\n",
      "theta: [[4.15962783]\n",
      " [2.94642949]]\n",
      "gradients: [[0.69623579]\n",
      " [0.54144164]]\n",
      "theta: [[4.16343987]\n",
      " [2.9534501 ]]\n",
      "gradients: [[-1.62393187]\n",
      " [-2.99078321]]\n",
      "theta: [[4.16091014]\n",
      " [2.94916386]]\n",
      "gradients: [[1.07817396]\n",
      " [1.82679653]]\n",
      "theta: [[4.16083409]\n",
      " [2.94911085]]\n",
      "gradients: [[0.03242657]\n",
      " [0.02260288]]\n",
      "theta: [[4.16655659]\n",
      " [2.95577222]]\n",
      "gradients: [[-2.44121772]\n",
      " [-2.84173731]]\n",
      "theta: [[4.16617279]\n",
      " [2.95569698]]\n",
      "gradients: [[0.16380633]\n",
      " [0.03211071]]\n",
      "theta: [[4.15779444]\n",
      " [2.95331602]]\n",
      "gradients: [[3.5775533 ]\n",
      " [1.01666868]]\n",
      "theta: [[4.15388241]\n",
      " [2.94744145]]\n",
      "gradients: [[1.67122108]\n",
      " [2.50961909]]\n",
      "theta: [[4.1636875 ]\n",
      " [2.94902262]]\n",
      "gradients: [[-4.19069819]\n",
      " [-0.67579506]]\n",
      "theta: [[4.17344096]\n",
      " [2.95059547]]\n",
      "gradients: [[-4.17057803]\n",
      " [-0.67255047]]\n",
      "theta: [[4.16643446]\n",
      " [2.94286015]]\n",
      "gradients: [[2.99738157]\n",
      " [3.30917016]]\n",
      "theta: [[4.16581903]\n",
      " [2.94279679]]\n",
      "gradients: [[0.26340306]\n",
      " [0.02711798]]\n",
      "theta: [[4.16397297]\n",
      " [2.94266472]]\n",
      "gradients: [[0.79048257]\n",
      " [0.05655357]]\n",
      "theta: [[4.15564957]\n",
      " [2.94029938]]\n",
      "gradients: [[3.56574666]\n",
      " [1.01331347]]\n",
      "theta: [[4.16141742]\n",
      " [2.94701353]]\n",
      "gradients: [[-2.47210104]\n",
      " [-2.87768751]]\n",
      "theta: [[4.15970119]\n",
      " [2.94655679]]\n",
      "gradients: [[0.73592046]\n",
      " [0.19585272]]\n",
      "theta: [[4.15746067]\n",
      " [2.94314498]]\n",
      "gradients: [[0.96117995]\n",
      " [1.46366678]]\n",
      "theta: [[4.15690158]\n",
      " [2.94283177]]\n",
      "gradients: [[0.23996157]\n",
      " [0.13442571]]\n",
      "theta: [[4.15308708]\n",
      " [2.93710366]]\n",
      "gradients: [[1.63794764]\n",
      " [2.45965343]]\n",
      "theta: [[4.14491484]\n",
      " [2.92914154]]\n",
      "gradients: [[3.51079588]\n",
      " [3.42052469]]\n",
      "theta: [[4.14488609]\n",
      " [2.92910485]]\n",
      "gradients: [[0.01235683]\n",
      " [0.01577264]]\n",
      "theta: [[4.13652348]\n",
      " [2.9169584 ]]\n",
      "gradients: [[3.59591934]\n",
      " [5.22296965]]\n",
      "theta: [[4.13513124]\n",
      " [2.9158757 ]]\n",
      "gradients: [[0.59894155]\n",
      " [0.46577884]]\n",
      "theta: [[4.14287943]\n",
      " [2.92690961]]\n",
      "gradients: [[-3.33482112]\n",
      " [-4.74899251]]\n",
      "theta: [[4.13584835]\n",
      " [2.91907987]]\n",
      "gradients: [[3.02758366]\n",
      " [3.37148356]]\n",
      "theta: [[4.13528152]\n",
      " [2.91829598]]\n",
      "gradients: [[0.24419301]\n",
      " [0.33769854]]\n",
      "theta: [[4.13481773]\n",
      " [2.91785922]]\n",
      "gradients: [[0.19989279]\n",
      " [0.18824342]]\n",
      "theta: [[4.13894293]\n",
      " [2.92545658]]\n",
      "gradients: [[-1.77878735]\n",
      " [-3.27597938]]\n",
      "theta: [[4.13696008]\n",
      " [2.92243713]]\n",
      "gradients: [[0.85540145]\n",
      " [1.30258925]]\n",
      "theta: [[4.1356708 ]\n",
      " [2.92095453]]\n",
      "gradients: [[0.55645221]\n",
      " [0.63989201]]\n",
      "theta: [[4.13519447]\n",
      " [2.92050596]]\n",
      "gradients: [[0.20567858]\n",
      " [0.19369203]]\n",
      "theta: [[4.13690431]\n",
      " [2.92300236]]\n",
      "gradients: [[-0.73864888]\n",
      " [-1.07844295]]\n",
      "theta: [[4.13143279]\n",
      " [2.91713148]]\n",
      "gradients: [[2.36479011]\n",
      " [2.53739326]]\n",
      "theta: [[4.12941475]\n",
      " [2.91663816]]\n",
      "gradients: [[0.87259891]\n",
      " [0.21330896]]\n",
      "theta: [[4.1281957 ]\n",
      " [2.91439749]]\n",
      "gradients: [[0.52736345]\n",
      " [0.9693136 ]]\n",
      "theta: [[4.12950652]\n",
      " [2.91576772]]\n",
      "gradients: [[-0.56732295]\n",
      " [-0.59303202]]\n",
      "theta: [[4.11948809]\n",
      " [2.90009037]]\n",
      "gradients: [[4.33798076]\n",
      " [6.78829112]]\n",
      "theta: [[4.13011395]\n",
      " [2.9199007 ]]\n",
      "gradients: [[-4.60312273]\n",
      " [-8.58183654]]\n",
      "theta: [[4.12846236]\n",
      " [2.91978254]]\n",
      "gradients: [[0.71579629]\n",
      " [0.05121028]]\n",
      "theta: [[4.12657777]\n",
      " [2.91691272]]\n",
      "gradients: [[0.81715969]\n",
      " [1.24435542]]\n",
      "theta: [[4.12550378]\n",
      " [2.91674185]]\n",
      "gradients: [[0.46589911]\n",
      " [0.07412278]]\n",
      "theta: [[4.12569637]\n",
      " [2.9168761 ]]\n",
      "gradients: [[-0.08358555]\n",
      " [-0.05826314]]\n",
      "theta: [[4.12802428]\n",
      " [2.91712557]]\n",
      "gradients: [[-1.01077732]\n",
      " [-0.10831872]]\n",
      "theta: [[4.1339665 ]\n",
      " [2.92404271]]\n",
      "gradients: [[-2.58130329]\n",
      " [-3.00480608]]\n",
      "theta: [[4.13476165]\n",
      " [2.92434996]]\n",
      "gradients: [[-0.34556875]\n",
      " [-0.13353002]]\n",
      "theta: [[4.13555222]\n",
      " [2.92465544]]\n",
      "gradients: [[-0.34374102]\n",
      " [-0.13282377]]\n",
      "theta: [[4.13635764]\n",
      " [2.92576118]]\n",
      "gradients: [[-0.35035675]\n",
      " [-0.48099862]]\n",
      "theta: [[4.13944525]\n",
      " [2.92630549]]\n",
      "gradients: [[-1.34372805]\n",
      " [-0.23688185]]\n",
      "theta: [[4.13830923]\n",
      " [2.92612475]]\n",
      "gradients: [[0.49462276]\n",
      " [0.07869261]]\n",
      "theta: [[4.14588332]\n",
      " [2.93691073]]\n",
      "gradients: [[-3.29927459]\n",
      " [-4.69837203]]\n",
      "theta: [[4.14529554]\n",
      " [2.9363572 ]]\n",
      "gradients: [[0.25615623]\n",
      " [0.24122793]]\n",
      "theta: [[4.14917099]\n",
      " [2.94349459]]\n",
      "gradients: [[-1.68969656]\n",
      " [-3.11190155]]\n",
      "theta: [[4.14106321]\n",
      " [2.94119052]]\n",
      "gradients: [[3.53661435]\n",
      " [1.00503465]]\n",
      "theta: [[4.14486169]\n",
      " [2.94487919]]\n",
      "gradients: [[-1.65766051]\n",
      " [-1.60973553]]\n",
      "theta: [[4.14487462]\n",
      " [2.9448882 ]]\n",
      "gradients: [[-0.00564356]\n",
      " [-0.00393383]]\n",
      "theta: [[4.14247232]\n",
      " [2.94273441]]\n",
      "gradients: [[1.04932506]\n",
      " [0.94077779]]\n",
      "theta: [[4.13546542]\n",
      " [2.9349316 ]]\n",
      "gradients: [[3.06201407]\n",
      " [3.40982489]]\n",
      "theta: [[4.13379879]\n",
      " [2.93481237]]\n",
      "gradients: [[0.72864995]\n",
      " [0.05212987]]\n",
      "theta: [[4.12800057]\n",
      " [2.93289378]]\n",
      "gradients: [[2.53614311]\n",
      " [0.83919164]]\n",
      "theta: [[4.13110369]\n",
      " [2.93344082]]\n",
      "gradients: [[-1.35792742]\n",
      " [-0.23938502]]\n",
      "theta: [[4.1316781 ]\n",
      " [2.93393786]]\n",
      "gradients: [[-0.25147379]\n",
      " [-0.2176055 ]]\n",
      "theta: [[4.13247973]\n",
      " [2.93547967]]\n",
      "gradients: [[-0.35111508]\n",
      " [-0.67531482]]\n",
      "theta: [[4.13233231]\n",
      " [2.93530421]]\n",
      "gradients: [[0.06460006]\n",
      " [0.07689033]]\n",
      "theta: [[4.12765579]\n",
      " [2.92649698]]\n",
      "gradients: [[2.05018599]\n",
      " [3.86108895]]\n",
      "theta: [[4.12757925]\n",
      " [2.92640588]]\n",
      "gradients: [[0.03356884]\n",
      " [0.03995537]]\n",
      "theta: [[4.12630396]\n",
      " [2.92406184]]\n",
      "gradients: [[0.55959929]\n",
      " [1.02856428]]\n",
      "theta: [[4.1289135 ]\n",
      " [2.92847659]]\n",
      "gradients: [[-1.14559067]\n",
      " [-1.93807521]]\n",
      "theta: [[4.13057092]\n",
      " [2.93089645]]\n",
      "gradients: [[-0.72793624]\n",
      " [-1.06280227]]\n",
      "theta: [[4.13491281]\n",
      " [2.93282741]]\n",
      "gradients: [[-1.90782735]\n",
      " [-0.84846421]]\n",
      "theta: [[4.13951462]\n",
      " [2.93817503]]\n",
      "gradients: [[-2.02295544]\n",
      " [-2.35081253]]\n",
      "theta: [[4.13285354]\n",
      " [2.93242706]]\n",
      "gradients: [[2.92954401]\n",
      " [2.52795456]]\n",
      "theta: [[4.12490424]\n",
      " [2.93016803]]\n",
      "gradients: [[3.49768912]\n",
      " [0.99397289]]\n",
      "theta: [[4.13121524]\n",
      " [2.94170964]]\n",
      "gradients: [[-2.77810044]\n",
      " [-5.08061507]]\n",
      "theta: [[4.1246696 ]\n",
      " [2.94018209]]\n",
      "gradients: [[2.88270195]\n",
      " [0.67273443]]\n",
      "theta: [[4.11781366]\n",
      " [2.9325474 ]]\n",
      "gradients: [[3.02072416]\n",
      " [3.3638449 ]]\n",
      "theta: [[4.12205552]\n",
      " [2.93453398]]\n",
      "gradients: [[-1.86981147]\n",
      " [-0.8756879 ]]\n",
      "theta: [[4.126272  ]\n",
      " [2.93650869]]\n",
      "gradients: [[-1.859467  ]\n",
      " [-0.87084327]]\n",
      "theta: [[4.13054814]\n",
      " [2.93725239]]\n",
      "gradients: [[-1.88663185]\n",
      " [-0.3281201 ]]\n",
      "theta: [[4.1367577 ]\n",
      " [2.94860849]]\n",
      "gradients: [[-2.74090081]\n",
      " [-5.01258405]]\n",
      "theta: [[4.14052049]\n",
      " [2.95553838]]\n",
      "gradients: [[-1.66164602]\n",
      " [-3.06024108]]\n",
      "theta: [[4.13629485]\n",
      " [2.95089709]]\n",
      "gradients: [[1.86688568]\n",
      " [2.05052172]]\n",
      "theta: [[4.1342613 ]\n",
      " [2.95039999]]\n",
      "gradients: [[0.8988312 ]\n",
      " [0.21972151]]\n",
      "theta: [[4.13653938]\n",
      " [2.95160536]]\n",
      "gradients: [[-1.00736791]\n",
      " [-0.53301805]]\n",
      "theta: [[4.12830116]\n",
      " [2.93963958]]\n",
      "gradients: [[3.64458864]\n",
      " [5.29366041]]\n",
      "theta: [[4.1218034 ]\n",
      " [2.93812321]]\n",
      "gradients: [[2.87590761]\n",
      " [0.67114884]]\n",
      "theta: [[4.11401159]\n",
      " [2.93053174]]\n",
      "gradients: [[3.45021519]\n",
      " [3.36150168]]\n",
      "theta: [[4.11642444]\n",
      " [2.93180843]]\n",
      "gradients: [[-1.06889269]\n",
      " [-0.56557201]]\n",
      "theta: [[4.11455235]\n",
      " [2.92895765]]\n",
      "gradients: [[0.8297094 ]\n",
      " [1.26346589]]\n",
      "theta: [[4.10474325]\n",
      " [2.91360788]]\n",
      "gradients: [[4.34935295]\n",
      " [6.80608689]]\n",
      "theta: [[4.09758435]\n",
      " [2.90477473]]\n",
      "gradients: [[3.1756908 ]\n",
      " [3.91838442]]\n",
      "theta: [[4.09842794]\n",
      " [2.90490491]]\n",
      "gradients: [[-0.37438744]\n",
      " [-0.05777288]]\n",
      "theta: [[4.10735729]\n",
      " [2.90560535]]\n",
      "gradients: [[-3.96462999]\n",
      " [-0.31099551]]\n",
      "theta: [[4.10766211]\n",
      " [2.90581783]]\n",
      "gradients: [[-0.13540388]\n",
      " [-0.09438301]]\n",
      "theta: [[4.11382025]\n",
      " [2.90886707]]\n",
      "gradients: [[-2.73667604]\n",
      " [-1.35508513]]\n",
      "theta: [[4.11260354]\n",
      " [2.90792087]]\n",
      "gradients: [[0.54095032]\n",
      " [0.4206808 ]]\n",
      "theta: [[4.11337552]\n",
      " [2.90804   ]]\n",
      "gradients: [[-0.34337807]\n",
      " [-0.05298773]]\n",
      "theta: [[4.11186475]\n",
      " [2.90682608]]\n",
      "gradients: [[0.67229507]\n",
      " [0.540193  ]]\n",
      "theta: [[4.11290756]\n",
      " [2.9083559 ]]\n",
      "gradients: [[-0.46426234]\n",
      " [-0.68107581]]\n",
      "theta: [[4.10511302]\n",
      " [2.89703456]]\n",
      "gradients: [[3.47168781]\n",
      " [5.04252692]]\n",
      "theta: [[4.11128554]\n",
      " [2.90009092]]\n",
      "gradients: [[-2.75047242]\n",
      " [-1.36191651]]\n",
      "theta: [[4.11106263]\n",
      " [2.89996605]]\n",
      "gradients: [[0.09937382]\n",
      " [0.0556689 ]]\n",
      "theta: [[4.10398939]\n",
      " [2.8912386 ]]\n",
      "gradients: [[3.15466511]\n",
      " [3.89244148]]\n",
      "theta: [[4.09787685]\n",
      " [2.88449023]]\n",
      "gradients: [[2.72741604]\n",
      " [3.01112273]]\n",
      "theta: [[4.09419355]\n",
      " [2.88234232]]\n",
      "gradients: [[1.64422339]\n",
      " [0.95882729]]\n",
      "theta: [[4.09276368]\n",
      " [2.88224002]]\n",
      "gradients: [[0.63858141]\n",
      " [0.04568609]]\n",
      "theta: [[4.0926586 ]\n",
      " [2.88214107]]\n",
      "gradients: [[0.04694774]\n",
      " [0.04421171]]\n",
      "theta: [[4.09296703]\n",
      " [2.88222851]]\n",
      "gradients: [[-0.13786672]\n",
      " [-0.03908604]]\n",
      "theta: [[4.0919433 ]\n",
      " [2.88143239]]\n",
      "gradients: [[0.45781186]\n",
      " [0.35602652]]\n",
      "theta: [[4.0922075 ]\n",
      " [2.88167474]]\n",
      "gradients: [[-0.11820354]\n",
      " [-0.10842711]]\n",
      "theta: [[4.09211683]\n",
      " [2.88162394]]\n",
      "gradients: [[0.04058436]\n",
      " [0.02273523]]\n",
      "theta: [[4.09454088]\n",
      " [2.88188372]]\n",
      "gradients: [[-1.08549191]\n",
      " [-0.11632541]]\n",
      "theta: [[4.09506542]\n",
      " [2.88226579]]\n",
      "gradients: [[-0.23499259]\n",
      " [-0.17116767]]\n",
      "theta: [[4.0888569 ]\n",
      " [2.88081691]]\n",
      "gradients: [[2.78265756]\n",
      " [0.64938713]]\n",
      "theta: [[4.0915605 ]\n",
      " [2.88083737]]\n",
      "gradients: [[-1.21229321]\n",
      " [-0.00917713]]\n",
      "theta: [[4.08734036]\n",
      " [2.87745071]]\n",
      "gradients: [[1.89315665]\n",
      " [1.51925761]]\n",
      "theta: [[4.08880444]\n",
      " [2.88026664]]\n",
      "gradients: [[-0.65707892]\n",
      " [-1.26378832]]\n",
      "theta: [[4.09555905]\n",
      " [2.89261953]]\n",
      "gradients: [[-3.03282031]\n",
      " [-5.54644905]]\n",
      "theta: [[4.09556561]\n",
      " [2.89262082]]\n",
      "gradients: [[-0.0029482 ]\n",
      " [-0.00057793]]\n",
      "theta: [[4.10029508]\n",
      " [2.89930602]]\n",
      "gradients: [[-2.12542357]\n",
      " [-3.00432929]]\n",
      "theta: [[4.09814374]\n",
      " [2.89830854]]\n",
      "gradients: [[0.96724262]\n",
      " [0.44846648]]\n",
      "theta: [[4.09850835]\n",
      " [2.89856269]]\n",
      "gradients: [[-0.16400343]\n",
      " [-0.11431826]]\n",
      "theta: [[4.09883112]\n",
      " [2.89906852]]\n",
      "gradients: [[-0.14524322]\n",
      " [-0.22762394]]\n",
      "theta: [[4.10496399]\n",
      " [2.90210526]]\n",
      "gradients: [[-2.76102197]\n",
      " [-1.3671402 ]]\n",
      "theta: [[4.10523315]\n",
      " [2.90252708]]\n",
      "gradients: [[-0.12122816]\n",
      " [-0.18998774]]\n",
      "theta: [[4.10963558]\n",
      " [2.90448497]]\n",
      "gradients: [[-1.98373619]\n",
      " [-0.88222299]]\n",
      "theta: [[4.11882366]\n",
      " [2.91675784]]\n",
      "gradients: [[-4.14198246]\n",
      " [-5.53261112]]\n",
      "theta: [[4.12313385]\n",
      " [2.91867471]]\n",
      "gradients: [[-1.94389755]\n",
      " [-0.86450563]]\n",
      "theta: [[4.1248611 ]\n",
      " [2.91888496]]\n",
      "gradients: [[-0.77933745]\n",
      " [-0.0948655 ]]\n",
      "theta: [[4.13058448]\n",
      " [2.92554735]]\n",
      "gradients: [[-2.58353354]\n",
      " [-3.00740224]]\n",
      "theta: [[4.1335857 ]\n",
      " [2.92607642]]\n",
      "gradients: [[-1.35534975]\n",
      " [-0.23893061]]\n",
      "theta: [[4.13153678]\n",
      " [2.92260484]]\n",
      "gradients: [[0.9257048 ]\n",
      " [1.56846147]]\n",
      "theta: [[4.12933294]\n",
      " [2.92178738]]\n",
      "gradients: [[0.99613341]\n",
      " [0.36949349]]\n",
      "theta: [[4.13015264]\n",
      " [2.92291273]]\n",
      "gradients: [[-0.37067033]\n",
      " [-0.50888678]]\n",
      "theta: [[4.12678256]\n",
      " [2.91785199]]\n",
      "gradients: [[1.52462619]\n",
      " [2.28948225]]\n",
      "theta: [[4.1327183 ]\n",
      " [2.92079111]]\n",
      "gradients: [[-2.68651755]\n",
      " [-1.33024879]]\n",
      "theta: [[4.13352801]\n",
      " [2.92190274]]\n",
      "gradients: [[-0.36663511]\n",
      " [-0.50334689]]\n",
      "theta: [[4.13730327]\n",
      " [2.92556885]]\n",
      "gradients: [[-1.71019118]\n",
      " [-1.66074748]]\n",
      "theta: [[4.13806308]\n",
      " [2.92661198]]\n",
      "gradients: [[-0.34434663]\n",
      " [-0.47274743]]\n",
      "theta: [[4.14217973]\n",
      " [2.92732795]]\n",
      "gradients: [[-1.86649213]\n",
      " [-0.32461743]]\n",
      "theta: [[4.14599187]\n",
      " [2.93434874]]\n",
      "gradients: [[-1.72918638]\n",
      " [-3.18462965]]\n",
      "theta: [[4.15006403]\n",
      " [2.93505696]]\n",
      "gradients: [[-1.84794341]\n",
      " [-0.32139147]]\n",
      "theta: [[4.15153191]\n",
      " [2.9372001 ]]\n",
      "gradients: [[-0.66642024]\n",
      " [-0.97298762]]\n",
      "theta: [[4.15218319]\n",
      " [2.93815553]]\n",
      "gradients: [[-0.29581025]\n",
      " [-0.43395551]]\n",
      "theta: [[4.1597361 ]\n",
      " [2.94565972]]\n",
      "gradients: [[-3.43204346]\n",
      " [-3.40990344]]\n",
      "theta: [[4.16379932]\n",
      " [2.95140316]]\n",
      "gradients: [[-1.84713945]\n",
      " [-2.61096906]]\n",
      "theta: [[4.17330497]\n",
      " [2.96912503]]\n",
      "gradients: [[-4.32317014]\n",
      " [-8.05990665]]\n",
      "theta: [[4.1735962 ]\n",
      " [2.96968516]]\n",
      "gradients: [[-0.13250729]\n",
      " [-0.25485701]]\n",
      "theta: [[4.17181516]\n",
      " [2.96641153]]\n",
      "gradients: [[0.81073103]\n",
      " [1.49015374]]\n",
      "theta: [[4.17223533]\n",
      " [2.96710143]]\n",
      "gradients: [[-0.19134531]\n",
      " [-0.31417667]]\n",
      "theta: [[4.17310336]\n",
      " [2.96801743]]\n",
      "gradients: [[-0.3954756 ]\n",
      " [-0.41733263]]\n",
      "theta: [[4.17643259]\n",
      " [2.97414886]]\n",
      "gradients: [[-1.51746409]\n",
      " [-2.79470229]]\n",
      "theta: [[4.18476101]\n",
      " [2.97480216]]\n",
      "gradients: [[-3.79775735]\n",
      " [-0.2979056 ]]\n",
      "theta: [[4.18423771]\n",
      " [2.97432214]]\n",
      "gradients: [[0.23872649]\n",
      " [0.21898181]]\n",
      "theta: [[4.18647285]\n",
      " [2.97433906]]\n",
      "gradients: [[-1.02011591]\n",
      " [-0.00772234]]\n",
      "theta: [[4.18691456]\n",
      " [2.97450975]]\n",
      "gradients: [[-0.20168638]\n",
      " [-0.07793293]]\n",
      "theta: [[4.186163  ]\n",
      " [2.97302963]]\n",
      "gradients: [[0.34331109]\n",
      " [0.67611485]]\n",
      "theta: [[4.18647136]\n",
      " [2.97353593]]\n",
      "gradients: [[-0.14091662]\n",
      " [-0.23137602]]\n",
      "theta: [[4.17985214]\n",
      " [2.96790925]]\n",
      "gradients: [[3.02630635]\n",
      " [2.57251598]]\n",
      "theta: [[4.1842738]\n",
      " [2.9728328]]\n",
      "gradients: [[-2.02246977]\n",
      " [-2.25203064]]\n",
      "theta: [[4.18226722]\n",
      " [2.97122049]]\n",
      "gradients: [[0.91821441]\n",
      " [0.73779062]]\n",
      "theta: [[4.18057472]\n",
      " [2.96990429]]\n",
      "gradients: [[0.77482501]\n",
      " [0.60255812]]\n",
      "theta: [[4.1799257 ]\n",
      " [2.96983747]]\n",
      "gradients: [[0.2972521 ]\n",
      " [0.03060282]]\n",
      "theta: [[4.17978622]\n",
      " [2.96973588]]\n",
      "gradients: [[0.06390737]\n",
      " [0.04654987]]\n",
      "theta: [[4.17799244]\n",
      " [2.96960755]]\n",
      "gradients: [[0.82227156]\n",
      " [0.05882785]]\n",
      "theta: [[4.17147417]\n",
      " [2.96808638]]\n",
      "gradients: [[2.98927738]\n",
      " [0.69760587]]\n",
      "theta: [[4.17375346]\n",
      " [2.96810364]]\n",
      "gradients: [[-1.0457374 ]\n",
      " [-0.00791629]]\n",
      "theta: [[4.17520458]\n",
      " [2.96828028]]\n",
      "gradients: [[-0.66606468]\n",
      " [-0.08107728]]\n",
      "theta: [[4.17351727]\n",
      " [2.96783123]]\n",
      "gradients: [[0.77481435]\n",
      " [0.20620367]]\n",
      "theta: [[4.17095472]\n",
      " [2.96664309]]\n",
      "gradients: [[1.17723105]\n",
      " [0.54582857]]\n",
      "theta: [[4.17758419]\n",
      " [2.97746106]]\n",
      "gradients: [[-3.04690266]\n",
      " [-4.97194014]]\n",
      "theta: [[4.16967112]\n",
      " [2.96975146]]\n",
      "gradients: [[3.63842955]\n",
      " [3.54487658]]\n",
      "theta: [[4.16119476]\n",
      " [2.9668509 ]]\n",
      "gradients: [[3.89912458]\n",
      " [1.33425633]]\n",
      "theta: [[4.15510382]\n",
      " [2.96039394]]\n",
      "gradients: [[2.80305299]\n",
      " [2.97149413]]\n",
      "theta: [[4.15096238]\n",
      " [2.95584513]]\n",
      "gradients: [[1.90671869]\n",
      " [2.09427291]]\n",
      "theta: [[4.15627129]\n",
      " [2.96202504]]\n",
      "gradients: [[-2.44528287]\n",
      " [-2.84646941]]\n",
      "theta: [[4.15380307]\n",
      " [2.96088064]]\n",
      "gradients: [[1.13735497]\n",
      " [0.52733984]]\n",
      "theta: [[4.14730132]\n",
      " [2.95527017]]\n",
      "gradients: [[2.99730705]\n",
      " [2.58642846]]\n",
      "theta: [[4.148867  ]\n",
      " [2.95546075]]\n",
      "gradients: [[-0.72209329]\n",
      " [-0.0878974 ]]\n",
      "theta: [[4.15123185]\n",
      " [2.95547866]]\n",
      "gradients: [[-1.09114289]\n",
      " [-0.00826002]]\n",
      "theta: [[4.15093159]\n",
      " [2.95500809]]\n",
      "gradients: [[0.13860021]\n",
      " [0.21721306]]\n",
      "theta: [[4.14948385]\n",
      " [2.95441213]]\n",
      "gradients: [[0.66856827]\n",
      " [0.27521319]]\n",
      "theta: [[4.14793408]\n",
      " [2.95399969]]\n",
      "gradients: [[0.71599135]\n",
      " [0.19054893]]\n",
      "theta: [[4.15009989]\n",
      " [2.95766373]]\n",
      "gradients: [[-1.00103455]\n",
      " [-1.6935196 ]]\n",
      "theta: [[4.14553992]\n",
      " [2.95227575]]\n",
      "gradients: [[2.10853082]\n",
      " [2.49140282]]\n",
      "theta: [[4.14149807]\n",
      " [2.94783633]]\n",
      "gradients: [[1.86975741]\n",
      " [2.05367594]]\n",
      "theta: [[4.14211318]\n",
      " [2.94873869]]\n",
      "gradients: [[-0.28467111]\n",
      " [-0.41761433]]\n",
      "theta: [[4.13547243]\n",
      " [2.94134362]]\n",
      "gradients: [[3.07466841]\n",
      " [3.42391661]]\n",
      "theta: [[4.13561601]\n",
      " [2.94144821]]\n",
      "gradients: [[-0.06650879]\n",
      " [-0.04844474]]\n",
      "theta: [[4.13964326]\n",
      " [2.94214862]]\n",
      "gradients: [[-1.86622568]\n",
      " [-0.32457109]]\n",
      "theta: [[4.14124076]\n",
      " [2.94234308]]\n",
      "gradients: [[-0.74060387]\n",
      " [-0.09015062]]\n",
      "theta: [[4.13929048]\n",
      " [2.94186633]]\n",
      "gradients: [[0.90454093]\n",
      " [0.22111727]]\n",
      "theta: [[4.14039959]\n",
      " [2.94303673]]\n",
      "gradients: [[-0.51462486]\n",
      " [-0.54306699]]\n",
      "theta: [[4.14504579]\n",
      " [2.9482103 ]]\n",
      "gradients: [[-2.15676623]\n",
      " [-2.40157045]]\n",
      "theta: [[4.1398021 ]\n",
      " [2.94258388]]\n",
      "gradients: [[2.43516875]\n",
      " [2.61290875]]\n",
      "theta: [[4.14045529]\n",
      " [2.94354212]]\n",
      "gradients: [[-0.3034738]\n",
      " [-0.445198 ]]\n",
      "theta: [[4.14261157]\n",
      " [2.94468305]]\n",
      "gradients: [[-1.00223718]\n",
      " [-0.53030327]]\n",
      "theta: [[4.14036548]\n",
      " [2.94266931]]\n",
      "gradients: [[1.04443109]\n",
      " [0.93639008]]\n",
      "theta: [[4.13081283]\n",
      " [2.92772084]]\n",
      "gradients: [[4.44389262]\n",
      " [6.95402733]]\n",
      "theta: [[4.13201918]\n",
      " [2.92899386]]\n",
      "gradients: [[-0.56143472]\n",
      " [-0.59246392]]\n",
      "theta: [[4.13324949]\n",
      " [2.93041344]]\n",
      "gradients: [[-0.57283149]\n",
      " [-0.66095484]]\n",
      "theta: [[4.1273203 ]\n",
      " [2.92077283]]\n",
      "gradients: [[2.76181693]\n",
      " [4.4905928 ]]\n",
      "theta: [[4.13284437]\n",
      " [2.92720322]]\n",
      "gradients: [[-2.57421993]\n",
      " [-2.99656059]]\n",
      "theta: [[4.14033576]\n",
      " [2.93464628]]\n",
      "gradients: [[-3.49248441]\n",
      " [-3.46995449]]\n",
      "theta: [[4.14250534]\n",
      " [2.93579425]]\n",
      "gradients: [[-1.01189017]\n",
      " [-0.53541086]]\n",
      "theta: [[4.14365443]\n",
      " [2.93712011]]\n",
      "gradients: [[-0.53616609]\n",
      " [-0.6186489 ]]\n",
      "theta: [[4.15288515]\n",
      " [2.95373979]]\n",
      "gradients: [[-4.30889937]\n",
      " [-7.75806426]]\n",
      "theta: [[4.14653994]\n",
      " [2.94673455]]\n",
      "gradients: [[2.96321271]\n",
      " [3.27144705]]\n",
      "theta: [[4.14753101]\n",
      " [2.94777053]]\n",
      "gradients: [[-0.46302956]\n",
      " [-0.48401243]]\n",
      "theta: [[4.14144024]\n",
      " [2.93786722]]\n",
      "gradients: [[2.84682372]\n",
      " [4.6288101 ]]\n",
      "theta: [[4.14571353]\n",
      " [2.94283306]]\n",
      "gradients: [[-1.99818738]\n",
      " [-2.32203034]]\n",
      "theta: [[4.1453918 ]\n",
      " [2.94259103]]\n",
      "gradients: [[0.15050389]\n",
      " [0.11322248]]\n",
      "theta: [[4.14751439]\n",
      " [2.94371413]]\n",
      "gradients: [[-0.99337064]\n",
      " [-0.52561181]]\n",
      "theta: [[4.14816213]\n",
      " [2.94396442]]\n",
      "gradients: [[-0.30327064]\n",
      " [-0.11718576]]\n",
      "theta: [[4.14190213]\n",
      " [2.93705326]]\n",
      "gradients: [[2.93218227]\n",
      " [3.23718881]]\n",
      "theta: [[4.14652673]\n",
      " [2.94220277]]\n",
      "gradients: [[-2.1670864 ]\n",
      " [-2.41306201]]\n",
      "theta: [[4.14633991]\n",
      " [2.94191   ]]\n",
      "gradients: [[0.08757826]\n",
      " [0.1372519 ]]\n",
      "theta: [[4.15164262]\n",
      " [2.9480827 ]]\n",
      "gradients: [[-2.4869706 ]\n",
      " [-2.89499666]]\n",
      "theta: [[4.15545252]\n",
      " [2.94986699]]\n",
      "gradients: [[-1.78760227]\n",
      " [-0.8371869 ]]\n",
      "theta: [[4.15605465]\n",
      " [2.95009965]]\n",
      "gradients: [[-0.28263938]\n",
      " [-0.1092137 ]]\n",
      "theta: [[4.15577486]\n",
      " [2.94966118]]\n",
      "gradients: [[0.13138594]\n",
      " [0.20590693]]\n",
      "theta: [[4.15547719]\n",
      " [2.94960283]]\n",
      "gradients: [[0.13984701]\n",
      " [0.027414  ]]\n",
      "theta: [[4.14955449]\n",
      " [2.9384376 ]]\n",
      "gradients: [[2.78366689]\n",
      " [5.24765914]]\n",
      "theta: [[4.14945801]\n",
      " [2.93831444]]\n",
      "gradients: [[0.0453677 ]\n",
      " [0.05790877]]\n",
      "theta: [[4.15313638]\n",
      " [2.93919597]]\n",
      "gradients: [[-1.7303068 ]\n",
      " [-0.41467332]]\n",
      "theta: [[4.14918966]\n",
      " [2.93135006]]\n",
      "gradients: [[1.85732602]\n",
      " [3.69228574]]\n",
      "theta: [[4.15130876]\n",
      " [2.93247132]]\n",
      "gradients: [[-0.99767055]\n",
      " [-0.52788698]]\n",
      "theta: [[4.1431625 ]\n",
      " [2.92968372]]\n",
      "gradients: [[3.83688578]\n",
      " [1.3129586 ]]\n",
      "theta: [[4.14702879]\n",
      " [2.93149442]]\n",
      "gradients: [[-1.82179608]\n",
      " [-0.85320087]]\n",
      "theta: [[4.1415973 ]\n",
      " [2.92969717]]\n",
      "gradients: [[2.56040734]\n",
      " [0.8472205 ]]\n",
      "theta: [[4.14151561]\n",
      " [2.92956916]]\n",
      "gradients: [[0.03852206]\n",
      " [0.06037144]]\n",
      "theta: [[4.14579141]\n",
      " [2.93453793]]\n",
      "gradients: [[-2.01732246]\n",
      " [-2.34426661]]\n",
      "theta: [[4.14360181]\n",
      " [2.93372575]]\n",
      "gradients: [[1.03349532]\n",
      " [0.38335206]]\n",
      "theta: [[4.15052057]\n",
      " [2.9435785 ]]\n",
      "gradients: [[-3.26704085]\n",
      " [-4.65246919]]\n",
      "theta: [[4.15618911]\n",
      " [2.95394517]]\n",
      "gradients: [[-2.67781744]\n",
      " [-4.89721662]]\n",
      "theta: [[4.15655123]\n",
      " [2.95404642]]\n",
      "gradients: [[-0.17113989]\n",
      " [-0.04785269]]\n",
      "theta: [[4.15503018]\n",
      " [2.95125068]]\n",
      "gradients: [[0.71915195]\n",
      " [1.32182799]]\n",
      "theta: [[4.15104184]\n",
      " [2.94687002]]\n",
      "gradients: [[1.88648615]\n",
      " [2.07205019]]\n",
      "theta: [[4.15158787]\n",
      " [2.94761966]]\n",
      "gradients: [[-0.25838148]\n",
      " [-0.35472738]]\n",
      "theta: [[4.15359971]\n",
      " [2.94783526]]\n",
      "gradients: [[-0.95240512]\n",
      " [-0.10206333]]\n",
      "theta: [[4.14774404]\n",
      " [2.93679637]]\n",
      "gradients: [[2.77324762]\n",
      " [5.22801713]]\n",
      "theta: [[4.14665801]\n",
      " [2.93662359]]\n",
      "gradients: [[0.51455846]\n",
      " [0.0818643 ]]\n",
      "theta: [[4.15027659]\n",
      " [2.93729482]]\n",
      "gradients: [[-1.71520564]\n",
      " [-0.31816382]]\n",
      "theta: [[4.15392306]\n",
      " [2.93816871]]\n",
      "gradients: [[-1.72915835]\n",
      " [-0.41439809]]\n",
      "theta: [[4.14624953]\n",
      " [2.92702312]]\n",
      "gradients: [[3.64032329]\n",
      " [5.28746512]]\n",
      "theta: [[4.14609351]\n",
      " [2.92688   ]]\n",
      "gradients: [[0.07404893]\n",
      " [0.06792446]]\n",
      "theta: [[4.14585856]\n",
      " [2.92683395]]\n",
      "gradients: [[0.11155278]\n",
      " [0.02186752]]\n",
      "theta: [[4.14385263]\n",
      " [2.92343521]]\n",
      "gradients: [[0.95281753]\n",
      " [1.61439974]]\n",
      "theta: [[4.15272995]\n",
      " [2.92486677]]\n",
      "gradients: [[-4.21850027]\n",
      " [-0.68027844]]\n",
      "theta: [[4.1497049 ]\n",
      " [2.92348639]]\n",
      "gradients: [[1.43810635]\n",
      " [0.65623569]]\n",
      "theta: [[4.1503888]\n",
      " [2.9244253]]\n",
      "gradients: [[-0.32526133]\n",
      " [-0.44654555]]\n",
      "theta: [[4.15080756]\n",
      " [2.92454239]]\n",
      "gradients: [[-0.19924871]\n",
      " [-0.05571223]]\n",
      "theta: [[4.14577416]\n",
      " [2.9191416 ]]\n",
      "gradients: [[2.39590149]\n",
      " [2.57077542]]\n",
      "theta: [[4.14634865]\n",
      " [2.91923025]]\n",
      "gradients: [[-0.27357383]\n",
      " [-0.04221602]]\n",
      "theta: [[4.14436655]\n",
      " [2.91895378]]\n",
      "gradients: [[0.94427498]\n",
      " [0.13171197]]\n",
      "theta: [[4.1441318 ]\n",
      " [2.91877718]]\n",
      "gradients: [[0.11188165]\n",
      " [0.08416738]]\n",
      "theta: [[4.14416147]\n",
      " [2.91878559]]\n",
      "gradients: [[-0.01414722]\n",
      " [-0.00401082]]\n",
      "theta: [[4.1429775 ]\n",
      " [2.91660942]]\n",
      "gradients: [[0.56475097]\n",
      " [1.03803325]]\n",
      "theta: [[4.13668069]\n",
      " [2.90959736]]\n",
      "gradients: [[3.00483945]\n",
      " [3.34615586]]\n",
      "theta: [[4.14060858]\n",
      " [2.91028049]]\n",
      "gradients: [[-1.87517522]\n",
      " [-0.32612759]]\n",
      "theta: [[4.14107409]\n",
      " [2.91104613]]\n",
      "gradients: [[-0.22232861]\n",
      " [-0.36566887]]\n",
      "theta: [[4.13693784]\n",
      " [2.90325638]]\n",
      "gradients: [[1.9762997 ]\n",
      " [3.72193986]]\n",
      "theta: [[4.1464701 ]\n",
      " [2.92102785]]\n",
      "gradients: [[-4.5564181]\n",
      " [-8.4947627]]\n",
      "theta: [[4.1403767 ]\n",
      " [2.91576976]]\n",
      "gradients: [[2.91386178]\n",
      " [2.51442209]]\n",
      "theta: [[4.14955801]\n",
      " [2.93230046]]\n",
      "gradients: [[-4.39233637]\n",
      " [-7.90829046]]\n",
      "theta: [[4.15230565]\n",
      " [2.93278484]]\n",
      "gradients: [[-1.31502173]\n",
      " [-0.2318213 ]]\n",
      "theta: [[4.14627246]\n",
      " [2.92765631]]\n",
      "gradients: [[2.8886939 ]\n",
      " [2.45553832]]\n",
      "theta: [[4.14437804]\n",
      " [2.92719322]]\n",
      "gradients: [[0.90742388]\n",
      " [0.22182201]]\n",
      "theta: [[4.14591138]\n",
      " [2.92737987]]\n",
      "gradients: [[-0.73477522]\n",
      " [-0.08944112]]\n",
      "theta: [[4.14954643]\n",
      " [2.92825102]]\n",
      "gradients: [[-1.74264107]\n",
      " [-0.41762926]]\n",
      "theta: [[4.14820666]\n",
      " [2.92720912]]\n",
      "gradients: [[0.64255128]\n",
      " [0.49969282]]\n",
      "theta: [[4.14094998]\n",
      " [2.92013903]]\n",
      "gradients: [[3.4817548 ]\n",
      " [3.39223032]]\n",
      "theta: [[4.13908935]\n",
      " [2.91968419]]\n",
      "gradients: [[0.89310369]\n",
      " [0.21832141]]\n",
      "theta: [[4.14636743]\n",
      " [2.92691532]]\n",
      "gradients: [[-3.49493551]\n",
      " [-3.47238978]]\n",
      "theta: [[4.14005067]\n",
      " [2.91988105]]\n",
      "gradients: [[3.03457239]\n",
      " [3.37926613]]\n",
      "theta: [[4.13967806]\n",
      " [2.91967231]]\n",
      "gradients: [[0.17907681]\n",
      " [0.10031826]]\n",
      "theta: [[4.14203599]\n",
      " [2.92366139]]\n",
      "gradients: [[-1.13369461]\n",
      " [-1.91794982]]\n",
      "theta: [[4.14583992]\n",
      " [2.92544289]]\n",
      "gradients: [[-1.82968997]\n",
      " [-0.85689781]]\n",
      "theta: [[4.14730073]\n",
      " [2.9275757 ]]\n",
      "gradients: [[-0.70294195]\n",
      " [-1.02631009]]\n",
      "theta: [[4.14574014]\n",
      " [2.92746405]]\n",
      "gradients: [[0.75126804]\n",
      " [0.05374804]]\n",
      "theta: [[4.14043457]\n",
      " [2.92570847]]\n",
      "gradients: [[2.5551628 ]\n",
      " [0.84548512]]\n",
      "theta: [[4.13987065]\n",
      " [2.92492861]]\n",
      "gradients: [[0.27169906]\n",
      " [0.37573711]]\n",
      "theta: [[4.13975146]\n",
      " [2.92481928]]\n",
      "gradients: [[0.0574486 ]\n",
      " [0.05269712]]\n",
      "theta: [[4.13992156]\n",
      " [2.92494318]]\n",
      "gradients: [[-0.08202325]\n",
      " [-0.05974541]]\n",
      "theta: [[4.14222151]\n",
      " [2.9249606 ]]\n",
      "gradients: [[-1.10949581]\n",
      " [-0.00839895]]\n",
      "theta: [[4.14334966]\n",
      " [2.92615109]]\n",
      "gradients: [[-0.54444295]\n",
      " [-0.57453306]]\n",
      "theta: [[4.14337354]\n",
      " [2.92615786]]\n",
      "gradients: [[-0.0115304 ]\n",
      " [-0.00326894]]\n",
      "theta: [[4.14312357]\n",
      " [2.92596981]]\n",
      "gradients: [[0.12073475]\n",
      " [0.09082747]]\n",
      "theta: [[4.14254865]\n",
      " [2.92517475]]\n",
      "gradients: [[0.27779988]\n",
      " [0.38417403]]\n",
      "theta: [[4.14407725]\n",
      " [2.92536082]]\n",
      "gradients: [[-0.7389254 ]\n",
      " [-0.08994631]]\n",
      "theta: [[4.1463543 ]\n",
      " [2.92537806]]\n",
      "gradients: [[-1.1011781 ]\n",
      " [-0.00833598]]\n",
      "theta: [[4.15024262]\n",
      " [2.9271073 ]]\n",
      "gradients: [[-1.88116896]\n",
      " [-0.83660847]]\n",
      "theta: [[4.14468811]\n",
      " [2.91663616]]\n",
      "gradients: [[2.68838239]\n",
      " [5.06803254]]\n",
      "theta: [[4.14176677]\n",
      " [2.9153031 ]]\n",
      "gradients: [[1.4145111 ]\n",
      " [0.64546872]]\n",
      "theta: [[4.14754453]\n",
      " [2.92586951]]\n",
      "gradients: [[-2.79874565]\n",
      " [-5.11837121]]\n",
      "theta: [[4.14325769]\n",
      " [2.92242933]]\n",
      "gradients: [[2.07740126]\n",
      " [1.66711385]]\n",
      "theta: [[4.14685727]\n",
      " [2.92905864]]\n",
      "gradients: [[-1.74507397]\n",
      " [-3.21388971]]\n",
      "theta: [[4.14530965]\n",
      " [2.92894792]]\n",
      "gradients: [[0.7505933 ]\n",
      " [0.05369976]]\n",
      "theta: [[4.14599487]\n",
      " [2.92995313]]\n",
      "gradients: [[-0.33246679]\n",
      " [-0.4877309 ]]\n",
      "theta: [[4.14600328]\n",
      " [2.92995552]]\n",
      "gradients: [[-0.00408418]\n",
      " [-0.00115789]]\n",
      "theta: [[4.15492009]\n",
      " [2.94601   ]]\n",
      "gradients: [[-4.330001  ]\n",
      " [-7.79605721]]\n",
      "theta: [[4.15604788]\n",
      " [2.94605825]]\n",
      "gradients: [[-0.54788042]\n",
      " [-0.02343876]]\n",
      "theta: [[4.15980047]\n",
      " [2.94671089]]\n",
      "gradients: [[-1.8237584 ]\n",
      " [-0.31718525]]\n",
      "theta: [[4.16679308]\n",
      " [2.9536584 ]]\n",
      "gradients: [[-3.39980856]\n",
      " [-3.37787649]]\n",
      "theta: [[4.17026405]\n",
      " [2.95449023]]\n",
      "gradients: [[-1.68828221]\n",
      " [-0.404602  ]]\n",
      "theta: [[4.1628965 ]\n",
      " [2.95239652]]\n",
      "gradients: [[3.58504997]\n",
      " [1.01879908]]\n",
      "theta: [[4.16322229]\n",
      " [2.95248761]]\n",
      "gradients: [[-0.15859114]\n",
      " [-0.04434391]]\n",
      "theta: [[4.16281151]\n",
      " [2.95217859]]\n",
      "gradients: [[0.20004743]\n",
      " [0.15049356]]\n",
      "theta: [[4.15677153]\n",
      " [2.9470443 ]]\n",
      "gradients: [[2.94267699]\n",
      " [2.50142672]]\n",
      "theta: [[4.15484724]\n",
      " [2.9465739 ]]\n",
      "gradients: [[0.93790092]\n",
      " [0.2292722 ]]\n",
      "theta: [[4.1553632 ]\n",
      " [2.94728226]]\n",
      "gradients: [[-0.25158377]\n",
      " [-0.34539492]]\n",
      "theta: [[4.15573016]\n",
      " [2.94759979]]\n",
      "gradients: [[-0.1790002]\n",
      " [-0.1548926]]\n",
      "theta: [[4.16076078]\n",
      " [2.95345576]]\n",
      "gradients: [[-2.45494354]\n",
      " [-2.85771506]]\n",
      "theta: [[4.15904007]\n",
      " [2.95207317]]\n",
      "gradients: [[0.84004925]\n",
      " [0.67498445]]\n",
      "theta: [[4.15303075]\n",
      " [2.94696493]]\n",
      "gradients: [[2.93495488]\n",
      " [2.49486253]]\n",
      "theta: [[4.15155895]\n",
      " [2.94657324]]\n",
      "gradients: [[0.71912125]\n",
      " [0.1913819 ]]\n",
      "theta: [[4.15943912]\n",
      " [2.94719138]]\n",
      "gradients: [[-3.85183084]\n",
      " [-0.30214726]]\n",
      "theta: [[4.15978354]\n",
      " [2.94728768]]\n",
      "gradients: [[-0.16841674]\n",
      " [-0.04709126]]\n",
      "theta: [[4.16012629]\n",
      " [2.94738351]]\n",
      "gradients: [[-0.16767406]\n",
      " [-0.0468836 ]]\n",
      "theta: [[4.1637456 ]\n",
      " [2.94907854]]\n",
      "gradients: [[-1.77128984]\n",
      " [-0.82954731]]\n",
      "theta: [[4.16334362]\n",
      " [2.9482869 ]]\n",
      "gradients: [[0.19680503]\n",
      " [0.38758669]]\n",
      "theta: [[4.15943614]\n",
      " [2.94051899]]\n",
      "gradients: [[1.91388529]\n",
      " [3.80472317]]\n",
      "theta: [[4.16377145]\n",
      " [2.94534638]]\n",
      "gradients: [[-2.12430015]\n",
      " [-2.3654193 ]]\n",
      "theta: [[4.16436973]\n",
      " [2.94534996]]\n",
      "gradients: [[-0.29327749]\n",
      " [-0.00175466]]\n",
      "theta: [[4.15944734]\n",
      " [2.93793056]]\n",
      "gradients: [[2.41393742]\n",
      " [3.63847489]]\n",
      "theta: [[4.16136084]\n",
      " [2.93813561]]\n",
      "gradients: [[-0.93876282]\n",
      " [-0.10060137]]\n",
      "theta: [[4.16498245]\n",
      " [2.93983172]]\n",
      "gradients: [[-1.77748286]\n",
      " [-0.83244768]]\n",
      "theta: [[4.15751346]\n",
      " [2.92898323]]\n",
      "gradients: [[3.66727301]\n",
      " [5.32660882]]\n",
      "theta: [[4.1573115 ]\n",
      " [2.92874284]]\n",
      "gradients: [[0.09920271]\n",
      " [0.11807619]]\n",
      "theta: [[4.15781524]\n",
      " [2.92882058]]\n",
      "gradients: [[-0.24753595]\n",
      " [-0.03819803]]\n",
      "theta: [[4.15486185]\n",
      " [2.92747289]]\n",
      "gradients: [[1.45188533]\n",
      " [0.66252331]]\n",
      "theta: [[4.15631313]\n",
      " [2.92764955]]\n",
      "gradients: [[-0.71373952]\n",
      " [-0.08688054]]\n",
      "theta: [[4.15695189]\n",
      " [2.92858661]]\n",
      "gradients: [[-0.31426927]\n",
      " [-0.46103502]]\n",
      "theta: [[4.16202455]\n",
      " [2.93449152]]\n",
      "gradients: [[-2.49676525]\n",
      " [-2.90639827]]\n",
      "theta: [[4.16237051]\n",
      " [2.93458826]]\n",
      "gradients: [[-0.17034794]\n",
      " [-0.04763124]]\n",
      "theta: [[4.16207183]\n",
      " [2.93452971]]\n",
      "gradients: [[0.14712885]\n",
      " [0.02884144]]\n",
      "theta: [[4.16150145]\n",
      " [2.93430496]]\n",
      "gradients: [[0.28108054]\n",
      " [0.11075395]]\n",
      "theta: [[4.15553833]\n",
      " [2.93291335]]\n",
      "gradients: [[2.93981832]\n",
      " [0.68606365]]\n",
      "theta: [[4.15365568]\n",
      " [2.93245313]]\n",
      "gradients: [[0.92852583]\n",
      " [0.22698044]]\n",
      "theta: [[4.16238227]\n",
      " [2.94816515]]\n",
      "gradients: [[-4.30570243]\n",
      " [-7.75230824]]\n",
      "theta: [[4.16453832]\n",
      " [2.94818147]]\n",
      "gradients: [[-1.06422281]\n",
      " [-0.00805623]]\n",
      "theta: [[4.16317983]\n",
      " [2.94661928]]\n",
      "gradients: [[0.67081807]\n",
      " [0.77140698]]\n",
      "theta: [[4.16577645]\n",
      " [2.94707703]]\n",
      "gradients: [[-1.28272963]\n",
      " [-0.22612862]]\n",
      "theta: [[4.16624666]\n",
      " [2.9479814 ]]\n",
      "gradients: [[-0.23237608]\n",
      " [-0.44693897]]\n",
      "theta: [[4.16431035]\n",
      " [2.94750807]]\n",
      "gradients: [[0.95730933]\n",
      " [0.23401663]]\n",
      "theta: [[4.16953092]\n",
      " [2.95009307]]\n",
      "gradients: [[-2.5820931 ]\n",
      " [-1.27854226]]\n",
      "theta: [[4.17339833]\n",
      " [2.95458726]]\n",
      "gradients: [[-1.91359146]\n",
      " [-2.22372411]]\n",
      "theta: [[4.16990567]\n",
      " [2.94981651]]\n",
      "gradients: [[1.72886292]\n",
      " [2.36152229]]\n",
      "theta: [[4.16838227]\n",
      " [2.94941108]]\n",
      "gradients: [[0.7543889 ]\n",
      " [0.20076778]]\n",
      "theta: [[4.16807165]\n",
      " [2.94892427]]\n",
      "gradients: [[0.15388293]\n",
      " [0.24116402]]\n",
      "theta: [[4.16774043]\n",
      " [2.94885934]]\n",
      "gradients: [[0.16415167]\n",
      " [0.0321784 ]]\n",
      "theta: [[4.16709022]\n",
      " [2.94824703]]\n",
      "gradients: [[0.32237499]\n",
      " [0.3035876 ]]\n",
      "theta: [[4.16655428]\n",
      " [2.94819185]]\n",
      "gradients: [[0.26582376]\n",
      " [0.02736719]]\n",
      "theta: [[4.16096337]\n",
      " [2.94226497]]\n",
      "gradients: [[2.77421141]\n",
      " [2.94091939]]\n",
      "theta: [[4.1659128 ]\n",
      " [2.94802643]]\n",
      "gradients: [[-2.45689728]\n",
      " [-2.85998934]]\n",
      "theta: [[4.16638659]\n",
      " [2.94872148]]\n",
      "gradients: [[-0.2352839 ]\n",
      " [-0.34516297]]\n",
      "theta: [[4.16149904]\n",
      " [2.94135458]]\n",
      "gradients: [[2.42813479]\n",
      " [3.65987426]]\n",
      "theta: [[4.1581938 ]\n",
      " [2.93639121]]\n",
      "gradients: [[1.64270605]\n",
      " [2.46679899]]\n",
      "theta: [[4.16343381]\n",
      " [2.93898584]]\n",
      "gradients: [[-2.60533541]\n",
      " [-1.29005086]]\n",
      "theta: [[4.16397013]\n",
      " [2.93977263]]\n",
      "gradients: [[-0.26676708]\n",
      " [-0.39134901]]\n",
      "theta: [[4.16061496]\n",
      " [2.93518966]]\n",
      "gradients: [[1.66953475]\n",
      " [2.28048359]]\n",
      "theta: [[4.16027585]\n",
      " [2.93493456]]\n",
      "gradients: [[0.16880665]\n",
      " [0.12699145]]\n",
      "theta: [[4.15459197]\n",
      " [2.92569282]]\n",
      "gradients: [[2.83057194]\n",
      " [4.60238543]]\n",
      "theta: [[4.14749174]\n",
      " [2.92367507]]\n",
      "gradients: [[3.53733852]\n",
      " [1.00524045]]\n",
      "theta: [[4.140298  ]\n",
      " [2.91322638]]\n",
      "gradients: [[3.58535747]\n",
      " [5.20762884]]\n",
      "theta: [[4.13988679]\n",
      " [2.91318404]]\n",
      "gradients: [[0.20502841]\n",
      " [0.02110817]]\n",
      "theta: [[4.1418579 ]\n",
      " [2.91339528]]\n",
      "gradients: [[-0.98318778]\n",
      " [-0.10536212]]\n",
      "theta: [[4.14140901]\n",
      " [2.9132184 ]]\n",
      "gradients: [[0.22399752]\n",
      " [0.08826157]]\n",
      "theta: [[4.14488334]\n",
      " [2.91386287]]\n",
      "gradients: [[-1.73438679]\n",
      " [-0.32172184]]\n",
      "theta: [[4.1445189 ]\n",
      " [2.91365872]]\n",
      "gradients: [[0.18199943]\n",
      " [0.1019555 ]]\n",
      "theta: [[4.14983355]\n",
      " [2.9162903 ]]\n",
      "gradients: [[-2.65519751]\n",
      " [-1.31474044]]\n",
      "theta: [[4.15018979]\n",
      " [2.91673793]]\n",
      "gradients: [[-0.17804923]\n",
      " [-0.22372462]]\n",
      "theta: [[4.15007898]\n",
      " [2.91660604]]\n",
      "gradients: [[0.0554054 ]\n",
      " [0.06594638]]\n",
      "theta: [[4.14837822]\n",
      " [2.91401616]]\n",
      "gradients: [[0.85071868]\n",
      " [1.29545842]]\n",
      "theta: [[4.14736188]\n",
      " [2.91385446]]\n",
      "gradients: [[0.50857835]\n",
      " [0.08091289]]\n",
      "theta: [[4.14387602]\n",
      " [2.90692472]]\n",
      "gradients: [[1.74502132]\n",
      " [3.46902872]]\n",
      "theta: [[4.14455289]\n",
      " [2.90718627]]\n",
      "gradients: [[-0.33897872]\n",
      " [-0.13098359]]\n",
      "theta: [[4.14460504]\n",
      " [2.90726799]]\n",
      "gradients: [[-0.02612455]\n",
      " [-0.04094217]]\n",
      "theta: [[4.15341289]\n",
      " [2.9231263 ]]\n",
      "gradients: [[-4.41449413]\n",
      " [-7.94818494]]\n",
      "theta: [[4.15410941]\n",
      " [2.92446594]]\n",
      "gradients: [[-0.34923417]\n",
      " [-0.6716972 ]]\n",
      "theta: [[4.15776799]\n",
      " [2.92510224]]\n",
      "gradients: [[-1.83514594]\n",
      " [-0.31916575]]\n",
      "theta: [[4.16157268]\n",
      " [2.93048024]]\n",
      "gradients: [[-1.90919251]\n",
      " [-2.69868231]]\n",
      "theta: [[4.15974806]\n",
      " [2.92770174]]\n",
      "gradients: [[0.91596083]\n",
      " [1.39480794]]\n",
      "theta: [[4.15416065]\n",
      " [2.91861686]]\n",
      "gradients: [[2.80599587]\n",
      " [4.56242581]]\n",
      "theta: [[4.1548475 ]\n",
      " [2.91962448]]\n",
      "gradients: [[-0.34507624]\n",
      " [-0.50622904]]\n",
      "theta: [[4.15918497]\n",
      " [2.92445427]]\n",
      "gradients: [[-2.18000971]\n",
      " [-2.42745219]]\n",
      "theta: [[4.15310954]\n",
      " [2.91768874]]\n",
      "gradients: [[3.05472627]\n",
      " [3.40170927]]\n",
      "theta: [[4.15696534]\n",
      " [2.92313899]]\n",
      "gradients: [[-1.93946767]\n",
      " [-2.74147687]]\n",
      "theta: [[4.15678975]\n",
      " [2.92297793]]\n",
      "gradients: [[0.08835479]\n",
      " [0.08104711]]\n",
      "theta: [[4.15662396]\n",
      " [2.9227806 ]]\n",
      "gradients: [[0.08345967]\n",
      " [0.09933801]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: [[4.15487135]\n",
      " [2.92011176]]\n",
      "gradients: [[0.88261364]\n",
      " [1.34402747]]\n",
      "theta: [[4.15474241]\n",
      " [2.91985781]]\n",
      "gradients: [[0.06496251]\n",
      " [0.12793679]]\n",
      "theta: [[4.14999297]\n",
      " [2.91476172]]\n",
      "gradients: [[2.39371819]\n",
      " [2.56843277]]\n",
      "theta: [[4.14795563]\n",
      " [2.91400601]]\n",
      "gradients: [[1.02722733]\n",
      " [0.38102709]]\n",
      "theta: [[4.14773434]\n",
      " [2.91383954]]\n",
      "gradients: [[0.11161551]\n",
      " [0.08396716]]\n",
      "theta: [[4.1478199 ]\n",
      " [2.91389918]]\n",
      "gradients: [[-0.04317051]\n",
      " [-0.03009192]]\n",
      "theta: [[4.14645084]\n",
      " [2.91353483]]\n",
      "gradients: [[0.69109978]\n",
      " [0.18392446]]\n",
      "theta: [[4.15302282]\n",
      " [2.92289373]]\n",
      "gradients: [[-3.31884903]\n",
      " [-4.72624726]]\n",
      "theta: [[4.15666072]\n",
      " [2.92352643]]\n",
      "gradients: [[-1.83786599]\n",
      " [-0.31963882]]\n",
      "theta: [[4.15806773]\n",
      " [2.9236977 ]]\n",
      "gradients: [[-0.71110256]\n",
      " [-0.08655955]]\n",
      "theta: [[4.15789866]\n",
      " [2.92336474]]\n",
      "gradients: [[0.08547952]\n",
      " [0.16834286]]\n",
      "theta: [[4.15186915]\n",
      " [2.91665034]]\n",
      "gradients: [[3.04972707]\n",
      " [3.39614222]]\n",
      "theta: [[4.15551015]\n",
      " [2.91728358]]\n",
      "gradients: [[-1.84234501]\n",
      " [-0.32041781]]\n",
      "theta: [[4.15660235]\n",
      " [2.91854381]]\n",
      "gradients: [[-0.55287309]\n",
      " [-0.63792608]]\n",
      "theta: [[4.15727456]\n",
      " [2.91952994]]\n",
      "gradients: [[-0.34040719]\n",
      " [-0.49937951]]\n",
      "theta: [[4.15374631]\n",
      " [2.91251593]]\n",
      "gradients: [[1.7874119 ]\n",
      " [3.55329942]]\n",
      "theta: [[4.15482693]\n",
      " [2.91365627]]\n",
      "gradients: [[-0.54765826]\n",
      " [-0.57792608]]\n",
      "theta: [[4.15282845]\n",
      " [2.91186453]]\n",
      "gradients: [[1.01322738]\n",
      " [0.90841423]]\n",
      "theta: [[4.15157285]\n",
      " [2.91134766]]\n",
      "gradients: [[0.63684228]\n",
      " [0.26215332]]\n",
      "theta: [[4.15164965]\n",
      " [2.9114012 ]]\n",
      "gradients: [[-0.03896742]\n",
      " [-0.02716216]]\n",
      "theta: [[4.14967402]\n",
      " [2.90962994]]\n",
      "gradients: [[1.00282922]\n",
      " [0.89909171]]\n",
      "theta: [[4.14667328]\n",
      " [2.90512382]]\n",
      "gradients: [[1.52377624]\n",
      " [2.2882059 ]]\n",
      "theta: [[4.15358017]\n",
      " [2.91198615]]\n",
      "gradients: [[-3.50870054]\n",
      " [-3.48606601]]\n",
      "theta: [[4.15393706]\n",
      " [2.9124346 ]]\n",
      "gradients: [[-0.1813726 ]\n",
      " [-0.22790054]]\n",
      "theta: [[4.15465237]\n",
      " [2.91348396]]\n",
      "gradients: [[-0.36366225]\n",
      " [-0.53349484]]\n",
      "theta: [[4.15119557]\n",
      " [2.90661199]]\n",
      "gradients: [[1.75812921]\n",
      " [3.49508666]]\n",
      "theta: [[4.15230646]\n",
      " [2.90778427]]\n",
      "gradients: [[-0.56522023]\n",
      " [-0.59645865]]\n",
      "theta: [[4.15254087]\n",
      " [2.90788111]]\n",
      "gradients: [[-0.11931788]\n",
      " [-0.04929004]]\n",
      "theta: [[4.15316182]\n",
      " [2.90788482]]\n",
      "gradients: [[-0.31618695]\n",
      " [-0.00189172]]\n",
      "theta: [[4.14851937]\n",
      " [2.90290353]]\n",
      "gradients: [[2.36486324]\n",
      " [2.53747173]]\n",
      "theta: [[4.14752776]\n",
      " [2.90274577]]\n",
      "gradients: [[0.50532469]\n",
      " [0.08039524]]\n",
      "theta: [[4.14654053]\n",
      " [2.9025887 ]]\n",
      "gradients: [[0.50329127]\n",
      " [0.08007173]]\n",
      "theta: [[4.15045287]\n",
      " [2.90811888]]\n",
      "gradients: [[-1.99529412]\n",
      " [-2.82038868]]\n",
      "theta: [[4.15038346]\n",
      " [2.90803626]]\n",
      "gradients: [[0.03541387]\n",
      " [0.04215141]]\n",
      "theta: [[4.15062436]\n",
      " [2.90813577]]\n",
      "gradients: [[-0.12295568]\n",
      " [-0.05079281]]\n",
      "theta: [[4.14314519]\n",
      " [2.90557645]]\n",
      "gradients: [[3.81886204]\n",
      " [1.30679098]]\n",
      "theta: [[4.13915923]\n",
      " [2.90237771]]\n",
      "gradients: [[2.03603223]\n",
      " [1.63391522]]\n",
      "theta: [[4.13876682]\n",
      " [2.90233731]]\n",
      "gradients: [[0.20051706]\n",
      " [0.02064371]]\n",
      "theta: [[4.14140213]\n",
      " [2.90280188]]\n",
      "gradients: [[-1.34716833]\n",
      " [-0.23748833]]\n",
      "theta: [[4.13809912]\n",
      " [2.89623565]]\n",
      "gradients: [[1.68915769]\n",
      " [3.3579742 ]]\n",
      "theta: [[4.14152152]\n",
      " [2.8995591 ]]\n",
      "gradients: [[-1.75089902]\n",
      " [-1.7002784 ]]\n",
      "theta: [[4.1397061 ]\n",
      " [2.89930587]]\n",
      "gradients: [[0.92913307]\n",
      " [0.12959991]]\n",
      "theta: [[4.14175795]\n",
      " [2.90039155]]\n",
      "gradients: [[-1.05054809]\n",
      " [-0.55586552]]\n",
      "theta: [[4.13793815]\n",
      " [2.89587814]]\n",
      "gradients: [[1.95650334]\n",
      " [2.31176984]]\n",
      "theta: [[4.14303366]\n",
      " [2.90180965]]\n",
      "gradients: [[-2.61094234]\n",
      " [-3.03930788]]\n",
      "theta: [[4.14284715]\n",
      " [2.90177309]]\n",
      "gradients: [[0.09560408]\n",
      " [0.01874112]]\n",
      "theta: [[4.1354389 ]\n",
      " [2.89923803]]\n",
      "gradients: [[3.79895309]\n",
      " [1.29997826]]\n",
      "theta: [[4.13035471]\n",
      " [2.89384832]]\n",
      "gradients: [[2.60818954]\n",
      " [2.76492093]]\n",
      "theta: [[4.12661692]\n",
      " [2.88943181]]\n",
      "gradients: [[1.91823414]\n",
      " [2.26655162]]\n",
      "theta: [[4.127654  ]\n",
      " [2.89142648]]\n",
      "gradients: [[-0.53243824]\n",
      " [-1.02406151]]\n",
      "theta: [[4.13115164]\n",
      " [2.8922647 ]]\n",
      "gradients: [[-1.7963885]\n",
      " [-0.43051  ]]\n",
      "theta: [[4.1243952 ]\n",
      " [2.89034466]]\n",
      "gradients: [[3.47145866]\n",
      " [0.98651872]]\n",
      "theta: [[4.1235051 ]\n",
      " [2.88932108]]\n",
      "gradients: [[0.457513 ]\n",
      " [0.5261169]]\n",
      "theta: [[4.11967262]\n",
      " [2.88624552]]\n",
      "gradients: [[1.9706622 ]\n",
      " [1.58145578]]\n",
      "theta: [[4.1188199 ]\n",
      " [2.88526493]]\n",
      "gradients: [[0.43864022]\n",
      " [0.50441416]]\n",
      "theta: [[4.11981798]\n",
      " [2.88672912]]\n",
      "gradients: [[-0.51361274]\n",
      " [-0.75347316]]\n",
      "theta: [[4.1201018]\n",
      " [2.8870914]]\n",
      "gradients: [[-0.14611001]\n",
      " [-0.18649946]]\n",
      "theta: [[4.12429379]\n",
      " [2.89196277]]\n",
      "gradients: [[-2.15887422]\n",
      " [-2.50875944]]\n",
      "theta: [[4.12779311]\n",
      " [2.8928014 ]]\n",
      "gradients: [[-1.80285188]\n",
      " [-0.43205897]]\n",
      "theta: [[4.1221248 ]\n",
      " [2.88648923]]\n",
      "gradients: [[2.92144597]\n",
      " [3.25328981]]\n",
      "theta: [[4.11562704]\n",
      " [2.88015855]]\n",
      "gradients: [[3.35024532]\n",
      " [3.26410228]]\n",
      "theta: [[4.12095111]\n",
      " [2.8827948 ]]\n",
      "gradients: [[-2.74615695]\n",
      " [-1.35977967]]\n",
      "theta: [[4.11535911]\n",
      " [2.8765676 ]]\n",
      "gradients: [[2.88547551]\n",
      " [3.2132335 ]]\n",
      "theta: [[4.12298254]\n",
      " [2.8771656 ]]\n",
      "gradients: [[-3.93521335]\n",
      " [-0.30868799]]\n",
      "theta: [[4.12279309]\n",
      " [2.8769872 ]]\n",
      "gradients: [[0.09782807]\n",
      " [0.09212684]]\n",
      "theta: [[4.12357567]\n",
      " [2.8772896 ]]\n",
      "gradients: [[-0.40428068]\n",
      " [-0.15621669]]\n",
      "theta: [[4.12809741]\n",
      " [2.88232457]]\n",
      "gradients: [[-2.33683362]\n",
      " [-2.60207642]]\n",
      "theta: [[4.12531047]\n",
      " [2.87851778]]\n",
      "gradients: [[1.44084816]\n",
      " [1.96811153]]\n",
      "theta: [[4.12447493]\n",
      " [2.87755695]]\n",
      "gradients: [[0.43214291]\n",
      " [0.49694257]]\n",
      "theta: [[4.12416378]\n",
      " [2.87743435]]\n",
      "gradients: [[0.16098887]\n",
      " [0.06343432]]\n",
      "theta: [[4.11876576]\n",
      " [2.8727763 ]]\n",
      "gradients: [[2.79401394]\n",
      " [2.4110033 ]]\n",
      "theta: [[4.12288921]\n",
      " [2.87860489]]\n",
      "gradients: [[-2.13512452]\n",
      " [-3.01804178]]\n",
      "theta: [[4.12414938]\n",
      " [2.87992216]]\n",
      "gradients: [[-0.65276512]\n",
      " [-0.68234613]]\n",
      "theta: [[4.12478413]\n",
      " [2.88002011]]\n",
      "gradients: [[-0.32892753]\n",
      " [-0.05075782]]\n",
      "theta: [[4.13145395]\n",
      " [2.88951835]]\n",
      "gradients: [[-3.45763653]\n",
      " [-4.92388928]]\n",
      "theta: [[4.13020946]\n",
      " [2.88918715]]\n",
      "gradients: [[0.6453908 ]\n",
      " [0.17175979]]\n",
      "theta: [[4.12538035]\n",
      " [2.8800835 ]]\n",
      "gradients: [[2.50534494]\n",
      " [4.72297757]]\n",
      "theta: [[4.12571934]\n",
      " [2.88033042]]\n",
      "gradients: [[-0.17593621]\n",
      " [-0.12815124]]\n",
      "theta: [[4.12976376]\n",
      " [2.88604728]]\n",
      "gradients: [[-2.09986157]\n",
      " [-2.9681969 ]]\n",
      "theta: [[4.1298294]\n",
      " [2.8861075]]\n",
      "gradients: [[-0.03409621]\n",
      " [-0.03127617]]\n",
      "theta: [[4.12545784]\n",
      " [2.88141686]]\n",
      "gradients: [[2.27146476]\n",
      " [2.43725621]]\n",
      "theta: [[4.12573925]\n",
      " [2.88197106]]\n",
      "gradients: [[-0.14627553]\n",
      " [-0.28807418]]\n",
      "theta: [[4.12402259]\n",
      " [2.88173161]]\n",
      "gradients: [[0.89266199]\n",
      " [0.12451275]]\n",
      "theta: [[4.1329855 ]\n",
      " [2.89844163]]\n",
      "gradients: [[-4.66250806]\n",
      " [-8.69255164]]\n",
      "theta: [[4.13203755]\n",
      " [2.89735153]]\n",
      "gradients: [[0.49331583]\n",
      " [0.56728834]]\n",
      "theta: [[4.13994426]\n",
      " [2.90791284]]\n",
      "gradients: [[-4.11623536]\n",
      " [-5.4982197 ]]\n",
      "theta: [[4.13475602]\n",
      " [2.89947699]]\n",
      "gradients: [[2.70203653]\n",
      " [4.3933925 ]]\n",
      "theta: [[4.12805815]\n",
      " [2.88974852]]\n",
      "gradients: [[3.48959199]\n",
      " [5.06853223]]\n",
      "theta: [[4.12425835]\n",
      " [2.88669919]]\n",
      "gradients: [[1.98045433]\n",
      " [1.58931397]]\n",
      "theta: [[4.12252503]\n",
      " [2.88514517]]\n",
      "gradients: [[0.90375319]\n",
      " [0.81026459]]\n",
      "theta: [[4.1222879 ]\n",
      " [2.88481723]]\n",
      "gradients: [[0.12368865]\n",
      " [0.17105107]]\n",
      "theta: [[4.11702322]\n",
      " [2.88034199]]\n",
      "gradients: [[2.74710853]\n",
      " [2.33518348]]\n",
      "theta: [[4.11513986]\n",
      " [2.87946876]]\n",
      "gradients: [[0.98311338]\n",
      " [0.45582503]]\n",
      "theta: [[4.1125276 ]\n",
      " [2.87554601]]\n",
      "gradients: [[1.36412378]\n",
      " [2.04846092]]\n",
      "theta: [[4.10619198]\n",
      " [2.86937329]]\n",
      "gradients: [[3.30972721]\n",
      " [3.22462599]]\n",
      "theta: [[4.10800209]\n",
      " [2.87201609]]\n",
      "gradients: [[-0.94596342]\n",
      " [-1.38112655]]\n",
      "theta: [[4.10090779]\n",
      " [2.86958847]]\n",
      "gradients: [[3.70889763]\n",
      " [1.26916184]]\n",
      "theta: [[4.10163169]\n",
      " [2.86970018]]\n",
      "gradients: [[-0.37859995]\n",
      " [-0.05842292]]\n",
      "theta: [[4.10012212]\n",
      " [2.86933116]]\n",
      "gradients: [[0.78980731]\n",
      " [0.19307035]]\n",
      "theta: [[4.09991998]\n",
      " [2.86925151]]\n",
      "gradients: [[0.10580086]\n",
      " [0.04168863]]\n",
      "theta: [[4.1066175 ]\n",
      " [2.88018052]]\n",
      "gradients: [[-3.50681961]\n",
      " [-5.72243327]]\n",
      "theta: [[4.1100849 ]\n",
      " [2.88082371]]\n",
      "gradients: [[-1.8162266]\n",
      " [-0.3369028]]\n",
      "theta: [[4.10605656]\n",
      " [2.87475189]]\n",
      "gradients: [[2.11084978]\n",
      " [3.18163754]]\n",
      "theta: [[4.10071293]\n",
      " [2.87350485]]\n",
      "gradients: [[2.80113281]\n",
      " [0.65369869]]\n",
      "theta: [[4.10150618]\n",
      " [2.87419127]]\n",
      "gradients: [[-0.41598301]\n",
      " [-0.35995875]]\n",
      "theta: [[4.11053336]\n",
      " [2.89102109]]\n",
      "gradients: [[-4.73565658]\n",
      " [-8.82892615]]\n",
      "theta: [[4.10977987]\n",
      " [2.88963615]]\n",
      "gradients: [[0.3954304 ]\n",
      " [0.72681575]]\n",
      "theta: [[4.10897297]\n",
      " [2.88950778]]\n",
      "gradients: [[0.42362411]\n",
      " [0.06739699]]\n",
      "theta: [[4.10796245]\n",
      " [2.8890918 ]]\n",
      "gradients: [[0.53072519]\n",
      " [0.21847069]]\n",
      "theta: [[4.10827419]\n",
      " [2.88948972]]\n",
      "gradients: [[-0.16378947]\n",
      " [-0.20906608]]\n",
      "theta: [[4.10402074]\n",
      " [2.88492582]]\n",
      "gradients: [[2.23561251]\n",
      " [2.39878714]]\n",
      "theta: [[4.10446725]\n",
      " [2.88511027]]\n",
      "gradients: [[-0.23477489]\n",
      " [-0.09698517]]\n",
      "theta: [[4.10603539]\n",
      " [2.88530115]]\n",
      "gradients: [[-0.82484196]\n",
      " [-0.10040457]]\n",
      "theta: [[4.10953703]\n",
      " [2.88614033]]\n",
      "gradients: [[-1.84256162]\n",
      " [-0.44157553]]\n",
      "theta: [[4.11476578]\n",
      " [2.88872938]]\n",
      "gradients: [[-2.75241312]\n",
      " [-1.36287746]]\n",
      "theta: [[4.11212395]\n",
      " [2.88476223]]\n",
      "gradients: [[1.39118838]\n",
      " [2.08910297]]\n",
      "theta: [[4.11071396]\n",
      " [2.88237323]]\n",
      "gradients: [[0.74278047]\n",
      " [1.2585249 ]]\n",
      "theta: [[4.10758958]\n",
      " [2.87894152]]\n",
      "gradients: [[1.64654856]\n",
      " [1.80851116]]\n",
      "theta: [[4.10511251]\n",
      " [2.87781118]]\n",
      "gradients: [[1.30591247]\n",
      " [0.59591307]]\n",
      "theta: [[4.10642077]\n",
      " [2.87917873]]\n",
      "gradients: [[-0.68997787]\n",
      " [-0.72124523]]\n",
      "theta: [[4.1101027 ]\n",
      " [2.88090309]]\n",
      "gradients: [[-1.94258549]\n",
      " [-0.90977012]]\n",
      "theta: [[4.10892396]\n",
      " [2.87995596]]\n",
      "gradients: [[0.6221401 ]\n",
      " [0.49989318]]\n",
      "theta: [[4.11580693]\n",
      " [2.88679454]]\n",
      "gradients: [[-3.63421017]\n",
      " [-3.61076598]]\n",
      "theta: [[4.11113537]\n",
      " [2.87798789]]\n",
      "gradients: [[2.46751894]\n",
      " [4.65166947]]\n",
      "theta: [[4.11635356]\n",
      " [2.88057171]]\n",
      "gradients: [[-2.75728992]\n",
      " [-1.36529225]]\n",
      "theta: [[4.11618143]\n",
      " [2.88040962]]\n",
      "gradients: [[0.09098533]\n",
      " [0.08568288]]\n",
      "theta: [[4.11963191]\n",
      " [2.88123654]]\n",
      "gradients: [[-1.82461409]\n",
      " [-0.43727435]]\n",
      "theta: [[4.11860123]\n",
      " [2.88081226]]\n",
      "gradients: [[0.54523344]\n",
      " [0.22444295]]\n",
      "theta: [[4.12233576]\n",
      " [2.88247311]]\n",
      "gradients: [[-1.97631442]\n",
      " [-0.87892232]]\n",
      "theta: [[4.13114406]\n",
      " [2.89889488]]\n",
      "gradients: [[-4.6631169 ]\n",
      " [-8.69368672]]\n",
      "theta: [[4.13327293]\n",
      " [2.898911  ]]\n",
      "gradients: [[-1.12744518]\n",
      " [-0.00853483]]\n",
      "theta: [[4.13141934]\n",
      " [2.89822346]]\n",
      "gradients: [[0.98202831]\n",
      " [0.36426152]]\n",
      "theta: [[4.12725713]\n",
      " [2.89194985]]\n",
      "gradients: [[2.20597116]\n",
      " [3.32501191]]\n",
      "theta: [[4.12202227]\n",
      " [2.88617046]]\n",
      "gradients: [[2.77552199]\n",
      " [3.06423267]]\n",
      "theta: [[4.12023103]\n",
      " [2.88550604]]\n",
      "gradients: [[0.95007536]\n",
      " [0.35240929]]\n",
      "theta: [[4.12014885]\n",
      " [2.88548993]]\n",
      "gradients: [[0.04360687]\n",
      " [0.00854819]]\n",
      "theta: [[4.12657945]\n",
      " [2.8959834 ]]\n",
      "gradients: [[-3.41336613]\n",
      " [-5.56993575]]\n",
      "theta: [[4.13024586]\n",
      " [2.89761395]]\n",
      "gradients: [[-1.9468639 ]\n",
      " [-0.86582485]]\n",
      "theta: [[4.12525876]\n",
      " [2.88950515]]\n",
      "gradients: [[2.64914865]\n",
      " [4.30739914]]\n",
      "theta: [[4.1244697 ]\n",
      " [2.88805482]]\n",
      "gradients: [[0.41930847]\n",
      " [0.77070454]]\n",
      "theta: [[4.12076285]\n",
      " [2.88508007]]\n",
      "gradients: [[1.97055904]\n",
      " [1.581373  ]]\n",
      "theta: [[4.1293038 ]\n",
      " [2.90045784]]\n",
      "gradients: [[-4.54207606]\n",
      " [-8.17789299]]\n",
      "theta: [[4.13266613]\n",
      " [2.90126363]]\n",
      "gradients: [[-1.78876012]\n",
      " [-0.42868184]]\n",
      "theta: [[4.13621011]\n",
      " [2.90187999]]\n",
      "gradients: [[-1.88610312]\n",
      " [-0.32802815]]\n",
      "theta: [[4.13513035]\n",
      " [2.9010403 ]]\n",
      "gradients: [[0.57486274]\n",
      " [0.44705347]]\n",
      "theta: [[4.13476823]\n",
      " [2.90053952]]\n",
      "gradients: [[0.19286255]\n",
      " [0.26671281]]\n",
      "theta: [[4.12996856]\n",
      " [2.89149137]]\n",
      "gradients: [[2.55726455]\n",
      " [4.82085436]]\n",
      "theta: [[4.13116854]\n",
      " [2.89275767]]\n",
      "gradients: [[-0.63958683]\n",
      " [-0.67493532]]\n",
      "theta: [[4.13127136]\n",
      " [2.89278682]]\n",
      "gradients: [[-0.05482711]\n",
      " [-0.01554381]]\n",
      "theta: [[4.13282261]\n",
      " [2.89505167]]\n",
      "gradients: [[-0.82743616]\n",
      " [-1.20807426]]\n",
      "theta: [[4.13616653]\n",
      " [2.89585305]]\n",
      "gradients: [[-1.7843137 ]\n",
      " [-0.42761624]]\n",
      "theta: [[4.13696873]\n",
      " [2.89695438]]\n",
      "gradients: [[-0.4282127 ]\n",
      " [-0.58788568]]\n",
      "theta: [[4.13776196]\n",
      " [2.89804339]]\n",
      "gradients: [[-0.42358434]\n",
      " [-0.58153148]]\n",
      "theta: [[4.13843225]\n",
      " [2.89830239]]\n",
      "gradients: [[-0.35807046]\n",
      " [-0.13836076]]\n",
      "theta: [[4.13804817]\n",
      " [2.89815105]]\n",
      "gradients: [[0.20525214]\n",
      " [0.08087534]]\n",
      "theta: [[4.13640853]\n",
      " [2.89775024]]\n",
      "gradients: [[0.87655004]\n",
      " [0.21427483]]\n",
      "theta: [[4.13484652]\n",
      " [2.89510366]]\n",
      "gradients: [[0.83536192]\n",
      " [1.41538964]]\n",
      "theta: [[4.1322761 ]\n",
      " [2.89393073]]\n",
      "gradients: [[1.37517655]\n",
      " [0.62751961]]\n",
      "theta: [[4.13143602]\n",
      " [2.89238663]]\n",
      "gradients: [[0.44961192]\n",
      " [0.82640341]]\n",
      "theta: [[4.13109419]\n",
      " [2.89235143]]\n",
      "gradients: [[0.18301343]\n",
      " [0.01884167]]\n",
      "theta: [[4.13169651]\n",
      " [2.89287264]]\n",
      "gradients: [[-0.32260379]\n",
      " [-0.27915577]]\n",
      "theta: [[4.13135379]\n",
      " [2.89283735]]\n",
      "gradients: [[0.1836345 ]\n",
      " [0.01890561]]\n",
      "theta: [[4.13248453]\n",
      " [2.89401934]]\n",
      "gradients: [[-0.60608112]\n",
      " [-0.63354658]]\n",
      "theta: [[4.13144913]\n",
      " [2.89321414]]\n",
      "gradients: [[0.55518561]\n",
      " [0.43175116]]\n",
      "theta: [[4.13399391]\n",
      " [2.89366275]]\n",
      "gradients: [[-1.36502032]\n",
      " [-0.2406354 ]]\n",
      "theta: [[4.13122906]\n",
      " [2.88988614]]\n",
      "gradients: [[1.48361568]\n",
      " [2.02652937]]\n",
      "theta: [[4.12856962]\n",
      " [2.88589254]]\n",
      "gradients: [[1.42758907]\n",
      " [2.14376471]]\n",
      "theta: [[4.12594341]\n",
      " [2.88194884]]\n",
      "gradients: [[1.41027606]\n",
      " [2.11776632]]\n",
      "theta: [[4.123439  ]\n",
      " [2.88080603]]\n",
      "gradients: [[1.34536471]\n",
      " [0.61391589]]\n",
      "theta: [[4.12354388]\n",
      " [2.88090223]]\n",
      "gradients: [[-0.05636123]\n",
      " [-0.05169969]]\n",
      "theta: [[4.12484738]\n",
      " [2.88240626]]\n",
      "gradients: [[-0.70076199]\n",
      " [-0.80856594]]\n",
      "theta: [[4.13126373]\n",
      " [2.89154355]]\n",
      "gradients: [[-3.45071396]\n",
      " [-4.91403111]]\n",
      "theta: [[4.13326308]\n",
      " [2.89260144]]\n",
      "gradients: [[-1.07564722]\n",
      " [-0.56914596]]\n",
      "theta: [[4.13223272]\n",
      " [2.89180016]]\n",
      "gradients: [[0.55453738]\n",
      " [0.43124705]]\n",
      "theta: [[4.13319023]\n",
      " [2.89337233]]\n",
      "gradients: [[-0.51552431]\n",
      " [-0.8464577 ]]\n",
      "theta: [[4.13309547]\n",
      " [2.89330105]]\n",
      "gradients: [[0.05103974]\n",
      " [0.03839665]]\n",
      "theta: [[4.12791696]\n",
      " [2.88758386]]\n",
      "gradients: [[2.79018217]\n",
      " [3.08041781]]\n",
      "theta: [[4.12706685]\n",
      " [2.88660628]]\n",
      "gradients: [[0.45820696]\n",
      " [0.52691492]]\n",
      "theta: [[4.1254924 ]\n",
      " [2.88622141]]\n",
      "gradients: [[0.84894311]\n",
      " [0.20752625]]\n",
      "theta: [[4.12544627]\n",
      " [2.8861867 ]]\n",
      "gradients: [[0.02488494]\n",
      " [0.01872068]]\n",
      "theta: [[4.12523849]\n",
      " [2.8860703 ]]\n",
      "gradients: [[0.11211708]\n",
      " [0.06280763]]\n",
      "theta: [[4.12536906]\n",
      " [2.88610732]]\n",
      "gradients: [[-0.07047902]\n",
      " [-0.01998122]]\n",
      "theta: [[4.12414492]\n",
      " [2.88512371]]\n",
      "gradients: [[0.66103606]\n",
      " [0.53114632]]\n",
      "theta: [[4.11775212]\n",
      " [2.88330701]]\n",
      "gradients: [[3.45338655]\n",
      " [0.98138299]]\n",
      "theta: [[4.11674698]\n",
      " [2.88289325]]\n",
      "gradients: [[0.54317847]\n",
      " [0.22359702]]\n",
      "theta: [[4.11838474]\n",
      " [2.88528442]]\n",
      "gradients: [[-0.88537456]\n",
      " [-1.29266555]]\n",
      "theta: [[4.12173459]\n",
      " [2.88853742]]\n",
      "gradients: [[-1.81159701]\n",
      " [-1.75922153]]\n",
      "theta: [[4.12505914]\n",
      " [2.89176585]]\n",
      "gradients: [[-1.79857941]\n",
      " [-1.74658029]]\n",
      "theta: [[4.13138514]\n",
      " [2.90077447]]\n",
      "gradients: [[-3.4236332 ]\n",
      " [-4.87546642]]\n",
      "theta: [[4.1324912 ]\n",
      " [2.90082179]]\n",
      "gradients: [[-0.59882074]\n",
      " [-0.02561802]]\n",
      "theta: [[4.1333717 ]\n",
      " [2.90251528]]\n",
      "gradients: [[-0.47687603]\n",
      " [-0.9171963 ]]\n",
      "theta: [[4.13692922]\n",
      " [2.90409741]]\n",
      "gradients: [[-1.9274696 ]\n",
      " [-0.85719966]]\n",
      "theta: [[4.13045808]\n",
      " [2.89469826]]\n",
      "gradients: [[3.50736046]\n",
      " [5.09434043]]\n",
      "theta: [[4.12887254]\n",
      " [2.89431067]]\n",
      "gradients: [[0.85968178]\n",
      " [0.21015134]]\n",
      "theta: [[4.12761659]\n",
      " [2.89330151]]\n",
      "gradients: [[0.68122591]\n",
      " [0.54736898]]\n",
      "theta: [[4.12068203]\n",
      " [2.89092855]]\n",
      "gradients: [[3.76269411]\n",
      " [1.28757066]]\n",
      "theta: [[4.12419392]\n",
      " [2.89739637]]\n",
      "gradients: [[-1.90625481]\n",
      " [-3.51073527]]\n",
      "theta: [[4.12332223]\n",
      " [2.89639397]]\n",
      "gradients: [[0.47332866]\n",
      " [0.54430411]]\n",
      "theta: [[4.1220824 ]\n",
      " [2.89539776]]\n",
      "gradients: [[0.67347317]\n",
      " [0.54113961]]\n",
      "theta: [[4.12269954]\n",
      " [2.89593179]]\n",
      "gradients: [[-0.33535527]\n",
      " [-0.29018989]]\n",
      "theta: [[4.12330088]\n",
      " [2.89602458]]\n",
      "gradients: [[-0.32688621]\n",
      " [-0.05044282]]\n",
      "theta: [[4.12031079]\n",
      " [2.89008042]]\n",
      "gradients: [[1.62600921]\n",
      " [3.23243768]]\n",
      "theta: [[4.11509609]\n",
      " [2.88886346]]\n",
      "gradients: [[2.83679569]\n",
      " [0.66202131]]\n",
      "theta: [[4.11872741]\n",
      " [2.89047841]]\n",
      "gradients: [[-1.97616349]\n",
      " [-0.8788552 ]]\n",
      "theta: [[4.11943282]\n",
      " [2.89048263]]\n",
      "gradients: [[-0.3840221 ]\n",
      " [-0.00229757]]\n",
      "theta: [[4.12338495]\n",
      " [2.89507528]]\n",
      "gradients: [[-2.15233048]\n",
      " [-2.50115517]]\n",
      "theta: [[4.11802942]\n",
      " [2.88911142]]\n",
      "gradients: [[2.91769398]\n",
      " [3.24911164]]\n",
      "theta: [[4.12131398]\n",
      " [2.88972069]]\n",
      "gradients: [[-1.79008947]\n",
      " [-0.33205447]]\n",
      "theta: [[4.12010574]\n",
      " [2.88874986]]\n",
      "gradients: [[0.65873265]\n",
      " [0.52929552]]\n",
      "theta: [[4.12641695]\n",
      " [2.89773741]]\n",
      "gradients: [[-3.44212988]\n",
      " [-4.90180684]]\n",
      "theta: [[4.12132653]\n",
      " [2.89341029]]\n",
      "gradients: [[2.77733225]\n",
      " [2.3608752 ]]\n",
      "theta: [[4.12186255]\n",
      " [2.89408382]]\n",
      "gradients: [[-0.29256223]\n",
      " [-0.3676139 ]]\n",
      "theta: [[4.11770019]\n",
      " [2.88961766]]\n",
      "gradients: [[2.27264807]\n",
      " [2.43852589]]\n",
      "theta: [[4.11656886]\n",
      " [2.88931657]]\n",
      "gradients: [[0.61793614]\n",
      " [0.1644532 ]]\n",
      "theta: [[4.11745713]\n",
      " [2.89053608]]\n",
      "gradients: [[-0.48535569]\n",
      " [-0.66633628]]\n",
      "theta: [[4.11722211]\n",
      " [2.89021106]]\n",
      "gradients: [[0.12846321]\n",
      " [0.17765389]]\n",
      "theta: [[4.11796316]\n",
      " [2.8904974 ]]\n",
      "gradients: [[-0.40520307]\n",
      " [-0.15657311]]\n",
      "theta: [[4.11922418]\n",
      " [2.89195242]]\n",
      "gradients: [[-0.6897809 ]\n",
      " [-0.79589553]]\n",
      "theta: [[4.11779628]\n",
      " [2.88953307]]\n",
      "gradients: [[0.78134624]\n",
      " [1.32386856]]\n",
      "theta: [[4.12173821]\n",
      " [2.89411386]]\n",
      "gradients: [[-2.15781046]\n",
      " [-2.50752328]]\n",
      "theta: [[4.12233969]\n",
      " [2.89420668]]\n",
      "gradients: [[-0.32936994]\n",
      " [-0.05082609]]\n",
      "theta: [[4.12420597]\n",
      " [2.89440667]]\n",
      "gradients: [[-1.02234936]\n",
      " [-0.10955882]]\n",
      "theta: [[4.12335474]\n",
      " [2.8934278 ]]\n",
      "gradients: [[0.46647677]\n",
      " [0.53642478]]\n",
      "theta: [[4.124581 ]\n",
      " [2.8948427]]\n",
      "gradients: [[-0.67223534]\n",
      " [-0.7756508 ]]\n",
      "theta: [[4.12324358]\n",
      " [2.8928061 ]]\n",
      "gradients: [[0.7334411 ]\n",
      " [1.11687033]]\n",
      "theta: [[4.11855863]\n",
      " [2.88783963]]\n",
      "gradients: [[2.57016202]\n",
      " [2.72460826]]\n",
      "theta: [[4.11737386]\n",
      " [2.88688766]]\n",
      "gradients: [[0.65019905]\n",
      " [0.52243872]]\n",
      "theta: [[4.11449986]\n",
      " [2.88117427]]\n",
      "gradients: [[1.57782757]\n",
      " [3.1366546 ]]\n",
      "theta: [[4.11489483]\n",
      " [2.88133743]]\n",
      "gradients: [[-0.21691618]\n",
      " [-0.08960776]]\n",
      "theta: [[4.12148297]\n",
      " [2.88788307]]\n",
      "gradients: [[-3.61952333]\n",
      " [-3.59617388]]\n",
      "theta: [[4.11737346]\n",
      " [2.88347362]]\n",
      "gradients: [[2.25858222]\n",
      " [2.42343338]]\n",
      "theta: [[4.11765504]\n",
      " [2.88391489]]\n",
      "gradients: [[-0.15480794]\n",
      " [-0.24261369]]\n",
      "theta: [[4.12091461]\n",
      " [2.88451953]]\n",
      "gradients: [[-1.7927661 ]\n",
      " [-0.33255097]]\n",
      "theta: [[4.11919408]\n",
      " [2.88388134]]\n",
      "gradients: [[0.94663529]\n",
      " [0.35113327]]\n",
      "theta: [[4.11989024]\n",
      " [2.8838855 ]]\n",
      "gradients: [[-0.38316771]\n",
      " [-0.00229246]]\n",
      "theta: [[4.11309621]\n",
      " [2.88156063]]\n",
      "gradients: [[3.74079722]\n",
      " [1.28007768]]\n",
      "theta: [[4.11140992]\n",
      " [2.88093514]]\n",
      "gradients: [[0.9288034 ]\n",
      " [0.34451893]]\n",
      "theta: [[4.11856496]\n",
      " [2.8814964 ]]\n",
      "gradients: [[-3.94242652]\n",
      " [-0.30925381]]\n",
      "theta: [[4.12343284]\n",
      " [2.88716292]]\n",
      "gradients: [[-2.68317128]\n",
      " [-3.1233871 ]]\n",
      "theta: [[4.12458225]\n",
      " [2.88836442]]\n",
      "gradients: [[-0.63378617]\n",
      " [-0.66250712]]\n",
      "theta: [[4.125476  ]\n",
      " [2.88967556]]\n",
      "gradients: [[-0.49299409]\n",
      " [-0.72322547]]\n",
      "theta: [[4.1258166 ]\n",
      " [2.88981626]]\n",
      "gradients: [[-0.18794015]\n",
      " [-0.0776378 ]]\n",
      "theta: [[4.12243649]\n",
      " [2.88345054]]\n",
      "gradients: [[1.86582083]\n",
      " [3.51387642]]\n",
      "theta: [[4.12953533]\n",
      " [2.88400739]]\n",
      "gradients: [[-3.91997877]\n",
      " [-0.30749295]]\n",
      "theta: [[4.13706047]\n",
      " [2.89405903]]\n",
      "gradients: [[-4.1568884 ]\n",
      " [-5.55252159]]\n",
      "theta: [[4.1372286 ]\n",
      " [2.89427364]]\n",
      "gradients: [[-0.09291279]\n",
      " [-0.11859683]]\n",
      "theta: [[4.14044111]\n",
      " [2.89504353]]\n",
      "gradients: [[-1.77587463]\n",
      " [-0.42559379]]\n",
      "theta: [[4.14380402]\n",
      " [2.89661847]]\n",
      "gradients: [[-1.85968491]\n",
      " [-0.87094533]]\n",
      "theta: [[4.15080904]\n",
      " [2.89716797]]\n",
      "gradients: [[-3.87517786]\n",
      " [-0.30397866]]\n",
      "theta: [[4.15119511]\n",
      " [2.89727592]]\n",
      "gradients: [[-0.21365116]\n",
      " [-0.05973932]]\n",
      "theta: [[4.1463361 ]\n",
      " [2.88937538]]\n",
      "gradients: [[2.68994786]\n",
      " [4.37373686]]\n",
      "theta: [[4.15154455]\n",
      " [2.89890064]]\n",
      "gradients: [[-2.88444069]\n",
      " [-5.27509107]]\n",
      "theta: [[4.15393232]\n",
      " [2.89932158]]\n",
      "gradients: [[-1.32282456]\n",
      " [-0.23319684]]\n",
      "theta: [[4.15073814]\n",
      " [2.8958132 ]]\n",
      "gradients: [[1.77021621]\n",
      " [1.94434337]]\n",
      "theta: [[4.15069165]\n",
      " [2.89577056]]\n",
      "gradients: [[0.02576893]\n",
      " [0.02363762]]\n",
      "theta: [[4.15080215]\n",
      " [2.8959116 ]]\n",
      "gradients: [[-0.0612811 ]\n",
      " [-0.07822114]]\n",
      "theta: [[4.15140352]\n",
      " [2.89614397]]\n",
      "gradients: [[-0.33363754]\n",
      " [-0.12891972]]\n",
      "theta: [[4.14631415]\n",
      " [2.89181775]]\n",
      "gradients: [[2.82459639]\n",
      " [2.40105214]]\n",
      "theta: [[4.14509597]\n",
      " [2.89149355]]\n",
      "gradients: [[0.6763351 ]\n",
      " [0.17999509]]\n",
      "theta: [[4.14165575]\n",
      " [2.88501464]]\n",
      "gradients: [[1.91069724]\n",
      " [3.59839158]]\n",
      "theta: [[4.14996209]\n",
      " [2.90050056]]\n",
      "gradients: [[-4.61500032]\n",
      " [-8.60398054]]\n",
      "theta: [[4.15034619]\n",
      " [2.90060796]]\n",
      "gradients: [[-0.21348139]\n",
      " [-0.05969186]]\n",
      "theta: [[4.1501731 ]\n",
      " [2.90047775]]\n",
      "gradients: [[0.09623821]\n",
      " [0.07239898]]\n",
      "theta: [[4.15023766]\n",
      " [2.90057893]]\n",
      "gradients: [[-0.03591123]\n",
      " [-0.05627977]]\n",
      "theta: [[4.1533257]\n",
      " [2.9035777]]\n",
      "gradients: [[-1.71818651]\n",
      " [-1.66851165]]\n",
      "theta: [[4.14646055]\n",
      " [2.90122848]]\n",
      "gradients: [[3.82114524]\n",
      " [1.30757228]]\n",
      "theta: [[4.14477327]\n",
      " [2.90099313]]\n",
      "gradients: [[0.93947683]\n",
      " [0.1310427 ]]\n",
      "theta: [[4.14517468]\n",
      " [2.90110537]]\n",
      "gradients: [[-0.22358357]\n",
      " [-0.06251654]]\n",
      "theta: [[4.1531351]\n",
      " [2.9154379]]\n",
      "gradients: [[-4.43554614]\n",
      " [-7.98608856]]\n",
      "theta: [[4.15442703]\n",
      " [2.91559517]]\n",
      "gradients: [[-0.72012296]\n",
      " [-0.08765757]]\n",
      "theta: [[4.15316229]\n",
      " [2.91525858]]\n",
      "gradients: [[0.70521676]\n",
      " [0.18768145]]\n",
      "theta: [[4.14955088]\n",
      " [2.9109914 ]]\n",
      "gradients: [[2.01444527]\n",
      " [2.38023299]]\n",
      "theta: [[4.14945905]\n",
      " [2.91090717]]\n",
      "gradients: [[0.05124009]\n",
      " [0.04700211]]\n",
      "theta: [[4.14776043]\n",
      " [2.91067023]]\n",
      "gradients: [[0.9481739 ]\n",
      " [0.13225581]]\n",
      "theta: [[4.14773616]\n",
      " [2.91062244]]\n",
      "gradients: [[0.01355249]\n",
      " [0.02669019]]\n",
      "theta: [[4.14731802]\n",
      " [2.91045768]]\n",
      "gradients: [[0.23356886]\n",
      " [0.09203296]]\n",
      "theta: [[4.14969312]\n",
      " [2.91087638]]\n",
      "gradients: [[-1.3272029 ]\n",
      " [-0.23396868]]\n",
      "theta: [[4.15003647]\n",
      " [2.91130781]]\n",
      "gradients: [[-0.19193565]\n",
      " [-0.24117335]]\n",
      "theta: [[4.14730124]\n",
      " [2.90720041]]\n",
      "gradients: [[1.52954038]\n",
      " [2.29686173]]\n",
      "theta: [[4.14569331]\n",
      " [2.90680734]]\n",
      "gradients: [[0.89948046]\n",
      " [0.21988023]]\n",
      "theta: [[4.14937785]\n",
      " [2.91108903]]\n",
      "gradients: [[-2.06186865]\n",
      " [-2.39603233]]\n",
      "theta: [[4.14658758]\n",
      " [2.9072777 ]]\n",
      "gradients: [[1.56199006]\n",
      " [2.13358403]]\n",
      "theta: [[4.1470622 ]\n",
      " [2.90768839]]\n",
      "gradients: [[-0.265785  ]\n",
      " [-0.22998929]]\n",
      "theta: [[4.13930103]\n",
      " [2.89554333]]\n",
      "gradients: [[4.34780625]\n",
      " [6.80366654]]\n",
      "theta: [[4.14686098]\n",
      " [2.89676245]]\n",
      "gradients: [[-4.2365992 ]\n",
      " [-0.68319709]]\n",
      "theta: [[4.14792177]\n",
      " [2.89788186]]\n",
      "gradients: [[-0.59467719]\n",
      " [-0.62754363]]\n",
      "theta: [[4.14810887]\n",
      " [2.89801815]]\n",
      "gradients: [[-0.10492484]\n",
      " [-0.07642684]]\n",
      "theta: [[4.14722419]\n",
      " [2.89639208]]\n",
      "gradients: [[0.49630311]\n",
      " [0.91222355]]\n",
      "theta: [[4.14452011]\n",
      " [2.89269846]]\n",
      "gradients: [[1.51753246]\n",
      " [2.07285764]]\n",
      "theta: [[4.14111063]\n",
      " [2.88627743]]\n",
      "gradients: [[1.91408389]\n",
      " [3.60476961]]\n",
      "theta: [[4.14710933]\n",
      " [2.89606612]]\n",
      "gradients: [[-3.36887248]\n",
      " [-5.49733094]]\n",
      "theta: [[4.14578079]\n",
      " [2.89597107]]\n",
      "gradients: [[0.74637665]\n",
      " [0.05339809]]\n",
      "theta: [[4.1458231 ]\n",
      " [2.89598307]]\n",
      "gradients: [[-0.02378057]\n",
      " [-0.00674193]]\n",
      "theta: [[4.14913442]\n",
      " [2.89655897]]\n",
      "gradients: [[-1.86162595]\n",
      " [-0.32377112]]\n",
      "theta: [[4.14874454]\n",
      " [2.89651883]]\n",
      "gradients: [[0.21926935]\n",
      " [0.02257431]]\n",
      "theta: [[4.14844186]\n",
      " [2.89634927]]\n",
      "gradients: [[0.17028967]\n",
      " [0.09539573]]\n",
      "theta: [[4.14893097]\n",
      " [2.89642474]]\n",
      "gradients: [[-0.27527273]\n",
      " [-0.04247818]]\n",
      "theta: [[4.14853174]\n",
      " [2.89626743]]\n",
      "gradients: [[0.22476989]\n",
      " [0.0885659 ]]\n",
      "theta: [[4.14338947]\n",
      " [2.89506739]]\n",
      "gradients: [[2.8961253 ]\n",
      " [0.67586703]]\n",
      "theta: [[4.13927549]\n",
      " [2.89065314]]\n",
      "gradients: [[2.31781261]\n",
      " [2.48698693]]\n",
      "theta: [[4.1376393 ]\n",
      " [2.89042492]]\n",
      "gradients: [[0.92215652]\n",
      " [0.12862679]]\n",
      "theta: [[4.13678051]\n",
      " [2.88943735]]\n",
      "gradients: [[0.48418579]\n",
      " [0.55678926]]\n",
      "theta: [[4.13416057]\n",
      " [2.88585867]]\n",
      "gradients: [[1.47764562]\n",
      " [2.01837463]]\n",
      "theta: [[4.13287515]\n",
      " [2.88390125]]\n",
      "gradients: [[0.72523884]\n",
      " [1.10438007]]\n",
      "theta: [[4.13339492]\n",
      " [2.88455436]]\n",
      "gradients: [[-0.29336184]\n",
      " [-0.36861864]]\n",
      "theta: [[4.13349198]\n",
      " [2.88466988]]\n",
      "gradients: [[-0.05479743]\n",
      " [-0.06522274]]\n",
      "theta: [[4.13229691]\n",
      " [2.88370964]]\n",
      "gradients: [[0.67497193]\n",
      " [0.54234387]]\n",
      "theta: [[4.13287453]\n",
      " [2.88465967]]\n",
      "gradients: [[-0.32635529]\n",
      " [-0.5367639 ]]\n",
      "theta: [[4.12797713]\n",
      " [2.88049662]]\n",
      "gradients: [[2.76801392]\n",
      " [2.35295414]]\n",
      "theta: [[4.13551887]\n",
      " [2.8817128 ]]\n",
      "gradients: [[-4.26409989]\n",
      " [-0.68763187]]\n",
      "theta: [[4.1360961 ]\n",
      " [2.88266218]]\n",
      "gradients: [[-0.32647986]\n",
      " [-0.53696879]]\n",
      "theta: [[4.14342618]\n",
      " [2.89245327]]\n",
      "gradients: [[-4.14736056]\n",
      " [-5.53979487]]\n",
      "theta: [[4.14450505]\n",
      " [2.89359177]]\n",
      "gradients: [[-0.61064148]\n",
      " [-0.64439023]]\n",
      "theta: [[4.1491026 ]\n",
      " [2.89894361]]\n",
      "gradients: [[-2.60313151]\n",
      " [-3.03021556]]\n",
      "theta: [[4.14562843]\n",
      " [2.89483859]]\n",
      "gradients: [[1.96777093]\n",
      " [2.32508341]]\n",
      "theta: [[4.1457588 ]\n",
      " [2.89492947]]\n",
      "gradients: [[-0.07387149]\n",
      " [-0.05149198]]\n",
      "theta: [[4.14811554]\n",
      " [2.89534493]]\n",
      "gradients: [[-1.33579618]\n",
      " [-0.23548357]]\n",
      "theta: [[4.14911609]\n",
      " [2.89639083]]\n",
      "gradients: [[-0.56731519]\n",
      " [-0.59302391]]\n",
      "theta: [[4.14438599]\n",
      " [2.8886999 ]]\n",
      "gradients: [[2.68291161]\n",
      " [4.36229623]]\n",
      "theta: [[4.14282694]\n",
      " [2.88831879]]\n",
      "gradients: [[0.88460497]\n",
      " [0.21624388]]\n",
      "theta: [[4.13978988]\n",
      " [2.88498299]]\n",
      "gradients: [[1.7238353 ]\n",
      " [1.89340021]]\n",
      "theta: [[4.14199285]\n",
      " [2.88870989]]\n",
      "gradients: [[-1.25084365]\n",
      " [-2.11613897]]\n",
      "theta: [[4.1421631 ]\n",
      " [2.88892721]]\n",
      "gradients: [[-0.09670363]\n",
      " [-0.12343558]]\n",
      "theta: [[4.14099011]\n",
      " [2.88861504]]\n",
      "gradients: [[0.66649446]\n",
      " [0.17737617]]\n",
      "theta: [[4.14140895]\n",
      " [2.88873215]]\n",
      "gradients: [[-0.23807201]\n",
      " [-0.06656768]]\n",
      "theta: [[4.13807986]\n",
      " [2.88246251]]\n",
      "gradients: [[1.89292218]\n",
      " [3.56491603]]\n",
      "theta: [[4.13627397]\n",
      " [2.8816252 ]]\n",
      "gradients: [[1.02719305]\n",
      " [0.47626277]]\n",
      "theta: [[4.13554924]\n",
      " [2.88029312]]\n",
      "gradients: [[0.41237163]\n",
      " [0.75795437]]\n",
      "theta: [[4.14301414]\n",
      " [2.88149692]]\n",
      "gradients: [[-4.2490213 ]\n",
      " [-0.68520029]]\n",
      "theta: [[4.14537807]\n",
      " [2.88191365]]\n",
      "gradients: [[-1.34602148]\n",
      " [-0.23728616]]\n",
      "theta: [[4.13924389]\n",
      " [2.88017044]]\n",
      "gradients: [[3.49402838]\n",
      " [0.99293258]]\n",
      "theta: [[4.13933784]\n",
      " [2.88028227]]\n",
      "gradients: [[-0.05353545]\n",
      " [-0.06372066]]\n",
      "theta: [[4.14015297]\n",
      " [2.88140134]]\n",
      "gradients: [[-0.4646238 ]\n",
      " [-0.63787383]]\n",
      "theta: [[4.14099878]\n",
      " [2.88264216]]\n",
      "gradients: [[-0.4822824 ]\n",
      " [-0.70751135]]\n",
      "theta: [[4.14211415]\n",
      " [2.88381916]]\n",
      "gradients: [[-0.63620297]\n",
      " [-0.67136444]]\n",
      "theta: [[4.14583384]\n",
      " [2.8881417 ]]\n",
      "gradients: [[-2.12245464]\n",
      " [-2.4664374 ]]\n",
      "theta: [[4.14329081]\n",
      " [2.88432291]]\n",
      "gradients: [[1.45155947]\n",
      " [2.1797603 ]]\n",
      "theta: [[4.13945927]\n",
      " [2.87854772]]\n",
      "gradients: [[2.18781014]\n",
      " [3.29763819]]\n",
      "theta: [[4.14281064]\n",
      " [2.88471991]]\n",
      "gradients: [[-1.91430369]\n",
      " [-3.52555882]]\n",
      "theta: [[4.14466534]\n",
      " [2.88570127]]\n",
      "gradients: [[-1.05977444]\n",
      " [-0.56074736]]\n",
      "theta: [[4.13977286]\n",
      " [2.88029987]]\n",
      "gradients: [[2.79654129]\n",
      " [3.08743841]]\n",
      "theta: [[4.13737426]\n",
      " [2.87920535]]\n",
      "gradients: [[1.37151871]\n",
      " [0.62585046]]\n",
      "theta: [[4.13558622]\n",
      " [2.87837631]]\n",
      "gradients: [[1.02276145]\n",
      " [0.47420803]]\n",
      "theta: [[4.13306081]\n",
      " [2.87492675]]\n",
      "gradients: [[1.4450396 ]\n",
      " [1.97383678]]\n",
      "theta: [[4.14049569]\n",
      " [2.87612571]]\n",
      "gradients: [[-4.25572893]\n",
      " [-0.68628196]]\n",
      "theta: [[4.14728055]\n",
      " [2.87665793]]\n",
      "gradients: [[-3.88500951]\n",
      " [-0.30474988]]\n",
      "theta: [[4.15465962]\n",
      " [2.87784788]]\n",
      "gradients: [[-4.2267311 ]\n",
      " [-0.68160575]]\n",
      "theta: [[4.15798743]\n",
      " [2.87932785]]\n",
      "gradients: [[-1.90683431]\n",
      " [-0.84802257]]\n",
      "theta: [[4.15204183]\n",
      " [2.87353513]]\n",
      "gradients: [[3.40801609]\n",
      " [3.32038762]]\n",
      "theta: [[4.15243318]\n",
      " [2.87364456]]\n",
      "gradients: [[-0.22440159]\n",
      " [-0.06274527]]\n",
      "theta: [[4.1494506 ]\n",
      " [2.87036859]]\n",
      "gradients: [[1.71081247]\n",
      " [1.87909639]]\n",
      "theta: [[4.14764035]\n",
      " [2.86952926]]\n",
      "gradients: [[1.03871971]\n",
      " [0.48160716]]\n",
      "theta: [[4.15099971]\n",
      " [2.87102326]]\n",
      "gradients: [[-1.9282719 ]\n",
      " [-0.85755647]]\n",
      "theta: [[4.14797853]\n",
      " [2.86926146]]\n",
      "gradients: [[1.73476262]\n",
      " [1.01162515]]\n",
      "theta: [[4.14926975]\n",
      " [2.86941864]]\n",
      "gradients: [[-0.74167783]\n",
      " [-0.09028135]]\n",
      "theta: [[4.14910376]\n",
      " [2.8693861 ]]\n",
      "gradients: [[0.09537713]\n",
      " [0.01869663]]\n",
      "theta: [[4.14915979]\n",
      " [2.86940198]]\n",
      "gradients: [[-0.03220862]\n",
      " [-0.00913134]]\n",
      "theta: [[4.14799441]\n",
      " [2.86909184]]\n",
      "gradients: [[0.67009523]\n",
      " [0.17833445]]\n",
      "theta: [[4.14731684]\n",
      " [2.86784644]]\n",
      "gradients: [[0.38973893]\n",
      " [0.71635463]]\n",
      "theta: [[4.14840548]\n",
      " [2.86898441]]\n",
      "gradients: [[-0.62640184]\n",
      " [-0.65478816]]\n",
      "theta: [[4.14737578]\n",
      " [2.86856054]]\n",
      "gradients: [[0.5926935 ]\n",
      " [0.24397967]]\n",
      "theta: [[4.14621899]\n",
      " [2.86825268]]\n",
      "gradients: [[0.66607933]\n",
      " [0.17726569]]\n",
      "theta: [[4.14122173]\n",
      " [2.86708647]]\n",
      "gradients: [[2.87842423]\n",
      " [0.67173614]]\n",
      "theta: [[4.14151883]\n",
      " [2.86767159]]\n",
      "gradients: [[-0.17119213]\n",
      " [-0.33714479]]\n",
      "theta: [[4.14242069]\n",
      " [2.86899463]]\n",
      "gradients: [[-0.51983396]\n",
      " [-0.76259973]]\n",
      "theta: [[4.14001482]\n",
      " [2.8653818 ]]\n",
      "gradients: [[1.3872281 ]\n",
      " [2.08315595]]\n",
      "theta: [[4.14045347]\n",
      " [2.86550445]]\n",
      "gradients: [[-0.25301515]\n",
      " [-0.07074595]]\n",
      "theta: [[4.14411432]\n",
      " [2.87067913]]\n",
      "gradients: [[-2.11230691]\n",
      " [-2.98578864]]\n",
      "theta: [[4.14344243]\n",
      " [2.86944417]]\n",
      "gradients: [[0.38781374]\n",
      " [0.71281606]]\n",
      "theta: [[4.14046736]\n",
      " [2.86770926]]\n",
      "gradients: [[1.71780637]\n",
      " [1.00173713]]\n",
      "theta: [[4.13963976]\n",
      " [2.86757759]]\n",
      "gradients: [[0.47802211]\n",
      " [0.07605151]]\n",
      "theta: [[4.13943267]\n",
      " [2.86746159]]\n",
      "gradients: [[0.11965453]\n",
      " [0.06703008]]\n",
      "theta: [[4.14255398]\n",
      " [2.87049265]]\n",
      "gradients: [[-1.80411626]\n",
      " [-1.75195707]]\n",
      "theta: [[4.14343514]\n",
      " [2.87178532]]\n",
      "gradients: [[-0.50948663]\n",
      " [-0.74742012]]\n",
      "theta: [[4.14350807]\n",
      " [2.871806  ]]\n",
      "gradients: [[-0.04218548]\n",
      " [-0.01195984]]\n",
      "theta: [[4.14236726]\n",
      " [2.87150239]]\n",
      "gradients: [[0.66007136]\n",
      " [0.17566677]]\n",
      "theta: [[4.14546056]\n",
      " [2.87450626]]\n",
      "gradients: [[-1.79039911]\n",
      " [-1.73863649]]\n",
      "theta: [[4.13952194]\n",
      " [2.86588058]]\n",
      "gradients: [[3.43846252]\n",
      " [4.99426814]]\n",
      "theta: [[4.13983186]\n",
      " [2.86600861]]\n",
      "gradients: [[-0.17950763]\n",
      " [-0.07415434]]\n",
      "theta: [[4.14014042]\n",
      " [2.86613607]]\n",
      "gradients: [[-0.178782  ]\n",
      " [-0.07385459]]\n",
      "theta: [[4.14240735]\n",
      " [2.86997119]]\n",
      "gradients: [[-1.31391182]\n",
      " [-2.22283578]]\n",
      "theta: [[4.15026039]\n",
      " [2.8841104 ]]\n",
      "gradients: [[-4.55319338]\n",
      " [-8.19790944]]\n",
      "theta: [[4.14646538]\n",
      " [2.87839025]]\n",
      "gradients: [[2.20110865]\n",
      " [3.31768275]]\n",
      "theta: [[4.14316665]\n",
      " [2.87449253]]\n",
      "gradients: [[1.91392551]\n",
      " [2.26146062]]\n",
      "theta: [[4.14428496]\n",
      " [2.87567264]]\n",
      "gradients: [[-0.64906733]\n",
      " [-0.68493979]]\n",
      "theta: [[4.14892375]\n",
      " [2.87796958]]\n",
      "gradients: [[-2.69328357]\n",
      " [-1.33359904]]\n",
      "theta: [[4.1521908 ]\n",
      " [2.88398648]]\n",
      "gradients: [[-1.89750424]\n",
      " [-3.4946194 ]]\n",
      "theta: [[4.15234289]\n",
      " [2.88418062]]\n",
      "gradients: [[-0.08836595]\n",
      " [-0.1127931 ]]\n",
      "theta: [[4.15237351]\n",
      " [2.88421705]]\n",
      "gradients: [[-0.01779118]\n",
      " [-0.02117599]]\n",
      "theta: [[4.14687226]\n",
      " [2.87742924]]\n",
      "gradients: [[3.19842249]\n",
      " [3.94643233]]\n",
      "theta: [[4.14778945]\n",
      " [2.87893521]]\n",
      "gradients: [[-0.53343747]\n",
      " [-0.87586996]]\n",
      "theta: [[4.14333802]\n",
      " [2.87421628]]\n",
      "gradients: [[2.58984492]\n",
      " [2.74547395]]\n",
      "theta: [[4.14007718]\n",
      " [2.87036333]]\n",
      "gradients: [[1.897807  ]\n",
      " [2.24241528]]\n",
      "theta: [[4.14059251]\n",
      " [2.87044285]]\n",
      "gradients: [[-0.30002203]\n",
      " [-0.04629732]]\n",
      "theta: [[4.13891746]\n",
      " [2.86982153]]\n",
      "gradients: [[0.97554822]\n",
      " [0.36185788]]\n",
      "theta: [[4.13800703]\n",
      " [2.86911352]]\n",
      "gradients: [[0.53041564]\n",
      " [0.4124883 ]]\n",
      "theta: [[4.13710193]\n",
      " [2.86840965]]\n",
      "gradients: [[0.52749358]\n",
      " [0.4102159 ]]\n",
      "theta: [[4.14045761]\n",
      " [2.87458978]]\n",
      "gradients: [[-1.95636078]\n",
      " [-3.60301505]]\n",
      "theta: [[4.13775682]\n",
      " [2.86922072]]\n",
      "gradients: [[1.57509969]\n",
      " [3.1312317 ]]\n",
      "theta: [[4.13895547]\n",
      " [2.87060377]]\n",
      "gradients: [[-0.69929327]\n",
      " [-0.80687127]]\n",
      "theta: [[4.142038  ]\n",
      " [2.87359719]]\n",
      "gradients: [[-1.79896798]\n",
      " [-1.74695762]]\n",
      "theta: [[4.14387612]\n",
      " [2.87456977]]\n",
      "gradients: [[-1.07309021]\n",
      " [-0.567793  ]]\n",
      "theta: [[4.14841152]\n",
      " [2.87984928]]\n",
      "gradients: [[-2.64867507]\n",
      " [-3.08323125]]\n",
      "theta: [[4.14520462]\n",
      " [2.87380977]]\n",
      "gradients: [[1.8734693 ]\n",
      " [3.52828067]]\n",
      "theta: [[4.14089493]\n",
      " [2.87238372]]\n",
      "gradients: [[2.51858412]\n",
      " [0.8333815 ]]\n",
      "theta: [[4.13660307]\n",
      " [2.87096358]]\n",
      "gradients: [[2.509021  ]\n",
      " [0.83021713]]\n",
      "theta: [[4.13570095]\n",
      " [2.87026202]]\n",
      "gradients: [[0.52756314]\n",
      " [0.41026999]]\n",
      "theta: [[4.13670609]\n",
      " [2.87219526]]\n",
      "gradients: [[-0.58801038]\n",
      " [-1.13094581]]\n",
      "theta: [[4.13650747]\n",
      " [2.87192058]]\n",
      "gradients: [[0.11623349]\n",
      " [0.16074121]]\n",
      "theta: [[4.13170872]\n",
      " [2.86777966]]\n",
      "gradients: [[2.80918548]\n",
      " [2.42409509]]\n",
      "theta: [[4.13160693]\n",
      " [2.86775971]]\n",
      "gradients: [[0.05961251]\n",
      " [0.01168575]]\n",
      "theta: [[4.13277865]\n",
      " [2.86899619]]\n",
      "gradients: [[-0.68639662]\n",
      " [-0.72433218]]\n",
      "theta: [[4.13267246]\n",
      " [2.86897537]]\n",
      "gradients: [[0.06222932]\n",
      " [0.01219872]]\n",
      "theta: [[4.13932851]\n",
      " [2.86949749]]\n",
      "gradients: [[-3.90177776]\n",
      " [-0.30606522]]\n",
      "theta: [[4.14254104]\n",
      " [2.87005621]]\n",
      "gradients: [[-1.88382779]\n",
      " [-0.32763243]]\n",
      "theta: [[4.14221508]\n",
      " [2.86992777]]\n",
      "gradients: [[0.19121008]\n",
      " [0.07534236]]\n",
      "theta: [[4.14271931]\n",
      " [2.87000558]]\n",
      "gradients: [[-0.29588066]\n",
      " [-0.04565826]]\n",
      "theta: [[4.14239302]\n",
      " [2.86987702]]\n",
      "gradients: [[0.19152671]\n",
      " [0.07546712]]\n",
      "theta: [[4.14266002]\n",
      " [2.87007149]]\n",
      "gradients: [[-0.15677958]\n",
      " [-0.11419762]]\n",
      "theta: [[4.14414281]\n",
      " [2.87223639]]\n",
      "gradients: [[-0.87098856]\n",
      " [-1.27166167]]\n",
      "theta: [[4.14916581]\n",
      " [2.8814225 ]]\n",
      "gradients: [[-2.95151513]\n",
      " [-5.39775742]]\n",
      "theta: [[4.15041852]\n",
      " [2.88157499]]\n",
      "gradients: [[-0.73634265]\n",
      " [-0.08963192]]\n",
      "theta: [[4.15066469]\n",
      " [2.88167668]]\n",
      "gradients: [[-0.14474779]\n",
      " [-0.0597951 ]]\n",
      "theta: [[4.15161997]\n",
      " [2.88171755]]\n",
      "gradients: [[-0.56189568]\n",
      " [-0.02403834]]\n",
      "theta: [[4.14841309]\n",
      " [2.87567809]]\n",
      "gradients: [[1.88692317]\n",
      " [3.55361819]]\n",
      "theta: [[4.14944578]\n",
      " [2.87675757]]\n",
      "gradients: [[-0.60783622]\n",
      " [-0.63538121]]\n",
      "theta: [[4.15025644]\n",
      " [2.87794682]]\n",
      "gradients: [[-0.47732169]\n",
      " [-0.70023396]]\n",
      "theta: [[4.15480498]\n",
      " [2.88019907]]\n",
      "gradients: [[-2.67908844]\n",
      " [-1.32657021]]\n",
      "theta: [[4.15799156]\n",
      " [2.88606776]]\n",
      "gradients: [[-1.87752971]\n",
      " [-3.45783245]]\n",
      "theta: [[4.15811278]\n",
      " [2.88622249]]\n",
      "gradients: [[-0.07145123]\n",
      " [-0.09120262]]\n",
      "theta: [[4.15688024]\n",
      " [2.88523214]]\n",
      "gradients: [[0.7267086 ]\n",
      " [0.58391459]]\n",
      "theta: [[4.16400938]\n",
      " [2.88638179]]\n",
      "gradients: [[-4.20476636]\n",
      " [-0.6780637 ]]\n",
      "theta: [[4.16399711]\n",
      " [2.88637831]]\n",
      "gradients: [[0.00723937]\n",
      " [0.0020524 ]]\n",
      "theta: [[4.16962701]\n",
      " [2.8955652 ]]\n",
      "gradients: [[-3.32277028]\n",
      " [-5.42210131]]\n",
      "theta: [[4.16658949]\n",
      " [2.89222889]]\n",
      "gradients: [[1.79335385]\n",
      " [1.96975694]]\n",
      "theta: [[4.16749853]\n",
      " [2.89317913]]\n",
      "gradients: [[-0.53688179]\n",
      " [-0.56121137]]\n",
      "theta: [[4.16506332]\n",
      " [2.89206789]]\n",
      "gradients: [[1.43872416]\n",
      " [0.65651761]]\n",
      "theta: [[4.16882127]\n",
      " [2.89625239]]\n",
      "gradients: [[-2.2209469 ]\n",
      " [-2.47303596]]\n",
      "theta: [[4.16145399]\n",
      " [2.8847237 ]]\n",
      "gradients: [[4.35553311]\n",
      " [6.81575792]]\n",
      "theta: [[4.16145198]\n",
      " [2.88472313]]\n",
      "gradients: [[0.00118845]\n",
      " [0.00033693]]\n",
      "theta: [[4.15643039]\n",
      " [2.87913115]]\n",
      "gradients: [[2.97077198]\n",
      " [3.3082187 ]]\n",
      "theta: [[4.15678946]\n",
      " [2.87923155]]\n",
      "gradients: [[-0.21249505]\n",
      " [-0.05941606]]\n",
      "theta: [[4.162466  ]\n",
      " [2.88849453]]\n",
      "gradients: [[-3.36050977]\n",
      " [-5.48368466]]\n",
      "theta: [[4.15919997]\n",
      " [2.88234366]]\n",
      "gradients: [[1.93414122]\n",
      " [3.64254333]]\n",
      "theta: [[4.16016609]\n",
      " [2.88335356]]\n",
      "gradients: [[-0.57232721]\n",
      " [-0.59826306]]\n",
      "theta: [[4.15886737]\n",
      " [2.88137589]]\n",
      "gradients: [[0.76962037]\n",
      " [1.17196344]]\n",
      "theta: [[4.16374024]\n",
      " [2.89028744]]\n",
      "gradients: [[-2.88863721]\n",
      " [-5.28276571]]\n",
      "theta: [[4.1645117 ]\n",
      " [2.89155413]]\n",
      "gradients: [[-0.45747686]\n",
      " [-0.75114754]]\n",
      "theta: [[4.16104531]\n",
      " [2.88877236]]\n",
      "gradients: [[2.05625943]\n",
      " [1.65014754]]\n",
      "theta: [[4.15949837]\n",
      " [2.8883942 ]]\n",
      "gradients: [[0.91795904]\n",
      " [0.22439736]]\n",
      "theta: [[4.15965941]\n",
      " [2.8885115 ]]\n",
      "gradients: [[-0.0955932 ]\n",
      " [-0.06962971]]\n",
      "theta: [[4.1631563 ]\n",
      " [2.89257514]]\n",
      "gradients: [[-2.07645848]\n",
      " [-2.41298671]]\n",
      "theta: [[4.17061472]\n",
      " [2.90600383]]\n",
      "gradients: [[-4.43029981]\n",
      " [-7.97664267]]\n",
      "theta: [[4.17023664]\n",
      " [2.90579203]]\n",
      "gradients: [[0.22465697]\n",
      " [0.12585212]]\n",
      "theta: [[4.16437513]\n",
      " [2.90008123]]\n",
      "gradients: [[3.48408195]\n",
      " [3.39449764]]\n",
      "theta: [[4.16751611]\n",
      " [2.90147812]]\n",
      "gradients: [[-1.86762771]\n",
      " [-0.8305863 ]]\n",
      "theta: [[4.17039413]\n",
      " [2.90216784]]\n",
      "gradients: [[-1.71184647]\n",
      " [-0.41024925]]\n",
      "theta: [[4.16942488]\n",
      " [2.90105325]]\n",
      "gradients: [[0.57670299]\n",
      " [0.66317938]]\n",
      "theta: [[4.16776938]\n",
      " [2.90082234]]\n",
      "gradients: [[0.98535661]\n",
      " [0.13744224]]\n",
      "theta: [[4.16685246]\n",
      " [2.89913701]]\n",
      "gradients: [[0.54593254]\n",
      " [1.00344428]]\n",
      "theta: [[4.16748518]\n",
      " [2.90006521]]\n",
      "gradients: [[-0.37684676]\n",
      " [-0.55283659]]\n",
      "theta: [[4.16705739]\n",
      " [2.89947362]]\n",
      "gradients: [[0.25487529]\n",
      " [0.35247124]]\n",
      "theta: [[4.1652102 ]\n",
      " [2.89861716]]\n",
      "gradients: [[1.10092266]\n",
      " [0.51044784]]\n",
      "theta: [[4.17078521]\n",
      " [2.90655631]]\n",
      "gradients: [[-3.32381767]\n",
      " [-4.7333229 ]]\n",
      "theta: [[4.1656912 ]\n",
      " [2.90088369]]\n",
      "gradients: [[3.03806481]\n",
      " [3.38315525]]\n",
      "theta: [[4.16851837]\n",
      " [2.90362912]]\n",
      "gradients: [[-1.68668754]\n",
      " [-1.63792335]]\n",
      "theta: [[4.1715572 ]\n",
      " [2.90415762]]\n",
      "gradients: [[-1.81357584]\n",
      " [-0.31541431]]\n",
      "theta: [[4.17242519]\n",
      " [2.90419476]]\n",
      "gradients: [[-0.51818714]\n",
      " [-0.02216846]]\n",
      "theta: [[4.1767935 ]\n",
      " [2.90635776]]\n",
      "gradients: [[-2.60875724]\n",
      " [-1.2917452 ]]\n",
      "theta: [[4.17735557]\n",
      " [2.90718232]]\n",
      "gradients: [[-0.33577889]\n",
      " [-0.49258977]]\n",
      "theta: [[4.18042677]\n",
      " [2.90854817]]\n",
      "gradients: [[-1.83535073]\n",
      " [-0.81623182]]\n",
      "theta: [[4.18046755]\n",
      " [2.90857787]]\n",
      "gradients: [[-0.02437625]\n",
      " [-0.01775557]]\n",
      "theta: [[4.18071539]\n",
      " [2.9089855 ]]\n",
      "gradients: [[-0.14821135]\n",
      " [-0.24376655]]\n",
      "theta: [[4.17881459]\n",
      " [2.90810419]]\n",
      "gradients: [[1.13705913]\n",
      " [0.52720268]]\n",
      "theta: [[4.17634972]\n",
      " [2.90697942]]\n",
      "gradients: [[1.47497747]\n",
      " [0.67306069]]\n",
      "theta: [[4.17232484]\n",
      " [2.90266077]]\n",
      "gradients: [[2.40929608]\n",
      " [2.58514767]]\n",
      "theta: [[4.17280142]\n",
      " [2.90284492]]\n",
      "gradients: [[-0.28537632]\n",
      " [-0.11027127]]\n",
      "theta: [[4.17157408]\n",
      " [2.90251828]]\n",
      "gradients: [[0.73517902]\n",
      " [0.1956554 ]]\n",
      "theta: [[4.17522002]\n",
      " [2.90657807]]\n",
      "gradients: [[-2.18465226]\n",
      " [-2.43262169]]\n",
      "theta: [[4.17516446]\n",
      " [2.90649099]]\n",
      "gradients: [[0.03330337]\n",
      " [0.05219276]]\n",
      "theta: [[4.17423091]\n",
      " [2.90634247]]\n",
      "gradients: [[0.55975637]\n",
      " [0.08905512]]\n",
      "theta: [[4.17264218]\n",
      " [2.9059541 ]]\n",
      "gradients: [[0.95292035]\n",
      " [0.23294374]]\n",
      "theta: [[4.16960517]\n",
      " [2.90261835]]\n",
      "gradients: [[1.8222058 ]\n",
      " [2.00144691]]\n",
      "theta: [[4.17254644]\n",
      " [2.90803527]]\n",
      "gradients: [[-1.76535045]\n",
      " [-3.25123276]]\n",
      "theta: [[4.17081662]\n",
      " [2.90648438]]\n",
      "gradients: [[1.03858733]\n",
      " [0.93115083]]\n",
      "theta: [[4.17056187]\n",
      " [2.90643445]]\n",
      "gradients: [[0.15300276]\n",
      " [0.0299929 ]]\n",
      "theta: [[4.17111175]\n",
      " [2.90718937]]\n",
      "gradients: [[-0.33036801]\n",
      " [-0.45355643]]\n",
      "theta: [[4.17285448]\n",
      " [2.90720256]]\n",
      "gradients: [[-1.04738423]\n",
      " [-0.00792876]]\n",
      "theta: [[4.17831702]\n",
      " [2.91498155]]\n",
      "gradients: [[-3.28407683]\n",
      " [-4.67672948]]\n",
      "theta: [[4.18363924]\n",
      " [2.92366635]]\n",
      "gradients: [[-3.20078083]\n",
      " [-5.22303875]]\n",
      "theta: [[4.18436573]\n",
      " [2.92442577]]\n",
      "gradients: [[-0.43705809]\n",
      " [-0.45686403]]\n",
      "theta: [[4.17839005]\n",
      " [2.9227276 ]]\n",
      "gradients: [[3.59616589]\n",
      " [1.021958  ]]\n",
      "theta: [[4.17868148]\n",
      " [2.92297978]]\n",
      "gradients: [[-0.17544183]\n",
      " [-0.15181346]]\n",
      "theta: [[4.17817467]\n",
      " [2.92278008]]\n",
      "gradients: [[0.30519782]\n",
      " [0.12025686]]\n",
      "theta: [[4.17663797]\n",
      " [2.92044001]]\n",
      "gradients: [[0.9257135 ]\n",
      " [1.40965912]]\n",
      "theta: [[4.17698885]\n",
      " [2.92049416]]\n",
      "gradients: [[-0.21144549]\n",
      " [-0.0326288 ]]\n",
      "theta: [[4.17431627]\n",
      " [2.91648082]]\n",
      "gradients: [[1.61103481]\n",
      " [2.41923931]]\n",
      "theta: [[4.17386097]\n",
      " [2.91605206]]\n",
      "gradients: [[0.27454354]\n",
      " [0.25854367]]\n",
      "theta: [[4.17211099]\n",
      " [2.9144831 ]]\n",
      "gradients: [[1.05559138]\n",
      " [0.94639589]]\n",
      "theta: [[4.17781073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [2.92014608]]\n",
      "gradients: [[-3.43922731]\n",
      " [-3.41704095]]\n",
      "theta: [[4.17856632]\n",
      " [2.92093591]]\n",
      "gradients: [[-0.4560747]\n",
      " [-0.4767424]]\n",
      "theta: [[4.18421968]\n",
      " [2.92655279]]\n",
      "gradients: [[-3.41349427]\n",
      " [-3.39147391]]\n",
      "theta: [[4.18465291]\n",
      " [2.92718835]]\n",
      "gradients: [[-0.26167407]\n",
      " [-0.38387752]]\n",
      "theta: [[4.18282278]\n",
      " [2.9265095 ]]\n",
      "gradients: [[1.10576599]\n",
      " [0.41015926]]\n",
      "theta: [[4.18233831]\n",
      " [2.92645963]]\n",
      "gradients: [[0.29281302]\n",
      " [0.0301458 ]]\n",
      "theta: [[4.18232915]\n",
      " [2.92645295]]\n",
      "gradients: [[0.00554009]\n",
      " [0.00403538]]\n",
      "theta: [[4.18498085]\n",
      " [2.92902799]]\n",
      "gradients: [[-1.6037516 ]\n",
      " [-1.55738519]]\n",
      "theta: [[4.18489408]\n",
      " [2.92896751]]\n",
      "gradients: [[0.05249667]\n",
      " [0.0365927 ]]\n",
      "theta: [[4.18495463]\n",
      " [2.92899252]]\n",
      "gradients: [[-0.0366411 ]\n",
      " [-0.01513638]]\n",
      "theta: [[4.18535067]\n",
      " [2.92914556]]\n",
      "gradients: [[-0.23976722]\n",
      " [-0.09264762]]\n",
      "theta: [[4.18048179]\n",
      " [2.92500675]]\n",
      "gradients: [[2.94859679]\n",
      " [2.50645886]]\n",
      "theta: [[4.18579396]\n",
      " [2.93257162]]\n",
      "gradients: [[-3.21811366]\n",
      " [-4.58279383]]\n",
      "theta: [[4.18575872]\n",
      " [2.93254595]]\n",
      "gradients: [[0.02135529]\n",
      " [0.01555511]]\n",
      "theta: [[4.18060218]\n",
      " [2.92680368]]\n",
      "gradients: [[3.12589537]\n",
      " [3.48096239]]\n",
      "theta: [[4.18036743]\n",
      " [2.92658835]]\n",
      "gradients: [[0.14235164]\n",
      " [0.13057796]]\n",
      "theta: [[4.1799269 ]\n",
      " [2.92634156]]\n",
      "gradients: [[0.26722515]\n",
      " [0.14969868]]\n",
      "theta: [[4.18007951]\n",
      " [2.92653332]]\n",
      "gradients: [[-0.09260307]\n",
      " [-0.11635875]]\n",
      "theta: [[4.17840937]\n",
      " [2.92630036]]\n",
      "gradients: [[1.01377403]\n",
      " [0.14140603]]\n",
      "theta: [[4.17288509]\n",
      " [2.91948413]]\n",
      "gradients: [[3.35434475]\n",
      " [4.13881988]]\n",
      "theta: [[4.17102283]\n",
      " [2.91862068]]\n",
      "gradients: [[1.13113398]\n",
      " [0.52445546]]\n",
      "theta: [[4.17114287]\n",
      " [2.91867027]]\n",
      "gradients: [[-0.07293212]\n",
      " [-0.03012815]]\n",
      "theta: [[4.1647804 ]\n",
      " [2.91649307]]\n",
      "gradients: [[3.86710873]\n",
      " [1.3233007 ]]\n",
      "theta: [[4.16179461]\n",
      " [2.91475191]]\n",
      "gradients: [[1.81535534]\n",
      " [1.05862272]]\n",
      "theta: [[4.15798576]\n",
      " [2.90901091]]\n",
      "gradients: [[2.31654767]\n",
      " [3.49168145]]\n",
      "theta: [[4.1532855 ]\n",
      " [2.90501545]]\n",
      "gradients: [[2.85963598]\n",
      " [2.43083759]]\n",
      "theta: [[4.15329149]\n",
      " [2.90501714]]\n",
      "gradients: [[-0.00364288]\n",
      " [-0.00103278]]\n",
      "theta: [[4.1529148 ]\n",
      " [2.90497836]]\n",
      "gradients: [[0.22932505]\n",
      " [0.02360956]]\n",
      "theta: [[4.1516891]\n",
      " [2.9039935]]\n",
      "gradients: [[0.74645354]\n",
      " [0.59977976]]\n",
      "theta: [[4.14636103]\n",
      " [2.89741937]]\n",
      "gradients: [[3.24585675]\n",
      " [4.00495996]]\n",
      "theta: [[4.1492033 ]\n",
      " [2.90017946]]\n",
      "gradients: [[-1.73207619]\n",
      " [-1.68199976]]\n",
      "theta: [[4.15496686]\n",
      " [2.90590584]]\n",
      "gradients: [[-3.51346541]\n",
      " [-3.49080015]]\n",
      "theta: [[4.15456346]\n",
      " [2.90534797]]\n",
      "gradients: [[0.24599286]\n",
      " [0.34018758]]\n",
      "theta: [[4.16087869]\n",
      " [2.90584336]]\n",
      "gradients: [[-3.85228944]\n",
      " [-0.30218323]]\n",
      "theta: [[4.16067354]\n",
      " [2.90568903]]\n",
      "gradients: [[0.12518027]\n",
      " [0.09417179]]\n",
      "theta: [[4.16610072]\n",
      " [2.91341767]]\n",
      "gradients: [[-3.31274944]\n",
      " [-4.71756106]]\n",
      "theta: [[4.16568036]\n",
      " [2.91337439]]\n",
      "gradients: [[0.25667323]\n",
      " [0.02642512]]\n",
      "theta: [[4.16520872]\n",
      " [2.91272215]]\n",
      "gradients: [[0.28807661]\n",
      " [0.39838589]]\n",
      "theta: [[4.16023221]\n",
      " [2.90718037]]\n",
      "gradients: [[3.04064425]\n",
      " [3.38602769]]\n",
      "theta: [[4.15737844]\n",
      " [2.90150719]]\n",
      "gradients: [[1.74422636]\n",
      " [3.46744839]]\n",
      "theta: [[4.16061147]\n",
      " [2.90607715]]\n",
      "gradients: [[-1.97667577]\n",
      " [-2.79407127]]\n",
      "theta: [[4.15944646]\n",
      " [2.9057671 ]]\n",
      "gradients: [[0.71251953]\n",
      " [0.18962496]]\n",
      "theta: [[4.16099216]\n",
      " [2.90593274]]\n",
      "gradients: [[-0.9456581 ]\n",
      " [-0.10134029]]\n",
      "theta: [[4.16061957]\n",
      " [2.90558186]]\n",
      "gradients: [[0.22802861]\n",
      " [0.21473954]]\n",
      "theta: [[4.16236473]\n",
      " [2.90559507]]\n",
      "gradients: [[-1.06839294]\n",
      " [-0.0080878 ]]\n",
      "theta: [[4.16077671]\n",
      " [2.90537357]]\n",
      "gradients: [[0.97250335]\n",
      " [0.1356494 ]]\n",
      "theta: [[4.16074615]\n",
      " [2.90531338]]\n",
      "gradients: [[0.01872262]\n",
      " [0.03687223]]\n",
      "theta: [[4.1626067 ]\n",
      " [2.90846099]]\n",
      "gradients: [[-1.14014243]\n",
      " [-1.92885805]]\n",
      "theta: [[4.16316251]\n",
      " [2.90922406]]\n",
      "gradients: [[-0.34071393]\n",
      " [-0.46776016]]\n",
      "theta: [[4.16941575]\n",
      " [2.90971458]]\n",
      "gradients: [[-3.83448324]\n",
      " [-0.30078647]]\n",
      "theta: [[4.16645402]\n",
      " [2.90798745]]\n",
      "gradients: [[1.8167203 ]\n",
      " [1.05941869]]\n",
      "theta: [[4.16349722]\n",
      " [2.9047398 ]]\n",
      "gradients: [[1.81429621]\n",
      " [1.9927593 ]]\n",
      "theta: [[4.16346192]\n",
      " [2.90467028]]\n",
      "gradients: [[0.02166736]\n",
      " [0.04267157]]\n",
      "theta: [[4.16197508]\n",
      " [2.90215107]]\n",
      "gradients: [[0.91291854]\n",
      " [1.54679716]]\n",
      "theta: [[4.16517544]\n",
      " [2.90667484]]\n",
      "gradients: [[-1.96566223]\n",
      " [-2.7785034 ]]\n",
      "theta: [[4.16873695]\n",
      " [2.91064061]]\n",
      "gradients: [[-2.18819282]\n",
      " [-2.43656413]]\n",
      "theta: [[4.16744877]\n",
      " [2.91054845]]\n",
      "gradients: [[0.79171731]\n",
      " [0.0566419 ]]\n",
      "theta: [[4.17424035]\n",
      " [2.91164366]]\n",
      "gradients: [[-4.17546425]\n",
      " [-0.67333842]]\n",
      "theta: [[4.17091017]\n",
      " [2.90770878]]\n",
      "gradients: [[2.04805874]\n",
      " [2.41995008]]\n",
      "theta: [[4.16997141]\n",
      " [2.90598329]]\n",
      "gradients: [[0.57752922]\n",
      " [1.06152015]]\n",
      "theta: [[4.16701897]\n",
      " [2.90274044]]\n",
      "gradients: [[1.81692839]\n",
      " [1.99565038]]\n",
      "theta: [[4.16315033]\n",
      " [2.89858943]]\n",
      "gradients: [[2.38153783]\n",
      " [2.55536338]]\n",
      "theta: [[4.16606215]\n",
      " [2.90395211]]\n",
      "gradients: [[-1.79310021]\n",
      " [-3.30233928]]\n",
      "theta: [[4.16435542]\n",
      " [2.90331904]]\n",
      "gradients: [[1.05134653]\n",
      " [0.38997357]]\n",
      "theta: [[4.16765411]\n",
      " [2.90715234]]\n",
      "gradients: [[-2.03265172]\n",
      " [-2.36208026]]\n",
      "theta: [[4.16184995]\n",
      " [2.89872196]]\n",
      "gradients: [[3.57768462]\n",
      " [5.19648424]]\n",
      "theta: [[4.15768459]\n",
      " [2.89734368]]\n",
      "gradients: [[2.56836131]\n",
      " [0.84985241]]\n",
      "theta: [[4.15402724]\n",
      " [2.89183104]]\n",
      "gradients: [[2.2558495 ]\n",
      " [3.40019244]]\n",
      "theta: [[4.15948188]\n",
      " [2.89959878]]\n",
      "gradients: [[-3.3655113 ]\n",
      " [-4.79269723]]\n",
      "theta: [[4.16136459]\n",
      " [2.90278389]]\n",
      "gradients: [[-1.16200653]\n",
      " [-1.96584706]]\n",
      "theta: [[4.16549159]\n",
      " [2.90758799]]\n",
      "gradients: [[-2.54801197]\n",
      " [-2.9660528 ]]\n",
      "theta: [[4.16058587]\n",
      " [2.90212503]]\n",
      "gradients: [[3.02977531]\n",
      " [3.37392415]]\n",
      "theta: [[4.16148569]\n",
      " [2.90307458]]\n",
      "gradients: [[-0.5559095 ]\n",
      " [-0.58663334]]\n",
      "theta: [[4.16141211]\n",
      " [2.90298701]]\n",
      "gradients: [[0.04547155]\n",
      " [0.05412259]]\n",
      "theta: [[4.15613417]\n",
      " [2.89647473]]\n",
      "gradients: [[3.26281901]\n",
      " [4.02588915]]\n",
      "theta: [[4.15577479]\n",
      " [2.89597773]]\n",
      "gradients: [[0.22224262]\n",
      " [0.30734298]]\n",
      "theta: [[4.16235809]\n",
      " [2.90477131]]\n",
      "gradients: [[-4.07243095]\n",
      " [-5.4397084 ]]\n",
      "theta: [[4.16130757]\n",
      " [2.90433887]]\n",
      "gradients: [[0.65006178]\n",
      " [0.26759507]]\n",
      "theta: [[4.15898685]\n",
      " [2.90327988]]\n",
      "gradients: [[1.43652705]\n",
      " [0.65551503]]\n",
      "theta: [[4.15764973]\n",
      " [2.90124373]]\n",
      "gradients: [[0.82794877]\n",
      " [1.26078483]]\n",
      "theta: [[4.15806197]\n",
      " [2.90130735]]\n",
      "gradients: [[-0.25534644]\n",
      " [-0.0394033 ]]\n",
      "theta: [[4.16085545]\n",
      " [2.90197681]]\n",
      "gradients: [[-1.7308366 ]\n",
      " [-0.41480029]]\n",
      "theta: [[4.16116519]\n",
      " [2.90236601]]\n",
      "gradients: [[-0.19197618]\n",
      " [-0.24122427]]\n",
      "theta: [[4.16235821]\n",
      " [2.90410785]]\n",
      "gradients: [[-0.73967688]\n",
      " [-1.07994386]]\n",
      "theta: [[4.16530199]\n",
      " [2.90461983]]\n",
      "gradients: [[-1.82572963]\n",
      " [-0.31752808]]\n",
      "theta: [[4.16281974]\n",
      " [2.90089232]]\n",
      "gradients: [[1.53998514]\n",
      " [2.3125463 ]]\n",
      "theta: [[4.16467433]\n",
      " [2.90402985]]\n",
      "gradients: [[-1.15095407]\n",
      " [-1.94714885]]\n",
      "theta: [[4.15996921]\n",
      " [2.89996972]]\n",
      "gradients: [[2.92093448]\n",
      " [2.52052524]]\n",
      "theta: [[4.15848567]\n",
      " [2.89960707]]\n",
      "gradients: [[0.92128128]\n",
      " [0.22520949]]\n",
      "theta: [[4.15293427]\n",
      " [2.89419841]]\n",
      "gradients: [[3.44852814]\n",
      " [3.359858  ]]\n",
      "theta: [[4.15278659]\n",
      " [2.89408731]]\n",
      "gradients: [[0.0917707 ]\n",
      " [0.06903812]]\n",
      "theta: [[4.15312671]\n",
      " [2.89418241]]\n",
      "gradients: [[-0.21141883]\n",
      " [-0.05911514]]\n",
      "theta: [[4.15216704]\n",
      " [2.8934361 ]]\n",
      "gradients: [[0.59672359]\n",
      " [0.464054  ]]\n",
      "theta: [[4.14761941]\n",
      " [2.88841543]]\n",
      "gradients: [[2.82862351]\n",
      " [3.12285783]]\n",
      "theta: [[4.14781118]\n",
      " [2.88855512]]\n",
      "gradients: [[-0.11932019]\n",
      " [-0.08691235]]\n",
      "theta: [[4.14475035]\n",
      " [2.8827907 ]]\n",
      "gradients: [[1.90505981]\n",
      " [3.58777468]]\n",
      "theta: [[4.15022708]\n",
      " [2.8905899 ]]\n",
      "gradients: [[-3.40981311]\n",
      " [-4.85578576]]\n",
      "theta: [[4.15034821]\n",
      " [2.89074451]]\n",
      "gradients: [[-0.07543575]\n",
      " [-0.09628859]]\n",
      "theta: [[4.14726895]\n",
      " [2.88494537]]\n",
      "gradients: [[1.91838037]\n",
      " [3.61286112]]\n",
      "theta: [[4.14731086]\n",
      " [2.88499526]]\n",
      "gradients: [[-0.02611858]\n",
      " [-0.03108769]]\n",
      "theta: [[4.14899594]\n",
      " [2.88588687]]\n",
      "gradients: [[-1.05048263]\n",
      " [-0.55583088]]\n",
      "theta: [[4.15197669]\n",
      " [2.88640528]]\n",
      "gradients: [[-1.8587921 ]\n",
      " [-0.32327826]]\n",
      "theta: [[4.15915026]\n",
      " [2.89932112]]\n",
      "gradients: [[-4.47487641]\n",
      " [-8.05690172]]\n",
      "theta: [[4.16232224]\n",
      " [2.90380477]]\n",
      "gradients: [[-1.97931225]\n",
      " [-2.79779798]]\n",
      "theta: [[4.15765091]\n",
      " [2.8997738 ]]\n",
      "gradients: [[2.91584185]\n",
      " [2.51613072]]\n",
      "theta: [[4.15623402]\n",
      " [2.89737311]]\n",
      "gradients: [[0.88470388]\n",
      " [1.49899185]]\n",
      "theta: [[4.1553737 ]\n",
      " [2.89638378]]\n",
      "gradients: [[0.53735537]\n",
      " [0.6179316 ]]\n",
      "theta: [[4.15105968]\n",
      " [2.88936937]]\n",
      "gradients: [[2.69540392]\n",
      " [4.38260817]]\n",
      "theta: [[4.15144888]\n",
      " [2.88985841]]\n",
      "gradients: [[-0.24325104]\n",
      " [-0.3056528 ]]\n",
      "theta: [[4.14865863]\n",
      " [2.8867937 ]]\n",
      "gradients: [[1.74446131]\n",
      " [1.91605509]]\n",
      "theta: [[4.14403446]\n",
      " [2.88571456]]\n",
      "gradients: [[2.89195734]\n",
      " [0.67489436]]\n",
      "theta: [[4.14408362]\n",
      " [2.88577308]]\n",
      "gradients: [[-0.03075649]\n",
      " [-0.03660797]]\n",
      "theta: [[4.14976009]\n",
      " [2.89141292]]\n",
      "gradients: [[-3.55233166]\n",
      " [-3.52941567]]\n",
      "theta: [[4.15688673]\n",
      " [2.90424426]]\n",
      "gradients: [[-4.46127731]\n",
      " [-8.03241689]]\n",
      "theta: [[4.15369947]\n",
      " [2.90047825]]\n",
      "gradients: [[1.9958655 ]\n",
      " [2.35827947]]\n",
      "theta: [[4.15406407]\n",
      " [2.90107793]]\n",
      "gradients: [[-0.22839078]\n",
      " [-0.37563947]]\n",
      "theta: [[4.15857442]\n",
      " [2.90932648]]\n",
      "gradients: [[-2.82618129]\n",
      " [-5.16854576]]\n",
      "theta: [[4.15773288]\n",
      " [2.9091926 ]]\n",
      "gradients: [[0.52747852]\n",
      " [0.08391983]]\n",
      "theta: [[4.15778017]\n",
      " [2.90922556]]\n",
      "gradients: [[-0.02965174]\n",
      " [-0.02066868]]\n",
      "theta: [[4.1586496 ]\n",
      " [2.90926276]]\n",
      "gradients: [[-0.54530759]\n",
      " [-0.02332869]]\n",
      "theta: [[4.15427625]\n",
      " [2.90215189]]\n",
      "gradients: [[2.743837  ]\n",
      " [4.46135822]]\n",
      "theta: [[4.15423027]\n",
      " [2.90209716]]\n",
      "gradients: [[0.0288562 ]\n",
      " [0.03434614]]\n",
      "theta: [[4.15511116]\n",
      " [2.90213485]]\n",
      "gradients: [[-0.5530173 ]\n",
      " [-0.02365852]]\n",
      "theta: [[4.15516879]\n",
      " [2.90220841]]\n",
      "gradients: [[-0.03619494]\n",
      " [-0.04620037]]\n",
      "theta: [[4.15789237]\n",
      " [2.90271363]]\n",
      "gradients: [[-1.71095184]\n",
      " [-0.31737475]]\n",
      "theta: [[4.16081272]\n",
      " [2.90322153]]\n",
      "gradients: [[-1.83514628]\n",
      " [-0.31916581]]\n",
      "theta: [[4.16074196]\n",
      " [2.90313732]]\n",
      "gradients: [[0.04447541]\n",
      " [0.05293693]]\n",
      "theta: [[4.15988257]\n",
      " [2.90155771]]\n",
      "gradients: [[0.54038774]\n",
      " [0.99325274]]\n",
      "theta: [[4.16028127]\n",
      " [2.90161924]]\n",
      "gradients: [[-0.25078385]\n",
      " [-0.03869923]]\n",
      "theta: [[4.15700099]\n",
      " [2.89898682]]\n",
      "gradients: [[2.06395307]\n",
      " [1.65632168]]\n",
      "theta: [[4.1566998 ]\n",
      " [2.89881809]]\n",
      "gradients: [[0.18956768]\n",
      " [0.10619521]]\n",
      "theta: [[4.15637254]\n",
      " [2.8985099 ]]\n",
      "gradients: [[0.20604384]\n",
      " [0.194036  ]]\n",
      "theta: [[4.15216722]\n",
      " [2.89405187]]\n",
      "gradients: [[2.64851305]\n",
      " [2.80766756]]\n",
      "theta: [[4.15237506]\n",
      " [2.89413773]]\n",
      "gradients: [[-0.13094203]\n",
      " [-0.05409196]]\n",
      "theta: [[4.15204459]\n",
      " [2.89368072]]\n",
      "gradients: [[0.20826064]\n",
      " [0.28800707]]\n",
      "theta: [[4.14800682]\n",
      " [2.89234465]]\n",
      "gradients: [[2.54541438]\n",
      " [0.84225944]]\n",
      "theta: [[4.14341873]\n",
      " [2.89127393]]\n",
      "gradients: [[2.89324455]\n",
      " [0.67519475]]\n",
      "theta: [[4.14022656]\n",
      " [2.88871221]]\n",
      "gradients: [[2.01362379]\n",
      " [1.61593245]]\n",
      "theta: [[4.14076704]\n",
      " [2.88871545]]\n",
      "gradients: [[-0.34104494]\n",
      " [-0.00204044]]\n",
      "theta: [[4.14092411]\n",
      " [2.88891593]]\n",
      "gradients: [[-0.09914106]\n",
      " [-0.1265468 ]]\n",
      "theta: [[4.14146204]\n",
      " [2.88891915]]\n",
      "gradients: [[-0.3396474 ]\n",
      " [-0.00203208]]\n",
      "theta: [[4.13593611]\n",
      " [2.88734879]]\n",
      "gradients: [[3.49017797]\n",
      " [0.99183837]]\n",
      "theta: [[4.13616441]\n",
      " [2.88751509]]\n",
      "gradients: [[-0.14424067]\n",
      " [-0.10506433]]\n",
      "theta: [[4.13674891]\n",
      " [2.88774094]]\n",
      "gradients: [[-0.36940196]\n",
      " [-0.14273933]]\n",
      "theta: [[4.1344835 ]\n",
      " [2.88433906]]\n",
      "gradients: [[1.432186  ]\n",
      " [2.15066779]]\n",
      "theta: [[4.12987253]\n",
      " [2.87920433]]\n",
      "gradients: [[2.91597963]\n",
      " [3.24720255]]\n",
      "theta: [[4.13048652]\n",
      " [2.87944158]]\n",
      "gradients: [[-0.38840837]\n",
      " [-0.15008353]]\n",
      "theta: [[4.12551992]\n",
      " [2.87331345]]\n",
      "gradients: [[3.14286391]\n",
      " [3.87788035]]\n",
      "theta: [[4.12660499]\n",
      " [2.87445849]]\n",
      "gradients: [[-0.68684926]\n",
      " [-0.72480984]]\n",
      "theta: [[4.12393604]\n",
      " [2.87290209]]\n",
      "gradients: [[1.68997968]\n",
      " [0.98551002]]\n",
      "theta: [[4.12487411]\n",
      " [2.87444235]]\n",
      "gradients: [[-0.59417649]\n",
      " [-0.97559953]]\n",
      "theta: [[4.12545183]\n",
      " [2.87494226]]\n",
      "gradients: [[-0.36603815]\n",
      " [-0.31674042]]\n",
      "theta: [[4.12831953]\n",
      " [2.87772705]]\n",
      "gradients: [[-1.81754916]\n",
      " [-1.7650016 ]]\n",
      "theta: [[4.12922498]\n",
      " [2.87946855]]\n",
      "gradients: [[-0.57405758]\n",
      " [-1.10410979]]\n",
      "theta: [[4.13594516]\n",
      " [2.88055225]]\n",
      "gradients: [[-4.26193576]\n",
      " [-0.68728288]]\n",
      "theta: [[4.13158328]\n",
      " [2.87684443]]\n",
      "gradients: [[2.76717214]\n",
      " [2.35223858]]\n",
      "theta: [[4.13374295]\n",
      " [2.87722516]]\n",
      "gradients: [[-1.37052354]\n",
      " [-0.24160555]]\n",
      "theta: [[4.12939967]\n",
      " [2.87353315]]\n",
      "gradients: [[2.75711132]\n",
      " [2.34368636]]\n",
      "theta: [[4.12858526]\n",
      " [2.8728998 ]]\n",
      "gradients: [[0.5171529 ]\n",
      " [0.40217426]]\n",
      "theta: [[4.12961375]\n",
      " [2.87397491]]\n",
      "gradients: [[-0.65330027]\n",
      " [-0.68290553]]\n",
      "theta: [[4.1298262 ]\n",
      " [2.87412299]]\n",
      "gradients: [[-0.13498682]\n",
      " [-0.0940923 ]]\n",
      "theta: [[4.13403925]\n",
      " [2.87902726]]\n",
      "gradients: [[-2.67781508]\n",
      " [-3.11715212]]\n",
      "theta: [[4.12960937]\n",
      " [2.87520464]]\n",
      "gradients: [[2.81651398]\n",
      " [2.43041898]]\n",
      "theta: [[4.12435273]\n",
      " [2.87008316]]\n",
      "gradients: [[3.34322559]\n",
      " [3.25726305]]\n",
      "theta: [[4.12458997]\n",
      " [2.87024853]]\n",
      "gradients: [[-0.15093434]\n",
      " [-0.10520848]]\n",
      "theta: [[4.12153809]\n",
      " [2.86779939]]\n",
      "gradients: [[1.94222051]\n",
      " [1.55863134]]\n",
      "theta: [[4.12141666]\n",
      " [2.86768504]]\n",
      "gradients: [[0.07729844]\n",
      " [0.07279363]]\n",
      "theta: [[4.1207894 ]\n",
      " [2.86696372]]\n",
      "gradients: [[0.39944109]\n",
      " [0.45933713]]\n",
      "theta: [[4.11681677]\n",
      " [2.8605044 ]]\n",
      "gradients: [[2.53056387]\n",
      " [4.11458549]]\n",
      "theta: [[4.11749733]\n",
      " [2.86162372]]\n",
      "gradients: [[-0.43364792]\n",
      " [-0.71323051]]\n",
      "theta: [[4.11784027]\n",
      " [2.86187352]]\n",
      "gradients: [[-0.21859431]\n",
      " [-0.15922323]]\n",
      "theta: [[4.11818779]\n",
      " [2.86241815]]\n",
      "gradients: [[-0.22157729]\n",
      " [-0.34725404]]\n",
      "theta: [[4.11944669]\n",
      " [2.86257139]]\n",
      "gradients: [[-0.80292532]\n",
      " [-0.09773675]]\n",
      "theta: [[4.12317376]\n",
      " [2.8667215 ]]\n",
      "gradients: [[-2.37786918]\n",
      " [-2.64776974]]\n",
      "theta: [[4.12348042]\n",
      " [2.86720211]]\n",
      "gradients: [[-0.1957149 ]\n",
      " [-0.30672273]]\n",
      "theta: [[4.12361309]\n",
      " [2.86723972]]\n",
      "gradients: [[-0.08469365]\n",
      " [-0.02401116]]\n",
      "theta: [[4.12467021]\n",
      " [2.86834474]]\n",
      "gradients: [[-0.67507777]\n",
      " [-0.70566991]]\n",
      "theta: [[4.12368227]\n",
      " [2.86755093]]\n",
      "gradients: [[0.63109371]\n",
      " [0.50708746]]\n",
      "theta: [[4.12915231]\n",
      " [2.87534061]]\n",
      "gradients: [[-3.49535401]\n",
      " [-4.97760131]]\n",
      "theta: [[4.12382022]\n",
      " [2.8675959 ]]\n",
      "gradients: [[3.40826976]\n",
      " [4.95041403]]\n",
      "theta: [[4.12949582]\n",
      " [2.87323489]]\n",
      "gradients: [[-3.62897829]\n",
      " [-3.60556785]]\n",
      "theta: [[4.12960408]\n",
      " [2.87326558]]\n",
      "gradients: [[-0.06924218]\n",
      " [-0.01963057]]\n",
      "theta: [[4.12515342]\n",
      " [2.87222693]]\n",
      "gradients: [[2.84753414]\n",
      " [0.66452734]]\n",
      "theta: [[4.12623135]\n",
      " [2.87336444]]\n",
      "gradients: [[-0.68987539]\n",
      " [-0.72800322]]\n",
      "theta: [[4.12414121]\n",
      " [2.87241067]]\n",
      "gradients: [[1.33810614]\n",
      " [0.61060367]]\n",
      "theta: [[4.12151369]\n",
      " [2.87087843]]\n",
      "gradients: [[1.68266375]\n",
      " [0.98124374]]\n",
      "theta: [[4.12137773]\n",
      " [2.87080226]]\n",
      "gradients: [[0.08710064]\n",
      " [0.0487935 ]]\n",
      "theta: [[4.12559502]\n",
      " [2.87571147]]\n",
      "gradients: [[-2.70244311]\n",
      " [-3.14582076]]\n",
      "theta: [[4.12621852]\n",
      " [2.8759524 ]]\n",
      "gradients: [[-0.39966272]\n",
      " [-0.15443228]]\n",
      "theta: [[4.12407298]\n",
      " [2.87273051]]\n",
      "gradients: [[1.37572028]\n",
      " [2.06587502]]\n",
      "theta: [[4.12585343]\n",
      " [2.87274399]]\n",
      "gradients: [[-1.14198348]\n",
      " [-0.00864488]]\n",
      "theta: [[4.1329861 ]\n",
      " [2.88558616]]\n",
      "gradients: [[-4.57631653]\n",
      " [-8.23954209]]\n",
      "theta: [[4.13399266]\n",
      " [2.88664836]]\n",
      "gradients: [[-0.64601491]\n",
      " [-0.68171867]]\n",
      "theta: [[4.1367746 ]\n",
      " [2.88731506]]\n",
      "gradients: [[-1.78600136]\n",
      " [-0.42802069]]\n",
      "theta: [[4.14378488]\n",
      " [2.8999369 ]]\n",
      "gradients: [[-4.5020045 ]\n",
      " [-8.10574515]]\n",
      "theta: [[4.14981648]\n",
      " [2.90041003]]\n",
      "gradients: [[-3.87469551]\n",
      " [-0.30394082]]\n",
      "theta: [[4.15249672]\n",
      " [2.90090721]]\n",
      "gradients: [[-1.72232366]\n",
      " [-0.31948418]]\n",
      "theta: [[4.15090687]\n",
      " [2.90031749]]\n",
      "gradients: [[1.02195679]\n",
      " [0.3790721 ]]\n",
      "theta: [[4.149502  ]\n",
      " [2.89997407]]\n",
      "gradients: [[0.90332661]\n",
      " [0.22082043]]\n",
      "theta: [[4.14486762]\n",
      " [2.89481326]]\n",
      "gradients: [[2.98083856]\n",
      " [3.31942874]]\n",
      "theta: [[4.14487916]\n",
      " [2.89482701]]\n",
      "gradients: [[-0.0074307]\n",
      " [-0.0088444]]\n",
      "theta: [[4.14454447]\n",
      " [2.89469513]]\n",
      "gradients: [[0.21540716]\n",
      " [0.08487672]]\n",
      "theta: [[4.14057619]\n",
      " [2.88721428]]\n",
      "gradients: [[2.5547818 ]\n",
      " [4.81617398]]\n",
      "theta: [[4.1397054 ]\n",
      " [2.88653709]]\n",
      "gradients: [[0.56078473]\n",
      " [0.43610543]]\n",
      "theta: [[4.13631001]\n",
      " [2.88141929]]\n",
      "gradients: [[2.18731409]\n",
      " [3.29689052]]\n",
      "theta: [[4.1355949 ]\n",
      " [2.88059695]]\n",
      "gradients: [[0.46081516]\n",
      " [0.52991422]]\n",
      "theta: [[4.13347974]\n",
      " [2.87963176]]\n",
      "gradients: [[1.36343392]\n",
      " [0.62216122]]\n",
      "theta: [[4.13433735]\n",
      " [2.88103991]]\n",
      "gradients: [[-0.55298974]\n",
      " [-0.90797353]]\n",
      "theta: [[4.13710935]\n",
      " [2.88373176]]\n",
      "gradients: [[-1.78793538]\n",
      " [-1.73624399]]\n",
      "theta: [[4.1431394 ]\n",
      " [2.88420477]]\n",
      "gradients: [[-3.89058893]\n",
      " [-0.30518754]]\n",
      "theta: [[4.14632203]\n",
      " [2.88870348]]\n",
      "gradients: [[-2.0540685 ]\n",
      " [-2.90346746]]\n",
      "theta: [[4.15286596]\n",
      " [2.88975876]]\n",
      "gradients: [[-4.22476321]\n",
      " [-0.68128841]]\n",
      "theta: [[4.15382861]\n",
      " [2.8908695 ]]\n",
      "gradients: [[-0.62167984]\n",
      " [-0.71731793]]\n",
      "theta: [[4.14838585]\n",
      " [2.88932278]]\n",
      "gradients: [[3.51601962]\n",
      " [0.99918204]]\n",
      "theta: [[4.15385889]\n",
      " [2.89476051]]\n",
      "gradients: [[-3.53667359]\n",
      " [-3.51385861]]\n",
      "theta: [[4.1543442 ]\n",
      " [2.89476341]]\n",
      "gradients: [[-0.31370792]\n",
      " [-0.00187689]]\n",
      "theta: [[4.15416563]\n",
      " [2.89472841]]\n",
      "gradients: [[0.11546264]\n",
      " [0.02263396]]\n",
      "theta: [[4.15276317]\n",
      " [2.89438557]]\n",
      "gradients: [[0.90711162]\n",
      " [0.22174568]]\n",
      "theta: [[4.15717316]\n",
      " [2.9024506 ]]\n",
      "gradients: [[-2.85326116]\n",
      " [-5.21806967]]\n",
      "theta: [[4.15409498]\n",
      " [2.89881347]]\n",
      "gradients: [[1.99219963]\n",
      " [2.35394794]]\n",
      "theta: [[4.14909361]\n",
      " [2.89264244]]\n",
      "gradients: [[3.23788555]\n",
      " [3.99512455]]\n",
      "theta: [[4.14652389]\n",
      " [2.88753396]]\n",
      "gradients: [[1.66414756]\n",
      " [3.30825512]]\n",
      "theta: [[4.14206568]\n",
      " [2.88649354]]\n",
      "gradients: [[2.88803336]\n",
      " [0.67397862]]\n",
      "theta: [[4.14398108]\n",
      " [2.88973396]]\n",
      "gradients: [[-1.24118103]\n",
      " [-2.09979205]]\n",
      "theta: [[4.14587307]\n",
      " [2.89293477]]\n",
      "gradients: [[-1.22638614]\n",
      " [-2.0747625 ]]\n",
      "theta: [[4.14557706]\n",
      " [2.89252542]]\n",
      "gradients: [[0.19192946]\n",
      " [0.26542241]]\n",
      "theta: [[4.1446843 ]\n",
      " [2.89183114]]\n",
      "gradients: [[0.57904711]\n",
      " [0.45030753]]\n",
      "theta: [[4.14478726]\n",
      " [2.89203392]]\n",
      "gradients: [[-0.06680296]\n",
      " [-0.13156135]]\n",
      "theta: [[4.14401348]\n",
      " [2.89114411]]\n",
      "gradients: [[0.50218225]\n",
      " [0.57748429]]\n",
      "theta: [[4.13999596]\n",
      " [2.88688517]]\n",
      "gradients: [[2.60817811]\n",
      " [2.76490881]]\n",
      "theta: [[4.13733003]\n",
      " [2.88533053]]\n",
      "gradients: [[1.73125482]\n",
      " [1.00957958]]\n",
      "theta: [[4.13648125]\n",
      " [2.88467047]]\n",
      "gradients: [[0.55136255]\n",
      " [0.42877808]]\n",
      "theta: [[4.13437457]\n",
      " [2.88370915]]\n",
      "gradients: [[1.36892427]\n",
      " [0.62466657]]\n",
      "theta: [[4.13426505]\n",
      " [2.88368768]]\n",
      "gradients: [[0.07118946]\n",
      " [0.01395516]]\n",
      "theta: [[4.13445726]\n",
      " [2.88393303]]\n",
      "gradients: [[-0.12498027]\n",
      " [-0.15952878]]\n",
      "theta: [[4.13720384]\n",
      " [2.88459126]]\n",
      "gradients: [[-1.78637363]\n",
      " [-0.42810991]]\n",
      "theta: [[4.13708519]\n",
      " [2.884568  ]]\n",
      "gradients: [[0.07719385]\n",
      " [0.01513219]]\n",
      "theta: [[4.13789891]\n",
      " [2.88590407]]\n",
      "gradients: [[-0.52956887]\n",
      " [-0.86951798]]\n",
      "theta: [[4.1383591 ]\n",
      " [2.88597508]]\n",
      "gradients: [[-0.29958229]\n",
      " [-0.04622947]]\n",
      "theta: [[4.14432921]\n",
      " [2.8864434 ]]\n",
      "gradients: [[-3.88773748]\n",
      " [-0.30496387]]\n",
      "theta: [[4.14473459]\n",
      " [2.88695277]]\n",
      "gradients: [[-0.26406512]\n",
      " [-0.33180637]]\n",
      "theta: [[4.14397848]\n",
      " [2.88683248]]\n",
      "gradients: [[0.49267972]\n",
      " [0.07838348]]\n",
      "theta: [[4.14411335]\n",
      " [2.88709807]]\n",
      "gradients: [[-0.08790327]\n",
      " [-0.17311619]]\n",
      "theta: [[4.14183433]\n",
      " [2.88398507]]\n",
      "gradients: [[1.48592066]\n",
      " [2.02967784]]\n",
      "theta: [[4.14228251]\n",
      " [2.88405423]]\n",
      "gradients: [[-0.29230371]\n",
      " [-0.04510629]]\n",
      "theta: [[4.13940536]\n",
      " [2.87863574]]\n",
      "gradients: [[1.87704954]\n",
      " [3.53502331]]\n",
      "theta: [[4.13697036]\n",
      " [2.87379506]]\n",
      "gradients: [[1.58908161]\n",
      " [3.15902717]]\n",
      "theta: [[4.13771664]\n",
      " [2.87481961]]\n",
      "gradients: [[-0.4871711 ]\n",
      " [-0.66882862]]\n",
      "theta: [[4.14044899]\n",
      " [2.87547443]]\n",
      "gradients: [[-1.78422299]\n",
      " [-0.4275945 ]]\n",
      "theta: [[4.14032635]\n",
      " [2.87545039]]\n",
      "gradients: [[0.08010983]\n",
      " [0.01570381]]\n",
      "theta: [[4.13971757]\n",
      " [2.87433143]]\n",
      "gradients: [[0.39777731]\n",
      " [0.73112947]]\n",
      "theta: [[4.14259604]\n",
      " [2.87483205]]\n",
      "gradients: [[-1.88136826]\n",
      " [-0.32720467]]\n",
      "theta: [[4.14970997]\n",
      " [2.88809491]]\n",
      "gradients: [[-4.6510876 ]\n",
      " [-8.67125988]]\n",
      "theta: [[4.14973097]\n",
      " [2.88811991]]\n",
      "gradients: [[-0.01373906]\n",
      " [-0.01635294]]\n",
      "theta: [[4.14573648]\n",
      " [2.88388538]]\n",
      "gradients: [[2.61320123]\n",
      " [2.77023379]]\n",
      "theta: [[4.15203967]\n",
      " [2.89230481]]\n",
      "gradients: [[-4.12481207]\n",
      " [-5.50967595]]\n",
      "theta: [[4.15712269]\n",
      " [2.90059928]]\n",
      "gradients: [[-3.32734341]\n",
      " [-5.42956374]]\n",
      "theta: [[4.15314865]\n",
      " [2.89310759]]\n",
      "gradients: [[2.60219879]\n",
      " [4.90556262]]\n",
      "theta: [[4.15828397]\n",
      " [2.9004206 ]]\n",
      "gradients: [[-3.36363272]\n",
      " [-4.79002201]]\n",
      "theta: [[4.16115257]\n",
      " [2.90169635]]\n",
      "gradients: [[-1.87950817]\n",
      " [-0.83586988]]\n",
      "theta: [[4.16223197]\n",
      " [2.90182774]]\n",
      "gradients: [[-0.70743341]\n",
      " [-0.08611292]]\n",
      "theta: [[4.16307584]\n",
      " [2.90271825]]\n",
      "gradients: [[-0.55324476]\n",
      " [-0.58382132]]\n",
      "theta: [[4.16308054]\n",
      " [2.90272562]]\n",
      "gradients: [[-0.00308314]\n",
      " [-0.00483186]]\n",
      "theta: [[4.16735207]\n",
      " [2.91053743]]\n",
      "gradients: [[-2.80212172]\n",
      " [-5.1245454 ]]\n",
      "theta: [[4.16770726]\n",
      " [2.91059224]]\n",
      "gradients: [[-0.23307348]\n",
      " [-0.03596629]]\n",
      "theta: [[4.16829054]\n",
      " [2.91154994]]\n",
      "gradients: [[-0.38286449]\n",
      " [-0.62863883]]\n",
      "theta: [[4.16789354]\n",
      " [2.91150907]]\n",
      "gradients: [[0.26066829]\n",
      " [0.02683643]]\n",
      "theta: [[4.17209629]\n",
      " [2.91919511]]\n",
      "gradients: [[-2.76036922]\n",
      " [-5.04818805]]\n",
      "theta: [[4.17843325]\n",
      " [2.92021701]]\n",
      "gradients: [[-4.16338047]\n",
      " [-0.67138978]]\n",
      "theta: [[4.17728339]\n",
      " [2.91991099]]\n",
      "gradients: [[0.75568925]\n",
      " [0.20111385]]\n",
      "theta: [[4.1777901 ]\n",
      " [2.92074298]]\n",
      "gradients: [[-0.33311063]\n",
      " [-0.5469462 ]]\n",
      "theta: [[4.17818619]\n",
      " [2.92089603]]\n",
      "gradients: [[-0.26047164]\n",
      " [-0.10064794]]\n",
      "theta: [[4.17978628]\n",
      " [2.92360301]]\n",
      "gradients: [[-1.05253785]\n",
      " [-1.7806513 ]]\n",
      "theta: [[4.18122196]\n",
      " [2.92436265]]\n",
      "gradients: [[-0.94467555]\n",
      " [-0.49984629]]\n",
      "theta: [[4.18279403]\n",
      " [2.92702224]]\n",
      "gradients: [[-1.03473686]\n",
      " [-1.75053614]]\n",
      "theta: [[4.18179362]\n",
      " [2.92587182]]\n",
      "gradients: [[0.65866538]\n",
      " [0.757432  ]]\n",
      "theta: [[4.17727424]\n",
      " [2.92481714]]\n",
      "gradients: [[2.97646659]\n",
      " [0.69461623]]\n",
      "theta: [[4.17258129]\n",
      " [2.91959112]]\n",
      "gradients: [[3.09171297]\n",
      " [3.44289725]]\n",
      "theta: [[4.16844529]\n",
      " [2.91520658]]\n",
      "gradients: [[2.72562662]\n",
      " [2.88941505]]\n",
      "theta: [[4.16566292]\n",
      " [2.91215052]]\n",
      "gradients: [[1.83413721]\n",
      " [2.01455195]]\n",
      "theta: [[4.16129482]\n",
      " [2.90843741]]\n",
      "gradients: [[2.88032798]\n",
      " [2.44842686]]\n",
      "theta: [[4.1639039 ]\n",
      " [2.90906268]]\n",
      "gradients: [[-1.72095343]\n",
      " [-0.41243175]]\n",
      "theta: [[4.1639898 ]\n",
      " [2.90912525]]\n",
      "gradients: [[-0.05667245]\n",
      " [-0.04127999]]\n",
      "theta: [[4.16705023]\n",
      " [2.91268169]]\n",
      "gradients: [[-2.01988854]\n",
      " [-2.34724857]]\n",
      "theta: [[4.16956622]\n",
      " [2.91512493]]\n",
      "gradients: [[-1.66105567]\n",
      " [-1.61303253]]\n",
      "theta: [[4.17629988]\n",
      " [2.92767883]]\n",
      "gradients: [[-4.44690705]\n",
      " [-8.29059567]]\n",
      "theta: [[4.17465074]\n",
      " [2.92706712]]\n",
      "gradients: [[1.08942379]\n",
      " [0.40409748]]\n",
      "theta: [[4.17426283]\n",
      " [2.92684982]]\n",
      "gradients: [[0.25632817]\n",
      " [0.14359423]]\n",
      "theta: [[4.17692887]\n",
      " [2.9280984 ]]\n",
      "gradients: [[-1.76224983]\n",
      " [-0.8253136 ]]\n",
      "theta: [[4.1724602]\n",
      " [2.9231649]]\n",
      "gradients: [[2.95468293]\n",
      " [3.26203   ]]\n",
      "theta: [[4.17498302]\n",
      " [2.92363288]]\n",
      "gradients: [[-1.66859433]\n",
      " [-0.3095176 ]]\n",
      "theta: [[4.1705063 ]\n",
      " [2.92258815]]\n",
      "gradients: [[2.96180038]\n",
      " [0.69119358]]\n",
      "theta: [[4.17098547]\n",
      " [2.92350976]]\n",
      "gradients: [[-0.31711747]\n",
      " [-0.60992576]]\n",
      "theta: [[4.17765134]\n",
      " [2.93593728]]\n",
      "gradients: [[-4.41280403]\n",
      " [-8.22701568]]\n",
      "theta: [[4.17741571]\n",
      " [2.93565682]]\n",
      "gradients: [[0.1560326 ]\n",
      " [0.18571807]]\n",
      "theta: [[4.17842211]\n",
      " [2.93577933]]\n",
      "gradients: [[-0.6666394 ]\n",
      " [-0.08114723]]\n",
      "theta: [[4.17853061]\n",
      " [2.93591567]]\n",
      "gradients: [[-0.07189494]\n",
      " [-0.09033832]]\n",
      "theta: [[4.17311265]\n",
      " [2.93437599]]\n",
      "gradients: [[3.59102605]\n",
      " [1.02049736]]\n",
      "theta: [[4.17265135]\n",
      " [2.93394157]]\n",
      "gradients: [[0.30584085]\n",
      " [0.28801703]]\n",
      "theta: [[4.17302931]\n",
      " [2.93446046]]\n",
      "gradients: [[-0.25066094]\n",
      " [-0.34412799]]\n",
      "theta: [[4.1792949 ]\n",
      " [2.93547086]]\n",
      "gradients: [[-4.15659103]\n",
      " [-0.67029491]]\n",
      "theta: [[4.17511659]\n",
      " [2.93104147]]\n",
      "gradients: [[2.77272179]\n",
      " [2.93934026]]\n",
      "theta: [[4.17469729]\n",
      " [2.9309983 ]]\n",
      "gradients: [[0.27833381]\n",
      " [0.02865513]]\n",
      "theta: [[4.17054963]\n",
      " [2.92660141]]\n",
      "gradients: [[2.75404394]\n",
      " [2.91954002]]\n",
      "theta: [[4.17078708]\n",
      " [2.9266678 ]]\n",
      "gradients: [[-0.1577101 ]\n",
      " [-0.04409756]]\n",
      "theta: [[4.16548024]\n",
      " [2.92149742]]\n",
      "gradients: [[3.52586083]\n",
      " [3.43520228]]\n",
      "theta: [[4.16568137]\n",
      " [2.92175014]]\n",
      "gradients: [[-0.13367004]\n",
      " [-0.16796073]]\n",
      "theta: [[4.16328638]\n",
      " [2.91815365]]\n",
      "gradients: [[1.59219199]\n",
      " [2.39094364]]\n",
      "theta: [[4.16607394]\n",
      " [2.91939336]]\n",
      "gradients: [[-1.85373059]\n",
      " [-0.82440586]]\n",
      "theta: [[4.16711616]\n",
      " [2.91952023]]\n",
      "gradients: [[-0.69328231]\n",
      " [-0.08439036]]\n",
      "theta: [[4.17035587]\n",
      " [2.92312766]]\n",
      "gradients: [[-2.15570459]\n",
      " [-2.4003883 ]]\n",
      "theta: [[4.17609192]\n",
      " [2.92357761]]\n",
      "gradients: [[-3.81791525]\n",
      " [-0.29948684]]\n",
      "theta: [[4.1790389]\n",
      " [2.9270022]]\n",
      "gradients: [[-1.96209501]\n",
      " [-2.28008855]]\n",
      "theta: [[4.18039313]\n",
      " [2.92714732]]\n",
      "gradients: [[-0.90192196]\n",
      " [-0.09665336]]\n",
      "theta: [[4.17721753]\n",
      " [2.92116676]]\n",
      "gradients: [[2.11558413]\n",
      " [3.98425244]]\n",
      "theta: [[4.17298632]\n",
      " [2.91428698]]\n",
      "gradients: [[2.81968364]\n",
      " [4.58468152]]\n",
      "theta: [[4.17897056]\n",
      " [2.92228037]]\n",
      "gradients: [[-3.98909511]\n",
      " [-5.32839339]]\n",
      "theta: [[4.17649343]\n",
      " [2.91889677]]\n",
      "gradients: [[1.65174888]\n",
      " [2.25618916]]\n",
      "theta: [[4.17923204]\n",
      " [2.92011471]]\n",
      "gradients: [[-1.82665552]\n",
      " [-0.81236482]]\n",
      "theta: [[4.17799791]\n",
      " [2.91912307]]\n",
      "gradients: [[0.8234123 ]\n",
      " [0.66161657]]\n",
      "theta: [[4.18052679]\n",
      " [2.92378049]]\n",
      "gradients: [[-1.68777173]\n",
      " [-3.10835661]]\n",
      "theta: [[4.18096491]\n",
      " [2.92462314]]\n",
      "gradients: [[-0.29248993]\n",
      " [-0.56255854]]\n",
      "theta: [[4.18191592]\n",
      " [2.92601164]]\n",
      "gradients: [[-0.63508566]\n",
      " [-0.92723846]]\n",
      "theta: [[4.18204983]\n",
      " [2.92617991]]\n",
      "gradients: [[-0.08945414]\n",
      " [-0.11240202]]\n",
      "theta: [[4.18151671]\n",
      " [2.92544264]]\n",
      "gradients: [[0.35623349]\n",
      " [0.49264117]]\n",
      "theta: [[4.18422585]\n",
      " [2.92664747]]\n",
      "gradients: [[-1.81078669]\n",
      " [-0.80530751]]\n",
      "theta: [[4.18467021]\n",
      " [2.92737709]]\n",
      "gradients: [[-0.29710399]\n",
      " [-0.48782561]]\n",
      "theta: [[4.1878148 ]\n",
      " [2.93087861]]\n",
      "gradients: [[-2.10309915]\n",
      " [-2.34181188]]\n",
      "theta: [[4.19045382]\n",
      " [2.93133758]]\n",
      "gradients: [[-1.7655046 ]\n",
      " [-0.30705384]]\n",
      "theta: [[4.19024256]\n",
      " [2.93100649]]\n",
      "gradients: [[0.14137676]\n",
      " [0.22156446]]\n",
      "theta: [[4.1933556 ]\n",
      " [2.93447288]]\n",
      "gradients: [[-2.08387176]\n",
      " [-2.32040207]]\n",
      "theta: [[4.1971443 ]\n",
      " [2.93634888]]\n",
      "gradients: [[-2.53691154]\n",
      " [-1.25617028]]\n",
      "theta: [[4.19557571]\n",
      " [2.93613009]]\n",
      "gradients: [[1.05064185]\n",
      " [0.14654853]]\n",
      "theta: [[4.1926886 ]\n",
      " [2.93295899]]\n",
      "gradients: [[1.93436135]\n",
      " [2.12463463]]\n",
      "theta: [[4.1894626 ]\n",
      " [2.92688351]]\n",
      "gradients: [[2.16206515]\n",
      " [4.07178955]]\n",
      "theta: [[4.18276111]\n",
      " [2.91639667]]\n",
      "gradients: [[4.49268203]\n",
      " [7.03037547]]\n",
      "theta: [[4.18053856]\n",
      " [2.91538248]]\n",
      "gradients: [[1.49043854]\n",
      " [0.68011588]]\n",
      "theta: [[4.18081265]\n",
      " [2.91561965]]\n",
      "gradients: [[-0.18385656]\n",
      " [-0.15909491]]\n",
      "theta: [[4.17643873]\n",
      " [2.91079076]]\n",
      "gradients: [[2.93489691]\n",
      " [3.24018583]]\n",
      "theta: [[4.18016225]\n",
      " [2.91512518]]\n",
      "gradients: [[-2.49922263]\n",
      " [-2.90925881]]\n",
      "theta: [[4.18634122]\n",
      " [2.9161216 ]]\n",
      "gradients: [[-4.1485612 ]\n",
      " [-0.66900002]]\n",
      "theta: [[4.1879082 ]\n",
      " [2.91877257]]\n",
      "gradients: [[-1.05238226]\n",
      " [-1.78038807]]\n",
      "theta: [[4.18769648]\n",
      " [2.91857836]]\n",
      "gradients: [[0.14222993]\n",
      " [0.13046632]]\n",
      "theta: [[4.19033044]\n",
      " [2.91903646]]\n",
      "gradients: [[-1.77001971]\n",
      " [-0.3078391 ]]\n",
      "theta: [[4.18666616]\n",
      " [2.91510472]]\n",
      "gradients: [[2.46313164]\n",
      " [2.64291262]]\n",
      "theta: [[4.18207236]\n",
      " [2.90998913]]\n",
      "gradients: [[3.08886553]\n",
      " [3.43972637]]\n",
      "theta: [[4.18260182]\n",
      " [2.91085846]]\n",
      "gradients: [[-0.35611481]\n",
      " [-0.58471758]]\n",
      "theta: [[4.18420359]\n",
      " [2.91356829]]\n",
      "gradients: [[-1.07766908]\n",
      " [-1.82316753]]\n",
      "theta: [[4.18316199]\n",
      " [2.91313952]]\n",
      "gradients: [[0.70099524]\n",
      " [0.28856161]]\n",
      "theta: [[4.17880353]\n",
      " [2.90832768]]\n",
      "gradients: [[2.93411936]\n",
      " [3.2393274 ]]\n",
      "theta: [[4.17958605]\n",
      " [2.90923059]]\n",
      "gradients: [[-0.52695364]\n",
      " [-0.60801923]]\n",
      "theta: [[4.17815996]\n",
      " [2.90681429]]\n",
      "gradients: [[0.96062027]\n",
      " [1.62762026]]\n",
      "theta: [[4.18380683]\n",
      " [2.90725725]]\n",
      "gradients: [[-3.8048664 ]\n",
      " [-0.29846325]]\n",
      "theta: [[4.18277567]\n",
      " [2.90683277]]\n",
      "gradients: [[0.6950059 ]\n",
      " [0.28609612]]\n",
      "theta: [[4.18921251]\n",
      " [2.91842214]]\n",
      "gradients: [[-4.33972007]\n",
      " [-7.81355615]]\n",
      "theta: [[4.18500915]\n",
      " [2.91158766]]\n",
      "gradients: [[2.83474835]\n",
      " [4.60917608]]\n",
      "theta: [[4.18366717]\n",
      " [2.90954413]]\n",
      "gradients: [[0.90529523]\n",
      " [1.37856656]]\n",
      "theta: [[4.18340587]\n",
      " [2.90934756]]\n",
      "gradients: [[0.17632535]\n",
      " [0.13264769]]\n",
      "theta: [[4.17848365]\n",
      " [2.90327418]]\n",
      "gradients: [[3.3225027 ]\n",
      " [4.09953097]]\n",
      "theta: [[4.1757763 ]\n",
      " [2.90030052]]\n",
      "gradients: [[1.82800166]\n",
      " [2.00781289]]\n",
      "theta: [[4.17636932]\n",
      " [2.90127421]]\n",
      "gradients: [[-0.40052307]\n",
      " [-0.65763309]]\n",
      "theta: [[4.18117898]\n",
      " [2.90912264]]\n",
      "gradients: [[-3.24941154]\n",
      " [-5.30239441]]\n",
      "theta: [[4.18110027]\n",
      " [2.90899927]]\n",
      "gradients: [[0.05319695]\n",
      " [0.08336981]]\n",
      "theta: [[4.1827082 ]\n",
      " [2.91171952]]\n",
      "gradients: [[-1.08696284]\n",
      " [-1.83889044]]\n",
      "theta: [[4.18051053]\n",
      " [2.91071669]]\n",
      "gradients: [[1.48606418]\n",
      " [0.67811977]]\n",
      "theta: [[4.17961197]\n",
      " [2.9090651 ]]\n",
      "gradients: [[0.6077872 ]\n",
      " [1.11713545]]\n",
      "theta: [[4.17841001]\n",
      " [2.9089791 ]]\n",
      "gradients: [[0.8132419 ]\n",
      " [0.05818184]]\n",
      "theta: [[4.18454779]\n",
      " [2.90996889]]\n",
      "gradients: [[-4.1540479 ]\n",
      " [-0.66988481]]\n",
      "theta: [[4.18351571]\n",
      " [2.90954403]]\n",
      "gradients: [[0.69872029]\n",
      " [0.28762513]]\n",
      "theta: [[4.18611458]\n",
      " [2.91076116]]\n",
      "gradients: [[-1.75995369]\n",
      " [-0.82423825]]\n",
      "theta: [[4.18593161]\n",
      " [2.91059332]]\n",
      "gradients: [[0.1239451]\n",
      " [0.1136938]]\n",
      "theta: [[4.18179535]\n",
      " [2.90386795]]\n",
      "gradients: [[2.8027279 ]\n",
      " [4.55711223]]\n",
      "theta: [[4.18769578]\n",
      " [2.91174939]]\n",
      "gradients: [[-3.99931128]\n",
      " [-5.34203954]]\n",
      "theta: [[4.18806099]\n",
      " [2.91189051]]\n",
      "gradients: [[-0.24761063]\n",
      " [-0.09567836]]\n",
      "theta: [[4.18766856]\n",
      " [2.91167067]]\n",
      "gradients: [[0.26614489]\n",
      " [0.14909352]]\n",
      "theta: [[4.18761892]\n",
      " [2.91163607]]\n",
      "gradients: [[0.0336743 ]\n",
      " [0.02347261]]\n",
      "theta: [[4.18363306]\n",
      " [2.90412209]]\n",
      "gradients: [[2.70480348]\n",
      " [5.09898894]]\n",
      "theta: [[4.18632239]\n",
      " [2.90531811]]\n",
      "gradients: [[-1.82551768]\n",
      " [-0.81185879]]\n",
      "theta: [[4.18685693]\n",
      " [2.90619579]]\n",
      "gradients: [[-0.36295378]\n",
      " [-0.59594672]]\n",
      "theta: [[4.18835268]\n",
      " [2.90620711]]\n",
      "gradients: [[-1.0159089 ]\n",
      " [-0.00769049]]\n",
      "theta: [[4.18831231]\n",
      " [2.90617898]]\n",
      "gradients: [[0.02742582]\n",
      " [0.01911711]]\n",
      "theta: [[4.18858341]\n",
      " [2.90641356]]\n",
      "gradients: [[-0.18423704]\n",
      " [-0.15942414]]\n",
      "theta: [[4.18757331]\n",
      " [2.90562804]]\n",
      "gradients: [[0.68666058]\n",
      " [0.53399529]]\n",
      "theta: [[4.18229111]\n",
      " [2.90412695]]\n",
      "gradients: [[3.59189718]\n",
      " [1.02074492]]\n",
      "theta: [[4.18086806]\n",
      " [2.90377908]]\n",
      "gradients: [[0.96795757]\n",
      " [0.23661962]]\n",
      "theta: [[4.18074179]\n",
      " [2.90362879]]\n",
      "gradients: [[0.08591336]\n",
      " [0.10225852]]\n",
      "theta: [[4.17548599]\n",
      " [2.9021352 ]]\n",
      "gradients: [[3.57709785]\n",
      " [1.01653925]]\n",
      "theta: [[4.17408562]\n",
      " [2.90179287]]\n",
      "gradients: [[0.95337356]\n",
      " [0.23305453]]\n",
      "theta: [[4.17886137]\n",
      " [2.90958595]]\n",
      "gradients: [[-3.25228624]\n",
      " [-5.30708535]]\n",
      "theta: [[4.17615641]\n",
      " [2.90661491]]\n",
      "gradients: [[1.84262237]\n",
      " [2.02387175]]\n",
      "theta: [[4.17088325]\n",
      " [2.8989558 ]]\n",
      "gradients: [[3.59312801]\n",
      " [5.21891532]]\n",
      "theta: [[4.16994478]\n",
      " [2.89822598]]\n",
      "gradients: [[0.63966092]\n",
      " [0.49744507]]\n",
      "theta: [[4.17282073]\n",
      " [2.90229119]]\n",
      "gradients: [[-1.9608192 ]\n",
      " [-2.77165768]]\n",
      "theta: [[4.17331519]\n",
      " [2.90297003]]\n",
      "gradients: [[-0.3372267 ]\n",
      " [-0.46297261]]\n",
      "theta: [[4.17185862]\n",
      " [2.90276686]]\n",
      "gradients: [[0.99367196]\n",
      " [0.1386021 ]]\n",
      "theta: [[4.1719318 ]\n",
      " [2.90282017]]\n",
      "gradients: [[-0.04993471]\n",
      " [-0.03637224]]\n",
      "theta: [[4.17457908]\n",
      " [2.90328058]]\n",
      "gradients: [[-1.80703036]\n",
      " [-0.31427594]]\n",
      "theta: [[4.1794001 ]\n",
      " [2.91014602]]\n",
      "gradients: [[-3.29179794]\n",
      " [-4.68772483]]\n",
      "theta: [[4.17702901]\n",
      " [2.90690725]]\n",
      "gradients: [[1.61945838]\n",
      " [2.21208229]]\n",
      "theta: [[4.17136327]\n",
      " [2.90496847]]\n",
      "gradients: [[3.87083055]\n",
      " [1.32457428]]\n",
      "theta: [[4.16909058]\n",
      " [2.90155564]]\n",
      "gradients: [[1.55315478]\n",
      " [2.33232272]]\n",
      "theta: [[4.16530955]\n",
      " [2.90030452]]\n",
      "gradients: [[2.58471787]\n",
      " [0.85526468]]\n",
      "theta: [[4.16494045]\n",
      " [2.90026652]]\n",
      "gradients: [[0.25239082]\n",
      " [0.02598424]]\n",
      "theta: [[4.16241683]\n",
      " [2.89524968]]\n",
      "gradients: [[1.72615395]\n",
      " [3.4315212 ]]\n",
      "theta: [[4.16247488]\n",
      " [2.89529015]]\n",
      "gradients: [[-0.03972159]\n",
      " [-0.02768786]]\n",
      "theta: [[4.16511457]\n",
      " [2.90015165]]\n",
      "gradients: [[-1.80660363]\n",
      " [-3.32720843]]\n",
      "theta: [[4.16481206]\n",
      " [2.89998218]]\n",
      "gradients: [[0.20709992]\n",
      " [0.11601672]]\n",
      "theta: [[4.16004833]\n",
      " [2.89410436]]\n",
      "gradients: [[3.26220378]\n",
      " [4.02513005]]\n",
      "theta: [[4.16279519]\n",
      " [2.89532596]]\n",
      "gradients: [[-1.88159747]\n",
      " [-0.83679905]]\n",
      "theta: [[4.16357812]\n",
      " [2.89535946]]\n",
      "gradients: [[-0.53646683]\n",
      " [-0.02295047]]\n",
      "theta: [[4.16460544]\n",
      " [2.89548451]]\n",
      "gradients: [[-0.70412504]\n",
      " [-0.08571021]]\n",
      "theta: [[4.16607101]\n",
      " [2.89625997]]\n",
      "gradients: [[-1.00479332]\n",
      " [-0.53165578]]\n",
      "theta: [[4.16894958]\n",
      " [2.90032889]]\n",
      "gradients: [[-1.97412474]\n",
      " [-2.79046533]]\n",
      "theta: [[4.16995858]\n",
      " [2.90045171]]\n",
      "gradients: [[-0.69217231]\n",
      " [-0.08425525]]\n",
      "theta: [[4.17478093]\n",
      " [2.90731904]]\n",
      "gradients: [[-3.30909589]\n",
      " [-4.71235817]]\n",
      "theta: [[4.17501946]\n",
      " [2.90771135]]\n",
      "gradients: [[-0.16372545]\n",
      " [-0.26928294]]\n",
      "theta: [[4.1748794 ]\n",
      " [2.90758288]]\n",
      "gradients: [[0.09615972]\n",
      " [0.0882065 ]]\n",
      "theta: [[4.17482732]\n",
      " [2.90750125]]\n",
      "gradients: [[0.0357716 ]\n",
      " [0.05606095]]\n",
      "theta: [[4.17560871]\n",
      " [2.90840285]]\n",
      "gradients: [[-0.53681319]\n",
      " [-0.61939555]]\n",
      "theta: [[4.17301872]\n",
      " [2.90325406]]\n",
      "gradients: [[1.77983981]\n",
      " [3.53824642]]\n",
      "theta: [[4.16901372]\n",
      " [2.89674211]]\n",
      "gradients: [[2.75303549]\n",
      " [4.47631457]]\n",
      "theta: [[4.16928832]\n",
      " [2.89708716]]\n",
      "gradients: [[-0.18881476]\n",
      " [-0.23725186]]\n",
      "theta: [[4.16785771]\n",
      " [2.89688761]]\n",
      "gradients: [[0.98397707]\n",
      " [0.13724981]]\n",
      "theta: [[4.16655634]\n",
      " [2.89468265]]\n",
      "gradients: [[0.89533707]\n",
      " [1.51700813]]\n",
      "theta: [[4.16682305]\n",
      " [2.89475723]]\n",
      "gradients: [[-0.18354639]\n",
      " [-0.05132168]]\n",
      "theta: [[4.16572217]\n",
      " [2.89387266]]\n",
      "gradients: [[0.75784455]\n",
      " [0.6089325 ]]\n",
      "theta: [[4.17128675]\n",
      " [2.89430916]]\n",
      "gradients: [[-3.83177232]\n",
      " [-0.30057382]]\n",
      "theta: [[4.16838143]\n",
      " [2.89087628]]\n",
      "gradients: [[2.00118727]\n",
      " [2.36456758]]\n",
      "theta: [[4.17393575]\n",
      " [2.89131198]]\n",
      "gradients: [[-3.82692389]\n",
      " [-0.3001935 ]]\n",
      "theta: [[4.17477143]\n",
      " [2.89227623]]\n",
      "gradients: [[-0.57595594]\n",
      " [-0.66455996]]\n",
      "theta: [[4.17539354]\n",
      " [2.89329769]]\n",
      "gradients: [[-0.42888355]\n",
      " [-0.70419916]]\n",
      "theta: [[4.17594009]\n",
      " [2.89409948]]\n",
      "gradients: [[-0.37689721]\n",
      " [-0.55291061]]\n",
      "theta: [[4.17726681]\n",
      " [2.89424165]]\n",
      "gradients: [[-0.91517153]\n",
      " [-0.09807324]]\n",
      "theta: [[4.18363794]\n",
      " [2.90571271]]\n",
      "gradients: [[-4.39607776]\n",
      " [-7.91502674]]\n",
      "theta: [[4.18432556]\n",
      " [2.90643149]]\n",
      "gradients: [[-0.47459517]\n",
      " [-0.49610215]]\n",
      "theta: [[4.18485176]\n",
      " [2.90729548]]\n",
      "gradients: [[-0.36329125]\n",
      " [-0.59650083]]\n",
      "theta: [[4.18177877]\n",
      " [2.90482941]]\n",
      "gradients: [[2.12220441]\n",
      " [1.70306836]]\n",
      "theta: [[4.1822569 ]\n",
      " [2.90553083]]\n",
      "gradients: [[-0.33029255]\n",
      " [-0.48454127]]\n",
      "theta: [[4.18384357]\n",
      " [2.9082151 ]]\n",
      "gradients: [[-1.09638517]\n",
      " [-1.85483085]]\n",
      "theta: [[4.18244644]\n",
      " [2.90584789]]\n",
      "gradients: [[0.96569413]\n",
      " [1.63621711]]\n",
      "theta: [[4.18374763]\n",
      " [2.90598733]]\n",
      "gradients: [[-0.89964082]\n",
      " [-0.09640891]]\n",
      "theta: [[4.18348929]\n",
      " [2.90593669]]\n",
      "gradients: [[0.1786699 ]\n",
      " [0.03502439]]\n",
      "theta: [[4.18251252]\n",
      " [2.90517708]]\n",
      "gradients: [[0.67573064]\n",
      " [0.52549541]]\n",
      "theta: [[4.1864927 ]\n",
      " [2.91245609]]\n",
      "gradients: [[-2.75429126]\n",
      " [-5.03707263]]\n",
      "theta: [[4.18379957]\n",
      " [2.90949804]]\n",
      "gradients: [[1.86418996]\n",
      " [2.04756084]]\n",
      "theta: [[4.18363059]\n",
      " [2.90934304]]\n",
      "gradients: [[0.11699777]\n",
      " [0.10732108]]\n",
      "theta: [[4.18400253]\n",
      " [2.90948676]]\n",
      "gradients: [[-0.25760066]\n",
      " [-0.09953858]]\n",
      "theta: [[4.18420515]\n",
      " [2.90954341]]\n",
      "gradients: [[-0.14037523]\n",
      " [-0.03925053]]\n",
      "theta: [[4.18729857]\n",
      " [2.91298796]]\n",
      "gradients: [[-2.14374508]\n",
      " [-2.38707133]]\n",
      "theta: [[4.18858017]\n",
      " [2.9131253 ]]\n",
      "gradients: [[-0.88840625]\n",
      " [-0.09520497]]\n",
      "theta: [[4.18333517]\n",
      " [2.90550708]]\n",
      "gradients: [[3.63688786]\n",
      " [5.28247526]]\n",
      "theta: [[4.18959724]\n",
      " [2.91678179]]\n",
      "gradients: [[-4.34337482]\n",
      " [-7.82013643]]\n",
      "theta: [[4.18839471]\n",
      " [2.91669575]]\n",
      "gradients: [[0.8343166 ]\n",
      " [0.05968959]]\n",
      "theta: [[4.188334  ]\n",
      " [2.91665344]]\n",
      "gradients: [[0.04213206]\n",
      " [0.02936807]]\n",
      "theta: [[4.18820275]\n",
      " [2.91644775]]\n",
      "gradients: [[0.09111139]\n",
      " [0.142789  ]]\n",
      "theta: [[4.18413261]\n",
      " [2.90982987]]\n",
      "gradients: [[2.82630827]\n",
      " [4.59545288]]\n",
      "theta: [[4.18020512]\n",
      " [2.90566637]]\n",
      "gradients: [[2.72803361]\n",
      " [2.89196667]]\n",
      "theta: [[4.18150645]\n",
      " [2.90580583]]\n",
      "gradients: [[-0.90416237]\n",
      " [-0.09689345]]\n",
      "theta: [[4.18054017]\n",
      " [2.90505438]]\n",
      "gradients: [[0.67156144]\n",
      " [0.52225314]]\n",
      "theta: [[4.18183998]\n",
      " [2.90519368]]\n",
      "gradients: [[-0.90362343]\n",
      " [-0.0968357 ]]\n",
      "theta: [[4.18313563]\n",
      " [2.90533252]]\n",
      "gradients: [[-0.90099397]\n",
      " [-0.09655392]]\n",
      "theta: [[4.17894237]\n",
      " [2.90070308]]\n",
      "gradients: [[2.91682847]\n",
      " [3.22023789]]\n",
      "theta: [[4.17944262]\n",
      " [2.90143695]]\n",
      "gradients: [[-0.34807205]\n",
      " [-0.51062392]]\n",
      "theta: [[4.1854116 ]\n",
      " [2.90239951]]\n",
      "gradients: [[-4.1544152 ]\n",
      " [-0.66994404]]\n",
      "theta: [[4.18165131]\n",
      " [2.90115526]]\n",
      "gradients: [[2.61791837]\n",
      " [0.86625049]]\n",
      "theta: [[4.18219306]\n",
      " [2.90219722]]\n",
      "gradients: [[-0.37727305]\n",
      " [-0.72562558]]\n",
      "theta: [[4.18181494]\n",
      " [2.90184115]]\n",
      "gradients: [[0.26339476]\n",
      " [0.24804462]]\n",
      "theta: [[4.18418661]\n",
      " [2.90414425]]\n",
      "gradients: [[-1.65258051]\n",
      " [-1.6048024 ]]\n",
      "theta: [[4.18470412]\n",
      " [2.9051396 ]]\n",
      "gradients: [[-0.36070473]\n",
      " [-0.69375902]]\n",
      "theta: [[4.186073 ]\n",
      " [2.9058639]]\n",
      "gradients: [[-0.95437857]\n",
      " [-0.50498035]]\n",
      "theta: [[4.1915063]\n",
      " [2.9062901]]\n",
      "gradients: [[-3.78918943]\n",
      " [-0.29723351]]\n",
      "theta: [[4.18644955]\n",
      " [2.90136337]]\n",
      "gradients: [[3.5275918 ]\n",
      " [3.43688875]]\n",
      "theta: [[4.18509144]\n",
      " [2.89906227]]\n",
      "gradients: [[0.94768771]\n",
      " [1.60570806]]\n",
      "theta: [[4.18279837]\n",
      " [2.89593007]]\n",
      "gradients: [[1.60056158]\n",
      " [2.18627041]]\n",
      "theta: [[4.1814163 ]\n",
      " [2.89559222]]\n",
      "gradients: [[0.9649646 ]\n",
      " [0.23588799]]\n",
      "theta: [[4.18151821]\n",
      " [2.89563432]]\n",
      "gradients: [[-0.07117123]\n",
      " [-0.02940073]]\n",
      "theta: [[4.18161974]\n",
      " [2.89567626]]\n",
      "gradients: [[-0.07093263]\n",
      " [-0.02930217]]\n",
      "theta: [[4.17727586]\n",
      " [2.89083897]]\n",
      "gradients: [[3.03550207]\n",
      " [3.38030141]]\n",
      "theta: [[4.17175322]\n",
      " [2.88894915]]\n",
      "gradients: [[3.86032733]\n",
      " [1.32098015]]\n",
      "theta: [[4.17772264]\n",
      " [2.88991179]]\n",
      "gradients: [[-4.17382158]\n",
      " [-0.67307352]]\n",
      "theta: [[4.17774631]\n",
      " [2.88992828]]\n",
      "gradients: [[-0.0165515 ]\n",
      " [-0.01153719]]\n",
      "theta: [[4.17769382]\n",
      " [2.8899134 ]]\n",
      "gradients: [[0.03672414]\n",
      " [0.01041151]]\n",
      "theta: [[4.17917207]\n",
      " [2.88992459]]\n",
      "gradients: [[-1.03448166]\n",
      " [-0.00783109]]\n",
      "theta: [[4.17660057]\n",
      " [2.88710014]]\n",
      "gradients: [[1.80005308]\n",
      " [1.97711514]]\n",
      "theta: [[4.18033855]\n",
      " [2.88895103]]\n",
      "gradients: [[-2.61733553]\n",
      " [-1.29599281]]\n",
      "theta: [[4.17411965]\n",
      " [2.87921938]]\n",
      "gradients: [[4.35571662]\n",
      " [6.81604508]]\n",
      "theta: [[4.17006419]\n",
      " [2.87577204]]\n",
      "gradients: [[2.84125512]\n",
      " [2.41521292]]\n",
      "theta: [[4.1741834 ]\n",
      " [2.88330528]]\n",
      "gradients: [[-2.88674034]\n",
      " [-5.27929669]]\n",
      "theta: [[4.17205254]\n",
      " [2.88010543]]\n",
      "gradients: [[1.49373321]\n",
      " [2.24309125]]\n",
      "theta: [[4.17464051]\n",
      " [2.88055553]]\n",
      "gradients: [[-1.81468991]\n",
      " [-0.31560807]]\n",
      "theta: [[4.17129125]\n",
      " [2.87696181]]\n",
      "gradients: [[2.34917259]\n",
      " [2.52063583]]\n",
      "theta: [[4.17026733]\n",
      " [2.87668931]]\n",
      "gradients: [[0.71838198]\n",
      " [0.19118515]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: [[4.16999501]\n",
      " [2.87653675]]\n",
      "gradients: [[0.19111839]\n",
      " [0.10706391]]\n",
      "theta: [[4.16890025]\n",
      " [2.87486968]]\n",
      "gradients: [[0.76851722]\n",
      " [1.17028358]]\n",
      "theta: [[4.1634422 ]\n",
      " [2.87300197]]\n",
      "gradients: [[3.83264693]\n",
      " [1.31150809]]\n",
      "theta: [[4.16461086]\n",
      " [2.87470824]]\n",
      "gradients: [[-0.82086709]\n",
      " [-1.19848327]]\n",
      "theta: [[4.16229962]\n",
      " [2.87011359]]\n",
      "gradients: [[1.62387719]\n",
      " [3.22819932]]\n",
      "theta: [[4.1608501 ]\n",
      " [2.86957593]]\n",
      "gradients: [[1.01871818]\n",
      " [0.37787081]]\n",
      "theta: [[4.16203937]\n",
      " [2.87131228]]\n",
      "gradients: [[-0.83605546]\n",
      " [-1.22065862]]\n",
      "theta: [[4.16193194]\n",
      " [2.87123146]]\n",
      "gradients: [[0.07554693]\n",
      " [0.05683315]]\n",
      "theta: [[4.16048353]\n",
      " [2.87069421]]\n",
      "gradients: [[1.01881212]\n",
      " [0.37790566]]\n",
      "theta: [[4.15944359]\n",
      " [2.86911061]]\n",
      "gradients: [[0.73170042]\n",
      " [1.11421965]]\n",
      "theta: [[4.15531561]\n",
      " [2.86814727]]\n",
      "gradients: [[2.90527386]\n",
      " [0.67800202]]\n",
      "theta: [[4.15534471]\n",
      " [2.86815552]]\n",
      "gradients: [[-0.02048736]\n",
      " [-0.00580829]]\n",
      "theta: [[4.15085063]\n",
      " [2.86261042]]\n",
      "gradients: [[3.16472925]\n",
      " [3.90485931]]\n",
      "theta: [[4.1515832]\n",
      " [2.8636851]]\n",
      "gradients: [[-0.5160199 ]\n",
      " [-0.75700448]]\n",
      "theta: [[4.15309397]\n",
      " [2.86448447]]\n",
      "gradients: [[-1.06448919]\n",
      " [-0.56324203]]\n",
      "theta: [[4.15255055]\n",
      " [2.86348565]]\n",
      "gradients: [[0.38300104]\n",
      " [0.70397013]]\n",
      "theta: [[4.15301814]\n",
      " [2.86389026]]\n",
      "gradients: [[-0.3296474 ]\n",
      " [-0.28525075]]\n",
      "theta: [[4.15947569]\n",
      " [2.87551693]]\n",
      "gradients: [[-4.55386894]\n",
      " [-8.19912576]]\n",
      "theta: [[4.15977116]\n",
      " [2.87559955]]\n",
      "gradients: [[-0.2084256]\n",
      " [-0.0582782]]\n",
      "theta: [[4.15993228]\n",
      " [2.87571691]]\n",
      "gradients: [[-0.11368676]\n",
      " [-0.08280899]]\n",
      "theta: [[4.1576391 ]\n",
      " [2.87115815]]\n",
      "gradients: [[1.61853042]\n",
      " [3.21757016]]\n",
      "theta: [[4.15704898]\n",
      " [2.87007349]]\n",
      "gradients: [[0.41662423]\n",
      " [0.7657708 ]]\n",
      "theta: [[4.15301743]\n",
      " [2.86659459]]\n",
      "gradients: [[2.84708072]\n",
      " [2.45679555]]\n",
      "theta: [[4.150968 ]\n",
      " [2.8637952]]\n",
      "gradients: [[1.4477158 ]\n",
      " [1.97749231]]\n",
      "theta: [[4.15120104]\n",
      " [2.86425414]]\n",
      "gradients: [[-0.16466319]\n",
      " [-0.32428673]]\n",
      "theta: [[4.14757124]\n",
      " [2.86040622]]\n",
      "gradients: [[2.56554152]\n",
      " [2.71971011]]\n",
      "theta: [[4.14563102]\n",
      " [2.85749265]]\n",
      "gradients: [[1.37173532]\n",
      " [2.05989094]]\n",
      "theta: [[4.14166816]\n",
      " [2.85407304]]\n",
      "gradients: [[2.80253236]\n",
      " [2.41835399]]\n",
      "theta: [[4.14245899]\n",
      " [2.85523319]]\n",
      "gradients: [[-0.55943362]\n",
      " [-0.82069268]]\n",
      "theta: [[4.14230147]\n",
      " [2.85514495]]\n",
      "gradients: [[0.11146241]\n",
      " [0.06244089]]\n",
      "theta: [[4.14323816]\n",
      " [2.85612408]]\n",
      "gradients: [[-0.66298673]\n",
      " [-0.69303095]]\n",
      "theta: [[4.14477655]\n",
      " [2.85693807]]\n",
      "gradients: [[-1.08918063]\n",
      " [-0.57630675]]\n",
      "theta: [[4.14565358]\n",
      " [2.8586249 ]]\n",
      "gradients: [[-0.62111222]\n",
      " [-1.19461202]]\n",
      "theta: [[4.15163297]\n",
      " [2.85958914]]\n",
      "gradients: [[-4.23580109]\n",
      " [-0.68306839]]\n",
      "theta: [[4.15242587]\n",
      " [2.85962306]]\n",
      "gradients: [[-0.56184896]\n",
      " [-0.02403634]]\n",
      "theta: [[4.14987887]\n",
      " [2.85482633]]\n",
      "gradients: [[1.80531446]\n",
      " [3.39992554]]\n",
      "theta: [[4.14601597]\n",
      " [2.85056161]]\n",
      "gradients: [[2.73879522]\n",
      " [3.02368558]]\n",
      "theta: [[4.14575822]\n",
      " [2.85046005]]\n",
      "gradients: [[0.18279705]\n",
      " [0.07202738]]\n",
      "theta: [[4.14138567]\n",
      " [2.84506489]]\n",
      "gradients: [[3.10188852]\n",
      " [3.82732211]]\n",
      "theta: [[4.14124767]\n",
      " [2.84498759]]\n",
      "gradients: [[0.09792326]\n",
      " [0.0548563 ]]\n",
      "theta: [[4.14459147]\n",
      " [2.84871092]]\n",
      "gradients: [[-2.37342653]\n",
      " [-2.64282283]]\n",
      "theta: [[4.14443876]\n",
      " [2.84862538]]\n",
      "gradients: [[0.10841985]\n",
      " [0.06073645]]\n",
      "theta: [[4.14701647]\n",
      " [2.85112856]]\n",
      "gradients: [[-1.83068734]\n",
      " [-1.77775994]]\n",
      "theta: [[4.14782137]\n",
      " [2.85116299]]\n",
      "gradients: [[-0.57180586]\n",
      " [-0.02446231]]\n",
      "theta: [[4.15327349]\n",
      " [2.85159067]]\n",
      "gradients: [[-3.87427442]\n",
      " [-0.30390779]]\n",
      "theta: [[4.1512937 ]\n",
      " [2.84888639]]\n",
      "gradients: [[1.40723903]\n",
      " [1.92220348]]\n",
      "theta: [[4.15317972]\n",
      " [2.84921887]]\n",
      "gradients: [[-1.34095999]\n",
      " [-0.23639388]]\n",
      "theta: [[4.15697849]\n",
      " [2.85109986]]\n",
      "gradients: [[-2.70169161]\n",
      " [-1.33776234]]\n",
      "theta: [[4.16203253]\n",
      " [2.8561213 ]]\n",
      "gradients: [[-3.595441  ]\n",
      " [-3.57224691]]\n",
      "theta: [[4.16579469]\n",
      " [2.85798416]]\n",
      "gradients: [[-2.67715041]\n",
      " [-1.32561058]]\n",
      "theta: [[4.16322953]\n",
      " [2.85315323]]\n",
      "gradients: [[1.82587903]\n",
      " [3.43865453]]\n",
      "theta: [[4.16348523]\n",
      " [2.8536568 ]]\n",
      "gradients: [[-0.18205661]\n",
      " [-0.35854123]]\n",
      "theta: [[4.15869171]\n",
      " [2.84669435]]\n",
      "gradients: [[3.41394537]\n",
      " [4.95865769]]\n",
      "theta: [[4.15512167]\n",
      " [2.84290978]]\n",
      "gradients: [[2.54329287]\n",
      " [2.69612449]]\n",
      "theta: [[4.15841988]\n",
      " [2.84658236]]\n",
      "gradients: [[-2.35030583]\n",
      " [-2.6170778 ]]\n",
      "theta: [[4.15600532]\n",
      " [2.84517431]]\n",
      "gradients: [[1.72109759]\n",
      " [1.0036564 ]]\n",
      "theta: [[4.15408116]\n",
      " [2.84429628]]\n",
      "gradients: [[1.37192669]\n",
      " [0.62603664]]\n",
      "theta: [[4.15026183]\n",
      " [2.84007966]]\n",
      "gradients: [[2.72394903]\n",
      " [3.00729508]]\n",
      "theta: [[4.14646732]\n",
      " [2.83589044]]\n",
      "gradients: [[2.70699989]\n",
      " [2.98858288]]\n",
      "theta: [[4.14407942]\n",
      " [2.83139334]]\n",
      "gradients: [[1.7040067 ]\n",
      " [3.20913393]]\n",
      "theta: [[4.14156038]\n",
      " [2.82841688]]\n",
      "gradients: [[1.79809215]\n",
      " [2.12459397]]\n",
      "theta: [[4.14295815]\n",
      " [2.82856667]]\n",
      "gradients: [[-0.99800854]\n",
      " [-0.10695037]]\n",
      "theta: [[4.1422993 ]\n",
      " [2.82846185]]\n",
      "gradients: [[0.47054882]\n",
      " [0.07486254]]\n",
      "theta: [[4.14286309]\n",
      " [2.82867971]]\n",
      "gradients: [[-0.40276928]\n",
      " [-0.15563268]]\n",
      "theta: [[4.1382744]\n",
      " [2.824209 ]]\n",
      "gradients: [[3.2790757]\n",
      " [3.1947626]]\n",
      "theta: [[4.14505741]\n",
      " [2.8368549 ]]\n",
      "gradients: [[-4.8484891 ]\n",
      " [-9.03928557]]\n",
      "theta: [[4.14547755]\n",
      " [2.83691973]]\n",
      "gradients: [[-0.30040316]\n",
      " [-0.04635614]]\n",
      "theta: [[4.1456073 ]\n",
      " [2.83703875]]\n",
      "gradients: [[-0.09279721]\n",
      " [-0.0851221 ]]\n",
      "theta: [[4.14819446]\n",
      " [2.83955111]]\n",
      "gradients: [[-1.85085355]\n",
      " [-1.79734312]]\n",
      "theta: [[4.14441903]\n",
      " [2.83538296]]\n",
      "gradients: [[2.70169811]\n",
      " [2.98272961]]\n",
      "theta: [[4.14253966]\n",
      " [2.83281586]]\n",
      "gradients: [[1.34525259]\n",
      " [1.83753375]]\n",
      "theta: [[4.14320067]\n",
      " [2.83390303]]\n",
      "gradients: [[-0.47328211]\n",
      " [-0.77841775]]\n",
      "theta: [[4.14252611]\n",
      " [2.83337845]]\n",
      "gradients: [[0.48311659]\n",
      " [0.37570525]]\n",
      "theta: [[4.14134705]\n",
      " [2.83232136]]\n",
      "gradients: [[0.84467876]\n",
      " [0.7573011 ]]\n",
      "theta: [[4.14728188]\n",
      " [2.83327841]]\n",
      "gradients: [[-4.2528976 ]\n",
      " [-0.68582538]]\n",
      "theta: [[4.14736046]\n",
      " [2.83330069]]\n",
      "gradients: [[-0.05632588]\n",
      " [-0.01596872]]\n",
      "theta: [[4.15245118]\n",
      " [2.83835857]]\n",
      "gradients: [[-3.65004577]\n",
      " [-3.62649943]]\n",
      "theta: [[4.15237569]\n",
      " [2.83825418]]\n",
      "gradients: [[0.05413703]\n",
      " [0.07486699]]\n",
      "theta: [[4.15157372]\n",
      " [2.83792405]]\n",
      "gradients: [[0.57533401]\n",
      " [0.23683371]]\n",
      "theta: [[4.14760663]\n",
      " [2.83350634]]\n",
      "gradients: [[2.84678559]\n",
      " [3.17014884]]\n",
      "theta: [[4.14415804]\n",
      " [2.82789909]]\n",
      "gradients: [[2.47539787]\n",
      " [4.02488802]]\n",
      "theta: [[4.14571404]\n",
      " [2.8287224 ]]\n",
      "gradients: [[-1.11720966]\n",
      " [-0.59113746]]\n",
      "theta: [[4.14845481]\n",
      " [2.8299413 ]]\n",
      "gradients: [[-1.96842042]\n",
      " [-0.87541164]]\n",
      "theta: [[4.1522736 ]\n",
      " [2.83438662]]\n",
      "gradients: [[-2.74341862]\n",
      " [-3.19351894]]\n",
      "theta: [[4.15257255]\n",
      " [2.8347682 ]]\n",
      "gradients: [[-0.21482203]\n",
      " [-0.27420566]]\n",
      "theta: [[4.15763196]\n",
      " [2.83979497]]\n",
      "gradients: [[-3.63670551]\n",
      " [-3.61324522]]\n",
      "theta: [[4.1582163 ]\n",
      " [2.84075605]]\n",
      "gradients: [[-0.42014008]\n",
      " [-0.69101386]]\n",
      "theta: [[4.15955397]\n",
      " [2.8408994 ]]\n",
      "gradients: [[-0.96205208]\n",
      " [-0.10309713]]\n",
      "theta: [[4.15644874]\n",
      " [2.83756753]]\n",
      "gradients: [[2.23389833]\n",
      " [2.39694785]]\n",
      "theta: [[4.15294755]\n",
      " [2.83385595]]\n",
      "gradients: [[2.51945641]\n",
      " [2.67085565]]\n",
      "theta: [[4.15324601]\n",
      " [2.83423691]]\n",
      "gradients: [[-0.21482886]\n",
      " [-0.27421437]]\n",
      "theta: [[4.15363008]\n",
      " [2.83499329]]\n",
      "gradients: [[-0.27653104]\n",
      " [-0.54459862]]\n",
      "theta: [[4.1566462 ]\n",
      " [2.83925664]]\n",
      "gradients: [[-2.17220998]\n",
      " [-3.07046283]]\n",
      "theta: [[4.15963638]\n",
      " [2.84348332]]\n",
      "gradients: [[-2.15412508]\n",
      " [-3.04489946]]\n",
      "theta: [[4.15990786]\n",
      " [2.84390878]]\n",
      "gradients: [[-0.19562702]\n",
      " [-0.306585  ]]\n",
      "theta: [[4.16475003]\n",
      " [2.85080433]]\n",
      "gradients: [[-3.49023864]\n",
      " [-4.9703167 ]]\n",
      "theta: [[4.16213519]\n",
      " [2.84771468]]\n",
      "gradients: [[1.88530475]\n",
      " [2.22764283]]\n",
      "theta: [[4.16180904]\n",
      " [2.8476811 ]]\n",
      "gradients: [[0.2352136]\n",
      " [0.0242158]]\n",
      "theta: [[4.16714152]\n",
      " [2.84809939]]\n",
      "gradients: [[-3.84684534]\n",
      " [-0.30175618]]\n",
      "theta: [[4.16860523]\n",
      " [2.84811047]]\n",
      "gradients: [[-1.05621933]\n",
      " [-0.00799564]]\n",
      "theta: [[4.16903727]\n",
      " [2.84865334]]\n",
      "gradients: [[-0.3118462 ]\n",
      " [-0.39184483]]\n",
      "theta: [[4.16826479]\n",
      " [2.84805261]]\n",
      "gradients: [[0.55773155]\n",
      " [0.43373106]]\n",
      "theta: [[4.16861169]\n",
      " [2.84810614]]\n",
      "gradients: [[-0.25053248]\n",
      " [-0.03866044]]\n",
      "theta: [[4.1681219 ]\n",
      " [2.84720588]]\n",
      "gradients: [[0.35382851]\n",
      " [0.65034994]]\n",
      "theta: [[4.17182215]\n",
      " [2.84903808]]\n",
      "gradients: [[-2.67380074]\n",
      " [-1.32395197]]\n",
      "theta: [[4.16798997]\n",
      " [2.84480727]]\n",
      "gradients: [[2.7699011 ]\n",
      " [3.05802709]]\n",
      "theta: [[4.17046715]\n",
      " [2.84721284]]\n",
      "gradients: [[-1.79100036]\n",
      " [-1.73922036]]\n",
      "theta: [[4.17626064]\n",
      " [2.8481471 ]]\n",
      "gradients: [[-4.18985459]\n",
      " [-0.67565902]]\n",
      "theta: [[4.17658482]\n",
      " [2.84819712]]\n",
      "gradients: [[-0.23451162]\n",
      " [-0.03618821]]\n",
      "theta: [[4.17634735]\n",
      " [2.8480641 ]]\n",
      "gradients: [[0.1718309 ]\n",
      " [0.09625912]]\n",
      "theta: [[4.17505051]\n",
      " [2.84690141]]\n",
      "gradients: [[0.93865422]\n",
      " [0.84155528]]\n",
      "theta: [[4.17376049]\n",
      " [2.84574483]]\n",
      "gradients: [[0.9339757 ]\n",
      " [0.83736073]]\n",
      "theta: [[4.17459755]\n",
      " [2.84735479]]\n",
      "gradients: [[-0.60620124]\n",
      " [-1.16593308]]\n",
      "theta: [[4.17476964]\n",
      " [2.84742588]]\n",
      "gradients: [[-0.12466235]\n",
      " [-0.05149783]]\n",
      "theta: [[4.18051646]\n",
      " [2.85510214]]\n",
      "gradients: [[-4.16414654]\n",
      " [-5.56221657]]\n",
      "theta: [[4.18626593]\n",
      " [2.8560293 ]]\n",
      "gradients: [[-4.16721148]\n",
      " [-0.67200758]]\n",
      "theta: [[4.18427647]\n",
      " [2.85512147]]\n",
      "gradients: [[1.44235458]\n",
      " [0.65817424]]\n",
      "theta: [[4.18503364]\n",
      " [2.85657777]]\n",
      "gradients: [[-0.54910026]\n",
      " [-1.05610829]]\n",
      "theta: [[4.18025624]\n",
      " [2.84963873]]\n",
      "gradients: [[3.46552748]\n",
      " [5.03357921]]\n",
      "theta: [[4.18050615]\n",
      " [2.84970861]]\n",
      "gradients: [[-0.18133619]\n",
      " [-0.05070369]]\n",
      "theta: [[4.18693898]\n",
      " [2.86170166]]\n",
      "gradients: [[-4.66894516]\n",
      " [-8.70455265]]\n",
      "theta: [[4.18774961]\n",
      " [2.86255709]]\n",
      "gradients: [[-0.58851824]\n",
      " [-0.62104429]]\n",
      "theta: [[4.18845679]\n",
      " [2.86391723]]\n",
      "gradients: [[-0.51355149]\n",
      " [-0.98773581]]\n",
      "theta: [[4.18753632]\n",
      " [2.86353833]]\n",
      "gradients: [[0.66862436]\n",
      " [0.27523628]]\n",
      "theta: [[4.18989736]\n",
      " [2.86583111]]\n",
      "gradients: [[-1.71552861]\n",
      " [-1.66593059]]\n",
      "theta: [[4.18515667]\n",
      " [2.86121231]]\n",
      "gradients: [[3.44553652]\n",
      " [3.35694331]]\n",
      "theta: [[4.18154318]\n",
      " [2.85738168]]\n",
      "gradients: [[2.62700353]\n",
      " [2.78486549]]\n",
      "theta: [[4.18167737]\n",
      " [2.85755296]]\n",
      "gradients: [[-0.09757962]\n",
      " [-0.12455372]]\n",
      "theta: [[4.18232241]\n",
      " [2.85849924]]\n",
      "gradients: [[-0.46920508]\n",
      " [-0.68832684]]\n",
      "theta: [[4.18207317]\n",
      " [2.85826452]]\n",
      "gradients: [[0.18135077]\n",
      " [0.170782  ]]\n",
      "theta: [[4.18773486]\n",
      " [2.86582708]]\n",
      "gradients: [[-4.12058428]\n",
      " [-5.50402873]]\n",
      "theta: [[4.18782228]\n",
      " [2.86593865]]\n",
      "gradients: [[-0.0636363]\n",
      " [-0.0812274]]\n",
      "theta: [[4.188038  ]\n",
      " [2.86599897]]\n",
      "gradients: [[-0.15708883]\n",
      " [-0.04392385]]\n",
      "theta: [[4.18776101]\n",
      " [2.86561592]]\n",
      "gradients: [[0.20175941]\n",
      " [0.27901641]]\n",
      "theta: [[4.18835582]\n",
      " [2.86648851]]\n",
      "gradients: [[-0.43338096]\n",
      " [-0.63577263]]\n",
      "theta: [[4.18703628]\n",
      " [2.86616595]]\n",
      "gradients: [[0.96168537]\n",
      " [0.23508637]]\n",
      "theta: [[4.18707884]\n",
      " [2.86619562]]\n",
      "gradients: [[-0.03102822]\n",
      " [-0.02162816]]\n",
      "theta: [[4.19166259]\n",
      " [2.8736754 ]]\n",
      "gradients: [[-3.34247511]\n",
      " [-5.45425568]]\n",
      "theta: [[4.19147292]\n",
      " [2.87353271]]\n",
      "gradients: [[0.13834886]\n",
      " [0.10407838]]\n",
      "theta: [[4.19115841]\n",
      " [2.87309777]]\n",
      "gradients: [[0.2294663 ]\n",
      " [0.31733272]]\n",
      "theta: [[4.18641435]\n",
      " [2.86847568]]\n",
      "gradients: [[3.46221826]\n",
      " [3.37319612]]\n",
      "theta: [[4.18416407]\n",
      " [2.86400222]]\n",
      "gradients: [[1.64270405]\n",
      " [3.26562631]]\n",
      "theta: [[4.18265456]\n",
      " [2.86330233]]\n",
      "gradients: [[1.10224306]\n",
      " [0.51106005]]\n",
      "theta: [[4.18261354]\n",
      " [2.86326471]]\n",
      "gradients: [[0.02995788]\n",
      " [0.02748011]]\n",
      "theta: [[4.17873848]\n",
      " [2.85997071]]\n",
      "gradients: [[2.83111831]\n",
      " [2.40659611]]\n",
      "theta: [[4.17730981]\n",
      " [2.85944077]]\n",
      "gradients: [[1.04407135]\n",
      " [0.38727501]]\n",
      "theta: [[4.17466845]\n",
      " [2.85631979]]\n",
      "gradients: [[1.93083365]\n",
      " [2.28143898]]\n",
      "theta: [[4.1735801 ]\n",
      " [2.85624193]]\n",
      "gradients: [[0.79580775]\n",
      " [0.05693455]]\n",
      "theta: [[4.17334105]\n",
      " [2.85610802]]\n",
      "gradients: [[0.1748348]\n",
      " [0.0979419]]\n",
      "theta: [[4.17280428]\n",
      " [2.85512141]]\n",
      "gradients: [[0.39270273]\n",
      " [0.7218022 ]]\n",
      "theta: [[4.17261729]\n",
      " [2.85508475]]\n",
      "gradients: [[0.13684087]\n",
      " [0.02682471]]\n",
      "theta: [[4.17337593]\n",
      " [2.85633039]]\n",
      "gradients: [[-0.55532385]\n",
      " [-0.91180598]]\n",
      "theta: [[4.17232575]\n",
      " [2.85455103]]\n",
      "gradients: [[0.76893785]\n",
      " [1.30284448]]\n",
      "theta: [[4.17154274]\n",
      " [2.85394211]]\n",
      "gradients: [[0.57348142]\n",
      " [0.44597926]]\n",
      "theta: [[4.17008536]\n",
      " [2.85326639]]\n",
      "gradients: [[1.06767157]\n",
      " [0.49503082]]\n",
      "theta: [[4.17031448]\n",
      " [2.85371762]]\n",
      "gradients: [[-0.16789923]\n",
      " [-0.33065977]]\n",
      "theta: [[4.17038865]\n",
      " [2.85380589]]\n",
      "gradients: [[-0.05436529]\n",
      " [-0.06470837]]\n",
      "theta: [[4.17110446]\n",
      " [2.85383652]]\n",
      "gradients: [[-0.52483242]\n",
      " [-0.02245275]]\n",
      "theta: [[4.17002957]\n",
      " [2.85375962]]\n",
      "gradients: [[0.78832445]\n",
      " [0.05639917]]\n",
      "theta: [[4.17569575]\n",
      " [2.86132815]]\n",
      "gradients: [[-4.15670623]\n",
      " [-5.55227825]]\n",
      "theta: [[4.17187347]\n",
      " [2.85710828]]\n",
      "gradients: [[2.80478527]\n",
      " [3.09653993]]\n",
      "theta: [[4.17269056]\n",
      " [2.85796239]]\n",
      "gradients: [[-0.59973811]\n",
      " [-0.62691612]]\n",
      "theta: [[4.17499555]\n",
      " [2.85838996]]\n",
      "gradients: [[-1.69232323]\n",
      " [-0.31391922]]\n",
      "theta: [[4.17265019]\n",
      " [2.85581391]]\n",
      "gradients: [[1.72242696]\n",
      " [1.89185333]]\n",
      "theta: [[4.16990697]\n",
      " [2.85361247]]\n",
      "gradients: [[2.01517338]\n",
      " [1.617176  ]]\n",
      "theta: [[4.16968304]\n",
      " [2.85348702]]\n",
      "gradients: [[0.16454251]\n",
      " [0.09217619]]\n",
      "theta: [[4.16895933]\n",
      " [2.85337188]]\n",
      "gradients: [[0.53192807]\n",
      " [0.08462774]]\n",
      "theta: [[4.16763843]\n",
      " [2.85318764]]\n",
      "gradients: [[0.97112385]\n",
      " [0.13545698]]\n",
      "theta: [[4.17126753]\n",
      " [2.85498462]]\n",
      "gradients: [[-2.66884385]\n",
      " [-1.32149753]]\n",
      "theta: [[4.17610596]\n",
      " [2.85979183]]\n",
      "gradients: [[-3.55914353]\n",
      " [-3.5361836 ]]\n",
      "theta: [[4.17574493]\n",
      " [2.85975466]]\n",
      "gradients: [[0.26564189]\n",
      " [0.02734847]]\n",
      "theta: [[4.17811784]\n",
      " [2.86205896]]\n",
      "gradients: [[-1.74645996]\n",
      " [-1.69596767]]\n",
      "theta: [[4.1785334 ]\n",
      " [2.86274244]]\n",
      "gradients: [[-0.30593215]\n",
      " [-0.50317351]]\n",
      "theta: [[4.18412234]\n",
      " [2.87020782]]\n",
      "gradients: [[-4.11570116]\n",
      " [-5.49750615]]\n",
      "theta: [[4.17974093]\n",
      " [2.86480173]]\n",
      "gradients: [[3.22734906]\n",
      " [3.98212391]]\n",
      "theta: [[4.17975332]\n",
      " [2.86481647]]\n",
      "gradients: [[-0.00912662]\n",
      " [-0.01086298]]\n",
      "theta: [[4.1787325]\n",
      " [2.863262 ]]\n",
      "gradients: [[0.75233899]\n",
      " [1.14564768]]\n",
      "theta: [[4.1794207 ]\n",
      " [2.86329144]]\n",
      "gradients: [[-0.50733564]\n",
      " [-0.02170422]]\n",
      "theta: [[4.18568659]\n",
      " [2.87497327]]\n",
      "gradients: [[-4.62046976]\n",
      " [-8.61417748]]\n",
      "theta: [[4.18545559]\n",
      " [2.87492798]]\n",
      "gradients: [[0.17038855]\n",
      " [0.03340101]]\n",
      "theta: [[4.18437868]\n",
      " [2.87328809]]\n",
      "gradients: [[0.79453876]\n",
      " [1.2099087 ]]\n",
      "theta: [[4.18571843]\n",
      " [2.87399698]]\n",
      "gradients: [[-0.98873595]\n",
      " [-0.52315951]]\n",
      "theta: [[4.1884247 ]\n",
      " [2.87782235]]\n",
      "gradients: [[-1.99776826]\n",
      " [-2.82388592]]\n",
      "theta: [[4.1908882 ]\n",
      " [2.88235935]]\n",
      "gradients: [[-1.81904462]\n",
      " [-3.3501209 ]]\n",
      "theta: [[4.18720444]\n",
      " [2.87636971]]\n",
      "gradients: [[2.72082669]\n",
      " [4.42394447]]\n",
      "theta: [[4.18715931]\n",
      " [2.87631601]]\n",
      "gradients: [[0.03333802]\n",
      " [0.03968063]]\n",
      "theta: [[4.19265618]\n",
      " [2.8836584 ]]\n",
      "gradients: [[-4.06218782]\n",
      " [-5.42602624]]\n",
      "theta: [[4.19111742]\n",
      " [2.88294494]]\n",
      "gradients: [[1.13745465]\n",
      " [0.52738606]]\n",
      "theta: [[4.1907111 ]\n",
      " [2.88290311]]\n",
      "gradients: [[0.30043215]\n",
      " [0.03093021]]\n",
      "theta: [[4.18950281]\n",
      " [2.88085584]]\n",
      "gradients: [[0.89365479]\n",
      " [1.51415776]]\n",
      "theta: [[4.18561689]\n",
      " [2.87755261]]\n",
      "gradients: [[2.87480358]\n",
      " [2.44373083]]\n",
      "theta: [[4.18425193]\n",
      " [2.87632885]]\n",
      "gradients: [[1.01006945]\n",
      " [0.90558297]]\n",
      "theta: [[4.18309216]\n",
      " [2.87436381]]\n",
      "gradients: [[0.85845835]\n",
      " [1.45452291]]\n",
      "theta: [[4.18280291]\n",
      " [2.87420177]]\n",
      "gradients: [[0.21416257]\n",
      " [0.11997319]]\n",
      "theta: [[4.18793482]\n",
      " [2.87460433]]\n",
      "gradients: [[-3.80069691]\n",
      " [-0.29813619]]\n",
      "theta: [[4.18552672]\n",
      " [2.87195935]]\n",
      "gradients: [[1.78392411]\n",
      " [1.95939965]]\n",
      "theta: [[4.19170207]\n",
      " [2.88347238]]\n",
      "gradients: [[-4.57593764]\n",
      " [-8.53115399]]\n",
      "theta: [[4.18761615]\n",
      " [2.87892234]]\n",
      "gradients: [[3.02848652]\n",
      " [3.37248898]]\n",
      "theta: [[4.18794847]\n",
      " [2.87892433]]\n",
      "gradients: [[-0.2463829 ]\n",
      " [-0.00147409]]\n",
      "theta: [[4.18776128]\n",
      " [2.87878351]]\n",
      "gradients: [[0.13881805]\n",
      " [0.10443135]]\n",
      "theta: [[4.18752398]\n",
      " [2.87873699]]\n",
      "gradients: [[0.17603177]\n",
      " [0.03450724]]\n",
      "theta: [[4.18674818]\n",
      " [2.87861357]]\n",
      "gradients: [[0.5756443 ]\n",
      " [0.09158283]]\n",
      "theta: [[4.19124524]\n",
      " [2.88501765]]\n",
      "gradients: [[-3.33771444]\n",
      " [-4.75311277]]\n",
      "theta: [[4.19363559]\n",
      " [2.88543338]]\n",
      "gradients: [[-1.77459586]\n",
      " [-0.30863498]]\n",
      "theta: [[4.19362342]\n",
      " [2.8854249 ]]\n",
      "gradients: [[0.00903106]\n",
      " [0.00629508]]\n",
      "theta: [[4.19418034]\n",
      " [2.88633933]]\n",
      "gradients: [[-0.41367844]\n",
      " [-0.67923335]]\n",
      "theta: [[4.1894777]\n",
      " [2.8817576]]\n",
      "gradients: [[3.4940643 ]\n",
      " [3.40422332]]\n",
      "theta: [[4.18677599]\n",
      " [2.87856531]]\n",
      "gradients: [[2.00790774]\n",
      " [2.37250837]]\n",
      "theta: [[4.18904168]\n",
      " [2.87910829]]\n",
      "gradients: [[-1.68430896]\n",
      " [-0.40364979]]\n",
      "theta: [[4.18969439]\n",
      " [2.87913621]]\n",
      "gradients: [[-0.48536146]\n",
      " [-0.02076415]]\n",
      "theta: [[4.18851282]\n",
      " [2.87713422]]\n",
      "gradients: [[0.87885655]\n",
      " [1.48908446]]\n",
      "theta: [[4.19096094]\n",
      " [2.8816429 ]]\n",
      "gradients: [[-1.82140305]\n",
      " [-3.35446441]]\n",
      "theta: [[4.19561934]\n",
      " [2.88627126]]\n",
      "gradients: [[-3.46678409]\n",
      " [-3.44441996]]\n",
      "theta: [[4.19209278]\n",
      " [2.87962313]]\n",
      "gradients: [[2.62517083]\n",
      " [4.94886861]]\n",
      "theta: [[4.19130704]\n",
      " [2.87949812]]\n",
      "gradients: [[0.58506387]\n",
      " [0.09308144]]\n",
      "theta: [[4.19054658]\n",
      " [2.87862363]]\n",
      "gradients: [[0.56639073]\n",
      " [0.6513208 ]]\n",
      "theta: [[4.18573786]\n",
      " [2.87725709]]\n",
      "gradients: [[3.5824955 ]\n",
      " [1.01807315]]\n",
      "theta: [[4.19185134]\n",
      " [2.88865475]]\n",
      "gradients: [[-4.55576169]\n",
      " [-8.49353894]]\n",
      "theta: [[4.19405501]\n",
      " [2.88906352]]\n",
      "gradients: [[-1.64261505]\n",
      " [-0.30469855]]\n",
      "theta: [[4.19368271]\n",
      " [2.88854866]]\n",
      "gradients: [[0.27758611]\n",
      " [0.38387841]]\n",
      "theta: [[4.19005973]\n",
      " [2.88470798]]\n",
      "gradients: [[2.70201372]\n",
      " [2.8643832 ]]\n",
      "theta: [[4.18685743]\n",
      " [2.88127194]]\n",
      "gradients: [[2.38892208]\n",
      " [2.5632866 ]]\n",
      "theta: [[4.18382105]\n",
      " [2.87669527]]\n",
      "gradients: [[2.26574603]\n",
      " [3.41510925]]\n",
      "theta: [[4.18247143]\n",
      " [2.87650702]]\n",
      "gradients: [[1.00735381]\n",
      " [0.14051051]]\n",
      "theta: [[4.18280588]\n",
      " [2.87705709]]\n",
      "gradients: [[-0.24969889]\n",
      " [-0.41068539]]\n",
      "theta: [[4.18309042]\n",
      " [2.877101  ]]\n",
      "gradients: [[-0.21249876]\n",
      " [-0.03279134]]\n",
      "theta: [[4.18271846]\n",
      " [2.87695443]]\n",
      "gradients: [[0.27786055]\n",
      " [0.10948518]]\n",
      "theta: [[4.18816461]\n",
      " [2.88422908]]\n",
      "gradients: [[-4.06936398]\n",
      " [-5.43561172]]\n",
      "theta: [[4.18809192]\n",
      " [2.88420847]]\n",
      "gradients: [[0.05432922]\n",
      " [0.01540266]]\n",
      "theta: [[4.19102449]\n",
      " [2.8874739 ]]\n",
      "gradients: [[-2.19239273]\n",
      " [-2.44124074]]\n",
      "theta: [[4.19440017]\n",
      " [2.89140342]]\n",
      "gradients: [[-2.52433581]\n",
      " [-2.93849221]]\n",
      "theta: [[4.19873916]\n",
      " [2.89848379]]\n",
      "gradients: [[-3.24556417]\n",
      " [-5.29611628]]\n",
      "theta: [[4.19830344]\n",
      " [2.8983121 ]]\n",
      "gradients: [[0.32600892]\n",
      " [0.12845704]]\n",
      "theta: [[4.20162325]\n",
      " [2.90217658]]\n",
      "gradients: [[-2.48454517]\n",
      " [-2.8921733 ]]\n",
      "theta: [[4.19768679]\n",
      " [2.89783064]]\n",
      "gradients: [[2.94683525]\n",
      " [3.253366  ]]\n",
      "theta: [[4.19741522]\n",
      " [2.89777741]]\n",
      "gradients: [[0.20335033]\n",
      " [0.03986246]]\n",
      "theta: [[4.19377163]\n",
      " [2.89391487]]\n",
      "gradients: [[2.72904538]\n",
      " [2.89303925]]\n",
      "theta: [[4.19911326]\n",
      " [2.9010499 ]]\n",
      "gradients: [[-4.00194816]\n",
      " [-5.34556172]]\n",
      "theta: [[4.2013979 ]\n",
      " [2.90525751]]\n",
      "gradients: [[-1.7121115 ]\n",
      " [-3.15318297]]\n",
      "theta: [[4.20182747]\n",
      " [2.9060837 ]]\n",
      "gradients: [[-0.32199978]\n",
      " [-0.61931612]]\n",
      "theta: [[4.19782802]\n",
      " [2.90263251]]\n",
      "gradients: [[2.99878538]\n",
      " [2.58770414]]\n",
      "theta: [[4.19846849]\n",
      " [2.90330838]]\n",
      "gradients: [[-0.48035414]\n",
      " [-0.50690221]]\n",
      "theta: [[4.19561187]\n",
      " [2.90101594]]\n",
      "gradients: [[2.14303858]\n",
      " [1.71978778]]\n",
      "theta: [[4.19546685]\n",
      " [2.90084333]]\n",
      "gradients: [[0.10882331]\n",
      " [0.12952713]]\n",
      "theta: [[4.19157568]\n",
      " [2.89753564]]\n",
      "gradients: [[2.92071245]\n",
      " [2.48275573]]\n",
      "theta: [[4.1918323 ]\n",
      " [2.89775769]]\n",
      "gradients: [[-0.19266882]\n",
      " [-0.16672034]]\n",
      "theta: [[4.1908959 ]\n",
      " [2.89737223]]\n",
      "gradients: [[0.70323593]\n",
      " [0.28948398]]\n",
      "theta: [[4.19077513]\n",
      " [2.89722849]]\n",
      "gradients: [[0.09071749]\n",
      " [0.10797665]]\n",
      "theta: [[4.18690877]\n",
      " [2.89394189]]\n",
      "gradients: [[2.90518341]\n",
      " [2.46955526]]\n",
      "theta: [[4.18384325]\n",
      " [2.8893213 ]]\n",
      "gradients: [[2.30404299]\n",
      " [3.47283342]]\n",
      "theta: [[4.18433762]\n",
      " [2.89004654]]\n",
      "gradients: [[-0.37166459]\n",
      " [-0.54523431]]\n",
      "theta: [[4.18985398]\n",
      " [2.89093611]]\n",
      "gradients: [[-4.14829885]\n",
      " [-0.66895771]]\n",
      "theta: [[4.18402978]\n",
      " [2.88182211]]\n",
      "gradients: [[4.38096017]\n",
      " [6.85554746]]\n",
      "theta: [[4.18365304]\n",
      " [2.88167367]]\n",
      "gradients: [[0.28345978]\n",
      " [0.11169144]]\n",
      "theta: [[4.18100082]\n",
      " [2.87853985]]\n",
      "gradients: [[1.99606008]\n",
      " [2.35850938]]\n",
      "theta: [[4.18365008]\n",
      " [2.88228463]]\n",
      "gradients: [[-1.99436062]\n",
      " [-2.81906915]]\n",
      "theta: [[4.18010603]\n",
      " [2.87852761]]\n",
      "gradients: [[2.66866756]\n",
      " [2.8290332 ]]\n",
      "theta: [[4.17736235]\n",
      " [2.87632581]]\n",
      "gradients: [[2.06654054]\n",
      " [1.65839812]]\n",
      "theta: [[4.17799426]\n",
      " [2.87736336]]\n",
      "gradients: [[-0.47608084]\n",
      " [-0.78169407]]\n",
      "theta: [[4.17763195]\n",
      " [2.87732606]]\n",
      "gradients: [[0.27303655]\n",
      " [0.02810977]]\n",
      "theta: [[4.18268707]\n",
      " [2.8777226 ]]\n",
      "gradients: [[-3.81054868]\n",
      " [-0.29890898]]\n",
      "theta: [[4.18296461]\n",
      " [2.87807134]]\n",
      "gradients: [[-0.20926533]\n",
      " [-0.26294866]]\n",
      "theta: [[4.18182196]\n",
      " [2.87613529]]\n",
      "gradients: [[0.86178845]\n",
      " [1.46016526]]\n",
      "theta: [[4.17830661]\n",
      " [2.87240871]]\n",
      "gradients: [[2.65197359]\n",
      " [2.81133606]]\n",
      "theta: [[4.17907945]\n",
      " [2.87322426]]\n",
      "gradients: [[-0.58318536]\n",
      " [-0.61541668]]\n",
      "theta: [[4.17943356]\n",
      " [2.87380667]]\n",
      "gradients: [[-0.26728129]\n",
      " [-0.43960356]]\n",
      "theta: [[4.17372958]\n",
      " [2.86488079]]\n",
      "gradients: [[4.30650933]\n",
      " [6.73904303]]\n",
      "theta: [[4.17371039]\n",
      " [2.86487535]]\n",
      "gradients: [[0.01448845]\n",
      " [0.00410756]]\n",
      "theta: [[4.17299077]\n",
      " [2.86476086]]\n",
      "gradients: [[0.54360645]\n",
      " [0.08648573]]\n",
      "theta: [[4.175397  ]\n",
      " [2.86517935]]\n",
      "gradients: [[-1.81815086]\n",
      " [-0.31621   ]]\n",
      "theta: [[4.17504594]\n",
      " [2.8651432 ]]\n",
      "gradients: [[0.26533329]\n",
      " [0.0273167 ]]\n",
      "theta: [[4.17158679]\n",
      " [2.86147619]]\n",
      "gradients: [[2.6151163 ]\n",
      " [2.77226394]]\n",
      "theta: [[4.17138003]\n",
      " [2.86119026]]\n",
      "gradients: [[0.15634772]\n",
      " [0.21621584]]\n",
      "theta: [[4.1736585]\n",
      " [2.8617363]]\n",
      "gradients: [[-1.72342884]\n",
      " [-0.41302499]]\n",
      "theta: [[4.16898083]\n",
      " [2.86040701]]\n",
      "gradients: [[3.53912125]\n",
      " [1.00574706]]\n",
      "theta: [[4.16704804]\n",
      " [2.85776693]]\n",
      "gradients: [[1.46273886]\n",
      " [1.9980129 ]]\n",
      "theta: [[4.16688111]\n",
      " [2.8577342 ]]\n",
      "gradients: [[0.12636558]\n",
      " [0.02477125]]\n",
      "theta: [[4.16241237]\n",
      " [2.85338037]]\n",
      "gradients: [[3.3837266 ]\n",
      " [3.29672267]]\n",
      "theta: [[4.16003348]\n",
      " [2.84890023]]\n",
      "gradients: [[1.80177389]\n",
      " [3.39325764]]\n",
      "theta: [[4.16144639]\n",
      " [2.84891093]]\n",
      "gradients: [[-1.07042328]\n",
      " [-0.00810317]]\n",
      "theta: [[4.16165674]\n",
      " [2.84917941]]\n",
      "gradients: [[-0.15939787]\n",
      " [-0.20346051]]\n",
      "theta: [[4.15800864]\n",
      " [2.84607834]]\n",
      "gradients: [[2.76525825]\n",
      " [2.35061167]]\n",
      "theta: [[4.15541003]\n",
      " [2.84399296]]\n",
      "gradients: [[1.9702647 ]\n",
      " [1.58113679]]\n",
      "theta: [[4.15096683]\n",
      " [2.83753934]]\n",
      "gradients: [[3.36972209]\n",
      " [4.89442464]]\n",
      "theta: [[4.15171171]\n",
      " [2.83757121]]\n",
      "gradients: [[-0.56506786]\n",
      " [-0.02417405]]\n",
      "theta: [[4.15134099]\n",
      " [2.83688981]]\n",
      "gradients: [[0.28130136]\n",
      " [0.51704235]]\n",
      "theta: [[4.1536798 ]\n",
      " [2.83745032]]\n",
      "gradients: [[-1.77515427]\n",
      " [-0.42542115]]\n",
      "theta: [[4.1528673 ]\n",
      " [2.83621306]]\n",
      "gradients: [[0.61684662]\n",
      " [0.93932244]]\n",
      "theta: [[4.15286152]\n",
      " [2.83620871]]\n",
      "gradients: [[0.00439325]\n",
      " [0.00330499]]\n",
      "theta: [[4.15643605]\n",
      " [2.83797866]]\n",
      "gradients: [[-2.71521215]\n",
      " [-1.34445713]]\n",
      "theta: [[4.15635569]\n",
      " [2.83786754]]\n",
      "gradients: [[0.06105601]\n",
      " [0.08443537]]\n",
      "theta: [[4.15511675]\n",
      " [2.83769472]]\n",
      "gradients: [[0.94159134]\n",
      " [0.13133765]]\n",
      "theta: [[4.15284354]\n",
      " [2.8334136 ]]\n",
      "gradients: [[1.72810151]\n",
      " [3.25451139]]\n",
      "theta: [[4.15321951]\n",
      " [2.83347162]]\n",
      "gradients: [[-0.28589297]\n",
      " [-0.04411703]]\n",
      "theta: [[4.15498462]\n",
      " [2.83378278]]\n",
      "gradients: [[-1.34254321]\n",
      " [-0.23667298]]\n",
      "theta: [[4.15370027]\n",
      " [2.83330638]]\n",
      "gradients: [[0.97713598]\n",
      " [0.36244682]]\n",
      "theta: [[4.15656077]\n",
      " [2.83734975]]\n",
      "gradients: [[-2.17683857]\n",
      " [-3.07700544]]\n",
      "theta: [[4.15476637]\n",
      " [2.83653093]]\n",
      "gradients: [[1.36589658]\n",
      " [0.62328498]]\n",
      "theta: [[4.15481826]\n",
      " [2.83654565]]\n",
      "gradients: [[-0.03951268]\n",
      " [-0.01120208]]\n",
      "theta: [[4.16037645]\n",
      " [2.84396994]]\n",
      "gradients: [[-4.23311563]\n",
      " [-5.65434133]]\n",
      "theta: [[4.16082107]\n",
      " [2.84452861]]\n",
      "gradients: [[-0.33870919]\n",
      " [-0.42559905]]\n",
      "theta: [[4.16367718]\n",
      " [2.84784761]]\n",
      "gradients: [[-2.17635741]\n",
      " [-2.5290761 ]]\n",
      "theta: [[4.1598674 ]\n",
      " [2.84695852]]\n",
      "gradients: [[2.90381678]\n",
      " [0.67766199]]\n",
      "theta: [[4.15968769]\n",
      " [2.84685785]]\n",
      "gradients: [[0.13700833]\n",
      " [0.07675163]]\n",
      "theta: [[4.15674125]\n",
      " [2.84369636]]\n",
      "gradients: [[2.24695248]\n",
      " [2.4109548 ]]\n",
      "theta: [[4.16071439]\n",
      " [2.85096246]]\n",
      "gradients: [[-3.03070678]\n",
      " [-5.54258381]]\n",
      "theta: [[4.15851577]\n",
      " [2.84854757]]\n",
      "gradients: [[1.67754844]\n",
      " [1.84256035]]\n",
      "theta: [[4.15765057]\n",
      " [2.84723007]]\n",
      "gradients: [[0.66031594]\n",
      " [1.00551671]]\n",
      "theta: [[4.15891046]\n",
      " [2.84736509]]\n",
      "gradients: [[-0.96179598]\n",
      " [-0.10306969]]\n",
      "theta: [[4.1593088 ]\n",
      " [2.84736747]]\n",
      "gradients: [[-0.3041719 ]\n",
      " [-0.00181984]]\n",
      "theta: [[4.15705193]\n",
      " [2.84605138]]\n",
      "gradients: [[1.72379109]\n",
      " [1.00522711]]\n",
      "theta: [[4.15694118]\n",
      " [2.84589822]]\n",
      "gradients: [[0.08461558]\n",
      " [0.11701628]]\n",
      "theta: [[4.15361992]\n",
      " [2.84237738]]\n",
      "gradients: [[2.53810388]\n",
      " [2.69062369]]\n",
      "theta: [[4.15503668]\n",
      " [2.84312701]]\n",
      "gradients: [[-1.08296439]\n",
      " [-0.57301762]]\n",
      "theta: [[4.15749433]\n",
      " [2.84427801]]\n",
      "gradients: [[-1.87912186]\n",
      " [-0.88004822]]\n",
      "theta: [[4.15890067]\n",
      " [2.84428865]]\n",
      "gradients: [[-1.07557156]\n",
      " [-0.00814214]]\n",
      "theta: [[4.16493033]\n",
      " [2.8551449 ]]\n",
      "gradients: [[-4.61268827]\n",
      " [-8.30502848]]\n",
      "theta: [[4.16231839]\n",
      " [2.85304881]]\n",
      "gradients: [[1.9986599 ]\n",
      " [1.60392393]]\n",
      "theta: [[4.16579617]\n",
      " [2.85709718]]\n",
      "gradients: [[-2.66189414]\n",
      " [-3.09861911]]\n",
      "theta: [[4.16597986]\n",
      " [2.85738506]]\n",
      "gradients: [[-0.14063639]\n",
      " [-0.22040415]]\n",
      "theta: [[4.16635844]\n",
      " [2.85738733]]\n",
      "gradients: [[-0.28991319]\n",
      " [-0.00173453]]\n",
      "theta: [[4.16728247]\n",
      " [2.85749981]]\n",
      "gradients: [[-0.70780879]\n",
      " [-0.08615861]]\n",
      "theta: [[4.16628963]\n",
      " [2.8558176 ]]\n",
      "gradients: [[0.76071372]\n",
      " [1.28890998]]\n",
      "theta: [[4.16901408]\n",
      " [2.85966866]]\n",
      "gradients: [[-2.08801973]\n",
      " [-2.95145821]]\n",
      "theta: [[4.16961658]\n",
      " [2.86049582]]\n",
      "gradients: [[-0.46187142]\n",
      " [-0.63409514]]\n",
      "theta: [[4.17096216]\n",
      " [2.86120779]]\n",
      "gradients: [[-1.03179746]\n",
      " [-0.54594419]]\n",
      "theta: [[4.17334852]\n",
      " [2.8623254 ]]\n",
      "gradients: [[-1.83033535]\n",
      " [-0.85720006]]\n",
      "theta: [[4.17405661]\n",
      " [2.86368729]]\n",
      "gradients: [[-0.54324493]\n",
      " [-1.0448465 ]]\n",
      "theta: [[4.17039917]\n",
      " [2.85964941]]\n",
      "gradients: [[2.80671607]\n",
      " [3.09867157]]\n",
      "theta: [[4.16591092]\n",
      " [2.85313035]]\n",
      "gradients: [[3.44518146]\n",
      " [5.0040272 ]]\n",
      "theta: [[4.17090934]\n",
      " [2.85352244]]\n",
      "gradients: [[-3.83778668]\n",
      " [-0.3010456 ]]\n",
      "theta: [[4.17073691]\n",
      " [2.85348864]]\n",
      "gradients: [[0.1324241]\n",
      " [0.0259589]]\n",
      "theta: [[4.17052074]\n",
      " [2.85336754]]\n",
      "gradients: [[0.16606367]\n",
      " [0.09302834]]\n",
      "theta: [[4.17282334]\n",
      " [2.85560356]]\n",
      "gradients: [[-1.76931326]\n",
      " [-1.71816026]]\n",
      "theta: [[4.17372798]\n",
      " [2.85571368]]\n",
      "gradients: [[-0.69531325]\n",
      " [-0.08463758]]\n",
      "theta: [[4.17039337]\n",
      " [2.85461028]]\n",
      "gradients: [[2.56365512]\n",
      " [0.84829517]]\n",
      "theta: [[4.16703383]\n",
      " [2.85104887]]\n",
      "gradients: [[2.58347942]\n",
      " [2.73872594]]\n",
      "theta: [[4.16943595]\n",
      " [2.85217385]]\n",
      "gradients: [[-1.84770746]\n",
      " [-0.86533594]]\n",
      "theta: [[4.17078891]\n",
      " [2.85288973]]\n",
      "gradients: [[-1.04096534]\n",
      " [-0.5507951 ]]\n",
      "theta: [[4.16988183]\n",
      " [2.85150845]]\n",
      "gradients: [[0.69808652]\n",
      " [1.06303304]]\n",
      "theta: [[4.16492129]\n",
      " [2.84981098]]\n",
      "gradients: [[3.81862194]\n",
      " [1.30670882]]\n",
      "theta: [[4.16731024]\n",
      " [2.85022646]]\n",
      "gradients: [[-1.83948992]\n",
      " [-0.31992125]]\n",
      "theta: [[4.16757887]\n",
      " [2.85030158]]\n",
      "gradients: [[-0.20689952]\n",
      " [-0.05785149]]\n",
      "theta: [[4.16769837]\n",
      " [2.85038487]]\n",
      "gradients: [[-0.09205948]\n",
      " [-0.06416988]]\n",
      "theta: [[4.16411074]\n",
      " [2.84642406]]\n",
      "gradients: [[2.7646273 ]\n",
      " [3.05220472]]\n",
      "theta: [[4.16292854]\n",
      " [2.84536415]]\n",
      "gradients: [[0.91124022]\n",
      " [0.81697712]]\n",
      "theta: [[4.16225949]\n",
      " [2.8452577 ]]\n",
      "gradients: [[0.51583442]\n",
      " [0.0820673 ]]\n",
      "theta: [[4.1620781 ]\n",
      " [2.84515609]]\n",
      "gradients: [[0.13988693]\n",
      " [0.07836421]]\n",
      "theta: [[4.16820045]\n",
      " [2.85657029]]\n",
      "gradients: [[-4.72277626]\n",
      " [-8.80491271]]\n",
      "theta: [[4.17281699]\n",
      " [2.86115705]]\n",
      "gradients: [[-3.56212682]\n",
      " [-3.53914764]]\n",
      "theta: [[4.17518376]\n",
      " [2.86226548]]\n",
      "gradients: [[-1.82667322]\n",
      " [-0.85548498]]\n",
      "theta: [[4.17761854]\n",
      " [2.8633483 ]]\n",
      "gradients: [[-1.87964589]\n",
      " [-0.83593112]]\n",
      "theta: [[4.17794944]\n",
      " [2.86376409]]\n",
      "gradients: [[-0.25552595]\n",
      " [-0.32107662]]\n",
      "theta: [[4.17863369]\n",
      " [2.86508012]]\n",
      "gradients: [[-0.52850888]\n",
      " [-1.01650401]]\n",
      "theta: [[4.1765451]\n",
      " [2.8609281]]\n",
      "gradients: [[1.61364227]\n",
      " [3.20785272]]\n",
      "theta: [[4.17530012]\n",
      " [2.85981191]]\n",
      "gradients: [[0.96211629]\n",
      " [0.86259032]]\n",
      "theta: [[4.17426834]\n",
      " [2.85973809]]\n",
      "gradients: [[0.79757076]\n",
      " [0.05706068]]\n",
      "theta: [[4.16986792]\n",
      " [2.85545082]]\n",
      "gradients: [[3.40240579]\n",
      " [3.31492158]]\n",
      "theta: [[4.16625744]\n",
      " [2.85238173]]\n",
      "gradients: [[2.79234265]\n",
      " [2.3736348 ]]\n",
      "theta: [[4.16702745]\n",
      " [2.85386272]]\n",
      "gradients: [[-0.59567727]\n",
      " [-1.14569187]]\n",
      "theta: [[4.16721911]\n",
      " [2.85416309]]\n",
      "gradients: [[-0.14831188]\n",
      " [-0.23243312]]\n",
      "theta: [[4.16764943]\n",
      " [2.85432937]]\n",
      "gradients: [[-0.3330674 ]\n",
      " [-0.12869942]]\n",
      "theta: [[4.16405088]\n",
      " [2.85127042]]\n",
      "gradients: [[2.78599911]\n",
      " [2.36824247]]\n",
      "theta: [[4.1645281]\n",
      " [2.8520553]]\n",
      "gradients: [[-0.3695544 ]\n",
      " [-0.60781444]]\n",
      "theta: [[4.16751173]\n",
      " [2.8553776 ]]\n",
      "gradients: [[-2.31112581]\n",
      " [-2.57345064]]\n",
      "theta: [[4.16296448]\n",
      " [2.85408536]]\n",
      "gradients: [[3.52321369]\n",
      " [1.00122646]]\n",
      "theta: [[4.16305246]\n",
      " [2.85419009]]\n",
      "gradients: [[-0.06818988]\n",
      " [-0.08116312]]\n",
      "theta: [[4.16205624]\n",
      " [2.85411881]]\n",
      "gradients: [[0.77227104]\n",
      " [0.05525066]]\n",
      "theta: [[4.15800219]\n",
      " [2.84911665]]\n",
      "gradients: [[3.14351344]\n",
      " [3.87868178]]\n",
      "theta: [[4.15785387]\n",
      " [2.84897697]]\n",
      "gradients: [[0.11503874]\n",
      " [0.1083345 ]]\n",
      "theta: [[4.15806837]\n",
      " [2.84925077]]\n",
      "gradients: [[-0.16641433]\n",
      " [-0.21241653]]\n",
      "theta: [[4.1627036 ]\n",
      " [2.85385609]]\n",
      "gradients: [[-3.59693557]\n",
      " [-3.57373184]]\n",
      "theta: [[4.16347288]\n",
      " [2.85533568]]\n",
      "gradients: [[-0.59711352]\n",
      " [-1.14845428]]\n",
      "theta: [[4.16791719]\n",
      " [2.86166466]]\n",
      "gradients: [[-3.45056336]\n",
      " [-4.91381664]]\n",
      "theta: [[4.16472766]\n",
      " [2.85565187]]\n",
      "gradients: [[2.47699173]\n",
      " [4.66952721]]\n",
      "theta: [[4.16932459]\n",
      " [2.86021915]]\n",
      "gradients: [[-3.57089739]\n",
      " [-3.54786163]]\n",
      "theta: [[4.17311494]\n",
      " [2.86715099]]\n",
      "gradients: [[-2.94510605]\n",
      " [-5.38603643]]\n",
      "theta: [[4.1685587 ]\n",
      " [2.86585619]]\n",
      "gradients: [[3.54111163]\n",
      " [1.00631269]]\n",
      "theta: [[4.16896076]\n",
      " [2.86651747]]\n",
      "gradients: [[-0.31255965]\n",
      " [-0.5140739 ]]\n",
      "theta: [[4.16599305]\n",
      " [2.86333315]]\n",
      "gradients: [[2.30768771]\n",
      " [2.47612302]]\n",
      "theta: [[4.17196781]\n",
      " [2.87447221]]\n",
      "gradients: [[-4.64716951]\n",
      " [-8.66395519]]\n",
      "theta: [[4.1778723 ]\n",
      " [2.88548023]]\n",
      "gradients: [[-4.59368578]\n",
      " [-8.56424274]]\n",
      "theta: [[4.18018684]\n",
      " [2.88588277]]\n",
      "gradients: [[-1.80118084]\n",
      " [-0.3132586 ]]\n",
      "theta: [[4.18029174]\n",
      " [2.88592611]]\n",
      "gradients: [[-0.08165206]\n",
      " [-0.03373035]]\n",
      "theta: [[4.18611544]\n",
      " [2.89678352]]\n",
      "gradients: [[-4.53432975]\n",
      " [-8.45358227]]\n",
      "theta: [[4.18486734]\n",
      " [2.89647842]]\n",
      "gradients: [[0.97201598]\n",
      " [0.23761171]]\n",
      "theta: [[4.18147562]\n",
      " [2.89008448]]\n",
      "gradients: [[2.64215111]\n",
      " [4.98087916]]\n",
      "theta: [[4.18079047]\n",
      " [2.88882514]]\n",
      "gradients: [[0.53387186]\n",
      " [0.98127631]]\n",
      "theta: [[4.181452  ]\n",
      " [2.88951665]]\n",
      "gradients: [[-0.51559582]\n",
      " [-0.5389608 ]]\n",
      "theta: [[4.18146188]\n",
      " [2.88953215]]\n",
      "gradients: [[-0.0077097 ]\n",
      " [-0.01208258]]\n",
      "theta: [[4.17802555]\n",
      " [2.88588931]]\n",
      "gradients: [[2.67965724]\n",
      " [2.84068328]]\n",
      "theta: [[4.18019367]\n",
      " [2.88799476]]\n",
      "gradients: [[-1.6911406 ]\n",
      " [-1.64224766]]\n",
      "theta: [[4.18026389]\n",
      " [2.8880459 ]]\n",
      "gradients: [[-0.0547845 ]\n",
      " [-0.03990481]]\n",
      "theta: [[4.18033382]\n",
      " [2.88809684]]\n",
      "gradients: [[-0.05456955]\n",
      " [-0.03974824]]\n",
      "theta: [[4.18565913]\n",
      " [2.8889556 ]]\n",
      "gradients: [[-4.15693528]\n",
      " [-0.67035043]]\n",
      "theta: [[4.1843392 ]\n",
      " [2.88777221]]\n",
      "gradients: [[1.03060074]\n",
      " [0.92399041]]\n",
      "theta: [[4.18479253]\n",
      " [2.88839459]]\n",
      "gradients: [[-0.35405546]\n",
      " [-0.48607651]]\n",
      "theta: [[4.18626372]\n",
      " [2.89088351]]\n",
      "gradients: [[-1.14929506]\n",
      " [-1.94434218]]\n",
      "theta: [[4.18429207]\n",
      " [2.88792273]]\n",
      "gradients: [[1.54065382]\n",
      " [2.31355043]]\n",
      "theta: [[4.18492424]\n",
      " [2.88794977]]\n",
      "gradients: [[-0.4941065 ]\n",
      " [-0.02113827]]\n",
      "theta: [[4.18296829]\n",
      " [2.88501258]]\n",
      "gradients: [[1.52916387]\n",
      " [2.29629634]]\n",
      "theta: [[4.18512041]\n",
      " [2.88710248]]\n",
      "gradients: [[-1.68295788]\n",
      " [-1.63430152]]\n",
      "theta: [[4.18093856]\n",
      " [2.88194264]]\n",
      "gradients: [[3.27103677]\n",
      " [4.03602879]]\n",
      "theta: [[4.18130175]\n",
      " [2.88208298]]\n",
      "gradients: [[-0.28416011]\n",
      " [-0.10980132]]\n",
      "theta: [[4.18008121]\n",
      " [2.88178461]]\n",
      "gradients: [[0.95520145]\n",
      " [0.23350136]]\n",
      "theta: [[4.18019011]\n",
      " [2.8818296 ]]\n",
      "gradients: [[-0.08524922]\n",
      " [-0.03521633]]\n",
      "theta: [[4.18086881]\n",
      " [2.88253906]]\n",
      "gradients: [[-0.53142164]\n",
      " [-0.55550379]]\n",
      "theta: [[4.18183684]\n",
      " [2.88395241]]\n",
      "gradients: [[-0.75816517]\n",
      " [-1.10693715]]\n",
      "theta: [[4.17928666]\n",
      " [2.88093916]]\n",
      "gradients: [[1.99781273]\n",
      " [2.36058028]]\n",
      "theta: [[4.18158366]\n",
      " [2.88133865]]\n",
      "gradients: [[-1.79993166]\n",
      " [-0.31304134]]\n",
      "theta: [[4.1872406 ]\n",
      " [2.89152382]]\n",
      "gradients: [[-4.43390712]\n",
      " [-7.98313755]]\n",
      "theta: [[4.18837979]\n",
      " [2.8916459 ]]\n",
      "gradients: [[-0.89312255]\n",
      " [-0.09571039]]\n",
      "theta: [[4.18845694]\n",
      " [2.89167777]]\n",
      "gradients: [[-0.06050469]\n",
      " [-0.0249944 ]]\n",
      "theta: [[4.18844028]\n",
      " [2.89165165]]\n",
      "gradients: [[0.01307398]\n",
      " [0.02048943]]\n",
      "theta: [[4.18398841]\n",
      " [2.88731425]]\n",
      "gradients: [[3.49293563]\n",
      " [3.40312367]]\n",
      "theta: [[4.17843554]\n",
      " [2.87862484]]\n",
      "gradients: [[4.35789371]\n",
      " [6.81945189]]\n",
      "theta: [[4.17708865]\n",
      " [2.87812524]]\n",
      "gradients: [[1.05730413]\n",
      " [0.39218341]]\n",
      "theta: [[4.17861622]\n",
      " [2.88070954]]\n",
      "gradients: [[-1.19944955]\n",
      " [-2.02919201]]\n",
      "theta: [[4.17867209]\n",
      " [2.88078086]]\n",
      "gradients: [[-0.04388069]\n",
      " [-0.0560107 ]]\n",
      "theta: [[4.18083575]\n",
      " [2.88288196]]\n",
      "gradients: [[-1.69976903]\n",
      " [-1.65062663]]\n",
      "theta: [[4.18075654]\n",
      " [2.8828093 ]]\n",
      "gradients: [[0.06224073]\n",
      " [0.0570929 ]]\n",
      "theta: [[4.18047155]\n",
      " [2.88254092]]\n",
      "gradients: [[0.22400568]\n",
      " [0.21095106]]\n",
      "theta: [[4.17911785]\n",
      " [2.88203879]]\n",
      "gradients: [[1.06428132]\n",
      " [0.39477144]]\n",
      "theta: [[4.17969492]\n",
      " [2.88298631]]\n",
      "gradients: [[-0.45380914]\n",
      " [-0.74512538]]\n",
      "theta: [[4.17972322]\n",
      " [2.88300603]]\n",
      "gradients: [[-0.02226173]\n",
      " [-0.0155175 ]]\n",
      "theta: [[4.17967651]\n",
      " [2.88299279]]\n",
      "gradients: [[0.03675296]\n",
      " [0.01041968]]\n",
      "theta: [[4.17993323]\n",
      " [2.88331537]]\n",
      "gradients: [[-0.20204212]\n",
      " [-0.25387246]]\n",
      "theta: [[4.17729873]\n",
      " [2.88120119]]\n",
      "gradients: [[2.0738793 ]\n",
      " [1.66428747]]\n",
      "theta: [[4.17504175]\n",
      " [2.8787222 ]]\n",
      "gradients: [[1.77714343]\n",
      " [1.95195199]]\n",
      "theta: [[4.17721421]\n",
      " [2.88083185]]\n",
      "gradients: [[-1.71102798]\n",
      " [-1.66156007]]\n",
      "theta: [[4.17359631]\n",
      " [2.87775645]]\n",
      "gradients: [[2.8501856 ]\n",
      " [2.42280429]]\n",
      "theta: [[4.17136005]\n",
      " [2.87530022]]\n",
      "gradients: [[1.76217142]\n",
      " [1.93550726]]\n",
      "theta: [[4.17111764]\n",
      " [2.87507193]]\n",
      "gradients: [[0.19106975]\n",
      " [0.17993457]]\n",
      "theta: [[4.16830742]\n",
      " [2.87083615]]\n",
      "gradients: [[2.21557619]\n",
      " [3.33948935]]\n",
      "theta: [[4.16808465]\n",
      " [2.87052808]]\n",
      "gradients: [[0.17567708]\n",
      " [0.24294673]]\n",
      "theta: [[4.16562701]\n",
      " [2.86762418]]\n",
      "gradients: [[1.93858444]\n",
      " [2.29059718]]\n",
      "theta: [[4.16124323]\n",
      " [2.86125686]]\n",
      "gradients: [[3.45880338]\n",
      " [5.02381266]]\n",
      "theta: [[4.15990788]\n",
      " [2.86063772]]\n",
      "gradients: [[1.05385559]\n",
      " [0.48862498]]\n",
      "theta: [[4.16010958]\n",
      " [2.86103494]]\n",
      "gradients: [[-0.15922007]\n",
      " [-0.31356707]]\n",
      "theta: [[4.15981335]\n",
      " [2.86100445]]\n",
      "gradients: [[0.23390509]\n",
      " [0.02408109]]\n",
      "theta: [[4.16468641]\n",
      " [2.8613867 ]]\n",
      "gradients: [[-3.8487465 ]\n",
      " [-0.30190532]]\n",
      "theta: [[4.15932167]\n",
      " [2.85299169]]\n",
      "gradients: [[4.23814424]\n",
      " [6.63206189]]\n",
      "theta: [[4.15800258]\n",
      " [2.85238008]]\n",
      "gradients: [[1.04234811]\n",
      " [0.48328948]]\n",
      "theta: [[4.16074011]\n",
      " [2.85556128]]\n",
      "gradients: [[-2.1637465 ]\n",
      " [-2.51442136]]\n",
      "theta: [[4.15987256]\n",
      " [2.8553304 ]]\n",
      "gradients: [[0.68588893]\n",
      " [0.18253768]]\n",
      "theta: [[4.16005911]\n",
      " [2.85540746]]\n",
      "gradients: [[-0.14752291]\n",
      " [-0.0609415 ]]\n",
      "theta: [[4.16088788]\n",
      " [2.85628204]]\n",
      "gradients: [[-0.65556211]\n",
      " [-0.69179352]]\n",
      "theta: [[4.16620397]\n",
      " [2.85713932]]\n",
      "gradients: [[-4.2060881 ]\n",
      " [-0.67827685]]\n",
      "theta: [[4.16739498]\n",
      " [2.85726695]]\n",
      "gradients: [[-0.94256536]\n",
      " [-0.10100886]]\n",
      "theta: [[4.16650485]\n",
      " [2.85591147]]\n",
      "gradients: [[0.70462978]\n",
      " [1.07299699]]\n",
      "theta: [[4.17085299]\n",
      " [2.8621035 ]]\n",
      "gradients: [[-3.44285949]\n",
      " [-4.90284585]]\n",
      "theta: [[4.17352401]\n",
      " [2.86520741]]\n",
      "gradients: [[-2.11544713]\n",
      " [-2.45829419]]\n",
      "theta: [[4.173506 ]\n",
      " [2.8652023]]\n",
      "gradients: [[0.0142625 ]\n",
      " [0.00404351]]\n",
      "theta: [[4.17233064]\n",
      " [2.86491498]]\n",
      "gradients: [[0.9313569]\n",
      " [0.2276725]]\n",
      "theta: [[4.16879043]\n",
      " [2.86100651]]\n",
      "gradients: [[2.80597493]\n",
      " [3.09785333]]\n",
      "theta: [[4.16894809]\n",
      " [2.86107164]]\n",
      "gradients: [[-0.12499759]\n",
      " [-0.05163632]]\n",
      "theta: [[4.1746633 ]\n",
      " [2.87136173]]\n",
      "gradients: [[-4.53215873]\n",
      " [-8.16003708]]\n",
      "theta: [[4.17476188]\n",
      " [2.87151622]]\n",
      "gradients: [[-0.07819157]\n",
      " [-0.12254116]]\n",
      "theta: [[4.17489343]\n",
      " [2.87157056]]\n",
      "gradients: [[-0.1043716 ]\n",
      " [-0.04311576]]\n",
      "theta: [[4.17084573]\n",
      " [2.86657623]]\n",
      "gradients: [[3.21225412]\n",
      " [3.96349874]]\n",
      "theta: [[4.17566534]\n",
      " [2.8669543 ]]\n",
      "gradients: [[-3.82580761]\n",
      " [-0.30010593]]\n",
      "theta: [[4.17694099]\n",
      " [2.86762927]]\n",
      "gradients: [[-1.01286532]\n",
      " [-0.53592683]]\n",
      "theta: [[4.17922299]\n",
      " [2.86869799]]\n",
      "gradients: [[-1.81236298]\n",
      " [-0.84878307]]\n",
      "theta: [[4.18344003]\n",
      " [2.87557937]]\n",
      "gradients: [[-3.35002005]\n",
      " [-5.46656752]]\n",
      "theta: [[4.18308317]\n",
      " [2.87554263]]\n",
      "gradients: [[0.28356076]\n",
      " [0.02919326]]\n",
      "theta: [[4.1818809 ]\n",
      " [2.87524873]]\n",
      "gradients: [[0.95556667]\n",
      " [0.23359064]]\n",
      "theta: [[4.18517462]\n",
      " [2.87687965]]\n",
      "gradients: [[-2.61851149]\n",
      " [-1.29657509]]\n",
      "theta: [[4.18481333]\n",
      " [2.87684245]]\n",
      "gradients: [[0.28729768]\n",
      " [0.02957799]]\n",
      "theta: [[4.18919932]\n",
      " [2.88120015]]\n",
      "gradients: [[-3.48861828]\n",
      " [-3.4661133 ]]\n",
      "theta: [[4.18888997]\n",
      " [2.88077233]]\n",
      "gradients: [[0.24612597]\n",
      " [0.34037166]]\n",
      "theta: [[4.18563415]\n",
      " [2.87463459]]\n",
      "gradients: [[2.59097936]\n",
      " [4.88441219]]\n",
      "theta: [[4.18455942]\n",
      " [2.87281364]]\n",
      "gradients: [[0.85548148]\n",
      " [1.44947908]]\n",
      "theta: [[4.18098259]\n",
      " [2.86886474]]\n",
      "gradients: [[2.84787304]\n",
      " [3.14410971]]\n",
      "theta: [[4.17667117]\n",
      " [2.86466418]]\n",
      "gradients: [[3.43361826]\n",
      " [3.3453315 ]]\n",
      "theta: [[4.18247188]\n",
      " [2.87547875]]\n",
      "gradients: [[-4.62085029]\n",
      " [-8.61488692]]\n",
      "theta: [[4.18226586]\n",
      " [2.87543836]]\n",
      "gradients: [[0.16415731]\n",
      " [0.03217951]]\n",
      "theta: [[4.1789019 ]\n",
      " [2.86996871]]\n",
      "gradients: [[2.68107557]\n",
      " [4.35931091]]\n",
      "theta: [[4.17798635]\n",
      " [2.86972505]]\n",
      "gradients: [[0.7298811 ]\n",
      " [0.19424545]]\n",
      "theta: [[4.17594118]\n",
      " [2.86565935]]\n",
      "gradients: [[1.63081544]\n",
      " [3.24199227]]\n",
      "theta: [[4.17500427]\n",
      " [2.86423264]]\n",
      "gradients: [[0.74728175]\n",
      " [1.13794661]]\n",
      "theta: [[4.1752345 ]\n",
      " [2.86429701]]\n",
      "gradients: [[-0.18367889]\n",
      " [-0.05135873]]\n",
      "theta: [[4.17603112]\n",
      " [2.86521618]]\n",
      "gradients: [[-0.63570024]\n",
      " [-0.7334952 ]]\n",
      "theta: [[4.17242718]\n",
      " [2.86210628]]\n",
      "gradients: [[2.87666208]\n",
      " [2.48232182]]\n",
      "theta: [[4.17311096]\n",
      " [2.86342142]]\n",
      "gradients: [[-0.54593049]\n",
      " [-1.05001174]]\n",
      "theta: [[4.17237361]\n",
      " [2.86284801]]\n",
      "gradients: [[0.58884831]\n",
      " [0.45792963]]\n",
      "theta: [[4.17501592]\n",
      " [2.86591855]]\n",
      "gradients: [[-2.11067554]\n",
      " [-2.45274928]]\n",
      "theta: [[4.17131627]\n",
      " [2.86179866]]\n",
      "gradients: [[2.95601871]\n",
      " [3.29178962]]\n",
      "theta: [[4.17032792]\n",
      " [2.86172795]]\n",
      "gradients: [[0.78988733]\n",
      " [0.05651098]]\n",
      "theta: [[4.17013462]\n",
      " [2.86146063]]\n",
      "gradients: [[0.15452633]\n",
      " [0.21369701]]\n",
      "theta: [[4.17172259]\n",
      " [2.86414712]]\n",
      "gradients: [[-1.26974296]\n",
      " [-2.14811226]]\n",
      "theta: [[4.16956139]\n",
      " [2.86177333]]\n",
      "gradients: [[1.72852797]\n",
      " [1.89855447]]\n",
      "theta: [[4.17072996]\n",
      " [2.86189856]]\n",
      "gradients: [[-0.93485731]\n",
      " [-0.10018284]]\n",
      "theta: [[4.16983912]\n",
      " [2.86118276]]\n",
      "gradients: [[0.71285412]\n",
      " [0.57278243]]\n",
      "theta: [[4.17014313]\n",
      " [2.86122967]]\n",
      "gradients: [[-0.24333152]\n",
      " [-0.03754924]]\n",
      "theta: [[4.16617456]\n",
      " [2.85633298]]\n",
      "gradients: [[3.17723494]\n",
      " [3.92028968]]\n",
      "theta: [[4.16701397]\n",
      " [2.85730152]]\n",
      "gradients: [[-0.67219851]\n",
      " [-0.7756083 ]]\n",
      "theta: [[4.17224931]\n",
      " [2.85814578]]\n",
      "gradients: [[-4.19350712]\n",
      " [-0.67624803]]\n",
      "theta: [[4.17741725]\n",
      " [2.8650488 ]]\n",
      "gradients: [[-4.14054921]\n",
      " [-5.53069667]]\n",
      "theta: [[4.17752488]\n",
      " [2.86518618]]\n",
      "gradients: [[-0.08625839]\n",
      " [-0.11010294]]\n",
      "theta: [[4.1755141 ]\n",
      " [2.86118883]]\n",
      "gradients: [[1.61184635]\n",
      " [3.20428251]]\n",
      "theta: [[4.17434995]\n",
      " [2.86090425]]\n",
      "gradients: [[0.93341088]\n",
      " [0.2281746 ]]\n",
      "theta: [[4.17037882]\n",
      " [2.8560044 ]]\n",
      "gradients: [[3.18484552]\n",
      " [3.92968013]]\n",
      "theta: [[4.17080431]\n",
      " [2.85670421]]\n",
      "gradients: [[-0.34132635]\n",
      " [-0.56138714]]\n",
      "theta: [[4.17110688]\n",
      " [2.8567509 ]]\n",
      "gradients: [[-0.24278333]\n",
      " [-0.03746464]]\n",
      "theta: [[4.16993102]\n",
      " [2.85569667]]\n",
      "gradients: [[0.94374967]\n",
      " [0.84612363]]\n",
      "theta: [[4.16628991]\n",
      " [2.85164197]]\n",
      "gradients: [[2.92308295]\n",
      " [3.25511273]]\n",
      "theta: [[4.16667297]\n",
      " [2.8521233 ]]\n",
      "gradients: [[-0.30760197]\n",
      " [-0.38651182]]\n",
      "theta: [[4.16928465]\n",
      " [2.85581496]]\n",
      "gradients: [[-2.09769696]\n",
      " [-2.96513717]]\n",
      "theta: [[4.16574103]\n",
      " [2.85275711]]\n",
      "gradients: [[2.84694419]\n",
      " [2.45667773]]\n",
      "theta: [[4.1658559 ]\n",
      " [2.85283718]]\n",
      "gradients: [[-0.09231192]\n",
      " [-0.06434584]]\n",
      "theta: [[4.16715899]\n",
      " [2.85352667]]\n",
      "gradients: [[-1.04742348]\n",
      " [-0.55421223]]\n",
      "theta: [[4.1675541 ]\n",
      " [2.85386856]]\n",
      "gradients: [[-0.31766595]\n",
      " [-0.27488295]]\n",
      "theta: [[4.16917135]\n",
      " [2.85660458]]\n",
      "gradients: [[-1.30059207]\n",
      " [-2.20030183]]\n",
      "theta: [[4.16999877]\n",
      " [2.85755929]]\n",
      "gradients: [[-0.66557819]\n",
      " [-0.76796953]]\n",
      "theta: [[4.17078318]\n",
      " [2.85838706]]\n",
      "gradients: [[-0.63114128]\n",
      " [-0.66602301]]\n",
      "theta: [[4.17060153]\n",
      " [2.85813584]]\n",
      "gradients: [[0.14619649]\n",
      " [0.20217754]]\n",
      "theta: [[4.16738243]\n",
      " [2.85472331]]\n",
      "gradients: [[2.59137059]\n",
      " [2.7470913 ]]\n",
      "theta: [[4.16668216]\n",
      " [2.85417872]]\n",
      "gradients: [[0.56386273]\n",
      " [0.43849909]]\n",
      "theta: [[4.16693786]\n",
      " [2.85425022]]\n",
      "gradients: [[-0.20594549]\n",
      " [-0.05758473]]\n",
      "theta: [[4.17118531]\n",
      " [2.86118121]]\n",
      "gradients: [[-3.42174208]\n",
      " [-5.58360364]]\n",
      "theta: [[4.17381242]\n",
      " [2.86423409]]\n",
      "gradients: [[-2.11692602]\n",
      " [-2.46001276]]\n",
      "theta: [[4.17709475]\n",
      " [2.86585936]]\n",
      "gradients: [[-2.64555641]\n",
      " [-1.30996658]]\n",
      "theta: [[4.17344918]\n",
      " [2.8650086 ]]\n",
      "gradients: [[2.9390587 ]\n",
      " [0.68588637]]\n",
      "theta: [[4.17277566]\n",
      " [2.86490144]]\n",
      "gradients: [[0.54312642]\n",
      " [0.08640936]]\n",
      "theta: [[4.17079052]\n",
      " [2.86095506]]\n",
      "gradients: [[1.60121579]\n",
      " [3.1831494 ]]\n",
      "theta: [[4.17147672]\n",
      " [2.86227487]]\n",
      "gradients: [[-0.55363219]\n",
      " [-1.06482475]]\n",
      "theta: [[4.17128052]\n",
      " [2.86200354]]\n",
      "gradients: [[0.15833662]\n",
      " [0.21896632]]\n",
      "theta: [[4.16994922]\n",
      " [2.86138628]]\n",
      "gradients: [[1.07462257]\n",
      " [0.49825368]]\n",
      "theta: [[4.16994794]\n",
      " [2.86138511]]\n",
      "gradients: [[0.00103205]\n",
      " [0.00094669]]\n",
      "theta: [[4.17009947]\n",
      " [2.8614477 ]]\n",
      "gradients: [[-0.12236976]\n",
      " [-0.05055077]]\n",
      "theta: [[4.16725336]\n",
      " [2.85839386]]\n",
      "gradients: [[2.29908552]\n",
      " [2.46689297]]\n",
      "theta: [[4.16498809]\n",
      " [2.8541277 ]]\n",
      "gradients: [[1.83033955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [3.44705497]]\n",
      "theta: [[4.16468836]\n",
      " [2.85409684]]\n",
      "gradients: [[0.24223988]\n",
      " [0.02493918]]\n",
      "theta: [[4.16539893]\n",
      " [2.85526356]]\n",
      "gradients: [[-0.57442587]\n",
      " [-0.94317028]]\n",
      "theta: [[4.170146  ]\n",
      " [2.85563593]]\n",
      "gradients: [[-3.83847599]\n",
      " [-0.30109967]]\n",
      "theta: [[4.17278187]\n",
      " [2.85869899]]\n",
      "gradients: [[-2.13189263]\n",
      " [-2.47740499]]\n",
      "theta: [[4.17487317]\n",
      " [2.85908692]]\n",
      "gradients: [[-1.69186734]\n",
      " [-0.31383465]]\n",
      "theta: [[4.17291779]\n",
      " [2.85519971]]\n",
      "gradients: [[1.58229278]\n",
      " [3.14553125]]\n",
      "theta: [[4.16970978]\n",
      " [2.84998362]]\n",
      "gradients: [[2.59656512]\n",
      " [4.22190062]]\n",
      "theta: [[4.17010343]\n",
      " [2.85032425]]\n",
      "gradients: [[-0.31869611]\n",
      " [-0.27577437]]\n",
      "theta: [[4.16593483]\n",
      " [2.84626284]]\n",
      "gradients: [[3.3757324 ]\n",
      " [3.28893402]]\n",
      "theta: [[4.16331956]\n",
      " [2.84232091]]\n",
      "gradients: [[2.11836394]\n",
      " [3.19296346]]\n",
      "theta: [[4.1597648 ]\n",
      " [2.83836236]]\n",
      "gradients: [[2.88006985]\n",
      " [3.20721382]]\n",
      "theta: [[4.15979994]\n",
      " [2.83837232]]\n",
      "gradients: [[-0.02847737]\n",
      " [-0.00807351]]\n",
      "theta: [[4.1595179 ]\n",
      " [2.83834329]]\n",
      "gradients: [[0.22861947]\n",
      " [0.02353692]]\n",
      "theta: [[4.15842323]\n",
      " [2.83736185]]\n",
      "gradients: [[0.88756484]\n",
      " [0.79575083]]\n",
      "theta: [[4.15909438]\n",
      " [2.83828326]]\n",
      "gradients: [[-0.54430241]\n",
      " [-0.74726319]]\n",
      "theta: [[4.15991321]\n",
      " [2.83985815]]\n",
      "gradients: [[-0.66423579]\n",
      " [-1.27755346]]\n",
      "theta: [[4.15966406]\n",
      " [2.83975998]]\n",
      "gradients: [[0.20215657]\n",
      " [0.0796556 ]]\n",
      "theta: [[4.16485611]\n",
      " [2.84059725]]\n",
      "gradients: [[-4.21386446]\n",
      " [-0.67953087]]\n",
      "theta: [[4.17003252]\n",
      " [2.8475116 ]]\n",
      "gradients: [[-4.20221615]\n",
      " [-5.61306767]]\n",
      "theta: [[4.1668911 ]\n",
      " [2.84647213]]\n",
      "gradients: [[2.55083618]\n",
      " [0.84405347]]\n",
      "theta: [[4.16303206]\n",
      " [2.84171058]]\n",
      "gradients: [[3.13431314]\n",
      " [3.86732983]]\n",
      "theta: [[4.16321972]\n",
      " [2.8417881 ]]\n",
      "gradients: [[-0.15245656]\n",
      " [-0.06297958]]\n",
      "theta: [[4.16410316]\n",
      " [2.84189564]]\n",
      "gradients: [[-0.71788388]\n",
      " [-0.08738501]]\n",
      "theta: [[4.16405959]\n",
      " [2.84186286]]\n",
      "gradients: [[0.03541485]\n",
      " [0.02664221]]\n",
      "theta: [[4.16536645]\n",
      " [2.84187275]]\n",
      "gradients: [[-1.0624776 ]\n",
      " [-0.00804302]]\n",
      "theta: [[4.16555291]\n",
      " [2.84200857]]\n",
      "gradients: [[-0.15162911]\n",
      " [-0.11044604]]\n",
      "theta: [[4.16573384]\n",
      " [2.84208331]]\n",
      "gradients: [[-0.14716866]\n",
      " [-0.06079516]]\n",
      "theta: [[4.17015352]\n",
      " [2.84647447]]\n",
      "gradients: [[-3.59584708]\n",
      " [-3.57265037]]\n",
      "theta: [[4.16930943]\n",
      " [2.84579625]]\n",
      "gradients: [[0.68691454]\n",
      " [0.55193983]]\n",
      "theta: [[4.17040105]\n",
      " [2.84739003]]\n",
      "gradients: [[-0.88857447]\n",
      " [-1.29733748]]\n",
      "theta: [[4.17056504]\n",
      " [2.84750948]]\n",
      "gradients: [[-0.13352239]\n",
      " [-0.09725718]]\n",
      "theta: [[4.16966447]\n",
      " [2.84598361]]\n",
      "gradients: [[0.73342478]\n",
      " [1.24267316]]\n",
      "theta: [[4.16952986]\n",
      " [2.84579745]]\n",
      "gradients: [[0.10965318]\n",
      " [0.1516412 ]]\n",
      "theta: [[4.17378319]\n",
      " [2.85185446]]\n",
      "gradients: [[-3.46561545]\n",
      " [-4.93525176]]\n",
      "theta: [[4.17634054]\n",
      " [2.85546932]]\n",
      "gradients: [[-2.08423655]\n",
      " [-2.94611061]]\n",
      "theta: [[4.17519693]\n",
      " [2.85518976]]\n",
      "gradients: [[0.93226747]\n",
      " [0.22789509]]\n",
      "theta: [[4.17340527]\n",
      " [2.85274247]]\n",
      "gradients: [[1.46091819]\n",
      " [1.99552597]]\n",
      "theta: [[4.17331903]\n",
      " [2.85267759]]\n",
      "gradients: [[0.07033898]\n",
      " [0.05291527]]\n",
      "theta: [[4.17490713]\n",
      " [2.85295755]]\n",
      "gradients: [[-1.29557264]\n",
      " [-0.22839268]]\n",
      "theta: [[4.16972061]\n",
      " [2.84484141]]\n",
      "gradients: [[4.23220495]\n",
      " [6.62276779]]\n",
      "theta: [[4.16712118]\n",
      " [2.84092336]]\n",
      "gradients: [[2.12165053]\n",
      " [3.19791727]]\n",
      "theta: [[4.17136526]\n",
      " [2.84784886]]\n",
      "gradients: [[-3.46486904]\n",
      " [-5.65397827]]\n",
      "theta: [[4.17196485]\n",
      " [2.84867202]]\n",
      "gradients: [[-0.48962347]\n",
      " [-0.67219544]]\n",
      "theta: [[4.16975728]\n",
      " [2.84451453]]\n",
      "gradients: [[1.80314451]\n",
      " [3.3958389 ]]\n",
      "theta: [[4.17400308]\n",
      " [2.8505608 ]]\n",
      "gradients: [[-3.46881453]\n",
      " [-4.93980745]]\n",
      "theta: [[4.17223376]\n",
      " [2.84814403]]\n",
      "gradients: [[1.44588472]\n",
      " [1.97499116]]\n",
      "theta: [[4.17231181]\n",
      " [2.84823692]]\n",
      "gradients: [[-0.06379468]\n",
      " [-0.07593173]]\n",
      "theta: [[4.17804911]\n",
      " [2.85893327]]\n",
      "gradients: [[-4.69082136]\n",
      " [-8.74533756]]\n",
      "theta: [[4.17708665]\n",
      " [2.85730253]]\n",
      "gradients: [[0.78710457]\n",
      " [1.33362513]]\n",
      "theta: [[4.17659204]\n",
      " [2.85639343]]\n",
      "gradients: [[0.40458502]\n",
      " [0.74364229]]\n",
      "theta: [[4.17592391]\n",
      " [2.85628713]]\n",
      "gradients: [[0.54667087]\n",
      " [0.08697326]]\n",
      "theta: [[4.17664892]\n",
      " [2.857045  ]]\n",
      "gradients: [[-0.59335398]\n",
      " [-0.62024269]]\n",
      "theta: [[4.17664102]\n",
      " [2.85703775]]\n",
      "gradients: [[0.00646702]\n",
      " [0.00593214]]\n",
      "theta: [[4.1732109 ]\n",
      " [2.85412197]]\n",
      "gradients: [[2.80858681]\n",
      " [2.38744318]]\n",
      "theta: [[4.16963848]\n",
      " [2.85328828]]\n",
      "gradients: [[2.9258127 ]\n",
      " [0.68279516]]\n",
      "theta: [[4.17069565]\n",
      " [2.85483178]]\n",
      "gradients: [[-0.86603934]\n",
      " [-1.26443572]]\n",
      "theta: [[4.17012397]\n",
      " [2.85417437]]\n",
      "gradients: [[0.46843786]\n",
      " [0.53867993]]\n",
      "theta: [[4.17018944]\n",
      " [2.8542523 ]]\n",
      "gradients: [[-0.05365901]\n",
      " [-0.06386773]]\n",
      "theta: [[4.16829422]\n",
      " [2.85048467]]\n",
      "gradients: [[1.55370325]\n",
      " [3.08869648]]\n",
      "theta: [[4.17046417]\n",
      " [2.8525919 ]]\n",
      "gradients: [[-1.77936535]\n",
      " [-1.72792173]]\n",
      "theta: [[4.16580613]\n",
      " [2.85099794]]\n",
      "gradients: [[3.82052813]\n",
      " [1.30736111]]\n",
      "theta: [[4.16368397]\n",
      " [2.84976041]]\n",
      "gradients: [[1.74101997]\n",
      " [1.01527411]]\n",
      "theta: [[4.16442843]\n",
      " [2.85119227]]\n",
      "gradients: [[-0.61090761]\n",
      " [-1.17498505]]\n",
      "theta: [[4.16682259]\n",
      " [2.85560157]]\n",
      "gradients: [[-1.96512601]\n",
      " [-3.61915791]]\n",
      "theta: [[4.1662593 ]\n",
      " [2.85495382]]\n",
      "gradients: [[0.46246219]\n",
      " [0.53180822]]\n",
      "theta: [[4.16857786]\n",
      " [2.85598494]]\n",
      "gradients: [[-1.90399821]\n",
      " [-0.84676128]]\n",
      "theta: [[4.16579685]\n",
      " [2.85300095]]\n",
      "gradients: [[2.28431934]\n",
      " [2.45104903]]\n",
      "theta: [[4.16662529]\n",
      " [2.85395683]]\n",
      "gradients: [[-0.68064318]\n",
      " [-0.78535209]]\n",
      "theta: [[4.16349246]\n",
      " [2.85063575]]\n",
      "gradients: [[2.57455784]\n",
      " [2.72926824]]\n",
      "theta: [[4.16860523]\n",
      " [2.85146024]]\n",
      "gradients: [[-4.2027    ]\n",
      " [-0.67773048]]\n",
      "theta: [[4.16547555]\n",
      " [2.84814249]]\n",
      "gradients: [[2.57322449]\n",
      " [2.72785476]]\n",
      "theta: [[4.16238443]\n",
      " [2.84711966]]\n",
      "gradients: [[2.54213974]\n",
      " [0.84117588]]\n",
      "theta: [[4.16122198]\n",
      " [2.84695751]]\n",
      "gradients: [[0.95622987]\n",
      " [0.1333795 ]]\n",
      "theta: [[4.16284648]\n",
      " [2.8497058 ]]\n",
      "gradients: [[-1.33664011]\n",
      " [-2.2612868 ]]\n",
      "theta: [[4.1585808 ]\n",
      " [2.84849357]]\n",
      "gradients: [[3.51065956]\n",
      " [0.99765883]]\n",
      "theta: [[4.16369889]\n",
      " [2.84931892]]\n",
      "gradients: [[-4.21321422]\n",
      " [-0.67942601]]\n",
      "theta: [[4.1637937 ]\n",
      " [2.84943177]]\n",
      "gradients: [[-0.07806758]\n",
      " [-0.09292007]]\n",
      "theta: [[4.16800295]\n",
      " [2.855426  ]]\n",
      "gradients: [[-3.46673678]\n",
      " [-4.9368486 ]]\n",
      "theta: [[4.16754225]\n",
      " [2.85457923]]\n",
      "gradients: [[0.37951938]\n",
      " [0.69757071]]\n",
      "theta: [[4.16761247]\n",
      " [2.8546628 ]]\n",
      "gradients: [[-0.05785867]\n",
      " [-0.06886638]]\n",
      "theta: [[4.16637748]\n",
      " [2.85420471]]\n",
      "gradients: [[1.01788163]\n",
      " [0.37756051]]\n",
      "theta: [[4.16620599]\n",
      " [2.85404322]]\n",
      "gradients: [[0.1413724 ]\n",
      " [0.13313349]]\n",
      "theta: [[4.16663787]\n",
      " [2.85475353]]\n",
      "gradients: [[-0.35612319]\n",
      " [-0.58572384]]\n",
      "theta: [[4.16354761]\n",
      " [2.85373099]]\n",
      "gradients: [[2.54883947]\n",
      " [0.84339278]]\n",
      "theta: [[4.1635624 ]\n",
      " [2.85373518]]\n",
      "gradients: [[-0.01219755]\n",
      " [-0.00345808]]\n",
      "theta: [[4.15947939]\n",
      " [2.84975716]]\n",
      "gradients: [[3.36929679]\n",
      " [3.28266389]]\n",
      "theta: [[4.16204636]\n",
      " [2.85338562]]\n",
      "gradients: [[-2.1187733 ]\n",
      " [-2.99492901]]\n",
      "theta: [[4.16291531]\n",
      " [2.85349139]]\n",
      "gradients: [[-0.71740717]\n",
      " [-0.08732698]]\n",
      "theta: [[4.15996524]\n",
      " [2.84793003]]\n",
      "gradients: [[2.43617215]\n",
      " [4.59257574]]\n",
      "theta: [[4.15915546]\n",
      " [2.84727936]]\n",
      "gradients: [[0.66887707]\n",
      " [0.53744662]]\n",
      "theta: [[4.15934449]\n",
      " [2.84741705]]\n",
      "gradients: [[-0.15617479]\n",
      " [-0.1137571 ]]\n",
      "theta: [[4.16355718]\n",
      " [2.85341619]]\n",
      "gradients: [[-3.48137338]\n",
      " [-4.95769203]]\n",
      "theta: [[4.16615848]\n",
      " [2.85643908]]\n",
      "gradients: [[-2.15022922]\n",
      " [-2.49871336]]\n",
      "theta: [[4.16701532]\n",
      " [2.85654338]]\n",
      "gradients: [[-0.70843956]\n",
      " [-0.08623539]]\n",
      "theta: [[4.17059836]\n",
      " [2.86309606]]\n",
      "gradients: [[-2.96316916]\n",
      " [-5.41907041]]\n",
      "theta: [[4.17125815]\n",
      " [2.86436507]]\n",
      "gradients: [[-0.54578075]\n",
      " [-1.04972375]]\n",
      "theta: [[4.17075188]\n",
      " [2.86343452]]\n",
      "gradients: [[0.41889046]\n",
      " [0.76993622]]\n",
      "theta: [[4.16980001]\n",
      " [2.86182173]]\n",
      "gradients: [[0.78776341]\n",
      " [1.33474144]]\n",
      "theta: [[4.16894553]\n",
      " [2.86159433]]\n",
      "gradients: [[0.70734095]\n",
      " [0.18824677]]\n",
      "theta: [[4.17048136]\n",
      " [2.8641926 ]]\n",
      "gradients: [[-1.27166878]\n",
      " [-2.1513703 ]]\n",
      "theta: [[4.1691833 ]\n",
      " [2.86359075]]\n",
      "gradients: [[1.07505419]\n",
      " [0.4984538 ]]\n",
      "theta: [[4.16956809]\n",
      " [2.86422363]]\n",
      "gradients: [[-0.31876251]\n",
      " [-0.52427588]]\n",
      "theta: [[4.16748701]\n",
      " [2.86193784]]\n",
      "gradients: [[1.72438705]\n",
      " [1.89400622]]\n",
      "theta: [[4.16762463]\n",
      " [2.8621135 ]]\n",
      "gradients: [[-0.11406072]\n",
      " [-0.14559072]]\n",
      "theta: [[4.16971208]\n",
      " [2.86261377]]\n",
      "gradients: [[-1.73049714]\n",
      " [-0.41471893]]\n",
      "theta: [[4.17055606]\n",
      " [2.8627165 ]]\n",
      "gradients: [[-0.69982912]\n",
      " [-0.08518728]]\n",
      "theta: [[4.16969541]\n",
      " [2.86202496]]\n",
      "gradients: [[0.71382075]\n",
      " [0.57355913]]\n",
      "theta: [[4.16978158]\n",
      " [2.86208503]]\n",
      "gradients: [[-0.07148287]\n",
      " [-0.04982699]]\n",
      "theta: [[4.17044596]\n",
      " [2.86336286]]\n",
      "gradients: [[-0.55130344]\n",
      " [-1.06034577]]\n",
      "theta: [[4.16852977]\n",
      " [2.85955355]]\n",
      "gradients: [[1.59043912]\n",
      " [3.16172585]]\n",
      "theta: [[4.16882663]\n",
      " [2.85959936]]\n",
      "gradients: [[-0.24645304]\n",
      " [-0.03803093]]\n",
      "theta: [[4.16912268]\n",
      " [2.85964505]]\n",
      "gradients: [[-0.24584518]\n",
      " [-0.03793713]]\n",
      "theta: [[4.17324861]\n",
      " [2.86552061]]\n",
      "gradients: [[-3.42699014]\n",
      " [-4.88024691]]\n",
      "theta: [[4.16940408]\n",
      " [2.86077697]]\n",
      "gradients: [[3.1940348]\n",
      " [3.9410185]]\n",
      "theta: [[4.16945147]\n",
      " [2.86083338]]\n",
      "gradients: [[-0.03938128]\n",
      " [-0.04687364]]\n",
      "theta: [[4.16979185]\n",
      " [2.86083541]]\n",
      "gradients: [[-0.28292872]\n",
      " [-0.00169274]]\n",
      "theta: [[4.16850419]\n",
      " [2.86023838]]\n",
      "gradients: [[1.07056203]\n",
      " [0.49637099]]\n",
      "theta: [[4.16874338]\n",
      " [2.86030526]]\n",
      "gradients: [[-0.19891272]\n",
      " [-0.05561829]]\n",
      "theta: [[4.17282894]\n",
      " [2.86697209]]\n",
      "gradients: [[-3.39836979]\n",
      " [-5.54546469]]\n",
      "theta: [[4.17296355]\n",
      " [2.86702769]]\n",
      "gradients: [[-0.11199181]\n",
      " [-0.04626365]]\n",
      "theta: [[4.17125028]\n",
      " [2.86624589]]\n",
      "gradients: [[1.42578739]\n",
      " [0.65061431]]\n",
      "theta: [[4.17114654]\n",
      " [2.86616786]]\n",
      "gradients: [[0.08634595]\n",
      " [0.06495714]]\n",
      "theta: [[4.17038284]\n",
      " [2.86585348]]\n",
      "gradients: [[0.63585679]\n",
      " [0.26174765]]\n",
      "theta: [[4.17061341]\n",
      " [2.86591795]]\n",
      "gradients: [[-0.19201532]\n",
      " [-0.0536897 ]]\n",
      "theta: [[4.17264645]\n",
      " [2.86629507]]\n",
      "gradients: [[-1.69352608]\n",
      " [-0.31414234]]\n",
      "theta: [[4.17317023]\n",
      " [2.86701416]]\n",
      "gradients: [[-0.43641211]\n",
      " [-0.59914251]]\n",
      "theta: [[4.17016127]\n",
      " [2.86134179]]\n",
      "gradients: [[2.50766717]\n",
      " [4.72735534]]\n",
      "theta: [[4.16987386]\n",
      " [2.86122854]]\n",
      "gradients: [[0.23958307]\n",
      " [0.09440273]]\n",
      "theta: [[4.16636888]\n",
      " [2.86041059]]\n",
      "gradients: [[2.92245555]\n",
      " [0.6820117 ]]\n",
      "theta: [[4.1637767 ]\n",
      " [2.85650344]]\n",
      "gradients: [[2.16188122]\n",
      " [3.25855611]]\n",
      "theta: [[4.16072674]\n",
      " [2.85549423]]\n",
      "gradients: [[2.54427519]\n",
      " [0.84188249]]\n",
      "theta: [[4.16330471]\n",
      " [2.85849001]]\n",
      "gradients: [[-2.15106046]\n",
      " [-2.49967932]]\n",
      "theta: [[4.16433936]\n",
      " [2.86000062]]\n",
      "gradients: [[-0.86351758]\n",
      " [-1.26075389]]\n",
      "theta: [[4.16992501]\n",
      " [2.87041424]]\n",
      "gradients: [[-4.66290291]\n",
      " [-8.69328777]]\n",
      "theta: [[4.16819268]\n",
      " [2.86781285]]\n",
      "gradients: [[1.44650032]\n",
      " [2.17216314]]\n",
      "theta: [[4.16542815]\n",
      " [2.86484654]]\n",
      "gradients: [[2.3089314 ]\n",
      " [2.47745749]]\n",
      "theta: [[4.16547321]\n",
      " [2.86490018]]\n",
      "gradients: [[-0.0376455 ]\n",
      " [-0.04480762]]\n",
      "theta: [[4.16472708]\n",
      " [2.86459304]]\n",
      "gradients: [[0.62346647]\n",
      " [0.25664723]]\n",
      "theta: [[4.16267454]\n",
      " [2.8623386 ]]\n",
      "gradients: [[1.71551653]\n",
      " [1.88426316]]\n",
      "theta: [[4.15811519]\n",
      " [2.86077841]]\n",
      "gradients: [[3.81161938]\n",
      " [1.30431259]]\n",
      "theta: [[4.16166156]\n",
      " [2.86726406]]\n",
      "gradients: [[-2.96547929]\n",
      " [-5.42329519]]\n",
      "theta: [[4.16571444]\n",
      " [2.87387754]]\n",
      "gradients: [[-3.3898227 ]\n",
      " [-5.53151754]]\n",
      "theta: [[4.16218211]\n",
      " [2.86994398]]\n",
      "gradients: [[2.95514182]\n",
      " [3.29081314]]\n",
      "theta: [[4.16470908]\n",
      " [2.87288049]]\n",
      "gradients: [[-2.11456652]\n",
      " [-2.45727087]]\n",
      "theta: [[4.16543714]\n",
      " [2.87364879]]\n",
      "gradients: [[-0.60938471]\n",
      " [-0.643064  ]]\n",
      "theta: [[4.1694917 ]\n",
      " [2.87942273]]\n",
      "gradients: [[-3.39447683]\n",
      " [-4.83394594]]\n",
      "theta: [[4.17060373]\n",
      " [2.8795419 ]]\n",
      "gradients: [[-0.93121395]\n",
      " [-0.0997924 ]]\n",
      "theta: [[4.16781132]\n",
      " [2.87654568]]\n",
      "gradients: [[2.33892379]\n",
      " [2.50963899]]\n",
      "theta: [[4.16397941]\n",
      " [2.87181761]]\n",
      "gradients: [[3.21036717]\n",
      " [3.96117049]]\n",
      "theta: [[4.1628263 ]\n",
      " [2.87165677]]\n",
      "gradients: [[0.96630982]\n",
      " [0.1347855 ]]\n",
      "theta: [[4.16489683]\n",
      " [2.87215298]]\n",
      "gradients: [[-1.73551965]\n",
      " [-0.41592259]]\n",
      "theta: [[4.16068939]\n",
      " [2.87095731]]\n",
      "gradients: [[3.52751834]\n",
      " [1.00244975]]\n",
      "theta: [[4.15689457]\n",
      " [2.86627501]]\n",
      "gradients: [[3.18233271]\n",
      " [3.92657966]]\n",
      "theta: [[4.15704917]\n",
      " [2.86651729]]\n",
      "gradients: [[-0.12967275]\n",
      " [-0.20322203]]\n",
      "theta: [[4.15622329]\n",
      " [2.86585368]]\n",
      "gradients: [[0.69291487]\n",
      " [0.55676113]]\n",
      "theta: [[4.15531733]\n",
      " [2.86578887]]\n",
      "gradients: [[0.76028158]\n",
      " [0.05439289]]\n",
      "theta: [[4.15514926]\n",
      " [2.8656306 ]]\n",
      "gradients: [[0.14107021]\n",
      " [0.13284891]]\n",
      "theta: [[4.15601661]\n",
      " [2.86573618]]\n",
      "gradients: [[-0.7282203 ]\n",
      " [-0.08864322]]\n",
      "theta: [[4.15482239]\n",
      " [2.86529321]]\n",
      "gradients: [[1.00290475]\n",
      " [0.37200517]]\n",
      "theta: [[4.15315463]\n",
      " [2.8627888 ]]\n",
      "gradients: [[1.4009149 ]\n",
      " [2.10370898]]\n",
      "theta: [[4.15357532]\n",
      " [2.8634807 ]]\n",
      "gradients: [[-0.35345782]\n",
      " [-0.58134004]]\n",
      "theta: [[4.15399219]\n",
      " [2.86416634]]\n",
      "gradients: [[-0.35034047]\n",
      " [-0.57621286]]\n",
      "theta: [[4.15479933]\n",
      " [2.86509766]]\n",
      "gradients: [[-0.6784864 ]\n",
      " [-0.78286351]]\n",
      "theta: [[4.15262202]\n",
      " [2.86099716]]\n",
      "gradients: [[1.83068186]\n",
      " [3.44769965]]\n",
      "theta: [[4.15582196]\n",
      " [2.86258163]]\n",
      "gradients: [[-2.69114278]\n",
      " [-1.33253901]]\n",
      "theta: [[4.15356889]\n",
      " [2.85991945]]\n",
      "gradients: [[1.89528029]\n",
      " [2.23942976]]\n",
      "theta: [[4.1541851 ]\n",
      " [2.86082343]]\n",
      "gradients: [[-0.51847873]\n",
      " [-0.76061159]]\n",
      "theta: [[4.15493052]\n",
      " [2.86160263]]\n",
      "gradients: [[-0.62734785]\n",
      " [-0.65577704]]\n",
      "theta: [[4.1538075 ]\n",
      " [2.86144599]]\n",
      "gradients: [[0.94536237]\n",
      " [0.13186365]]\n",
      "theta: [[4.15210295]\n",
      " [2.85911768]]\n",
      "gradients: [[1.43523056]\n",
      " [1.96043822]]\n",
      "theta: [[4.15527107]\n",
      " [2.86280558]]\n",
      "gradients: [[-2.66819591]\n",
      " [-3.10595479]]\n",
      "theta: [[4.15613606]\n",
      " [2.86291087]]\n",
      "gradients: [[-0.72866443]\n",
      " [-0.08869728]]\n",
      "theta: [[4.15738956]\n",
      " [2.86357413]]\n",
      "gradients: [[-1.05620278]\n",
      " [-0.55885753]]\n",
      "theta: [[4.15667029]\n",
      " [2.86327804]]\n",
      "gradients: [[0.60620744]\n",
      " [0.24954262]]\n",
      "theta: [[4.15450235]\n",
      " [2.85919519]]\n",
      "gradients: [[1.82757003]\n",
      " [3.44183917]]\n",
      "theta: [[4.15492291]\n",
      " [2.8593577 ]]\n",
      "gradients: [[-0.35461206]\n",
      " [-0.13702441]]\n",
      "theta: [[4.15618256]\n",
      " [2.8600242 ]]\n",
      "gradients: [[-1.0623892 ]\n",
      " [-0.56213088]]\n",
      "theta: [[4.15837959]\n",
      " [2.86040631]]\n",
      "gradients: [[-1.85341486]\n",
      " [-0.32234306]]\n",
      "theta: [[4.15632088]\n",
      " [2.85920577]]\n",
      "gradients: [[1.73713984]\n",
      " [1.01301142]]\n",
      "theta: [[4.15746055]\n",
      " [2.85932791]]\n",
      "gradients: [[-0.96188864]\n",
      " [-0.10307962]]\n",
      "theta: [[4.15531145]\n",
      " [2.85528053]]\n",
      "gradients: [[1.81427209]\n",
      " [3.41679534]]\n",
      "theta: [[4.15479191]\n",
      " [2.85468308]]\n",
      "gradients: [[0.43870154]\n",
      " [0.50448466]]\n",
      "theta: [[4.15267086]\n",
      " [2.85068853]]\n",
      "gradients: [[1.79143973]\n",
      " [3.37379544]]\n",
      "theta: [[4.15001799]\n",
      " [2.84784204]]\n",
      "gradients: [[2.24113937]\n",
      " [2.4047174 ]]\n",
      "theta: [[4.15321162]\n",
      " [2.85155963]]\n",
      "gradients: [[-2.69861698]\n",
      " [-3.14136689]]\n",
      "theta: [[4.15479253]\n",
      " [2.85183833]]\n",
      "gradients: [[-1.33618162]\n",
      " [-0.23555151]]\n",
      "theta: [[4.15492914]\n",
      " [2.85193355]]\n",
      "gradients: [[-0.11548979]\n",
      " [-0.08050193]]\n",
      "theta: [[4.15414454]\n",
      " [2.85073878]]\n",
      "gradients: [[0.66345489]\n",
      " [1.01029664]]\n",
      "theta: [[4.15403605]\n",
      " [2.85058874]]\n",
      "gradients: [[0.09176536]\n",
      " [0.12690382]]\n",
      "theta: [[4.15400253]\n",
      " [2.85056352]]\n",
      "gradients: [[0.02836008]\n",
      " [0.02133498]]\n",
      "theta: [[4.15856647]\n",
      " [2.85092153]]\n",
      "gradients: [[-3.86200617]\n",
      " [-0.30294544]]\n",
      "theta: [[4.1641292 ]\n",
      " [2.86129243]]\n",
      "gradients: [[-4.70830193]\n",
      " [-8.77792748]]\n",
      "theta: [[4.16076742]\n",
      " [2.85839148]]\n",
      "gradients: [[2.84608651]\n",
      " [2.45593762]]\n",
      "theta: [[4.16060441]\n",
      " [2.85823797]]\n",
      "gradients: [[0.13803784]\n",
      " [0.12999326]]\n",
      "theta: [[4.16044216]\n",
      " [2.85808518]]\n",
      "gradients: [[0.13742269]\n",
      " [0.12941396]]\n",
      "theta: [[4.160295  ]\n",
      " [2.85788166]]\n",
      "gradients: [[0.12467951]\n",
      " [0.17242135]]\n",
      "theta: [[4.15815375]\n",
      " [2.85384908]]\n",
      "gradients: [[1.8144936]\n",
      " [3.4172125]]\n",
      "theta: [[4.16369671]\n",
      " [2.8641831 ]]\n",
      "gradients: [[-4.69821141]\n",
      " [-8.75911521]]\n",
      "theta: [[4.16162997]\n",
      " [2.86297788]]\n",
      "gradients: [[1.75217894]\n",
      " [1.02178146]]\n",
      "theta: [[4.15946445]\n",
      " [2.85889959]]\n",
      "gradients: [[1.83635884]\n",
      " [3.45839102]]\n",
      "theta: [[4.15657638]\n",
      " [2.85345512]]\n",
      "gradients: [[2.44966108]\n",
      " [4.61800454]]\n",
      "theta: [[4.15906828]\n",
      " [2.85697746]]\n",
      "gradients: [[-2.11412505]\n",
      " [-2.98835861]]\n",
      "theta: [[4.15835636]\n",
      " [2.8566844 ]]\n",
      "gradients: [[0.60413389]\n",
      " [0.24868906]]\n",
      "theta: [[4.15631495]\n",
      " [2.85549396]]\n",
      "gradients: [[1.73275254]\n",
      " [1.01045297]]\n",
      "theta: [[4.15948245]\n",
      " [2.85706237]]\n",
      "gradients: [[-2.68920684]\n",
      " [-1.33158041]]\n",
      "theta: [[4.15735128]\n",
      " [2.85304878]]\n",
      "gradients: [[1.80978255]\n",
      " [3.40834025]]\n",
      "theta: [[4.16140689]\n",
      " [2.85966673]]\n",
      "gradients: [[-3.44483628]\n",
      " [-5.62128879]]\n",
      "theta: [[4.15837461]\n",
      " [2.85645223]]\n",
      "gradients: [[2.57622708]\n",
      " [2.73103779]]\n",
      "theta: [[4.15876314]\n",
      " [2.85678843]]\n",
      "gradients: [[-0.33017161]\n",
      " [-0.28570436]]\n",
      "theta: [[4.15907707]\n",
      " [2.85683688]]\n",
      "gradients: [[-0.26683968]\n",
      " [-0.04117685]]\n",
      "theta: [[4.16223204]\n",
      " [2.85839908]]\n",
      "gradients: [[-2.68235268]\n",
      " [-1.32818652]]\n",
      "theta: [[4.16424648]\n",
      " [2.85877275]]\n",
      "gradients: [[-1.71307826]\n",
      " [-0.3177692 ]]\n",
      "theta: [[4.16171567]\n",
      " [2.85495813]]\n",
      "gradients: [[2.15269906]\n",
      " [3.24471604]]\n",
      "theta: [[4.16235282]\n",
      " [2.85498539]]\n",
      "gradients: [[-0.54207979]\n",
      " [-0.0231906 ]]\n",
      "theta: [[4.16013144]\n",
      " [2.85236065]]\n",
      "gradients: [[1.89039084]\n",
      " [2.23365246]]\n",
      "theta: [[4.15672586]\n",
      " [2.85156589]]\n",
      "gradients: [[2.89883171]\n",
      " [0.67649862]]\n",
      "theta: [[4.16164619]\n",
      " [2.85813818]]\n",
      "gradients: [[-4.18917416]\n",
      " [-5.59564696]]\n",
      "theta: [[4.15752096]\n",
      " [2.85696587]]\n",
      "gradients: [[3.51305162]\n",
      " [0.9983386 ]]\n",
      "theta: [[4.15420398]\n",
      " [2.85410359]]\n",
      "gradients: [[2.82540309]\n",
      " [2.43808954]]\n",
      "theta: [[4.15120448]\n",
      " [2.84922654]]\n",
      "gradients: [[2.555573  ]\n",
      " [4.15524925]]\n",
      "theta: [[4.1508253]\n",
      " [2.8485296]]\n",
      "gradients: [[0.32313275]\n",
      " [0.59393   ]]\n",
      "theta: [[4.15108935]\n",
      " [2.84904962]]\n",
      "gradients: [[-0.22507655]\n",
      " [-0.44326445]]\n",
      "theta: [[4.14914929]\n",
      " [2.84691872]]\n",
      "gradients: [[1.65409638]\n",
      " [1.81680142]]\n",
      "theta: [[4.15074511]\n",
      " [2.84961849]]\n",
      "gradients: [[-1.36091673]\n",
      " [-2.30235724]]\n",
      "theta: [[4.14779827]\n",
      " [2.8486434 ]]\n",
      "gradients: [[2.51365566]\n",
      " [0.83175071]]\n",
      "theta: [[4.14853212]\n",
      " [2.84984832]]\n",
      "gradients: [[-0.62611446]\n",
      " [-1.02803961]]\n",
      "theta: [[4.14653407]\n",
      " [2.84868316]]\n",
      "gradients: [[1.70513114]\n",
      " [0.99434558]]\n",
      "theta: [[4.14858196]\n",
      " [2.84906304]]\n",
      "gradients: [[-1.74807872]\n",
      " [-0.32426164]]\n",
      "theta: [[4.1487866]\n",
      " [2.8492121]]\n",
      "gradients: [[-0.17472334]\n",
      " [-0.12726779]]\n",
      "theta: [[4.15037195]\n",
      " [2.85189413]]\n",
      "gradients: [[-1.35388239]\n",
      " [-2.29045676]]\n",
      "theta: [[4.14709127]\n",
      " [2.84906318]]\n",
      "gradients: [[2.80235208]\n",
      " [2.41819843]]\n",
      "theta: [[4.14319702]\n",
      " [2.84526906]]\n",
      "gradients: [[3.32725079]\n",
      " [3.24169899]]\n",
      "theta: [[4.14572923]\n",
      " [2.84884839]]\n",
      "gradients: [[-2.1640261 ]\n",
      " [-3.05889476]]\n",
      "theta: [[4.14982905]\n",
      " [2.85468679]]\n",
      "gradients: [[-3.50452728]\n",
      " [-4.99066462]]\n",
      "theta: [[4.15435502]\n",
      " [2.85504182]]\n",
      "gradients: [[-3.86970625]\n",
      " [-0.30354945]]\n",
      "theta: [[4.15114148]\n",
      " [2.851494  ]]\n",
      "gradients: [[2.74822333]\n",
      " [3.0340944 ]]\n",
      "theta: [[4.15608317]\n",
      " [2.8522909 ]]\n",
      "gradients: [[-4.22712516]\n",
      " [-0.6816693 ]]\n",
      "theta: [[4.15430934]\n",
      " [2.84876459]]\n",
      "gradients: [[1.51769236]\n",
      " [3.01710835]]\n",
      "theta: [[4.1532753 ]\n",
      " [2.84851182]]\n",
      "gradients: [[0.88492709]\n",
      " [0.21632262]]\n",
      "theta: [[4.15251627]\n",
      " [2.84735599]]\n",
      "gradients: [[0.64972612]\n",
      " [0.98939072]]\n",
      "theta: [[4.15506988]\n",
      " [2.85032345]]\n",
      "gradients: [[-2.18639579]\n",
      " [-2.54074138]]\n",
      "theta: [[4.15552601]\n",
      " [2.85107366]]\n",
      "gradients: [[-0.3906314 ]\n",
      " [-0.64248026]]\n",
      "theta: [[4.15393879]\n",
      " [2.84869018]]\n",
      "gradients: [[1.35961606]\n",
      " [2.04169183]]\n",
      "theta: [[4.15746125]\n",
      " [2.85513209]]\n",
      "gradients: [[-3.01804623]\n",
      " [-5.51943009]]\n",
      "theta: [[4.15408099]\n",
      " [2.85136787]]\n",
      "gradients: [[2.896886 ]\n",
      " [3.2259401]]\n",
      "theta: [[4.15346031]\n",
      " [2.85088519]]\n",
      "gradients: [[0.53204098]\n",
      " [0.41375227]]\n",
      "theta: [[4.14858181]\n",
      " [2.84325107]]\n",
      "gradients: [[4.18282544]\n",
      " [6.54549624]]\n",
      "theta: [[4.14471182]\n",
      " [2.83948058]]\n",
      "gradients: [[3.31890653]\n",
      " [3.23356928]]\n",
      "theta: [[4.14112975]\n",
      " [2.83506077]]\n",
      "gradients: [[3.07270128]\n",
      " [3.7913089 ]]\n",
      "theta: [[4.14609998]\n",
      " [2.84169971]]\n",
      "gradients: [[-4.26445946]\n",
      " [-5.69620854]]\n",
      "theta: [[4.14318804]\n",
      " [2.83696502]]\n",
      "gradients: [[2.49902868]\n",
      " [4.06331068]]\n",
      "theta: [[4.14243904]\n",
      " [2.83569596]]\n",
      "gradients: [[0.64293891]\n",
      " [1.08935906]]\n",
      "theta: [[4.14504054]\n",
      " [2.83871909]]\n",
      "gradients: [[-2.23364975]\n",
      " [-2.59565371]]\n",
      "theta: [[4.14492629]\n",
      " [2.83865508]]\n",
      "gradients: [[0.09812321]\n",
      " [0.05496831]]\n",
      "theta: [[4.14472695]\n",
      " [2.83857653]]\n",
      "gradients: [[0.17123465]\n",
      " [0.06747146]]\n",
      "theta: [[4.14701003]\n",
      " [2.83959189]]\n",
      "gradients: [[-1.9616298 ]\n",
      " [-0.87239166]]\n",
      "theta: [[4.14815585]\n",
      " [2.83971468]]\n",
      "gradients: [[-0.98471412]\n",
      " [-0.10552569]]\n",
      "theta: [[4.14894762]\n",
      " [2.84123753]]\n",
      "gradients: [[-0.68060662]\n",
      " [-1.30904017]]\n",
      "theta: [[4.14848975]\n",
      " [2.840711  ]]\n",
      "gradients: [[0.39367638]\n",
      " [0.45270801]]\n",
      "theta: [[4.14915225]\n",
      " [2.84073934]]\n",
      "gradients: [[-0.56975064]\n",
      " [-0.02437438]]\n",
      "theta: [[4.15042362]\n",
      " [2.84141205]]\n",
      "gradients: [[-1.09363318]\n",
      " [-0.57866268]]\n",
      "theta: [[4.14727362]\n",
      " [2.83793438]]\n",
      "gradients: [[2.71026546]\n",
      " [2.99218813]]\n",
      "theta: [[4.14715543]\n",
      " [2.83786817]]\n",
      "gradients: [[0.10171018]\n",
      " [0.05697772]]\n",
      "theta: [[4.1438587 ]\n",
      " [2.83419697]]\n",
      "gradients: [[2.83782455]\n",
      " [3.16016992]]\n",
      "theta: [[4.14415637]\n",
      " [2.83466347]]\n",
      "gradients: [[-0.25628935]\n",
      " [-0.40165449]]\n",
      "theta: [[4.14030115]\n",
      " [2.82906387]]\n",
      "gradients: [[3.32011312]\n",
      " [4.82236903]]\n",
      "theta: [[4.14038552]\n",
      " [2.82908779]]\n",
      "gradients: [[-0.07267703]\n",
      " [-0.02060437]]\n",
      "theta: [[4.13603979]\n",
      " [2.82760071]]\n",
      "gradients: [[3.7442849 ]\n",
      " [1.28127115]]\n",
      "theta: [[4.1345128 ]\n",
      " [2.82690392]]\n",
      "gradients: [[1.31595727]\n",
      " [0.60049671]]\n",
      "theta: [[4.13946444]\n",
      " [2.82770242]]\n",
      "gradients: [[-4.26831334]\n",
      " [-0.68831134]]\n",
      "theta: [[4.1398291 ]\n",
      " [2.82775869]]\n",
      "gradients: [[-0.31441379]\n",
      " [-0.04851816]]\n",
      "theta: [[4.14397613]\n",
      " [2.83366431]]\n",
      "gradients: [[-3.57639359]\n",
      " [-5.09300671]]\n",
      "theta: [[4.14389408]\n",
      " [2.83364823]]\n",
      "gradients: [[0.07077216]\n",
      " [0.01387336]]\n",
      "theta: [[4.14502398]\n",
      " [2.83529791]]\n",
      "gradients: [[-0.9748779 ]\n",
      " [-1.42334231]]\n",
      "theta: [[4.14396001]\n",
      " [2.8351495 ]]\n",
      "gradients: [[0.91821108]\n",
      " [0.12807646]]\n",
      "theta: [[4.14441861]\n",
      " [2.83554634]]\n",
      "gradients: [[-0.39586821]\n",
      " [-0.34255299]]\n",
      "theta: [[4.14006748]\n",
      " [2.83405741]]\n",
      "gradients: [[3.75677124]\n",
      " [1.28554389]]\n",
      "theta: [[4.14042788]\n",
      " [2.83411303]]\n",
      "gradients: [[-0.3112464 ]\n",
      " [-0.04802939]]\n",
      "theta: [[4.14020908]\n",
      " [2.8340905 ]]\n",
      "gradients: [[0.18899835]\n",
      " [0.01945783]]\n",
      "theta: [[4.14067653]\n",
      " [2.83467786]]\n",
      "gradients: [[-0.40387159]\n",
      " [-0.50747772]]\n",
      "theta: [[4.13957819]\n",
      " [2.83427045]]\n",
      "gradients: [[0.9491838 ]\n",
      " [0.35207858]]\n",
      "theta: [[4.14235541]\n",
      " [2.83736291]]\n",
      "gradients: [[-2.40063266]\n",
      " [-2.673117  ]]\n",
      "theta: [[4.14224989]\n",
      " [2.83730379]]\n",
      "gradients: [[0.0912335 ]\n",
      " [0.05110871]]\n",
      "theta: [[4.1411939]\n",
      " [2.8371565]]\n",
      "gradients: [[0.91322248]\n",
      " [0.12738062]]\n",
      "theta: [[4.13831956]\n",
      " [2.8362054 ]]\n",
      "gradients: [[2.48630607]\n",
      " [0.82270092]]\n",
      "theta: [[4.14090937]\n",
      " [2.83921494]]\n",
      "gradients: [[-2.24070471]\n",
      " [-2.60385207]]\n",
      "theta: [[4.1389387 ]\n",
      " [2.83550361]]\n",
      "gradients: [[1.70541274]\n",
      " [3.21178191]]\n",
      "theta: [[4.13887947]\n",
      " [2.83544783]]\n",
      "gradients: [[0.05127239]\n",
      " [0.04828433]]\n",
      "theta: [[4.13977458]\n",
      " [2.83648064]]\n",
      "gradients: [[-0.77498487]\n",
      " [-0.89420713]]\n",
      "theta: [[4.1433439 ]\n",
      " [2.84300825]]\n",
      "gradients: [[-3.09103247]\n",
      " [-5.65290798]]\n",
      "theta: [[4.14263609]\n",
      " [2.84193041]]\n",
      "gradients: [[0.61310185]\n",
      " [0.93361997]]\n",
      "theta: [[4.14314753]\n",
      " [2.84277158]]\n",
      "gradients: [[-0.4431074 ]\n",
      " [-0.72878873]]\n",
      "theta: [[4.14076781]\n",
      " [2.83918468]]\n",
      "gradients: [[2.06226476]\n",
      " [3.1084064 ]]\n",
      "theta: [[4.14099747]\n",
      " [2.83927956]]\n",
      "gradients: [[-0.19907195]\n",
      " [-0.08223633]]\n",
      "theta: [[4.1408929 ]\n",
      " [2.83922098]]\n",
      "gradients: [[0.09066502]\n",
      " [0.05079026]]\n",
      "theta: [[4.14510325]\n",
      " [2.84340417]]\n",
      "gradients: [[-3.6512167 ]\n",
      " [-3.62766281]]\n",
      "theta: [[4.14437478]\n",
      " [2.84281883]]\n",
      "gradients: [[0.63187999]\n",
      " [0.50771925]]\n",
      "theta: [[4.14692575]\n",
      " [2.84578324]]\n",
      "gradients: [[-2.21322376]\n",
      " [-2.57191732]]\n",
      "theta: [[4.14453015]\n",
      " [2.8421724 ]]\n",
      "gradients: [[2.07889999]\n",
      " [3.13348032]]\n",
      "theta: [[4.14444373]\n",
      " [2.84209102]]\n",
      "gradients: [[0.07501557]\n",
      " [0.07064381]]\n",
      "theta: [[4.14459782]\n",
      " [2.84227443]]\n",
      "gradients: [[-0.13378396]\n",
      " [-0.15923658]]\n",
      "theta: [[4.14486209]\n",
      " [2.84268859]]\n",
      "gradients: [[-0.22949327]\n",
      " [-0.3596599 ]]\n",
      "theta: [[4.14009583]\n",
      " [2.8352301 ]]\n",
      "gradients: [[4.1399761 ]\n",
      " [6.47844344]]\n",
      "theta: [[4.13817224]\n",
      " [2.83410837]]\n",
      "gradients: [[1.67120936]\n",
      " [0.97456413]]\n",
      "theta: [[4.13857018]\n",
      " [2.83411075]]\n",
      "gradients: [[-0.34580695]\n",
      " [-0.00206894]]\n",
      "theta: [[4.13547139]\n",
      " [2.83147662]]\n",
      "gradients: [[2.69346686]\n",
      " [2.2895853 ]]\n",
      "theta: [[4.13824925]\n",
      " [2.83456978]]\n",
      "gradients: [[-2.41506816]\n",
      " [-2.68919099]]\n",
      "theta: [[4.13871681]\n",
      " [2.83515727]]\n",
      "gradients: [[-0.40658681]\n",
      " [-0.51088947]]\n",
      "theta: [[4.13953532]\n",
      " [2.83601288]]\n",
      "gradients: [[-0.71194295]\n",
      " [-0.74420569]]\n",
      "theta: [[4.14116411]\n",
      " [2.83876841]]\n",
      "gradients: [[-1.41704502]\n",
      " [-2.39731337]]\n",
      "theta: [[4.14204063]\n",
      " [2.83977978]]\n",
      "gradients: [[-0.76275277]\n",
      " [-0.88009326]]\n",
      "theta: [[4.13982531]\n",
      " [2.83800198]]\n",
      "gradients: [[1.9282195 ]\n",
      " [1.54739553]]\n",
      "theta: [[4.14110624]\n",
      " [2.83867975]]\n",
      "gradients: [[-1.11518385]\n",
      " [-0.59006556]]\n",
      "theta: [[4.14027234]\n",
      " [2.83862009]]\n",
      "gradients: [[0.72615928]\n",
      " [0.05195168]]\n",
      "theta: [[4.13872722]\n",
      " [2.83650955]]\n",
      "gradients: [[1.34580267]\n",
      " [1.83828513]]\n",
      "theta: [[4.13954425]\n",
      " [2.83808097]]\n",
      "gradients: [[-0.71179301]\n",
      " [-1.36902231]]\n",
      "theta: [[4.14038561]\n",
      " [2.83896883]]\n",
      "gradients: [[-0.73316001]\n",
      " [-0.77368007]]\n",
      "theta: [[4.14057175]\n",
      " [2.83909858]]\n",
      "gradients: [[-0.16224495]\n",
      " [-0.11309252]]\n",
      "theta: [[4.14371223]\n",
      " [2.8427543 ]]\n",
      "gradients: [[-2.73786538]\n",
      " [-3.18705461]]\n",
      "theta: [[4.14365624]\n",
      " [2.84267688]]\n",
      "gradients: [[0.04881697]\n",
      " [0.06750979]]\n",
      "theta: [[4.14767605]\n",
      " [2.84923641]]\n",
      "gradients: [[-3.50607612]\n",
      " [-5.72122004]]\n",
      "theta: [[4.14543549]\n",
      " [2.84743835]]\n",
      "gradients: [[1.95466821]\n",
      " [1.56862062]]\n",
      "theta: [[4.14465285]\n",
      " [2.84611231]]\n",
      "gradients: [[0.68292464]\n",
      " [1.1571086 ]]\n",
      "theta: [[4.14178948]\n",
      " [2.84516484]]\n",
      "gradients: [[2.4991508 ]\n",
      " [0.82695115]]\n",
      "theta: [[4.13891864]\n",
      " [2.84212148]]\n",
      "gradients: [[2.50624558]\n",
      " [2.65685095]]\n",
      "theta: [[4.1405192 ]\n",
      " [2.84482926]]\n",
      "gradients: [[-1.3976097 ]\n",
      " [-2.36443328]]\n",
      "theta: [[4.13766823]\n",
      " [2.8438859 ]]\n",
      "gradients: [[2.49003439]\n",
      " [0.8239346 ]]\n",
      "theta: [[4.14079613]\n",
      " [2.84752697]]\n",
      "gradients: [[-2.73252692]\n",
      " [-3.18084029]]\n",
      "theta: [[4.13752546]\n",
      " [2.84676369]]\n",
      "gradients: [[2.85790501]\n",
      " [0.66694758]]\n",
      "theta: [[4.13747108]\n",
      " [2.84668848]]\n",
      "gradients: [[0.04753277]\n",
      " [0.06573385]]\n",
      "theta: [[4.13364853]\n",
      " [2.84113634]]\n",
      "gradients: [[3.34167453]\n",
      " [4.85368636]]\n",
      "theta: [[4.1371781 ]\n",
      " [2.84759125]]\n",
      "gradients: [[-3.08625581]\n",
      " [-5.64417238]]\n",
      "theta: [[4.13748525]\n",
      " [2.84767713]]\n",
      "gradients: [[-0.26863748]\n",
      " [-0.07511413]]\n",
      "theta: [[4.13996427]\n",
      " [2.85118127]]\n",
      "gradients: [[-2.16864191]\n",
      " [-3.0654193 ]]\n",
      "theta: [[4.139963  ]\n",
      " [2.85118032]]\n",
      "gradients: [[0.00110801]\n",
      " [0.00083355]]\n",
      "theta: [[4.14058375]\n",
      " [2.85203253]]\n",
      "gradients: [[-0.54328059]\n",
      " [-0.74586037]]\n",
      "theta: [[4.13975324]\n",
      " [2.85197312]]\n",
      "gradients: [[0.72702489]\n",
      " [0.05201361]]\n",
      "theta: [[4.13690579]\n",
      " [2.85103091]]\n",
      "gradients: [[2.49323018]\n",
      " [0.82499206]]\n",
      "theta: [[4.14176506]\n",
      " [2.85181452]]\n",
      "gradients: [[-4.25574589]\n",
      " [-0.6862847 ]]\n",
      "theta: [[4.14024186]\n",
      " [2.84952719]]\n",
      "gradients: [[1.33431921]\n",
      " [2.00370436]]\n",
      "theta: [[4.13873033]\n",
      " [2.84725737]]\n",
      "gradients: [[1.32440319]\n",
      " [1.98881379]]\n",
      "theta: [[4.13521603]\n",
      " [2.84292119]]\n",
      "gradients: [[3.07992938]\n",
      " [3.80022743]]\n",
      "theta: [[4.13733811]\n",
      " [2.84498192]]\n",
      "gradients: [[-1.86021133]\n",
      " [-1.80643036]]\n",
      "theta: [[4.13568307]\n",
      " [2.84169176]]\n",
      "gradients: [[1.45114235]\n",
      " [2.88480973]]\n",
      "theta: [[4.13636183]\n",
      " [2.8417208 ]]\n",
      "gradients: [[-0.59528009]\n",
      " [-0.02546655]]\n",
      "theta: [[4.13402995]\n",
      " [2.838206  ]]\n",
      "gradients: [[2.04552571]\n",
      " [3.08317601]]\n",
      "theta: [[4.13484448]\n",
      " [2.83977261]]\n",
      "gradients: [[-0.7146618 ]\n",
      " [-1.37453998]]\n",
      "theta: [[4.13493281]\n",
      " [2.83979765]]\n",
      "gradients: [[-0.07751839]\n",
      " [-0.02197693]]\n",
      "theta: [[4.13330861]\n",
      " [2.83656882]]\n",
      "gradients: [[1.42571954]\n",
      " [2.83427028]]\n",
      "theta: [[4.13363041]\n",
      " [2.8366588 ]]\n",
      "gradients: [[-0.28254045]\n",
      " [-0.07900156]]\n",
      "theta: [[4.13081568]\n",
      " [2.83367493]]\n",
      "gradients: [[2.47189306]\n",
      " [2.62043413]]\n",
      "theta: [[4.12657128]\n",
      " [2.83222252]]\n",
      "gradients: [[3.72828461]\n",
      " [1.27579594]]\n",
      "theta: [[4.12727048]\n",
      " [2.83225243]]\n",
      "gradients: [[-0.61431387]\n",
      " [-0.02628083]]\n",
      "theta: [[4.12548445]\n",
      " [2.83029072]]\n",
      "gradients: [[1.56955973]\n",
      " [1.72394934]]\n",
      "theta: [[4.12525455]\n",
      " [2.82986816]]\n",
      "gradients: [[0.20208323]\n",
      " [0.37143649]]\n",
      "theta: [[4.12378519]\n",
      " [2.8278611 ]]\n",
      "gradients: [[1.29185785]\n",
      " [1.76459976]]\n",
      "theta: [[4.12454947]\n",
      " [2.8289823 ]]\n",
      "gradients: [[-0.6721057 ]\n",
      " [-0.98598334]]\n",
      "theta: [[4.12376314]\n",
      " [2.82892605]]\n",
      "gradients: [[0.69165816]\n",
      " [0.04948336]]\n",
      "theta: [[4.12595576]\n",
      " [2.82930739]]\n",
      "gradients: [[-1.92907079]\n",
      " [-0.33550102]]\n",
      "theta: [[4.12352187]\n",
      " [2.82669585]]\n",
      "gradients: [[2.14182571]\n",
      " [2.29815496]]\n",
      "theta: [[4.12630489]\n",
      " [2.82979475]]\n",
      "gradients: [[-2.44961403]\n",
      " [-2.72765801]]\n",
      "theta: [[4.1265313 ]\n",
      " [2.83006424]]\n",
      "gradients: [[-0.19933293]\n",
      " [-0.23725636]]\n",
      "theta: [[4.12374651]\n",
      " [2.82914277]]\n",
      "gradients: [[2.45228731]\n",
      " [0.81144436]]\n",
      "theta: [[4.12306776]\n",
      " [2.82896214]]\n",
      "gradients: [[0.59784005]\n",
      " [0.15910497]]\n",
      "theta: [[4.12423713]\n",
      " [2.83066944]]\n",
      "gradients: [[-1.03021413]\n",
      " [-1.50413438]]\n",
      "theta: [[4.12462745]\n",
      " [2.83072967]]\n",
      "gradients: [[-0.3439527]\n",
      " [-0.0530764]]\n",
      "theta: [[4.12479293]\n",
      " [2.83088146]]\n",
      "gradients: [[-0.14585358]\n",
      " [-0.13379027]]\n",
      "theta: [[4.12513868]\n",
      " [2.83142332]]\n",
      "gradients: [[-0.30481295]\n",
      " [-0.47770026]]\n",
      "theta: [[4.1236671 ]\n",
      " [2.83075181]]\n",
      "gradients: [[1.29764373]\n",
      " [0.59213988]]\n",
      "theta: [[4.12455189]\n",
      " [2.8316855 ]]\n",
      "gradients: [[-0.78038276]\n",
      " [-0.82351272]]\n",
      "theta: [[4.12351503]\n",
      " [2.8313009 ]]\n",
      "gradients: [[0.91471462]\n",
      " [0.33929301]]\n",
      "theta: [[4.12077246]\n",
      " [2.8268416 ]]\n",
      "gradients: [[2.42004275]\n",
      " [3.93488303]]\n",
      "theta: [[4.12107012]\n",
      " [2.82705841]]\n",
      "gradients: [[-0.26271436]\n",
      " [-0.1913601 ]]\n",
      "theta: [[4.12000329]\n",
      " [2.82656377]]\n",
      "gradients: [[0.94179684]\n",
      " [0.43666842]]\n",
      "theta: [[4.11941854]\n",
      " [2.82567332]]\n",
      "gradients: [[0.51633796]\n",
      " [0.78626974]]\n",
      "theta: [[4.12060413]\n",
      " [2.82740431]]\n",
      "gradients: [[-1.04711606]\n",
      " [-1.52881155]]\n",
      "theta: [[4.11785767]\n",
      " [2.82449282]]\n",
      "gradients: [[2.42621929]\n",
      " [2.57201572]]\n",
      "theta: [[4.11728531]\n",
      " [2.82362123]]\n",
      "gradients: [[0.50573949]\n",
      " [0.7701306 ]]\n",
      "theta: [[4.11533223]\n",
      " [2.8213135 ]]\n",
      "gradients: [[1.72613717]\n",
      " [2.03957323]]\n",
      "theta: [[4.11850533]\n",
      " [2.82288469]]\n",
      "gradients: [[-2.80502168]\n",
      " [-1.38892698]]\n",
      "theta: [[4.11937537]\n",
      " [2.82431323]]\n",
      "gradients: [[-0.76928864]\n",
      " [-1.2631224 ]]\n",
      "theta: [[4.11975555]\n",
      " [2.82490906]]\n",
      "gradients: [[-0.33623543]\n",
      " [-0.52694531]]\n",
      "theta: [[4.12013268]\n",
      " [2.82550009]]\n",
      "gradients: [[-0.33360753]\n",
      " [-0.52282687]]\n",
      "theta: [[4.12098874]\n",
      " [2.82690569]]\n",
      "gradients: [[-0.75744529]\n",
      " [-1.24367638]]\n",
      "theta: [[4.11802901]\n",
      " [2.82363808]]\n",
      "gradients: [[2.61936507]\n",
      " [2.89183226]]\n",
      "theta: [[4.12247792]\n",
      " [2.82398707]]\n",
      "gradients: [[-3.9381774]\n",
      " [-0.3089205]]\n",
      "theta: [[4.12051566]\n",
      " [2.82166849]]\n",
      "gradients: [[1.73738691]\n",
      " [2.05286573]]\n",
      "theta: [[4.11871063]\n",
      " [2.8182691 ]]\n",
      "gradients: [[1.59853533]\n",
      " [3.01050106]]\n",
      "theta: [[4.11917179]\n",
      " [2.81917731]]\n",
      "gradients: [[-0.4084956 ]\n",
      " [-0.80448886]]\n",
      "theta: [[4.12338679]\n",
      " [2.82336511]]\n",
      "gradients: [[-3.73448766]\n",
      " [-3.71039658]]\n",
      "theta: [[4.12615964]\n",
      " [2.8264527 ]]\n",
      "gradients: [[-2.45730177]\n",
      " [-2.73621835]]\n",
      "theta: [[4.13150982]\n",
      " [2.83608556]]\n",
      "gradients: [[-4.7423967 ]\n",
      " [-8.53856523]]\n",
      "theta: [[4.13045873]\n",
      " [2.83569568]]\n",
      "gradients: [[0.93189469]\n",
      " [0.34566557]]\n",
      "theta: [[4.13173272]\n",
      " [2.83570532]]\n",
      "gradients: [[-1.1297727 ]\n",
      " [-0.00855245]]\n",
      "theta: [[4.13287826]\n",
      " [2.83582809]]\n",
      "gradients: [[-1.01610176]\n",
      " [-0.1088893 ]]\n",
      "theta: [[4.1332288 ]\n",
      " [2.83651844]]\n",
      "gradients: [[-0.31099921]\n",
      " [-0.61248003]]\n",
      "theta: [[4.13013941]\n",
      " [2.83385254]]\n",
      "gradients: [[2.74152989]\n",
      " [2.3657139 ]]\n",
      "theta: [[4.12866367]\n",
      " [2.83317914]]\n",
      "gradients: [[1.30986218]\n",
      " [0.5977154 ]]\n",
      "theta: [[4.12798665]\n",
      " [2.83203203]]\n",
      "gradients: [[0.60106101]\n",
      " [1.01840353]]\n",
      "theta: [[4.12731568]\n",
      " [2.83089518]]\n",
      "gradients: [[0.59581977]\n",
      " [1.00952307]]\n",
      "theta: [[4.12759008]\n",
      " [2.83109505]]\n",
      "gradients: [[-0.24372269]\n",
      " [-0.17752664]]\n",
      "theta: [[4.12700491]\n",
      " [2.83085417]]\n",
      "gradients: [[0.51986874]\n",
      " [0.21400168]]\n",
      "theta: [[4.12632376]\n",
      " [2.83067289]]\n",
      "gradients: [[0.60526776]\n",
      " [0.16108173]]\n",
      "theta: [[4.12944456]\n",
      " [2.83221818]]\n",
      "gradients: [[-2.77376988]\n",
      " [-1.37345242]]\n",
      "theta: [[4.12637759]\n",
      " [2.82957163]]\n",
      "gradients: [[2.72653988]\n",
      " [2.35277875]]\n",
      "theta: [[4.12545577]\n",
      " [2.82934629]]\n",
      "gradients: [[0.81968007]\n",
      " [0.20037282]]\n",
      "theta: [[4.12322235]\n",
      " [2.8259799 ]]\n",
      "gradients: [[1.98640995]\n",
      " [2.99407212]]\n",
      "theta: [[4.12259272]\n",
      " [2.82547399]]\n",
      "gradients: [[0.56011718]\n",
      " [0.45005741]]\n",
      "theta: [[4.12108217]\n",
      " [2.82247107]]\n",
      "gradients: [[1.34408968]\n",
      " [2.67199356]]\n",
      "theta: [[4.12161174]\n",
      " [2.82313651]]\n",
      "gradients: [[-0.4713258 ]\n",
      " [-0.59223611]]\n",
      "theta: [[4.12222619]\n",
      " [2.8241471 ]]\n",
      "gradients: [[-0.54697763]\n",
      " [-0.89962643]]\n",
      "theta: [[4.12299676]\n",
      " [2.82527754]]\n",
      "gradients: [[-0.68612066]\n",
      " [-1.00654337]]\n",
      "theta: [[4.12324009]\n",
      " [2.82556715]]\n",
      "gradients: [[-0.21670243]\n",
      " [-0.25793043]]\n",
      "theta: [[4.12599344]\n",
      " [2.82863303]]\n",
      "gradients: [[-2.45269122]\n",
      " [-2.73108447]]\n",
      "theta: [[4.12851361]\n",
      " [2.83219533]]\n",
      "gradients: [[-2.24546398]\n",
      " [-3.17400885]]\n",
      "theta: [[4.1282722 ]\n",
      " [2.83175161]]\n",
      "gradients: [[0.21514301]\n",
      " [0.39544084]]\n",
      "theta: [[4.12875865]\n",
      " [2.83236285]]\n",
      "gradients: [[-0.43362315]\n",
      " [-0.5448615 ]]\n",
      "theta: [[4.12860842]\n",
      " [2.83230366]]\n",
      "gradients: [[0.13394073]\n",
      " [0.05277656]]\n",
      "theta: [[4.12720743]\n",
      " [2.83019983]]\n",
      "gradients: [[1.24940827]\n",
      " [1.87619633]]\n",
      "theta: [[4.12718745]\n",
      " [2.83018101]]\n",
      "gradients: [[0.01782045]\n",
      " [0.01678191]]\n",
      "theta: [[4.12752618]\n",
      " [2.83071188]]\n",
      "gradients: [[-0.3022194 ]\n",
      " [-0.47363566]]\n",
      "theta: [[4.12649532]\n",
      " [2.8303295 ]]\n",
      "gradients: [[0.91994093]\n",
      " [0.34123159]]\n",
      "theta: [[4.12806053]\n",
      " [2.83060543]]\n",
      "gradients: [[-1.39709942]\n",
      " [-0.24629053]]\n",
      "theta: [[4.12507387]\n",
      " [2.82806661]]\n",
      "gradients: [[2.66648814]\n",
      " [2.266652  ]]\n",
      "theta: [[4.12417773]\n",
      " [2.82726318]]\n",
      "gradients: [[0.80024956]\n",
      " [0.71746787]]\n",
      "theta: [[4.12326623]\n",
      " [2.82704036]]\n",
      "gradients: [[0.81415173]\n",
      " [0.19902141]]\n",
      "theta: [[4.12259939]\n",
      " [2.82686289]]\n",
      "gradients: [[0.59576045]\n",
      " [0.15855152]]\n",
      "theta: [[4.12613627]\n",
      " [2.83333118]]\n",
      "gradients: [[-3.16056091]\n",
      " [-5.78006222]]\n",
      "theta: [[4.12662175]\n",
      " [2.8339412 ]]\n",
      "gradients: [[-0.43392544]\n",
      " [-0.54524135]]\n",
      "theta: [[4.12677385]\n",
      " [2.83408072]]\n",
      "gradients: [[-0.13597316]\n",
      " [-0.12472704]]\n",
      "theta: [[4.12659304]\n",
      " [2.83406211]]\n",
      "gradients: [[0.16168363]\n",
      " [0.01664572]]\n",
      "theta: [[4.12295146]\n",
      " [2.83051417]]\n",
      "gradients: [[3.2570236 ]\n",
      " [3.17327751]]\n",
      "theta: [[4.12364641]\n",
      " [2.8305439 ]]\n",
      "gradients: [[-0.62169968]\n",
      " [-0.0265968 ]]\n",
      "theta: [[4.12307474]\n",
      " [2.83030857]]\n",
      "gradients: [[0.51152763]\n",
      " [0.2105681 ]]\n",
      "theta: [[4.12435365]\n",
      " [2.83031825]]\n",
      "gradients: [[-1.14462223]\n",
      " [-0.00866486]]\n",
      "theta: [[4.12640043]\n",
      " [2.83080877]]\n",
      "gradients: [[-1.83227875]\n",
      " [-0.43911121]]\n",
      "theta: [[4.12590378]\n",
      " [2.83042254]]\n",
      "gradients: [[0.44470349]\n",
      " [0.34583253]]\n",
      "theta: [[4.12617983]\n",
      " [2.83062362]]\n",
      "gradients: [[-0.24723504]\n",
      " [-0.18008502]]\n",
      "theta: [[4.12818417]\n",
      " [2.83099541]]\n",
      "gradients: [[-1.79548715]\n",
      " [-0.33305572]]\n",
      "theta: [[4.12902579]\n",
      " [2.83261413]]\n",
      "gradients: [[-0.75409026]\n",
      " [-1.45037443]]\n",
      "theta: [[4.13155607]\n",
      " [2.83555449]]\n",
      "gradients: [[-2.26763884]\n",
      " [-2.63515136]]\n",
      "theta: [[4.13552029]\n",
      " [2.8420233 ]]\n",
      "gradients: [[-3.55352109]\n",
      " [-5.79864081]]\n",
      "theta: [[4.1349845 ]\n",
      " [2.84160664]]\n",
      "gradients: [[0.48038561]\n",
      " [0.37358145]]\n",
      "theta: [[4.13549685]\n",
      " [2.84244931]]\n",
      "gradients: [[-0.45947563]\n",
      " [-0.75570992]]\n",
      "theta: [[4.13573155]\n",
      " [2.84262027]]\n",
      "gradients: [[-0.21052838]\n",
      " [-0.15334804]]\n",
      "theta: [[4.13345004]\n",
      " [2.83918139]]\n",
      "gradients: [[2.04697666]\n",
      " [3.08536299]]\n",
      "theta: [[4.13753537]\n",
      " [2.84324037]]\n",
      "gradients: [[-3.66618109]\n",
      " [-3.64253066]]\n",
      "theta: [[4.13778236]\n",
      " [2.84355564]]\n",
      "gradients: [[-0.22169606]\n",
      " [-0.28297989]]\n",
      "theta: [[4.14251444]\n",
      " [2.84987646]]\n",
      "gradients: [[-4.24846038]\n",
      " [-5.67483793]]\n",
      "theta: [[4.13973341]\n",
      " [2.84895624]]\n",
      "gradients: [[2.49736504]\n",
      " [0.82636026]]\n",
      "theta: [[4.14037727]\n",
      " [2.84990079]]\n",
      "gradients: [[-0.57831587]\n",
      " [-0.84839307]]\n",
      "theta: [[4.13728408]\n",
      " [2.84723162]]\n",
      "gradients: [[2.77892255]\n",
      " [2.39798068]]\n",
      "theta: [[4.13356398]\n",
      " [2.84182829]]\n",
      "gradients: [[3.34287831]\n",
      " [4.85543481]]\n",
      "theta: [[4.13421124]\n",
      " [2.8427169 ]]\n",
      "gradients: [[-0.5817571 ]\n",
      " [-0.79868408]]\n",
      "theta: [[4.13349436]\n",
      " [2.84150225]]\n",
      "gradients: [[0.64447662]\n",
      " [1.09196448]]\n",
      "theta: [[4.13388924]\n",
      " [2.84150462]]\n",
      "gradients: [[-0.35507424]\n",
      " [-0.00212438]]\n",
      "theta: [[4.13162114]\n",
      " [2.83808596]]\n",
      "gradients: [[2.03992884]\n",
      " [3.07473995]]\n",
      "theta: [[4.12888846]\n",
      " [2.83364274]]\n",
      "gradients: [[2.4583194 ]\n",
      " [3.99711918]]\n",
      "theta: [[4.13197129]\n",
      " [2.83723136]]\n",
      "gradients: [[-2.77393387]\n",
      " [-3.22904069]]\n",
      "theta: [[4.13228779]\n",
      " [2.83731986]]\n",
      "gradients: [[-0.28484457]\n",
      " [-0.07964582]]\n",
      "theta: [[4.13312014]\n",
      " [2.83819821]]\n",
      "gradients: [[-0.74927928]\n",
      " [-0.79069022]]\n",
      "theta: [[4.13310344]\n",
      " [2.83817512]]\n",
      "gradients: [[0.0150314 ]\n",
      " [0.02078718]]\n",
      "theta: [[4.13068822]\n",
      " [2.83558361]]\n",
      "gradients: [[2.17515103]\n",
      " [2.33391265]]\n",
      "theta: [[4.13270541]\n",
      " [2.83606704]]\n",
      "gradients: [[-1.8170859]\n",
      " [-0.4354702]]\n",
      "theta: [[4.13664498]\n",
      " [2.84249563]]\n",
      "gradients: [[-3.54954968]\n",
      " [-5.79216027]]\n",
      "theta: [[4.13516832]\n",
      " [2.8418218 ]]\n",
      "gradients: [[1.33076132]\n",
      " [0.60725208]]\n",
      "theta: [[4.13821363]\n",
      " [2.84332971]]\n",
      "gradients: [[-2.74503983]\n",
      " [-1.35922652]]\n",
      "theta: [[4.13720783]\n",
      " [2.84318941]]\n",
      "gradients: [[0.90683099]\n",
      " [0.12648911]]\n",
      "theta: [[4.13872827]\n",
      " [2.84345745]]\n",
      "gradients: [[-1.37114034]\n",
      " [-0.24171428]]\n",
      "theta: [[4.13566341]\n",
      " [2.84081273]]\n",
      "gradients: [[2.76450442]\n",
      " [2.38553902]]\n",
      "theta: [[4.13585086]\n",
      " [2.84094339]]\n",
      "gradients: [[-0.16911876]\n",
      " [-0.1178839 ]]\n",
      "theta: [[4.13426386]\n",
      " [2.8377885 ]]\n",
      "gradients: [[1.43211102]\n",
      " [2.84697625]]\n",
      "theta: [[4.1346556 ]\n",
      " [2.83779084]]\n",
      "gradients: [[-0.35357968]\n",
      " [-0.00211544]]\n",
      "theta: [[4.13154012]\n",
      " [2.83432148]]\n",
      "gradients: [[2.81265265]\n",
      " [3.13213877]]\n",
      "theta: [[4.12851203]\n",
      " [2.83170849]]\n",
      "gradients: [[2.73436094]\n",
      " [2.35952768]]\n",
      "theta: [[4.12934318]\n",
      " [2.83330707]]\n",
      "gradients: [[-0.75069154]\n",
      " [-1.44383753]]\n",
      "theta: [[4.13202555]\n",
      " [2.8362939 ]]\n",
      "gradients: [[-2.42324814]\n",
      " [-2.69829945]]\n",
      "theta: [[4.131763  ]\n",
      " [2.83581134]]\n",
      "gradients: [[0.23723354]\n",
      " [0.43604407]]\n",
      "theta: [[4.13150306]\n",
      " [2.83533356]]\n",
      "gradients: [[0.23493452]\n",
      " [0.43181837]]\n",
      "theta: [[4.13399904]\n",
      " [2.83823405]]\n",
      "gradients: [[-2.25636399]\n",
      " [-2.62204922]]\n",
      "theta: [[4.13793425]\n",
      " [2.84383804]]\n",
      "gradients: [[-3.55821859]\n",
      " [-5.06712439]]\n",
      "theta: [[4.13801058]\n",
      " [2.84385968]]\n",
      "gradients: [[-0.0690337 ]\n",
      " [-0.01957147]]\n",
      "theta: [[4.13881097]\n",
      " [2.8447043 ]]\n",
      "gradients: [[-0.72403116]\n",
      " [-0.7640467 ]]\n",
      "theta: [[4.13690791]\n",
      " [2.84112029]]\n",
      "gradients: [[1.72189204]\n",
      " [3.24281717]]\n",
      "theta: [[4.13378683]\n",
      " [2.83764469]]\n",
      "gradients: [[2.82457254]\n",
      " [3.14541263]]\n",
      "theta: [[4.13896452]\n",
      " [2.84696698]]\n",
      "gradients: [[-4.68684051]\n",
      " [-8.43853771]]\n",
      "theta: [[4.14006815]\n",
      " [2.84708525]]\n",
      "gradients: [[-0.99922447]\n",
      " [-0.10708067]]\n",
      "theta: [[4.14230862]\n",
      " [2.85121152]]\n",
      "gradients: [[-2.0289743 ]\n",
      " [-3.73674683]]\n",
      "theta: [[4.13771429]\n",
      " [2.84402208]]\n",
      "gradients: [[4.16154338]\n",
      " [6.512193  ]]\n",
      "theta: [[4.13966512]\n",
      " [2.84438395]]\n",
      "gradients: [[-1.76744751]\n",
      " [-0.32785447]]\n",
      "theta: [[4.13816397]\n",
      " [2.84233348]]\n",
      "gradients: [[1.36033438]\n",
      " [1.85813457]]\n",
      "theta: [[4.1345273 ]\n",
      " [2.83879031]]\n",
      "gradients: [[3.29628287]\n",
      " [3.21152734]]\n",
      "theta: [[4.13228483]\n",
      " [2.83541029]]\n",
      "gradients: [[2.03302254]\n",
      " [3.06433025]]\n",
      "theta: [[4.12958198]\n",
      " [2.83101557]]\n",
      "gradients: [[2.45094574]\n",
      " [3.98512993]]\n",
      "theta: [[4.12867041]\n",
      " [2.83079274]]\n",
      "gradients: [[0.82679479]\n",
      " [0.20211203]]\n",
      "theta: [[4.13262772]\n",
      " [2.83642819]]\n",
      "gradients: [[-3.59006965]\n",
      " [-5.11248227]]\n",
      "theta: [[4.13290202]\n",
      " [2.83677832]]\n",
      "gradients: [[-0.24890195]\n",
      " [-0.31770635]]\n",
      "theta: [[4.13080294]\n",
      " [2.83509381]]\n",
      "gradients: [[1.90512493]\n",
      " [1.52886214]]\n",
      "theta: [[4.12905931]\n",
      " [2.83317867]]\n",
      "gradients: [[1.58286639]\n",
      " [1.7385649 ]]\n",
      "theta: [[4.13137452]\n",
      " [2.83744258]]\n",
      "gradients: [[-2.10221529]\n",
      " [-3.87163421]]\n",
      "theta: [[4.1318294 ]\n",
      " [2.83801414]]\n",
      "gradients: [[-0.41311672]\n",
      " [-0.51909451]]\n",
      "theta: [[4.13395437]\n",
      " [2.83900933]]\n",
      "gradients: [[-1.93032543]\n",
      " [-0.90402837]]\n",
      "theta: [[4.13212371]\n",
      " [2.83794179]]\n",
      "gradients: [[1.66333416]\n",
      " [0.96997171]]\n",
      "theta: [[4.13459847]\n",
      " [2.84081763]]\n",
      "gradients: [[-2.2490608 ]\n",
      " [-2.61356241]]\n",
      "theta: [[4.13974016]\n",
      " [2.8500751 ]]\n",
      "gradients: [[-4.67379166]\n",
      " [-8.41504359]]\n",
      "theta: [[4.14123999]\n",
      " [2.8503395 ]]\n",
      "gradients: [[-1.36364796]\n",
      " [-0.24039347]]\n",
      "theta: [[4.13809494]\n",
      " [2.84960554]]\n",
      "gradients: [[2.86010546]\n",
      " [0.6674611 ]]\n",
      "theta: [[4.14319076]\n",
      " [2.85878043]]\n",
      "gradients: [[-4.63515387]\n",
      " [-8.34547723]]\n",
      "theta: [[4.14394057]\n",
      " [2.85957168]]\n",
      "gradients: [[-0.68218003]\n",
      " [-0.71988256]]\n",
      "theta: [[4.14611116]\n",
      " [2.86356924]]\n",
      "gradients: [[-1.97523711]\n",
      " [-3.63777946]]\n",
      "theta: [[4.1486626 ]\n",
      " [2.86641028]]\n",
      "gradients: [[-2.322318  ]\n",
      " [-2.58591321]]\n",
      "theta: [[4.14765625]\n",
      " [2.86550803]]\n",
      "gradients: [[0.91618145]\n",
      " [0.82140721]]\n",
      "theta: [[4.15190878]\n",
      " [2.86584161]]\n",
      "gradients: [[-3.87235415]\n",
      " [-0.30375716]]\n",
      "theta: [[4.15229818]\n",
      " [2.86599208]]\n",
      "gradients: [[-0.35466276]\n",
      " [-0.137044  ]]\n",
      "theta: [[4.15304204]\n",
      " [2.86685038]]\n",
      "gradients: [[-0.67766122]\n",
      " [-0.78191138]]\n",
      "theta: [[4.15696217]\n",
      " [2.87074521]]\n",
      "gradients: [[-3.57201609]\n",
      " [-3.54897311]]\n",
      "theta: [[4.15485897]\n",
      " [2.86826011]]\n",
      "gradients: [[1.9168526 ]\n",
      " [2.26491921]]\n",
      "theta: [[4.1549604 ]\n",
      " [2.86833081]]\n",
      "gradients: [[-0.09246336]\n",
      " [-0.0644514 ]]\n",
      "theta: [[4.15190663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [2.86573496]]\n",
      "gradients: [[2.78442493]\n",
      " [2.36690433]]\n",
      "theta: [[4.15653492]\n",
      " [2.86648132]]\n",
      "gradients: [[-4.22100183]\n",
      " [-0.68068185]]\n",
      "theta: [[4.1585635 ]\n",
      " [2.86683412]]\n",
      "gradients: [[-1.8504641 ]\n",
      " [-0.32182987]]\n",
      "theta: [[4.15869437]\n",
      " [2.86700117]]\n",
      "gradients: [[-0.11940819]\n",
      " [-0.1524164 ]]\n",
      "theta: [[4.16057577]\n",
      " [2.86735016]]\n",
      "gradients: [[-1.71696229]\n",
      " [-0.31848967]]\n",
      "theta: [[4.16201736]\n",
      " [2.8676043 ]]\n",
      "gradients: [[-1.315886  ]\n",
      " [-0.23197366]]\n",
      "theta: [[4.15922645]\n",
      " [2.86668081]]\n",
      "gradients: [[2.5481029 ]\n",
      " [0.84314905]]\n",
      "theta: [[4.15860649]\n",
      " [2.86619868]]\n",
      "gradients: [[0.56614873]\n",
      " [0.44027685]]\n",
      "theta: [[4.15756204]\n",
      " [2.866053  ]]\n",
      "gradients: [[0.95399646]\n",
      " [0.13306797]]\n",
      "theta: [[4.1614637 ]\n",
      " [2.86992949]]\n",
      "gradients: [[-3.56456057]\n",
      " [-3.54156569]]\n",
      "theta: [[4.16147156]\n",
      " [2.86993172]]\n",
      "gradients: [[-0.00718062]\n",
      " [-0.00203575]]\n",
      "theta: [[4.16042039]\n",
      " [2.8697851 ]]\n",
      "gradients: [[0.96076801]\n",
      " [0.1340125 ]]\n",
      "theta: [[4.15729928]\n",
      " [2.86709183]]\n",
      "gradients: [[2.85332583]\n",
      " [2.46218456]]\n",
      "theta: [[4.1574374]\n",
      " [2.8673083]]\n",
      "gradients: [[-0.12630311]\n",
      " [-0.19794116]]\n",
      "theta: [[4.15822817]\n",
      " [2.86740456]]\n",
      "gradients: [[-0.72323558]\n",
      " [-0.08803645]]\n",
      "theta: [[4.15572694]\n",
      " [2.86472076]]\n",
      "gradients: [[2.2881262 ]\n",
      " [2.45513375]]\n",
      "theta: [[4.16026905]\n",
      " [2.87078784]]\n",
      "gradients: [[-4.15602901]\n",
      " [-5.55137367]]\n",
      "theta: [[4.15923403]\n",
      " [2.86985989]]\n",
      "gradients: [[0.94724379]\n",
      " [0.84925631]]\n",
      "theta: [[4.15818938]\n",
      " [2.86971418]]\n",
      "gradients: [[0.95627292]\n",
      " [0.1333855 ]]\n",
      "theta: [[4.15742449]\n",
      " [2.86909959]]\n",
      "gradients: [[0.70033276]\n",
      " [0.56272144]]\n",
      "theta: [[4.15632358]\n",
      " [2.86869123]]\n",
      "gradients: [[1.00821569]\n",
      " [0.37397514]]\n",
      "theta: [[4.15637457]\n",
      " [2.86875191]]\n",
      "gradients: [[-0.04670235]\n",
      " [-0.05558755]]\n",
      "theta: [[4.16089756]\n",
      " [2.87479345]]\n",
      "gradients: [[-4.14396462]\n",
      " [-5.53525878]]\n",
      "theta: [[4.16088935]\n",
      " [2.87478592]]\n",
      "gradients: [[0.0075253]\n",
      " [0.0069029]]\n",
      "theta: [[4.16070195]\n",
      " [2.87452677]]\n",
      "gradients: [[0.17176533]\n",
      " [0.23753711]]\n",
      "theta: [[4.15913083]\n",
      " [2.87216747]]\n",
      "gradients: [[1.44040551]\n",
      " [2.16301076]]\n",
      "theta: [[4.15936092]\n",
      " [2.8722318 ]]\n",
      "gradients: [[-0.21098843]\n",
      " [-0.05899479]]\n",
      "theta: [[4.15716407]\n",
      " [2.87046883]]\n",
      "gradients: [[2.01494554]\n",
      " [1.61699315]]\n",
      "theta: [[4.15830441]\n",
      " [2.87107221]]\n",
      "gradients: [[-1.04614863]\n",
      " [-0.55353768]]\n",
      "theta: [[4.1575105 ]\n",
      " [2.86986326]]\n",
      "gradients: [[0.72849342]\n",
      " [1.10933609]]\n",
      "theta: [[4.15829767]\n",
      " [2.86995908]]\n",
      "gradients: [[-0.72246738]\n",
      " [-0.08794294]]\n",
      "theta: [[4.1562759 ]\n",
      " [2.86615149]]\n",
      "gradients: [[1.85598943]\n",
      " [3.49536106]]\n",
      "theta: [[4.16001599]\n",
      " [2.87147762]]\n",
      "gradients: [[-3.43415254]\n",
      " [-4.89044662]]\n",
      "theta: [[4.16231927]\n",
      " [2.87415419]]\n",
      "gradients: [[-2.11533439]\n",
      " [-2.45816319]]\n",
      "theta: [[4.16688868]\n",
      " [2.87489105]]\n",
      "gradients: [[-4.19746117]\n",
      " [-0.67688566]]\n",
      "theta: [[4.17135814]\n",
      " [2.88086108]]\n",
      "gradients: [[-4.1065358 ]\n",
      " [-5.48526361]]\n",
      "theta: [[4.17022124]\n",
      " [2.88043938]]\n",
      "gradients: [[1.04480831]\n",
      " [0.38754836]]\n",
      "theta: [[4.16964859]\n",
      " [2.87978085]]\n",
      "gradients: [[0.52638393]\n",
      " [0.605315  ]]\n",
      "theta: [[4.17025419]\n",
      " [2.8804139 ]]\n",
      "gradients: [[-0.55678786]\n",
      " [-0.58201952]]\n",
      "theta: [[4.17337444]\n",
      " [2.88612024]]\n",
      "gradients: [[-2.86938219]\n",
      " [-5.24755195]]\n",
      "theta: [[4.17092456]\n",
      " [2.8824276 ]]\n",
      "gradients: [[2.25339553]\n",
      " [3.39649361]]\n",
      "theta: [[4.17206384]\n",
      " [2.88243622]]\n",
      "gradients: [[-1.0481335 ]\n",
      " [-0.00793443]]\n",
      "theta: [[4.17127831]\n",
      " [2.88222717]]\n",
      "gradients: [[0.72284099]\n",
      " [0.19237184]]\n",
      "theta: [[4.17184396]\n",
      " [2.88225136]]\n",
      "gradients: [[-0.52062133]\n",
      " [-0.02227259]]\n",
      "theta: [[4.17564996]\n",
      " [2.88603282]]\n",
      "gradients: [[-3.50380899]\n",
      " [-3.48120601]]\n",
      "theta: [[4.17761069]\n",
      " [2.88637382]]\n",
      "gradients: [[-1.80543329]\n",
      " [-0.31399818]]\n",
      "theta: [[4.17471681]\n",
      " [2.88330605]]\n",
      "gradients: [[2.66525862]\n",
      " [2.82541941]]\n",
      "theta: [[4.17924321]\n",
      " [2.88403598]]\n",
      "gradients: [[-4.16971442]\n",
      " [-0.6724112 ]]\n",
      "theta: [[4.17756335]\n",
      " [2.8817414 ]]\n",
      "gradients: [[1.54781511]\n",
      " [2.11422191]]\n",
      "theta: [[4.17957894]\n",
      " [2.88263779]]\n",
      "gradients: [[-1.85756373]\n",
      " [-0.82611057]]\n",
      "theta: [[4.1786346 ]\n",
      " [2.88103776]]\n",
      "gradients: [[0.87049139]\n",
      " [1.47491102]]\n",
      "theta: [[4.17477338]\n",
      " [2.87994048]]\n",
      "gradients: [[3.56004363]\n",
      " [1.01169278]]\n",
      "theta: [[4.17254161]\n",
      " [2.87814948]]\n",
      "gradients: [[2.05814289]\n",
      " [1.65165902]]\n",
      "theta: [[4.17094256]\n",
      " [2.87574823]]\n",
      "gradients: [[1.47496503]\n",
      " [2.21490768]]\n",
      "theta: [[4.17016536]\n",
      " [2.8755414 ]]\n",
      "gradients: [[0.71703864]\n",
      " [0.19082765]]\n",
      "theta: [[4.16996041]\n",
      " [2.87534838]]\n",
      "gradients: [[0.18913462]\n",
      " [0.17811222]]\n",
      "theta: [[4.16975297]\n",
      " [2.87506152]]\n",
      "gradients: [[0.19146313]\n",
      " [0.26477752]]\n",
      "theta: [[4.16654039]\n",
      " [2.87148402]]\n",
      "gradients: [[2.96585582]\n",
      " [3.30274413]]\n",
      "theta: [[4.16703704]\n",
      " [2.87221261]]\n",
      "gradients: [[-0.45860512]\n",
      " [-0.67277662]]\n",
      "theta: [[4.16452939]\n",
      " [2.86952193]]\n",
      "gradients: [[2.31606191]\n",
      " [2.48510844]]\n",
      "theta: [[4.16395922]\n",
      " [2.86943122]]\n",
      "gradients: [[0.52672295]\n",
      " [0.08379963]]\n",
      "theta: [[4.16409742]\n",
      " [2.86948831]]\n",
      "gradients: [[-0.12769953]\n",
      " [-0.05275249]]\n",
      "theta: [[4.16856242]\n",
      " [2.87545239]]\n",
      "gradients: [[-4.12655164]\n",
      " [-5.51199956]]\n",
      "theta: [[4.17099746]\n",
      " [2.87816382]]\n",
      "gradients: [[-2.2509516 ]\n",
      " [-2.50644635]]\n",
      "theta: [[4.16634326]\n",
      " [2.87088069]]\n",
      "gradients: [[4.3032737 ]\n",
      " [6.73397975]]\n",
      "theta: [[4.16570862]\n",
      " [2.87038715]]\n",
      "gradients: [[0.58691461]\n",
      " [0.45642585]]\n",
      "theta: [[4.16705824]\n",
      " [2.87267038]]\n",
      "gradients: [[-1.24839174]\n",
      " [-2.1119909 ]]\n",
      "theta: [[4.16648238]\n",
      " [2.87257877]]\n",
      "gradients: [[0.53278246]\n",
      " [0.08476367]]\n",
      "theta: [[4.16548722]\n",
      " [2.8723355 ]]\n",
      "gradients: [[0.92091604]\n",
      " [0.22512021]]\n",
      "theta: [[4.16963115]\n",
      " [2.87266056]]\n",
      "gradients: [[-3.83562107]\n",
      " [-0.30087573]]\n",
      "theta: [[4.17073171]\n",
      " [2.87324289]]\n",
      "gradients: [[-1.01889509]\n",
      " [-0.5391173 ]]\n",
      "theta: [[4.16911043]\n",
      " [2.87102831]]\n",
      "gradients: [[1.50130669]\n",
      " [2.05069423]]\n",
      "theta: [[4.16606863]\n",
      " [2.86844263]]\n",
      "gradients: [[2.81731101]\n",
      " [2.3948592 ]]\n",
      "theta: [[4.16696342]\n",
      " [2.86974903]]\n",
      "gradients: [[-0.82892768]\n",
      " [-1.21025191]]\n",
      "theta: [[4.16882847]\n",
      " [2.870196  ]]\n",
      "gradients: [[-1.7281598 ]\n",
      " [-0.41415878]]\n",
      "theta: [[4.16771514]\n",
      " [2.86978303]]\n",
      "gradients: [[1.03183702]\n",
      " [0.38273695]]\n",
      "theta: [[4.16487416]\n",
      " [2.86516373]]\n",
      "gradients: [[2.6335835 ]\n",
      " [4.28209088]]\n",
      "theta: [[4.16170974]\n",
      " [2.86163987]]\n",
      "gradients: [[2.93405409]\n",
      " [3.26733007]]\n",
      "theta: [[4.15892667]\n",
      " [2.85868956]]\n",
      "gradients: [[2.58101619]\n",
      " [2.73611468]]\n",
      "theta: [[4.15827417]\n",
      " [2.85842096]]\n",
      "gradients: [[0.60526023]\n",
      " [0.24915271]]\n",
      "theta: [[4.15842664]\n",
      " [2.85861558]]\n",
      "gradients: [[-0.14146449]\n",
      " [-0.18056977]]\n",
      "theta: [[4.15895028]\n",
      " [2.85933448]]\n",
      "gradients: [[-0.48593781]\n",
      " [-0.66713547]]\n",
      "theta: [[4.15582625]\n",
      " [2.85860543]]\n",
      "gradients: [[2.89972435]\n",
      " [0.67670694]]\n",
      "theta: [[4.15653422]\n",
      " [2.85935252]]\n",
      "gradients: [[-0.6572784 ]\n",
      " [-0.69360466]]\n",
      "theta: [[4.15354875]\n",
      " [2.85681472]]\n",
      "gradients: [[2.77230856]\n",
      " [2.35660479]]\n",
      "theta: [[4.15051559]\n",
      " [2.85419735]]\n",
      "gradients: [[2.81719782]\n",
      " [2.43100907]]\n",
      "theta: [[4.15061551]\n",
      " [2.85431628]]\n",
      "gradients: [[-0.09282105]\n",
      " [-0.11048041]]\n",
      "theta: [[4.14960959]\n",
      " [2.85417597]]\n",
      "gradients: [[0.93469967]\n",
      " [0.13037636]]\n",
      "theta: [[4.14813837]\n",
      " [2.85350462]]\n",
      "gradients: [[1.36735048]\n",
      " [0.62394842]]\n",
      "theta: [[4.1502782 ]\n",
      " [2.85744554]]\n",
      "gradients: [[-1.98918885]\n",
      " [-3.66347425]]\n",
      "theta: [[4.15017851]\n",
      " [2.85742599]]\n",
      "gradients: [[0.09269991]\n",
      " [0.01817182]]\n",
      "theta: [[4.15003941]\n",
      " [2.85734807]]\n",
      "gradients: [[0.12935823]\n",
      " [0.07246607]]\n",
      "theta: [[4.14708877]\n",
      " [2.85409051]]\n",
      "gradients: [[2.74468442]\n",
      " [3.03018737]]\n",
      "theta: [[4.15080971]\n",
      " [2.86016234]]\n",
      "gradients: [[-3.46196151]\n",
      " [-5.64923377]]\n",
      "theta: [[4.15496497]\n",
      " [2.86048829]]\n",
      "gradients: [[-3.86688589]\n",
      " [-0.30332822]]\n",
      "theta: [[4.15220919]\n",
      " [2.8575669 ]]\n",
      "gradients: [[2.56508509]\n",
      " [2.71922625]]\n",
      "theta: [[4.15238785]\n",
      " [2.85784691]]\n",
      "gradients: [[-0.16633806]\n",
      " [-0.2606836 ]]\n",
      "theta: [[4.15292493]\n",
      " [2.85858425]]\n",
      "gradients: [[-0.500126  ]\n",
      " [-0.68661418]]\n",
      "theta: [[4.15112258]\n",
      " [2.85660461]]\n",
      "gradients: [[1.67871253]\n",
      " [1.84383894]]\n",
      "theta: [[4.15074678]\n",
      " [2.85591388]]\n",
      "gradients: [[0.35009127]\n",
      " [0.64348076]]\n",
      "theta: [[4.1557965 ]\n",
      " [2.86532833]]\n",
      "gradients: [[-4.70532631]\n",
      " [-8.77237989]]\n",
      "theta: [[4.1521738 ]\n",
      " [2.86179878]]\n",
      "gradients: [[3.37635509]\n",
      " [3.28954071]]\n",
      "theta: [[4.15177551]\n",
      " [2.8610667 ]]\n",
      "gradients: [[0.37128787]\n",
      " [0.68244089]]\n",
      "theta: [[4.15029317]\n",
      " [2.85884073]]\n",
      "gradients: [[1.3821275 ]\n",
      " [2.07549654]]\n",
      "theta: [[4.14734605]\n",
      " [2.85558704]]\n",
      "gradients: [[2.74848779]\n",
      " [3.03438636]]\n",
      "theta: [[4.14524034]\n",
      " [2.85389722]]\n",
      "gradients: [[1.96420098]\n",
      " [1.57627066]]\n",
      "theta: [[4.14562712]\n",
      " [2.8542319 ]]\n",
      "gradients: [[-0.36086196]\n",
      " [-0.31226136]]\n",
      "theta: [[4.1427028 ]\n",
      " [2.85100339]]\n",
      "gradients: [[2.72897921]\n",
      " [3.01284849]]\n",
      "theta: [[4.14297672]\n",
      " [2.85107998]]\n",
      "gradients: [[-0.25567993]\n",
      " [-0.07149105]]\n",
      "theta: [[4.14670424]\n",
      " [2.85716255]]\n",
      "gradients: [[-3.48001078]\n",
      " [-5.67868658]]\n",
      "theta: [[4.14878299]\n",
      " [2.85808703]]\n",
      "gradients: [[-1.94114377]\n",
      " [-0.86328095]]\n",
      "theta: [[4.14807332]\n",
      " [2.8575168 ]]\n",
      "gradients: [[0.66283501]\n",
      " [0.53259179]]\n",
      "theta: [[4.14711094]\n",
      " [2.85665398]]\n",
      "gradients: [[0.89905591]\n",
      " [0.80605321]]\n",
      "theta: [[4.14828405]\n",
      " [2.85666286]]\n",
      "gradients: [[-1.09615096]\n",
      " [-0.00829793]]\n",
      "theta: [[4.14897723]\n",
      " [2.85738745]]\n",
      "gradients: [[-0.64784818]\n",
      " [-0.67720638]]\n",
      "theta: [[4.14902884]\n",
      " [2.8574348 ]]\n",
      "gradients: [[-0.04824811]\n",
      " [-0.04425759]]\n",
      "theta: [[4.1459497 ]\n",
      " [2.85671622]]\n",
      "gradients: [[2.87899482]\n",
      " [0.6718693 ]]\n",
      "theta: [[4.14739206]\n",
      " [2.85697049]]\n",
      "gradients: [[-1.34888738]\n",
      " [-0.23779138]]\n",
      "theta: [[4.14776755]\n",
      " [2.85729541]]\n",
      "gradients: [[-0.3512398 ]\n",
      " [-0.30393511]]\n",
      "theta: [[4.14802624]\n",
      " [2.85736775]]\n",
      "gradients: [[-0.24203177]\n",
      " [-0.06767487]]\n",
      "theta: [[4.14703204]\n",
      " [2.85722907]]\n",
      "gradients: [[0.93037241]\n",
      " [0.12977278]]\n",
      "theta: [[4.14403538]\n",
      " [2.85464319]]\n",
      "gradients: [[2.8048795 ]\n",
      " [2.42037938]]\n",
      "theta: [[4.14693498]\n",
      " [2.85607895]]\n",
      "gradients: [[-2.7146085 ]\n",
      " [-1.34415823]]\n",
      "theta: [[4.14691104]\n",
      " [2.85606094]]\n",
      "gradients: [[0.0224184 ]\n",
      " [0.01686513]]\n",
      "theta: [[4.14763758]\n",
      " [2.85682764]]\n",
      "gradients: [[-0.68047904]\n",
      " [-0.71808756]]\n",
      "theta: [[4.14430564]\n",
      " [2.85271647]]\n",
      "gradients: [[3.12136079]\n",
      " [3.85134833]]\n",
      "theta: [[4.14361701]\n",
      " [2.85216314]]\n",
      "gradients: [[0.64524975]\n",
      " [0.51846192]]\n",
      "theta: [[4.14006777]\n",
      " [2.84870517]]\n",
      "gradients: [[3.32634278]\n",
      " [3.24081433]]\n",
      "theta: [[4.13900114]\n",
      " [2.84821062]]\n",
      "gradients: [[0.99986538]\n",
      " [0.46359217]]\n",
      "theta: [[4.14088181]\n",
      " [2.84855948]]\n",
      "gradients: [[-1.7633199 ]\n",
      " [-0.32708882]]\n",
      "theta: [[4.13758959]\n",
      " [2.84449731]]\n",
      "gradients: [[3.08744559]\n",
      " [3.80950144]]\n",
      "theta: [[4.14147801]\n",
      " [2.84836064]]\n",
      "gradients: [[-3.64733874]\n",
      " [-3.62380985]]\n",
      "theta: [[4.13962233]\n",
      " [2.84486587]]\n",
      "gradients: [[1.740998  ]\n",
      " [3.27879919]]\n",
      "theta: [[4.13944595]\n",
      " [2.84479637]]\n",
      "gradients: [[0.1655212 ]\n",
      " [0.06522019]]\n",
      "theta: [[4.14332729]\n",
      " [2.84865267]]\n",
      "gradients: [[-3.64303177]\n",
      " [-3.61953067]]\n",
      "theta: [[4.1426377 ]\n",
      " [2.84846915]]\n",
      "gradients: [[0.64738607]\n",
      " [0.1722908 ]]\n",
      "theta: [[4.14333841]\n",
      " [2.84981686]]\n",
      "gradients: [[-0.6579672 ]\n",
      " [-1.26549679]]\n",
      "theta: [[4.13890992]\n",
      " [2.84288693]]\n",
      "gradients: [[4.15923809]\n",
      " [6.50858557]]\n",
      "theta: [[4.13907996]\n",
      " [2.84300546]]\n",
      "gradients: [[-0.1597341 ]\n",
      " [-0.11134234]]\n",
      "theta: [[4.13858253]\n",
      " [2.84292632]]\n",
      "gradients: [[0.46738676]\n",
      " [0.07435946]]\n",
      "theta: [[4.13879924]\n",
      " [2.84308417]]\n",
      "gradients: [[-0.20366213]\n",
      " [-0.14834669]]\n",
      "theta: [[4.13821184]\n",
      " [2.84284237]]\n",
      "gradients: [[0.55215758]\n",
      " [0.22729324]]\n",
      "theta: [[4.13854394]\n",
      " [2.84289362]]\n",
      "gradients: [[-0.31224641]\n",
      " [-0.04818371]]\n",
      "theta: [[4.13871457]\n",
      " [2.84301255]]\n",
      "gradients: [[-0.16045675]\n",
      " [-0.11184606]]\n",
      "theta: [[4.13948473]\n",
      " [2.84382527]]\n",
      "gradients: [[-0.72441109]\n",
      " [-0.76444762]]\n",
      "theta: [[4.13621839]\n",
      " [2.83979505]]\n",
      "gradients: [[3.07296866]\n",
      " [3.79163881]]\n",
      "theta: [[4.1361611 ]\n",
      " [2.83974109]]\n",
      "gradients: [[0.05391443]\n",
      " [0.0507724 ]]\n",
      "theta: [[4.13249384]\n",
      " [2.83869893]]\n",
      "gradients: [[3.45162526]\n",
      " [0.98088246]]\n",
      "theta: [[4.13639128]\n",
      " [2.84257123]]\n",
      "gradients: [[-3.66905219]\n",
      " [-3.64538324]]\n",
      "theta: [[4.13575633]\n",
      " [2.84160434]]\n",
      "gradients: [[0.59786563]\n",
      " [0.91041855]]\n",
      "theta: [[4.13485984]\n",
      " [2.84138519]]\n",
      "gradients: [[0.8443204 ]\n",
      " [0.20639621]]\n",
      "theta: [[4.13604973]\n",
      " [2.8413942 ]]\n",
      "gradients: [[-1.12088434]\n",
      " [-0.00848516]]\n",
      "theta: [[4.13615952]\n",
      " [2.84149491]]\n",
      "gradients: [[-0.10344406]\n",
      " [-0.09488837]]\n",
      "theta: [[4.13645036]\n",
      " [2.84157623]]\n",
      "gradients: [[-0.27408384]\n",
      " [-0.076637  ]]\n",
      "theta: [[4.13790721]\n",
      " [2.84183305]]\n",
      "gradients: [[-1.37322404]\n",
      " [-0.24208161]]\n",
      "theta: [[4.13814538]\n",
      " [2.84213706]]\n",
      "gradients: [[-0.22454509]\n",
      " [-0.28661647]]\n",
      "theta: [[4.13529563]\n",
      " [2.83899088]]\n",
      "gradients: [[2.68730981]\n",
      " [2.96684464]]\n",
      "theta: [[4.13462343]\n",
      " [2.83785195]]\n",
      "gradients: [[0.6340191 ]\n",
      " [1.07424584]]\n",
      "theta: [[4.13700235]\n",
      " [2.84061641]]\n",
      "gradients: [[-2.24427017]\n",
      " [-2.60799538]]\n",
      "theta: [[4.13953695]\n",
      " [2.8434387 ]]\n",
      "gradients: [[-2.39165184]\n",
      " [-2.6631168 ]]\n",
      "theta: [[4.14059526]\n",
      " [2.84355212]]\n",
      "gradients: [[-0.99883581]\n",
      " [-0.10703902]]\n",
      "theta: [[4.13774004]\n",
      " [2.84039989]]\n",
      "gradients: [[2.69533409]\n",
      " [2.97570361]]\n",
      "theta: [[4.13697783]\n",
      " [2.84034536]]\n",
      "gradients: [[0.719673  ]\n",
      " [0.05148763]]\n",
      "theta: [[4.13727962]\n",
      " [2.84093969]]\n",
      "gradients: [[-0.2850075]\n",
      " [-0.5612921]]\n",
      "theta: [[4.14234853]\n",
      " [2.85038993]]\n",
      "gradients: [[-4.78809491]\n",
      " [-8.92668961]]\n",
      "theta: [[4.14167792]\n",
      " [2.84936873]]\n",
      "gradients: [[0.63359247]\n",
      " [0.96482272]]\n",
      "theta: [[4.14353775]\n",
      " [2.84971373]]\n",
      "gradients: [[-1.75753668]\n",
      " [-0.32601606]]\n",
      "theta: [[4.14422689]\n",
      " [2.85103919]]\n",
      "gradients: [[-0.65137962]\n",
      " [-1.25282662]]\n",
      "theta: [[4.14441788]\n",
      " [2.8511783 ]]\n",
      "gradients: [[-0.18055464]\n",
      " [-0.13151528]]\n",
      "theta: [[4.14690656]\n",
      " [2.85394946]]\n",
      "gradients: [[-2.35329934]\n",
      " [-2.6204111 ]]\n",
      "theta: [[4.14542533]\n",
      " [2.85192619]]\n",
      "gradients: [[1.40094908]\n",
      " [1.9136118 ]]\n",
      "theta: [[4.14615702]\n",
      " [2.85269831]]\n",
      "gradients: [[-0.69217702]\n",
      " [-0.73043205]]\n",
      "theta: [[4.14641893]\n",
      " [2.85277155]]\n",
      "gradients: [[-0.24782365]\n",
      " [-0.06929435]]\n",
      "theta: [[4.14435022]\n",
      " [2.85111141]]\n",
      "gradients: [[1.95782788]\n",
      " [1.57115625]]\n",
      "theta: [[4.14147727]\n",
      " [2.84793961]]\n",
      "gradients: [[2.71953523]\n",
      " [3.00242215]]\n",
      "theta: [[4.1438084 ]\n",
      " [2.85064855]]\n",
      "gradients: [[-2.20711738]\n",
      " [-2.56482129]]\n",
      "theta: [[4.14086535]\n",
      " [2.84810893]]\n",
      "gradients: [[2.78707533]\n",
      " [2.40501585]]\n",
      "theta: [[4.1399492 ]\n",
      " [2.84728756]]\n",
      "gradients: [[0.86777061]\n",
      " [0.77800421]]\n",
      "theta: [[4.13893898]\n",
      " [2.84691284]]\n",
      "gradients: [[0.95708373]\n",
      " [0.35500889]]\n",
      "theta: [[4.13926563]\n",
      " [2.84696325]]\n",
      "gradients: [[-0.30953586]\n",
      " [-0.04776543]]\n",
      "theta: [[4.14213772]\n",
      " [2.85030655]]\n",
      "gradients: [[-2.72216764]\n",
      " [-3.16878141]]\n",
      "theta: [[4.14233372]\n",
      " [2.85044931]]\n",
      "gradients: [[-0.18580028]\n",
      " [-0.13533618]]\n",
      "theta: [[4.14439642]\n",
      " [2.85136665]]\n",
      "gradients: [[-1.95585594]\n",
      " [-0.86982387]]\n",
      "theta: [[4.14385586]\n",
      " [2.85094627]]\n",
      "gradients: [[0.51266996]\n",
      " [0.39868802]]\n",
      "theta: [[4.14318297]\n",
      " [2.84992161]]\n",
      "gradients: [[0.63830151]\n",
      " [0.97199355]]\n",
      "theta: [[4.14605079]\n",
      " [2.85134163]]\n",
      "gradients: [[-2.72098917]\n",
      " [-1.34731766]]\n",
      "theta: [[4.14636053]\n",
      " [2.85138943]]\n",
      "gradients: [[-0.2939454 ]\n",
      " [-0.04535962]]\n",
      "theta: [[4.14662196]\n",
      " [2.85146253]]\n",
      "gradients: [[-0.24814857]\n",
      " [-0.0693852 ]]\n",
      "theta: [[4.14607712]\n",
      " [2.85103883]]\n",
      "gradients: [[0.51727017]\n",
      " [0.40226546]]\n",
      "theta: [[4.14646059]\n",
      " [2.85137064]]\n",
      "gradients: [[-0.36413525]\n",
      " [-0.3150938 ]]\n",
      "theta: [[4.14666827]\n",
      " [2.85169612]]\n",
      "gradients: [[-0.19725672]\n",
      " [-0.30913905]]\n",
      "theta: [[4.14645237]\n",
      " [2.85167389]]\n",
      "gradients: [[0.20509956]\n",
      " [0.02111549]]\n",
      "theta: [[4.14787336]\n",
      " [2.85407788]]\n",
      "gradients: [[-1.35022127]\n",
      " [-2.28426299]]\n",
      "theta: [[4.1492825 ]\n",
      " [2.85646181]]\n",
      "gradients: [[-1.33924533]\n",
      " [-2.26569423]]\n",
      "theta: [[4.1483014 ]\n",
      " [2.85632496]]\n",
      "gradients: [[0.93263219]\n",
      " [0.13008798]]\n",
      "theta: [[4.14607861]\n",
      " [2.8529746 ]]\n",
      "gradients: [[2.11342992]\n",
      " [3.18552653]]\n",
      "theta: [[4.14703978]\n",
      " [2.85437793]]\n",
      "gradients: [[-0.91407503]\n",
      " [-1.33456884]]\n",
      "theta: [[4.14714422]\n",
      " [2.85450224]]\n",
      "gradients: [[-0.09934281]\n",
      " [-0.11824294]]\n",
      "theta: [[4.14659446]\n",
      " [2.85407471]]\n",
      "gradients: [[0.52304247]\n",
      " [0.4067544 ]]\n",
      "theta: [[4.14698789]\n",
      " [2.85422673]]\n",
      "gradients: [[-0.37438502]\n",
      " [-0.14466481]]\n",
      "theta: [[4.14463722]\n",
      " [2.85170449]]\n",
      "gradients: [[2.23736632]\n",
      " [2.40066896]]\n",
      "theta: [[4.14025934]\n",
      " [2.84485376]]\n",
      "gradients: [[4.16774343]\n",
      " [6.52189514]]\n",
      "theta: [[4.13872975]\n",
      " [2.841813  ]]\n",
      "gradients: [[1.45647526]\n",
      " [2.89541134]]\n",
      "theta: [[4.13768943]\n",
      " [2.84133065]]\n",
      "gradients: [[0.99079816]\n",
      " [0.45938811]]\n",
      "theta: [[4.13805337]\n",
      " [2.84133283]]\n",
      "gradients: [[-0.34668616]\n",
      " [-0.0020742 ]]\n",
      "theta: [[4.13766283]\n",
      " [2.84088373]]\n",
      "gradients: [[0.37210706]\n",
      " [0.42790437]]\n",
      "theta: [[4.13967329]\n",
      " [2.84182529]]\n",
      "gradients: [[-1.91597075]\n",
      " [-0.89730565]]\n",
      "theta: [[4.1425408 ]\n",
      " [2.84516326]]\n",
      "gradients: [[-2.73331418]\n",
      " [-3.18175671]]\n",
      "theta: [[4.14740996]\n",
      " [2.85393006]]\n",
      "gradients: [[-4.64225859]\n",
      " [-8.35826909]]\n",
      "theta: [[4.14475049]\n",
      " [2.85111078]]\n",
      "gradients: [[2.53607043]\n",
      " [2.68846804]]\n",
      "theta: [[4.14758289]\n",
      " [2.85440788]]\n",
      "gradients: [[-2.70154192]\n",
      " [-3.14477172]]\n",
      "theta: [[4.14651352]\n",
      " [2.85391206]]\n",
      "gradients: [[1.02018379]\n",
      " [0.47301289]]\n",
      "theta: [[4.14640757]\n",
      " [2.85381229]]\n",
      "gradients: [[0.10109328]\n",
      " [0.09520176]]\n",
      "theta: [[4.1435339 ]\n",
      " [2.85136951]]\n",
      "gradients: [[2.74263628]\n",
      " [2.33138184]]\n",
      "theta: [[4.14390452]\n",
      " [2.85183522]]\n",
      "gradients: [[-0.35379869]\n",
      " [-0.44455949]]\n",
      "theta: [[4.14313615]\n",
      " [2.85178024]]\n",
      "gradients: [[0.7336382 ]\n",
      " [0.05248674]]\n",
      "theta: [[4.14246662]\n",
      " [2.8507607 ]]\n",
      "gradients: [[0.63940201]\n",
      " [0.97366937]]\n",
      "theta: [[4.13894537]\n",
      " [2.84564619]]\n",
      "gradients: [[3.36349515]\n",
      " [4.88538019]]\n",
      "theta: [[4.13713911]\n",
      " [2.84224446]]\n",
      "gradients: [[1.72570852]\n",
      " [3.2500047 ]]\n",
      "theta: [[4.13857445]\n",
      " [2.8424975 ]]\n",
      "gradients: [[-1.37161094]\n",
      " [-0.24179725]]\n",
      "theta: [[4.13929538]\n",
      " [2.84388409]]\n",
      "gradients: [[-0.6890648 ]\n",
      " [-1.32530815]]\n",
      "theta: [[4.14373529]\n",
      " [2.84981466]]\n",
      "gradients: [[-4.24455689]\n",
      " [-5.66962388]]\n",
      "theta: [[4.14476967]\n",
      " [2.84992551]]\n",
      "gradients: [[-0.98907259]\n",
      " [-0.10599275]]\n",
      "theta: [[4.14673511]\n",
      " [2.85026734]]\n",
      "gradients: [[-1.87975334]\n",
      " [-0.3269238 ]]\n",
      "theta: [[4.15116365]\n",
      " [2.85098148]]\n",
      "gradients: [[-4.23633351]\n",
      " [-0.68315424]]\n",
      "theta: [[4.15191048]\n",
      " [2.85184321]]\n",
      "gradients: [[-0.71456987]\n",
      " [-0.824498  ]]\n",
      "theta: [[4.15262039]\n",
      " [2.85259235]]\n",
      "gradients: [[-0.67938185]\n",
      " [-0.71692972]]\n",
      "theta: [[4.15332701]\n",
      " [2.85333803]]\n",
      "gradients: [[-0.67638094]\n",
      " [-0.71376296]]\n",
      "theta: [[4.15296928]\n",
      " [2.85268051]]\n",
      "gradients: [[0.34249196]\n",
      " [0.62951295]]\n",
      "theta: [[4.15117593]\n",
      " [2.85163472]]\n",
      "gradients: [[1.71730864]\n",
      " [1.00144688]]\n",
      "theta: [[4.15137117]\n",
      " [2.85194069]]\n",
      "gradients: [[-0.18699831]\n",
      " [-0.29306215]]\n",
      "theta: [[4.15364469]\n",
      " [2.85458268]]\n",
      "gradients: [[-2.17803052]\n",
      " [-2.53102037]]\n",
      "theta: [[4.15271958]\n",
      " [2.85435653]]\n",
      "gradients: [[0.88644229]\n",
      " [0.21669301]]\n",
      "theta: [[4.15336144]\n",
      " [2.85559104]]\n",
      "gradients: [[-0.61515655]\n",
      " [-1.18315722]]\n",
      "theta: [[4.15352381]\n",
      " [2.85570932]]\n",
      "gradients: [[-0.15565445]\n",
      " [-0.11337808]]\n",
      "theta: [[4.15553549]\n",
      " [2.85660397]]\n",
      "gradients: [[-1.92879721]\n",
      " [-0.85779009]]\n",
      "theta: [[4.15754172]\n",
      " [2.8574962 ]]\n",
      "gradients: [[-1.9239781]\n",
      " [-0.8556469]]\n",
      "theta: [[4.15811534]\n",
      " [2.85752073]]\n",
      "gradients: [[-0.55021053]\n",
      " [-0.02353844]]\n",
      "theta: [[4.15921806]\n",
      " [2.8581042 ]]\n",
      "gradients: [[-1.05794828]\n",
      " [-0.55978111]]\n",
      "theta: [[4.15565581]\n",
      " [2.85293015]]\n",
      "gradients: [[3.4183305 ]\n",
      " [4.96502696]]\n",
      "theta: [[4.15878053]\n",
      " [2.85864466]]\n",
      "gradients: [[-2.999104  ]\n",
      " [-5.48478836]]\n",
      "theta: [[4.16312027]\n",
      " [2.86444143]]\n",
      "gradients: [[-4.16615403]\n",
      " [-5.56489806]]\n",
      "theta: [[4.16211784]\n",
      " [2.8643016 ]]\n",
      "gradients: [[0.96253381]\n",
      " [0.1342588 ]]\n",
      "theta: [[4.16117226]\n",
      " [2.86407045]]\n",
      "gradients: [[0.90814022]\n",
      " [0.22199713]]\n",
      "theta: [[4.15848113]\n",
      " [2.86121761]]\n",
      "gradients: [[2.58509451]\n",
      " [2.74043808]]\n",
      "theta: [[4.15578831]\n",
      " [2.8568392 ]]\n",
      "gradients: [[2.58726148]\n",
      " [4.20677333]]\n",
      "theta: [[4.15499942]\n",
      " [2.85678277]]\n",
      "gradients: [[0.75812179]\n",
      " [0.05423838]]\n",
      "theta: [[4.15212295]\n",
      " [2.85433761]]\n",
      "gradients: [[2.76487011]\n",
      " [2.35028173]]\n",
      "theta: [[4.14946831]\n",
      " [2.85002128]]\n",
      "gradients: [[2.55217196]\n",
      " [4.1497193 ]]\n",
      "theta: [[4.15059474]\n",
      " [2.8506173 ]]\n",
      "gradients: [[-1.08317856]\n",
      " [-0.57313094]]\n",
      "theta: [[4.14666519]\n",
      " [2.84927263]]\n",
      "gradients: [[3.77943787]\n",
      " [1.29330027]]\n",
      "theta: [[4.14406096]\n",
      " [2.84841091]]\n",
      "gradients: [[2.50526694]\n",
      " [0.82897494]]\n",
      "theta: [[4.14472024]\n",
      " [2.8494934 ]]\n",
      "gradients: [[-0.63435253]\n",
      " [-1.04156599]]\n",
      "theta: [[4.14654007]\n",
      " [2.84983097]]\n",
      "gradients: [[-1.7514058]\n",
      " [-0.3248788]]\n",
      "theta: [[4.14645464]\n",
      " [2.84981422]]\n",
      "gradients: [[0.08223829]\n",
      " [0.01612105]]\n",
      "theta: [[4.1513743 ]\n",
      " [2.85898621]]\n",
      "gradients: [[-4.73665441]\n",
      " [-8.83078646]]\n",
      "theta: [[4.15123567]\n",
      " [2.85890855]]\n",
      "gradients: [[0.13349788]\n",
      " [0.07478509]]\n",
      "theta: [[4.15262432]\n",
      " [2.85915335]]\n",
      "gradients: [[-1.33754248]\n",
      " [-0.23579142]]\n",
      "theta: [[4.15200875]\n",
      " [2.85889995]]\n",
      "gradients: [[0.59303736]\n",
      " [0.24412122]]\n",
      "theta: [[4.14939115]\n",
      " [2.8580338 ]]\n",
      "gradients: [[2.52232528]\n",
      " [0.83461942]]\n",
      "theta: [[4.14640298]\n",
      " [2.85733646]]\n",
      "gradients: [[2.879999  ]\n",
      " [0.67210365]]\n",
      "theta: [[4.144992  ]\n",
      " [2.85521764]]\n",
      "gradients: [[1.36017927]\n",
      " [2.04253758]]\n",
      "theta: [[4.14694998]\n",
      " [2.85613462]]\n",
      "gradients: [[-1.88788641]\n",
      " [-0.88415292]]\n",
      "theta: [[4.14699564]\n",
      " [2.85614757]]\n",
      "gradients: [[-0.04402992]\n",
      " [-0.01248275]]\n",
      "theta: [[4.14439303]\n",
      " [2.85528638]]\n",
      "gradients: [[2.51047756]\n",
      " [0.8306991 ]]\n",
      "theta: [[4.14452931]\n",
      " [2.85538137]]\n",
      "gradients: [[-0.13148187]\n",
      " [-0.09164918]]\n",
      "theta: [[4.14433903]\n",
      " [2.8553064 ]]\n",
      "gradients: [[0.18362198]\n",
      " [0.07235243]]\n",
      "theta: [[4.14546609]\n",
      " [2.85590275]]\n",
      "gradients: [[-1.0878442 ]\n",
      " [-0.57559962]]\n",
      "theta: [[4.14559917]\n",
      " [2.85599551]]\n",
      "gradients: [[-0.12847647]\n",
      " [-0.08955427]]\n",
      "theta: [[4.14918111]\n",
      " [2.86184053]]\n",
      "gradients: [[-3.45872352]\n",
      " [-5.64395001]]\n",
      "theta: [[4.14697381]\n",
      " [2.85851351]]\n",
      "gradients: [[2.13181635]\n",
      " [3.21323998]]\n",
      "theta: [[4.14345928]\n",
      " [2.85340876]]\n",
      "gradients: [[3.39503101]\n",
      " [4.93118511]]\n",
      "theta: [[4.14530466]\n",
      " [2.85385101]]\n",
      "gradients: [[-1.78300006]\n",
      " [-0.42730142]]\n",
      "theta: [[4.14608154]\n",
      " [2.85394558]]\n",
      "gradients: [[-0.75077727]\n",
      " [-0.09138899]]\n",
      "theta: [[4.14626388]\n",
      " [2.8540209 ]]\n",
      "gradients: [[-0.17624909]\n",
      " [-0.07280824]]\n",
      "theta: [[4.14443114]\n",
      " [2.85056933]]\n",
      "gradients: [[1.77188952]\n",
      " [3.33697678]]\n",
      "theta: [[4.14401118]\n",
      " [2.8500864 ]]\n",
      "gradients: [[0.40610564]\n",
      " [0.46700102]]\n",
      "theta: [[4.14140352]\n",
      " [2.84584646]]\n",
      "gradients: [[2.52212384]\n",
      " [4.10086238]]\n",
      "theta: [[4.1421108 ]\n",
      " [2.84658579]]\n",
      "gradients: [[-0.68422235]\n",
      " [-0.71522889]]\n",
      "theta: [[4.14586664]\n",
      " [2.8503174 ]]\n",
      "gradients: [[-3.63414629]\n",
      " [-3.61070251]]\n",
      "theta: [[4.14290841]\n",
      " [2.84702315]]\n",
      "gradients: [[2.86297361]\n",
      " [3.18817563]]\n",
      "theta: [[4.14031548]\n",
      " [2.84280716]]\n",
      "gradients: [[2.5099569 ]\n",
      " [4.08107947]]\n",
      "theta: [[4.13804372]\n",
      " [2.84036959]]\n",
      "gradients: [[2.19951535]\n",
      " [2.3600553 ]]\n",
      "theta: [[4.13447521]\n",
      " [2.83935549]]\n",
      "gradients: [[3.45574772]\n",
      " [0.98205398]]\n",
      "theta: [[4.13410312]\n",
      " [2.83892761]]\n",
      "gradients: [[0.36040306]\n",
      " [0.41444536]]\n",
      "theta: [[4.13893548]\n",
      " [2.84762815]]\n",
      "gradients: [[-4.68158822]\n",
      " [-8.4290811 ]]\n",
      "theta: [[4.13845192]\n",
      " [2.84755121]]\n",
      "gradients: [[0.46856869]\n",
      " [0.0745475 ]]\n",
      "theta: [[4.14324127]\n",
      " [2.85617432]]\n",
      "gradients: [[-4.64183746]\n",
      " [-8.35751085]]\n",
      "theta: [[4.14028394]\n",
      " [2.85548417]]\n",
      "gradients: [[2.86683135]\n",
      " [0.66903072]]\n",
      "theta: [[4.1382729]\n",
      " [2.8538703]]\n",
      "gradients: [[1.94991165]\n",
      " [1.56480348]]\n",
      "theta: [[4.13684635]\n",
      " [2.85192172]]\n",
      "gradients: [[1.38346551]\n",
      " [1.88973029]]\n",
      "theta: [[4.13546515]\n",
      " [2.85129146]]\n",
      "gradients: [[1.33976669]\n",
      " [0.61136141]]\n",
      "theta: [[4.13660908]\n",
      " [2.85189673]]\n",
      "gradients: [[-1.10984073]\n",
      " [-0.58723842]]\n",
      "theta: [[4.13651012]\n",
      " [2.8518413 ]]\n",
      "gradients: [[0.09602443]\n",
      " [0.05379258]]\n",
      "theta: [[4.13930872]\n",
      " [2.85509905]]\n",
      "gradients: [[-2.71632192]\n",
      " [-3.16197661]]\n",
      "theta: [[4.137565 ]\n",
      " [2.8540822]]\n",
      "gradients: [[1.69280827]\n",
      " [0.98715951]]\n",
      "theta: [[4.13575787]\n",
      " [2.85067886]]\n",
      "gradients: [[1.75472265]\n",
      " [3.30464663]]\n",
      "theta: [[4.13387667]\n",
      " [2.84845606]]\n",
      "gradients: [[1.8270239 ]\n",
      " [2.15877921]]\n",
      "theta: [[4.13408772]\n",
      " [2.84860979]]\n",
      "gradients: [[-0.20501817]\n",
      " [-0.14933442]]\n",
      "theta: [[4.1341846 ]\n",
      " [2.84869866]]\n",
      "gradients: [[-0.09413048]\n",
      " [-0.0863451 ]]\n",
      "theta: [[4.12992711]\n",
      " [2.84203632]]\n",
      "gradients: [[4.13743085]\n",
      " [6.47446049]]\n",
      "theta: [[4.13486406]\n",
      " [2.85124052]]\n",
      "gradients: [[-4.79871093]\n",
      " [-8.94648159]]\n",
      "theta: [[4.13708974]\n",
      " [2.85438657]]\n",
      "gradients: [[-2.16381045]\n",
      " [-3.05858993]]\n",
      "theta: [[4.13643826]\n",
      " [2.8538631 ]]\n",
      "gradients: [[0.63350182]\n",
      " [0.5090224 ]]\n",
      "theta: [[4.13429731]\n",
      " [2.8506361 ]]\n",
      "gradients: [[2.08228222]\n",
      " [3.13857828]]\n",
      "theta: [[4.13615037]\n",
      " [2.85108019]]\n",
      "gradients: [[-1.80265295]\n",
      " [-0.4320113 ]]\n",
      "theta: [[4.133221  ]\n",
      " [2.85039657]]\n",
      "gradients: [[2.85027193]\n",
      " [0.66516626]]\n",
      "theta: [[4.13303817]\n",
      " [2.85037775]]\n",
      "gradients: [[0.17793745]\n",
      " [0.01831909]]\n",
      "theta: [[4.13273918]\n",
      " [2.8498282 ]]\n",
      "gradients: [[0.29103206]\n",
      " [0.53492773]]\n",
      "theta: [[4.13172619]\n",
      " [2.84935852]]\n",
      "gradients: [[0.9862496 ]\n",
      " [0.45727915]]\n",
      "theta: [[4.13381829]\n",
      " [2.85321152]]\n",
      "gradients: [[-2.03728489]\n",
      " [-3.75205237]]\n",
      "theta: [[4.13402504]\n",
      " [2.85329694]]\n",
      "gradients: [[-0.20138206]\n",
      " [-0.08319064]]\n",
      "theta: [[4.13214684]\n",
      " [2.85107768]]\n",
      "gradients: [[1.8297452 ]\n",
      " [2.16199465]]\n",
      "theta: [[4.13074743]\n",
      " [2.84916618]]\n",
      "gradients: [[1.3635843 ]\n",
      " [1.86257376]]\n",
      "theta: [[4.12798934]\n",
      " [2.84612119]]\n",
      "gradients: [[2.6880345 ]\n",
      " [2.96764471]]\n",
      "theta: [[4.13162883]\n",
      " [2.85130405]]\n",
      "gradients: [[-3.54777445]\n",
      " [-5.05225127]]\n",
      "theta: [[4.13229521]\n",
      " [2.85239819]]\n",
      "gradients: [[-0.64971611]\n",
      " [-1.066792  ]]\n",
      "theta: [[4.12886216]\n",
      " [2.84741179]]\n",
      "gradients: [[3.34790916]\n",
      " [4.86274199]]\n",
      "theta: [[4.12710678]\n",
      " [2.84410591]]\n",
      "gradients: [[1.71219236]\n",
      " [3.2245499 ]]\n",
      "theta: [[4.12733467]\n",
      " [2.84420005]]\n",
      "gradients: [[-0.22232809]\n",
      " [-0.09184341]]\n",
      "theta: [[4.12731412]\n",
      " [2.84417162]]\n",
      "gradients: [[0.02006059]\n",
      " [0.02774212]]\n",
      "theta: [[4.12547522]\n",
      " [2.84199882]]\n",
      "gradients: [[1.79475873]\n",
      " [2.12065526]]\n",
      "theta: [[4.12209061]\n",
      " [2.83708277]]\n",
      "gradients: [[3.30405962]\n",
      " [4.79905178]]\n",
      "theta: [[4.12253742]\n",
      " [2.8374694 ]]\n",
      "gradients: [[-0.43626121]\n",
      " [-0.3775059 ]]\n",
      "theta: [[4.11920386]\n",
      " [2.83422156]]\n",
      "gradients: [[3.25555172]\n",
      " [3.17184348]]\n",
      "theta: [[4.11875789]\n",
      " [2.83387474]]\n",
      "gradients: [[0.43561838]\n",
      " [0.33876732]]\n",
      "theta: [[4.12020244]\n",
      " [2.8341294 ]]\n",
      "gradients: [[-1.41132432]\n",
      " [-0.2487982 ]]\n",
      "theta: [[4.11879667]\n",
      " [2.83133478]]\n",
      "gradients: [[1.37372231]\n",
      " [2.73090197]]\n",
      "theta: [[4.11820829]\n",
      " [2.83033787]]\n",
      "gradients: [[0.57507704]\n",
      " [0.97437778]]\n",
      "theta: [[4.12051621]\n",
      " [2.83360015]]\n",
      "gradients: [[-2.25621462]\n",
      " [-3.1892051 ]]\n",
      "theta: [[4.12097176]\n",
      " [2.83399435]]\n",
      "gradients: [[-0.44543718]\n",
      " [-0.38544606]]\n",
      "theta: [[4.12004204]\n",
      " [2.83364949]]\n",
      "gradients: [[0.9092672 ]\n",
      " [0.33727241]]\n",
      "theta: [[4.1190751 ]\n",
      " [2.83320117]]\n",
      "gradients: [[0.94585263]\n",
      " [0.43854891]]\n",
      "theta: [[4.11855939]\n",
      " [2.83298887]]\n",
      "gradients: [[0.50457273]\n",
      " [0.20770514]]\n",
      "theta: [[4.1182386 ]\n",
      " [2.83261998]]\n",
      "gradients: [[0.31392886]\n",
      " [0.36100237]]\n",
      "theta: [[4.11632899]\n",
      " [2.83108752]]\n",
      "gradients: [[1.86912395]\n",
      " [1.49997138]]\n",
      "theta: [[4.12012522]\n",
      " [2.83485926]]\n",
      "gradients: [[-3.7165065 ]\n",
      " [-3.69253142]]\n",
      "theta: [[4.12023729]\n",
      " [2.83489103]]\n",
      "gradients: [[-0.10974284]\n",
      " [-0.03111275]]\n",
      "theta: [[4.12105976]\n",
      " [2.83499115]]\n",
      "gradients: [[-0.80552784]\n",
      " [-0.09805355]]\n",
      "theta: [[4.12084487]\n",
      " [2.83459616]]\n",
      "gradients: [[0.21051296]\n",
      " [0.38693064]]\n",
      "theta: [[4.11991666]\n",
      " [2.83425186]]\n",
      "gradients: [[0.90945987]\n",
      " [0.33734388]]\n",
      "theta: [[4.11948168]\n",
      " [2.83418266]]\n",
      "gradients: [[0.42627482]\n",
      " [0.06781871]]\n",
      "theta: [[4.11855694]\n",
      " [2.83383965]]\n",
      "gradients: [[0.90642674]\n",
      " [0.3362188 ]]\n",
      "theta: [[4.11606935]\n",
      " [2.83301652]]\n",
      "gradients: [[2.43883711]\n",
      " [0.80699378]]\n",
      "theta: [[4.11229784]\n",
      " [2.83172593]]\n",
      "gradients: [[3.69834133]\n",
      " [1.26554954]]\n",
      "theta: [[4.11277206]\n",
      " [2.83213629]]\n",
      "gradients: [[-0.46511751]\n",
      " [-0.40247585]]\n",
      "theta: [[4.11563616]\n",
      " [2.83547028]]\n",
      "gradients: [[-2.80967389]\n",
      " [-3.27064441]]\n",
      "theta: [[4.11481973]\n",
      " [2.8352707 ]]\n",
      "gradients: [[0.80108107]\n",
      " [0.19582625]]\n",
      "theta: [[4.11588965]\n",
      " [2.83538536]]\n",
      "gradients: [[-1.05002089]\n",
      " [-0.1125242 ]]\n",
      "theta: [[4.11610038]\n",
      " [2.83563618]]\n",
      "gradients: [[-0.20685497]\n",
      " [-0.24620947]]\n",
      "theta: [[4.112773  ]\n",
      " [2.83080325]]\n",
      "gradients: [[3.26682682]\n",
      " [4.74497221]]\n",
      "theta: [[4.1134268 ]\n",
      " [2.83083122]]\n",
      "gradients: [[-0.64203188]\n",
      " [-0.02746663]]\n",
      "theta: [[4.114242  ]\n",
      " [2.83169148]]\n",
      "gradients: [[-0.80069576]\n",
      " [-0.84494838]]\n",
      "theta: [[4.11530053]\n",
      " [2.83323695]]\n",
      "gradients: [[-1.03989585]\n",
      " [-1.5182699 ]]\n",
      "theta: [[4.11576443]\n",
      " [2.83381986]]\n",
      "gradients: [[-0.45583373]\n",
      " [-0.57276982]]\n",
      "theta: [[4.11622581]\n",
      " [2.8343996 ]]\n",
      "gradients: [[-0.45344102]\n",
      " [-0.56976331]]\n",
      "theta: [[4.11659084]\n",
      " [2.83445593]]\n",
      "gradients: [[-0.35882412]\n",
      " [-0.05537126]]\n",
      "theta: [[4.11501126]\n",
      " [2.83272097]]\n",
      "gradients: [[1.55304094]\n",
      " [1.70580568]]\n",
      "theta: [[4.11523671]\n",
      " [2.83287812]]\n",
      "gradients: [[-0.22170375]\n",
      " [-0.15453816]]\n",
      "theta: [[4.11606633]\n",
      " [2.83297911]]\n",
      "gradients: [[-0.81601906]\n",
      " [-0.0993306 ]]\n",
      "theta: [[4.11301758]\n",
      " [2.82921734]]\n",
      "gradients: [[2.99936638]\n",
      " [3.7008233 ]]\n",
      "theta: [[4.11408421]\n",
      " [2.83077465]]\n",
      "gradients: [[-1.04956929]\n",
      " [-1.53239332]]\n",
      "theta: [[4.11903482]\n",
      " [2.84000432]]\n",
      "gradients: [[-4.87238814]\n",
      " [-9.08384177]]\n",
      "theta: [[4.11924155]\n",
      " [2.84014842]]\n",
      "gradients: [[-0.20350294]\n",
      " [-0.14185132]]\n",
      "theta: [[4.11921733]\n",
      " [2.84014368]]\n",
      "gradients: [[0.02384514]\n",
      " [0.00467433]]\n",
      "theta: [[4.11614732]\n",
      " [2.83635568]]\n",
      "gradients: [[3.02334865]\n",
      " [3.73041425]]\n",
      "theta: [[4.11527346]\n",
      " [2.83623379]]\n",
      "gradients: [[0.86075283]\n",
      " [0.12006191]]\n",
      "theta: [[4.11181441]\n",
      " [2.8352508 ]]\n",
      "gradients: [[3.40785657]\n",
      " [0.96844428]]\n",
      "theta: [[4.11051576]\n",
      " [2.83347693]]\n",
      "gradients: [[1.2796823 ]\n",
      " [1.74796869]]\n",
      "theta: [[4.11130704]\n",
      " [2.83499883]]\n",
      "gradients: [[-0.77988144]\n",
      " [-1.49997973]]\n",
      "theta: [[4.11171232]\n",
      " [2.83500125]]\n",
      "gradients: [[-0.39952671]\n",
      " [-0.00239034]]\n",
      "theta: [[4.11080817]\n",
      " [2.83466588]]\n",
      "gradients: [[0.8914953 ]\n",
      " [0.33068032]]\n",
      "theta: [[4.11574067]\n",
      " [2.84386179]]\n",
      "gradients: [[-4.86443101]\n",
      " [-9.06900689]]\n",
      "theta: [[4.11517244]\n",
      " [2.84299651]]\n",
      "gradients: [[0.56049489]\n",
      " [0.85351109]]\n",
      "theta: [[4.11284007]\n",
      " [2.83859962]]\n",
      "gradients: [[2.30111733]\n",
      " [4.33797573]]\n",
      "theta: [[4.11329333]\n",
      " [2.83916915]]\n",
      "gradients: [[-0.44727791]\n",
      " [-0.56201916]]\n",
      "theta: [[4.11164977]\n",
      " [2.83821071]]\n",
      "gradients: [[1.62219848]\n",
      " [0.94598348]]\n",
      "theta: [[4.11241902]\n",
      " [2.83969024]]\n",
      "gradients: [[-0.75940408]\n",
      " [-1.46059473]]\n",
      "theta: [[4.10867625]\n",
      " [2.83840949]]\n",
      "gradients: [[3.69560809]\n",
      " [1.26461424]]\n",
      "theta: [[4.10813984]\n",
      " [2.83759265]]\n",
      "gradients: [[0.52976075]\n",
      " [0.80670971]]\n",
      "theta: [[4.10963254]\n",
      " [2.84011796]]\n",
      "gradients: [[-1.47449076]\n",
      " [-2.49449831]]\n",
      "theta: [[4.10832828]\n",
      " [2.83833641]]\n",
      "gradients: [[1.28861506]\n",
      " [1.7601703 ]]\n",
      "theta: [[4.11270119]\n",
      " [2.84417748]]\n",
      "gradients: [[-4.32131161]\n",
      " [-5.77214822]]\n",
      "theta: [[4.11552155]\n",
      " [2.845574  ]]\n",
      "gradients: [[-2.78764123]\n",
      " [-1.38032092]]\n",
      "theta: [[4.1149387 ]\n",
      " [2.84510568]]\n",
      "gradients: [[0.57620353]\n",
      " [0.46298289]]\n",
      "theta: [[4.1192773 ]\n",
      " [2.85090092]]\n",
      "gradients: [[-4.2900068 ]\n",
      " [-5.73033313]]\n",
      "theta: [[4.11925457]\n",
      " [2.85086949]]\n",
      "gradients: [[0.02247931]\n",
      " [0.03108701]]\n",
      "theta: [[4.12004171]\n",
      " [2.85177773]]\n",
      "gradients: [[-0.77864648]\n",
      " [-0.89843204]]\n",
      "theta: [[4.11934846]\n",
      " [2.85172813]]\n",
      "gradients: [[0.68590436]\n",
      " [0.04907172]]\n",
      "theta: [[4.11714886]\n",
      " [2.84936798]]\n",
      "gradients: [[2.17672553]\n",
      " [2.33560207]]\n",
      "theta: [[4.11543525]\n",
      " [2.84614076]]\n",
      "gradients: [[1.69613392]\n",
      " [3.19430724]]\n",
      "theta: [[4.11339788]\n",
      " [2.84306988]]\n",
      "gradients: [[2.01699676]\n",
      " [3.04017494]]\n",
      "theta: [[4.11361046]\n",
      " [2.84321806]]\n",
      "gradients: [[-0.21050315]\n",
      " [-0.14673081]]\n",
      "theta: [[4.1134719 ]\n",
      " [2.84320379]]\n",
      "gradients: [[0.13723828]\n",
      " [0.01412901]]\n",
      "theta: [[4.11359134]\n",
      " [2.84323765]]\n",
      "gradients: [[-0.11831803]\n",
      " [-0.03354387]]\n",
      "theta: [[4.11834213]\n",
      " [2.85179135]]\n",
      "gradients: [[-4.70709153]\n",
      " [-8.47499916]]\n",
      "theta: [[4.11874892]\n",
      " [2.85230248]]\n",
      "gradients: [[-0.40312211]\n",
      " [-0.50653597]]\n",
      "theta: [[4.11956032]\n",
      " [2.85240125]]\n",
      "gradients: [[-0.80426574]\n",
      " [-0.09789991]]\n",
      "theta: [[4.11928645]\n",
      " [2.85189787]]\n",
      "gradients: [[0.27151493]\n",
      " [0.49905453]]\n",
      "theta: [[4.11598153]\n",
      " [2.84867792]]\n",
      "gradients: [[3.27716476]\n",
      " [3.1929008 ]]\n",
      "theta: [[4.12082307]\n",
      " [2.85770425]]\n",
      "gradients: [[-4.80183755]\n",
      " [-8.95231072]]\n",
      "theta: [[4.11945307]\n",
      " [2.85583291]]\n",
      "gradients: [[1.35903972]\n",
      " [1.85636614]]\n",
      "theta: [[4.11694178]\n",
      " [2.85174968]]\n",
      "gradients: [[2.49169478]\n",
      " [4.05138607]]\n",
      "theta: [[4.11688483]\n",
      " [2.85171777]]\n",
      "gradients: [[0.05652508]\n",
      " [0.03166517]]\n",
      "theta: [[4.1167382 ]\n",
      " [2.85170267]]\n",
      "gradients: [[0.14553713]\n",
      " [0.0149834 ]]\n",
      "theta: [[4.1171477 ]\n",
      " [2.85221722]]\n",
      "gradients: [[-0.40655282]\n",
      " [-0.51084677]]\n",
      "theta: [[4.12024814]\n",
      " [2.85788732]]\n",
      "gradients: [[-3.07872781]\n",
      " [-5.6304051 ]]\n",
      "theta: [[4.12017764]\n",
      " [2.85784783]]\n",
      "gradients: [[0.07001436]\n",
      " [0.03922182]]\n",
      "theta: [[4.11746269]\n",
      " [2.85553998]]\n",
      "gradients: [[2.69703726]\n",
      " [2.29262032]]\n",
      "theta: [[4.1164955 ]\n",
      " [2.85509154]]\n",
      "gradients: [[0.96099319]\n",
      " [0.4455689 ]]\n",
      "theta: [[4.11721467]\n",
      " [2.8558433 ]]\n",
      "gradients: [[-0.71471032]\n",
      " [-0.74709847]]\n",
      "theta: [[4.1163753 ]\n",
      " [2.85509075]]\n",
      "gradients: [[0.83433783]\n",
      " [0.74802988]]\n",
      "theta: [[4.11572077]\n",
      " [2.85398175]]\n",
      "gradients: [[0.65073584]\n",
      " [1.10256974]]\n",
      "theta: [[4.1149059 ]\n",
      " [2.85378256]]\n",
      "gradients: [[0.81030064]\n",
      " [0.19808   ]]\n",
      "theta: [[4.11860011]\n",
      " [2.85745293]]\n",
      "gradients: [[-3.67425541]\n",
      " [-3.65055289]]\n",
      "theta: [[4.11882373]\n",
      " [2.85761582]]\n",
      "gradients: [[-0.22246473]\n",
      " [-0.16204242]]\n",
      "theta: [[4.12083027]\n",
      " [2.85850818]]\n",
      "gradients: [[-1.99650162]\n",
      " [-0.88790013]]\n",
      "theta: [[4.12092565]\n",
      " [2.85853522]]\n",
      "gradients: [[-0.09492352]\n",
      " [-0.02691139]]\n",
      "theta: [[4.1244416 ]\n",
      " [2.86427256]]\n",
      "gradients: [[-3.49978198]\n",
      " [-5.71094925]]\n",
      "theta: [[4.12629003]\n",
      " [2.86606755]]\n",
      "gradients: [[-1.84029204]\n",
      " [-1.78708696]]\n",
      "theta: [[4.12699359]\n",
      " [2.86680999]]\n",
      "gradients: [[-0.70060178]\n",
      " [-0.73932243]]\n",
      "theta: [[4.1244409 ]\n",
      " [2.86265944]]\n",
      "gradients: [[2.54247231]\n",
      " [4.13394809]]\n",
      "theta: [[4.12464488]\n",
      " [2.86280801]]\n",
      "gradients: [[-0.20319833]\n",
      " [-0.14800886]]\n",
      "theta: [[4.12663227]\n",
      " [2.86369186]]\n",
      "gradients: [[-1.9802411 ]\n",
      " [-0.88066863]]\n",
      "theta: [[4.12384757]\n",
      " [2.86128889]]\n",
      "gradients: [[2.77523367]\n",
      " [2.39479748]]\n",
      "theta: [[4.12413613]\n",
      " [2.86136958]]\n",
      "gradients: [[-0.28763849]\n",
      " [-0.08042704]]\n",
      "theta: [[4.12478342]\n",
      " [2.86261454]]\n",
      "gradients: [[-0.64534644]\n",
      " [-1.24122274]]\n",
      "theta: [[4.12535316]\n",
      " [2.86345035]]\n",
      "gradients: [[-0.56814223]\n",
      " [-0.83346827]]\n",
      "theta: [[4.12717229]\n",
      " [2.8638863 ]]\n",
      "gradients: [[-1.81439932]\n",
      " [-0.43482635]]\n",
      "theta: [[4.12828806]\n",
      " [2.86447668]]\n",
      "gradients: [[-1.11309809]\n",
      " [-0.58896195]]\n",
      "theta: [[4.12587442]\n",
      " [2.85992657]]\n",
      "gradients: [[2.40833573]\n",
      " [4.54009962]]\n",
      "theta: [[4.12542716]\n",
      " [2.85985542]]\n",
      "gradients: [[0.44635984]\n",
      " [0.07101416]]\n",
      "theta: [[4.12656869]\n",
      " [2.85986406]]\n",
      "gradients: [[-1.13947004]\n",
      " [-0.00862586]]\n",
      "theta: [[4.12573248]\n",
      " [2.85965965]]\n",
      "gradients: [[0.83487238]\n",
      " [0.20408662]]\n",
      "theta: [[4.12242266]\n",
      " [2.85643493]]\n",
      "gradients: [[3.30518121]\n",
      " [3.22019688]]\n",
      "theta: [[4.11958955]\n",
      " [2.85328001]]\n",
      "gradients: [[2.82971049]\n",
      " [3.1511342 ]]\n",
      "theta: [[4.11962607]\n",
      " [2.85330749]]\n",
      "gradients: [[-0.03648368]\n",
      " [-0.02744629]]\n",
      "theta: [[4.12029375]\n",
      " [2.85440377]]\n",
      "gradients: [[-0.66714259]\n",
      " [-1.09540516]]\n",
      "theta: [[4.12233654]\n",
      " [2.85816596]]\n",
      "gradients: [[-2.04156618]\n",
      " [-3.7599372 ]]\n",
      "theta: [[4.12586273]\n",
      " [2.86318747]]\n",
      "gradients: [[-3.52477503]\n",
      " [-5.01949867]]\n",
      "theta: [[4.1258166 ]\n",
      " [2.86317843]]\n",
      "gradients: [[0.04612012]\n",
      " [0.00904086]]\n",
      "theta: [[4.12635523]\n",
      " [2.8639179 ]]\n",
      "gradients: [[-0.5386294 ]\n",
      " [-0.73947482]]\n",
      "theta: [[4.12571255]\n",
      " [2.86293925]]\n",
      "gradients: [[0.64280616]\n",
      " [0.97885314]]\n",
      "theta: [[4.12331612]\n",
      " [2.85842159]]\n",
      "gradients: [[2.39738807]\n",
      " [4.51946152]]\n",
      "theta: [[4.1268361 ]\n",
      " [2.86343426]]\n",
      "gradients: [[-3.52208781]\n",
      " [-5.01567191]]\n",
      "theta: [[4.12711633]\n",
      " [2.86351261]]\n",
      "gradients: [[-0.28046171]\n",
      " [-0.07842032]]\n",
      "theta: [[4.12825123]\n",
      " [2.8635212 ]]\n",
      "gradients: [[-1.13603633]\n",
      " [-0.00859986]]\n",
      "theta: [[4.12886685]\n",
      " [2.864532  ]]\n",
      "gradients: [[-0.61635174]\n",
      " [-1.01200985]]\n",
      "theta: [[4.12853259]\n",
      " [2.86391763]]\n",
      "gradients: [[0.33472151]\n",
      " [0.61523057]]\n",
      "theta: [[4.12926141]\n",
      " [2.86475856]]\n",
      "gradients: [[-0.72997954]\n",
      " [-0.84227826]]\n",
      "theta: [[4.12965546]\n",
      " [2.86540668]]\n",
      "gradients: [[-0.39476483]\n",
      " [-0.64927861]]\n",
      "theta: [[4.12956661]\n",
      " [2.86532301]]\n",
      "gradients: [[0.08902664]\n",
      " [0.08383834]]\n",
      "theta: [[4.12947812]\n",
      " [2.86523967]]\n",
      "gradients: [[0.08869136]\n",
      " [0.08352259]]\n",
      "theta: [[4.12984998]\n",
      " [2.86556145]]\n",
      "gradients: [[-0.37275669]\n",
      " [-0.32255412]]\n",
      "theta: [[4.1318262 ]\n",
      " [2.86920103]]\n",
      "gradients: [[-1.98135569]\n",
      " [-3.64904799]]\n",
      "theta: [[4.13247892]\n",
      " [2.86988334]]\n",
      "gradients: [[-0.65455116]\n",
      " [-0.68421311]]\n",
      "theta: [[4.13318512]\n",
      " [2.87069818]]\n",
      "gradients: [[-0.70831996]\n",
      " [-0.81728662]]\n",
      "theta: [[4.13507607]\n",
      " [2.87158376]]\n",
      "gradients: [[-1.89700018]\n",
      " [-0.88842117]]\n",
      "theta: [[4.13337828]\n",
      " [2.8705937 ]]\n",
      "gradients: [[1.70356906]\n",
      " [0.99343465]]\n",
      "theta: [[4.13004849]\n",
      " [2.86734952]]\n",
      "gradients: [[3.34177862]\n",
      " [3.25585328]]\n",
      "theta: [[4.12934302]\n",
      " [2.86729905]]\n",
      "gradients: [[0.70814601]\n",
      " [0.05066295]]\n",
      "theta: [[4.12924466]\n",
      " [2.86724395]]\n",
      "gradients: [[0.09874898]\n",
      " [0.05531886]]\n",
      "theta: [[4.12978802]\n",
      " [2.86804106]]\n",
      "gradients: [[-0.54563698]\n",
      " [-0.80045292]]\n",
      "theta: [[4.12724713]\n",
      " [2.86390969]]\n",
      "gradients: [[2.5520645 ]\n",
      " [4.14954458]]\n",
      "theta: [[4.12440421]\n",
      " [2.86074384]]\n",
      "gradients: [[2.85600705]\n",
      " [3.18041775]]\n",
      "theta: [[4.12503435]\n",
      " [2.86177849]]\n",
      "gradients: [[-0.63316632]\n",
      " [-1.03961831]]\n",
      "theta: [[4.12434707]\n",
      " [2.860614  ]]\n",
      "gradients: [[0.69071658]\n",
      " [1.17031082]]\n",
      "theta: [[4.12390584]\n",
      " [2.8605438 ]]\n",
      "gradients: [[0.44352387]\n",
      " [0.07056297]]\n",
      "theta: [[4.12208902]\n",
      " [2.85839708]]\n",
      "gradients: [[1.82663233]\n",
      " [2.15831654]]\n",
      "theta: [[4.12204045]\n",
      " [2.85832992]]\n",
      "gradients: [[0.04883587]\n",
      " [0.06753593]]\n",
      "theta: [[4.12166347]\n",
      " [2.8578964 ]]\n",
      "gradients: [[0.37917282]\n",
      " [0.43602964]]\n",
      "theta: [[4.12437909]\n",
      " [2.86105757]]\n",
      "gradients: [[-2.73191816]\n",
      " [-3.18013166]]\n",
      "theta: [[4.12652283]\n",
      " [2.86408778]]\n",
      "gradients: [[-2.1570272 ]\n",
      " [-3.04900167]]\n",
      "theta: [[4.12730368]\n",
      " [2.86418283]]\n",
      "gradients: [[-0.78584878]\n",
      " [-0.09565809]]\n",
      "theta: [[4.13187773]\n",
      " [2.8724183 ]]\n",
      "gradients: [[-4.60424433]\n",
      " [-8.28982538]]\n",
      "theta: [[4.13193223]\n",
      " [2.8724683 ]]\n",
      "gradients: [[-0.05487176]\n",
      " [-0.05033341]]\n",
      "theta: [[4.13387042]\n",
      " [2.87603783]]\n",
      "gradients: [[-1.9517506 ]\n",
      " [-3.59452452]]\n",
      "theta: [[4.13244546]\n",
      " [2.87409142]]\n",
      "gradients: [[1.43521957]\n",
      " [1.9604232 ]]\n",
      "theta: [[4.13155453]\n",
      " [2.87329266]]\n",
      "gradients: [[0.8975203 ]\n",
      " [0.80467646]]\n",
      "theta: [[4.13222426]\n",
      " [2.87399941]]\n",
      "gradients: [[-0.67482392]\n",
      " [-0.71211989]]\n",
      "theta: [[4.13271653]\n",
      " [2.87467523]]\n",
      "gradients: [[-0.49610221]\n",
      " [-0.68108999]]\n",
      "theta: [[4.12988476]\n",
      " [2.87401438]]\n",
      "gradients: [[2.85441696]\n",
      " [0.66613358]]\n",
      "theta: [[4.13065515]\n",
      " [2.87410816]]\n",
      "gradients: [[-0.77670825]\n",
      " [-0.09454546]]\n",
      "theta: [[4.13296551]\n",
      " [2.87668075]]\n",
      "gradients: [[-2.32975975]\n",
      " [-2.59419964]]\n",
      "theta: [[4.13311414]\n",
      " [2.87697347]]\n",
      "gradients: [[-0.14991474]\n",
      " [-0.29524122]]\n",
      "theta: [[4.12999952]\n",
      " [2.87313044]]\n",
      "gradients: [[3.14202851]\n",
      " [3.87684958]]\n",
      "theta: [[4.13108739]\n",
      " [2.87370605]]\n",
      "gradients: [[-1.09766111]\n",
      " [-0.58079394]]\n",
      "theta: [[4.12923236]\n",
      " [2.87151418]]\n",
      "gradients: [[1.87210001]\n",
      " [2.21204034]]\n",
      "theta: [[4.13387887]\n",
      " [2.8801769 ]]\n",
      "gradients: [[-4.69018629]\n",
      " [-8.74415358]]\n",
      "theta: [[4.13514564]\n",
      " [2.88231998]]\n",
      "gradients: [[-1.27892724]\n",
      " [-2.16364994]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "t0, t1 = 5, 50\n",
    "def learning_schedule (t):\n",
    "    return t0 / (t + t1)\n",
    "theta = np.random.rand (2,1)\n",
    "for epoch in range (n_epochs):\n",
    "    for i in range(m):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi= x_b[random_index: random_index + 1]\n",
    "        yi= y[random_index: random_index +1]\n",
    "        print(\"theta:\", theta)\n",
    "        print(\"gradients:\", gradients)\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        eta = learning_schedule(epoch * m + i)\n",
    "        theta = theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "final-meeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.13234864],\n",
       "       [2.8799064 ]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "colonial-stable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(eta0=0.1, penalty=None)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(max_iter= 1000, tol= 1e-3, penalty= None, eta0= 0.1)\n",
    "sgd_reg.fit(x,y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "developmental-retreat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.1917504]), array([2.95500981]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.intercept_ , sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "sealed-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "x= 6* np.random.rand(m,1)- 3\n",
    "y = 0.5 * x**2 + x + 2 + np.random.rand(m,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "contrary-perspective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x,y,s=10)\n",
    "plt.xlabel('Predictor',fontsize=16)\n",
    "plt.ylabel('Target',fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "aboriginal-durham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57638749])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree= 2, include_bias= False)\n",
    "x_poly = poly_features.fit_transform(x)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "superb-discrimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57638749, 0.33222254])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_poly[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "strategic-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_poly, y)\n",
    "lin_reg.intercept_ , lin_reg.coef_\n",
    "poly_y_pred = lin_reg.predict(x_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "bright-construction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "orders = np.argsort(x.ravel())\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x,y,s= 10)\n",
    "plt.plot(x[orders],poly_y_pred[orders], 'r-')\n",
    "plt.plot()\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "static-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree= 25, include_bias= False)\n",
    "x_poly_300 = poly_features.fit_transform(x)\n",
    "lin_reg_300 = LinearRegression()\n",
    "lin_reg_300.fit(x_poly_300, y)\n",
    "poly_y_pred_300 = lin_reg_300.predict(x_poly_300)\n",
    "#lin_reg_300.intercept_ , lin_reg_300.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "isolated-observer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "orders_300 = np.argsort(x.ravel())\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x,y,s= 10)\n",
    "plt.plot(x[orders],poly_y_pred_300[orders], 'r-')\n",
    "plt.plot()\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "architectural-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.axis\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "def plot_learning_curves (model, x,y):\n",
    "    x_train, x_val , y_train, y_val = train_test_split(x,y,test_size= 0.2)\n",
    "    train_erros, val_erros = [], []\n",
    "    for m in range (1, len(x_train)):\n",
    "        model.fit(x_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(x_train[:m])\n",
    "        y_val_predict = model.predict(x_val)\n",
    "        train_erros.append(mean_squared_error(y_train[:m], y_train_predict))\n",
    "        val_erros.append(mean_squared_error(y_val,y_val_predict))\n",
    "    plt.xlim((0,80 ))\n",
    "    plt.ylim(0, 3.0)\n",
    "    plt.plot(np.sqrt(train_erros), \"r-+\", linewidth = 2, label = \"train\")\n",
    "    plt.plot( np.sqrt(val_erros), \"b-\", linewidth = 3, label =' val')\n",
    "    plt.grid(True)\n",
    "                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "general-pocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "plot_learning_curves(lin_reg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "extended-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "polynomial_regression = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree= 10, include_bias= False)),\n",
    "    (\"lin_reg\", LinearRegression()),\n",
    "])\n",
    "plot_learning_curves(polynomial_regression,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "available-postcard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, solver='cholesky')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge(alpha=1, solver= 'cholesky')\n",
    "ridge_reg.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "complimentary-language",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.57891443]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "australian-bennett",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.66545128]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "usual-employment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.55239445])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg = SGDRegressor(penalty= 'l2')\n",
    "sgd_reg.fit(x,y.ravel())\n",
    "sgd_reg.predict([[1.5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "chicken-monaco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.0213939])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg = Lasso(alpha = 0.1)\n",
    "lasso_reg.fit (x,y)\n",
    "lasso_reg.predict([[1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "celtic-spray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.53672333])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "elastic_reg = ElasticNet(alpha= 0.1, l1_ratio = 0.5)\n",
    "elastic_reg.fit(x,y)\n",
    "elastic_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "spiritual-restoration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/abdullah/Machinelearning/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1220: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_train, x_val , y_train, y_val = train_test_split(x,y,test_size= 0.2)\n",
    "poly_scaler = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree= 90, include_bias= False)),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "])\n",
    "x_train_poly_scaled =  poly_scaler.fit_transform(x_train)\n",
    "x_val_poly_scaled = poly_scaler.fit_transform(x_val)\n",
    "sgd_reg =  SGDRegressor(max_iter= 1, tol= np.infty, warm_start= True, penalty = None, \n",
    "                        learning_rate= \"constant\", eta0= 0.0005)\n",
    "minimum_val_error = float(\"inf\")\n",
    "best_epoch = None\n",
    "best_model = None\n",
    "for epoch in range (1000):\n",
    "     sgd_reg.fit(x_train_poly_scaled, y_train)\n",
    "     y_val_predict = sgd_reg.predict(x_val_poly_scaled)\n",
    "     val_error = mean_squared_error(y_val, y_val_predict)\n",
    "     if val_error < minimum_val_error:\n",
    "         minimum_val_error = val_error\n",
    "         best_epoch = epoch\n",
    "         best_model = clone(sgd_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "framed-clearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "handled-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(eta0=0.0005, learning_rate='constant', max_iter=1, penalty=None,\n",
       "             tol=inf, warm_start=True)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "caring-carroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.17896826])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "deluxe-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "list(iris.keys())\n",
    "x = iris['data'][:, 3:]\n",
    "y = (iris['target'] == 2).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "controlled-villa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "animal-compilation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f33aea3a250>]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x,y)\n",
    "x_new = np.linspace( 0, 3,1000).reshape(-1,1)\n",
    "y_proba = log_reg.predict_proba(x_new)\n",
    "plt.plot(x_new, y_proba[:,1], 'g-', label = \"Iris_Verginica\")\n",
    "plt.plot(x_new, y_proba[:,0], 'b--', label ='Not Iris-virginica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "banned-museum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict([[1.7], [1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "polish-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris['data'][: , (2,3)]\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "smoking-mathematics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, multi_class='multinomial')"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_reg = LogisticRegression(multi_class= \"multinomial\", solver = 'lbfgs', C = 10)\n",
    "softmax_reg.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "differential-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_reg.predict([[5,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "pregnant-citizen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.38014896e-07, 5.74929995e-02, 9.42506362e-01]])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_reg.predict_proba([[5,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-bidding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
